{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 20:35:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-31a483cf-4d30-4f19-a61e-36d08e9d3fb9--2001384727-driver-0-1, groupId=spark-kafka-source-31a483cf-4d30-4f19-a61e-36d08e9d3fb9--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 20:35:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0f361c7e-4cd5-4e48-8290-a06ff9a0332a--2042041463-driver-0-3, groupId=spark-kafka-source-0f361c7e-4cd5-4e48-8290-a06ff9a0332a--2042041463-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 20:35:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-31a483cf-4d30-4f19-a61e-36d08e9d3fb9--2001384727-driver-0-1, groupId=spark-kafka-source-31a483cf-4d30-4f19-a61e-36d08e9d3fb9--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 1369.\n",
      "23/06/22 20:35:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-0f361c7e-4cd5-4e48-8290-a06ff9a0332a--2042041463-driver-0-3, groupId=spark-kafka-source-0f361c7e-4cd5-4e48-8290-a06ff9a0332a--2042041463-driver-0] Resetting offset for partition ticketmaster-0 to offset 1369.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import findspark\n",
    "from datetime import datetime\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, udf, col, when\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType,FloatType, DoubleType\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nicburkett/.sdkman/candidates/spark/current\n"
     ]
    }
   ],
   "source": [
    "findspark.init()\n",
    "topic_name = 'ticketmaster'\n",
    "\n",
    "spark_path = findspark.find()\n",
    "print(spark_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials_location = '/Users/nicburkett/.google/credentials/google_credentials.json'\n",
    "\n",
    "# Spark COnfig\n",
    "conf = SparkConf() \\\n",
    "    .setMaster('local[*]') \\\n",
    "    .setAppName('TwitterSentimentAnalysis') \\\n",
    "    .set(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.2\") \\\n",
    "    .set(\"spark.jars\", \"gs://path/to/spark-bigquery-latest.jar,gs://path/to/google-cloud-bigquery-latest.jar,/path/to/local-jar-file.jar\") \\\n",
    "    .set(\"spark.hadoop.fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\") \\\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\") \\\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", credentials_location)\\\n",
    "    .set(\"spark.jars\", \"gcs-connector-hadoop3-2.2.5.jar\") \n",
    "\n",
    "\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "hadoop_conf = sc._jsc.hadoopConfiguration()\n",
    "\n",
    "hadoop_conf.set(\"fs.AbstractFileSystem.gs.impl\",  \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "hadoop_conf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "hadoop_conf.set(\"fs.gs.auth.service.account.json.keyfile\", credentials_location)\n",
    "hadoop_conf.set(\"fs.gs.auth.service.account.enable\", \"true\")\n",
    "\n",
    "# Spark Context\n",
    "# sc = spark.sparkContext\n",
    "# sc.setLogLevel('ERROR')\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .config(conf=sc.getConf()) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 20:57:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 20:57:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-8c615a1e-fabc-43c7-ba3c-87f1c674f1d4--2001384727-driver-0-40, groupId=spark-kafka-source-8c615a1e-fabc-43c7-ba3c-87f1c674f1d4--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 20:57:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-8c615a1e-fabc-43c7-ba3c-87f1c674f1d4--2001384727-driver-0-40, groupId=spark-kafka-source-8c615a1e-fabc-43c7-ba3c-87f1c674f1d4--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 1429.\n",
      "23/06/22 20:57:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 1429.\n",
      "23/06/22 20:57:40 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T01:57:40.001Z\",\n",
      "  \"batchId\" : 16,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 8,\n",
      "    \"triggerExecution\" : 10\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1429\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1429\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 0\n",
      "  }\n",
      "}\n",
      "23/06/22 20:57:40 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"20ca1a02-6b83-4a1b-ade0-557ef9d437ba\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T01:57:40.005Z\",\n",
      "  \"batchId\" : 101,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 5,\n",
      "    \"triggerExecution\" : 6\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1429\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1429\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@1cbdb2d1,com.google.cloud.bigquery.connector.common.BigQueryClient@4a3cdf57)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# schema = StructType([\n",
    "#     StructField(\"event_name\", StringType(), nullable=True),\n",
    "#     StructField(\"event_type\", StringType(), nullable=True),\n",
    "#     StructField(\"event_id\", StringType(), nullable=True),\n",
    "#     StructField(\"event_url\", StringType(), nullable=True),\n",
    "#     StructField(\"venue_name\", StringType(), nullable=True),\n",
    "#     StructField(\"venue_id\", StringType(), nullable=True),\n",
    "#     StructField(\"venue_zipcode\", IntegerType(), nullable=True),\n",
    "#     StructField(\"venues_timezone\", StringType(), nullable=True),\n",
    "#     StructField(\"venue_city\", StringType(), nullable=True),\n",
    "#     StructField(\"venue_state_full\", StringType(), nullable=True),\n",
    "#     StructField(\"venue_state_short\", StringType(), nullable=True),\n",
    "#     StructField(\"venue_country_name\", StringType(), nullable=True),\n",
    "#     StructField(\"venue_country_short\", StringType(), nullable=True),\n",
    "#     StructField(\"venue_address\", StringType(), nullable=True),\n",
    "#     StructField(\"venue_longitude\", DoubleType(), nullable=True),\n",
    "#     StructField(\"venue_latitude\", DoubleType(), nullable=True),\n",
    "#     StructField(\"attraction_name\", StringType(), nullable=True),\n",
    "#     StructField(\"attraction_type\", StringType(), nullable=True),\n",
    "#     StructField(\"attraction_id\", StringType(), nullable=True),\n",
    "#     StructField(\"attraction_url\", StringType(), nullable=True),\n",
    "#     StructField(\"attraction_segment_id\", StringType(), nullable=True),\n",
    "#     StructField(\"attraction_segment_name\", StringType(), nullable=True),\n",
    "#     StructField(\"attraction_genre_id\", StringType(), nullable=True),\n",
    "#     StructField(\"attraction_genre_name\", StringType(), nullable=True),\n",
    "#     StructField(\"attraction_subgenre_id\", StringType(), nullable=True),\n",
    "#     StructField(\"attraction_subgenre_name\", StringType(), nullable=True),\n",
    "#     StructField(\"event_start_date\", DateType(), nullable=True),\n",
    "#     StructField(\"ticket_status\", StringType(), nullable=True),\n",
    "#     StructField(\"event_start_time\", StringType(), nullable=True),\n",
    "#     StructField(\"currency\", StringType(), nullable=True),\n",
    "#     StructField(\"min_price\", FloatType(), nullable=True),\n",
    "#     StructField(\"max_price\", FloatType(), nullable=True)\n",
    "# ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"event_name\", StringType()),\n",
    "    StructField(\"event_type\", StringType()),\n",
    "    StructField(\"event_id\", StringType()),\n",
    "    StructField(\"event_url\", StringType()),\n",
    "    StructField(\"venue_name\", StringType()),\n",
    "    StructField(\"venue_id\", StringType()),\n",
    "    StructField(\"venue_zipcode\", StringType()),\n",
    "    StructField(\"venues_timezone\", StringType()),\n",
    "    StructField(\"venue_city\", StringType()),\n",
    "    StructField(\"venue_state_full\", StringType()),\n",
    "    StructField(\"venue_state_short\", StringType()),\n",
    "    StructField(\"venue_country_name\", StringType()),\n",
    "    StructField(\"venue_country_short\", StringType()),\n",
    "    StructField(\"venue_address\", StringType()),\n",
    "    StructField(\"venue_longitude\", StringType()),\n",
    "    StructField(\"venue_latitude\", StringType()),\n",
    "    StructField(\"attraction_name\", StringType()),\n",
    "    StructField(\"attraction_type\", StringType()),\n",
    "    StructField(\"attraction_id\", StringType()),\n",
    "    StructField(\"attraction_url\", StringType()),\n",
    "    StructField(\"attraction_segment_id\", StringType()),\n",
    "    StructField(\"attraction_segment_name\", StringType()),\n",
    "    StructField(\"attraction_genre_id\", StringType()),\n",
    "    StructField(\"attraction_genre_name\", StringType()),\n",
    "    StructField(\"attraction_subgenre_id\", StringType()),\n",
    "    StructField(\"attraction_subgenre_name\", StringType()),\n",
    "    StructField(\"event_start_date\", StringType()),\n",
    "    StructField(\"ticket_status\", StringType()),\n",
    "    StructField(\"event_start_time\", StringType()),\n",
    "    StructField(\"currency\", StringType()),\n",
    "    StructField(\"min_price\", StringType()),\n",
    "    StructField(\"max_price\", StringType())\n",
    "])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global-maxim-338114\n"
     ]
    }
   ],
   "source": [
    "\n",
    "PROJECT_ID = 'global-maxim-338114'\n",
    "BUCKET = \"kafka-spark-data\"\n",
    "\n",
    "dataset = 'global-maxim-338114.twitter_kafka_pyspark_test'\n",
    "table = 'twitter_kafka_pyspark_test'\n",
    "\n",
    "gcs_metadata_folder = \"gs://kafka-spark-data/spark-metadata\"\n",
    "gcs_data_folder = \"gs://kafka-spark-data/raw-spark-data\"\n",
    "print(PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK DATA TYPES \n",
    "## BATCH DATA PROCESSING \n",
    "\n",
    "df = spark \\\n",
    "  .read \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "  .option(\"subscribe\", topic_name) \\\n",
    "  .load()\\\n",
    "  .selectExpr(\"CAST(value AS STRING)\")\n",
    "\n",
    "\n",
    "# Apply deserialization or further processing if needed\n",
    "df1 = df.withColumn(\"parsed_data\", from_json(\"value\",))\n",
    "\n",
    "# Extract and convert the \"venue_zipcode\" as Integer\n",
    "df1 = df1.withColumn(\"venue_zipcode\", col(\"parsed_data.venue_zipcode\").cast(IntegerType()))\n",
    "# Extract and convert the coordinates as Double\n",
    "df1 = df1.withColumn(\"venue_longitude\", col(\"parsed_data.venue_longitude\").cast(DoubleType()))\n",
    "df1 = df1.withColumn(\"venue_latitude\", col(\"parsed_data.venue_latitude\").cast(DoubleType()))\n",
    "# Extract and Convert the event_start_date as Date \n",
    "df1 = df1.withColumn(\"event_start_date\", col(\"parsed_data.event_start_date\").cast(DateType()))\n",
    "# Extract and Convert the event_start_date as Date \n",
    "# df1 = df1.withColumn(\"event_start_time\", col(\"parsed_data.event_start_date\").cast(TimeType()))\n",
    "\n",
    "\n",
    "# Select the desired columns\n",
    "df2 = df1.select(\"parsed_data.*\")\n",
    "\n",
    "\n",
    "df2.printSchema()\n",
    "df2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- event_name: string (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- event_id: string (nullable = true)\n",
      " |-- event_url: string (nullable = true)\n",
      " |-- venue_name: string (nullable = true)\n",
      " |-- venue_id: string (nullable = true)\n",
      " |-- venue_zipcode: string (nullable = true)\n",
      " |-- venues_timezone: string (nullable = true)\n",
      " |-- venue_city: string (nullable = true)\n",
      " |-- venue_state_full: string (nullable = true)\n",
      " |-- venue_state_short: string (nullable = true)\n",
      " |-- venue_country_name: string (nullable = true)\n",
      " |-- venue_country_short: string (nullable = true)\n",
      " |-- venue_address: string (nullable = true)\n",
      " |-- venue_longitude: string (nullable = true)\n",
      " |-- venue_latitude: string (nullable = true)\n",
      " |-- attraction_name: string (nullable = true)\n",
      " |-- attraction_type: string (nullable = true)\n",
      " |-- attraction_id: string (nullable = true)\n",
      " |-- attraction_url: string (nullable = true)\n",
      " |-- attraction_segment_id: string (nullable = true)\n",
      " |-- attraction_segment_name: string (nullable = true)\n",
      " |-- attraction_genre_id: string (nullable = true)\n",
      " |-- attraction_genre_name: string (nullable = true)\n",
      " |-- attraction_subgenre_id: string (nullable = true)\n",
      " |-- attraction_subgenre_name: string (nullable = true)\n",
      " |-- event_start_date: string (nullable = true)\n",
      " |-- ticket_status: string (nullable = true)\n",
      " |-- event_start_time: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- min_price: string (nullable = true)\n",
      " |-- max_price: string (nullable = true)\n",
      "\n",
      "23/06/22 21:38:53 INFO GoogleCloudStorageImpl: Ignoring exception of type GoogleJsonResponseException; verified object already exists with desired state.\n",
      "23/06/22 21:38:53 INFO ResolveWriteToStream: Checkpoint root gs://kafka-spark-data/spark-metadata resolved to gs://kafka-spark-data/spark-metadata.\n",
      "23/06/22 21:38:53 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "23/06/22 21:38:54 WARN StreamingQueryManager: Stopping existing streaming query [id=f2bc1daa-c744-4e59-9ab7-7162c43fc781, runId=207a7e1a-2b20-4285-9494-8e4d9af1c908], as a new run is being started.\n",
      "23/06/22 21:38:54 INFO DAGScheduler: Asked to cancel job group 207a7e1a-2b20-4285-9494-8e4d9af1c908\n",
      "23/06/22 21:38:54 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-b5fe6030-2e60-4cbd-a0de-9ec21fbc0184--2001384727-driver-0-51, groupId=spark-kafka-source-b5fe6030-2e60-4cbd-a0de-9ec21fbc0184--2001384727-driver-0] Revoke previously assigned partitions ticketmaster-0\n",
      "23/06/22 21:38:54 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-b5fe6030-2e60-4cbd-a0de-9ec21fbc0184--2001384727-driver-0-51, groupId=spark-kafka-source-b5fe6030-2e60-4cbd-a0de-9ec21fbc0184--2001384727-driver-0] Member consumer-spark-kafka-source-b5fe6030-2e60-4cbd-a0de-9ec21fbc0184--2001384727-driver-0-51-05aa0e25-25f8-4887-9a10-e3b3d0428a79 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147483646 rack: null) due to the consumer is being closed\n",
      "23/06/22 21:38:54 INFO DAGScheduler: Asked to cancel job group 207a7e1a-2b20-4285-9494-8e4d9af1c908\n",
      "23/06/22 21:38:54 INFO MicroBatchExecution: Query [id = f2bc1daa-c744-4e59-9ab7-7162c43fc781, runId = 207a7e1a-2b20-4285-9494-8e4d9af1c908] was stopped\n",
      "23/06/22 21:38:54 INFO MicroBatchExecution: Starting [id = f2bc1daa-c744-4e59-9ab7-7162c43fc781, runId = 74802c4c-e991-4c01-8644-e6c0d1d872fd]. Use gs://kafka-spark-data/spark-metadata to store the query checkpoint.\n",
      "23/06/22 21:38:54 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@6f0805ca] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@61cfe783]\n",
      "23/06/22 21:38:55 INFO MicroBatchExecution: Resuming at batch 182 with committed offsets {KafkaV2[Subscribe[ticketmaster]]: {\"ticketmaster\":{\"0\":1646}}} and available offsets {KafkaV2[Subscribe[ticketmaster]]: {\"ticketmaster\":{\"0\":1646}}}\n",
      "23/06/22 21:38:55 INFO MicroBatchExecution: Stream started from {KafkaV2[Subscribe[ticketmaster]]: {\"ticketmaster\":{\"0\":1646}}}\n",
      "23/06/22 21:38:55 INFO ConsumerConfig: ConsumerConfig values: \n",
      "\tallow.auto.create.topics = true\n",
      "\tauto.commit.interval.ms = 5000\n",
      "\tauto.offset.reset = earliest\n",
      "\tbootstrap.servers = [localhost:9092]\n",
      "\tcheck.crcs = true\n",
      "\tclient.dns.lookup = use_all_dns_ips\n",
      "\tclient.id = consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53\n",
      "\tclient.rack = \n",
      "\tconnections.max.idle.ms = 540000\n",
      "\tdefault.api.timeout.ms = 60000\n",
      "\tenable.auto.commit = false\n",
      "\texclude.internal.topics = true\n",
      "\tfetch.max.bytes = 52428800\n",
      "\tfetch.max.wait.ms = 500\n",
      "\tfetch.min.bytes = 1\n",
      "\tgroup.id = spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0\n",
      "\tgroup.instance.id = null\n",
      "\theartbeat.interval.ms = 3000\n",
      "\tinterceptor.classes = []\n",
      "\tinternal.leave.group.on.close = true\n",
      "\tinternal.throw.on.fetch.stable.offset.unsupported = false\n",
      "\tisolation.level = read_uncommitted\n",
      "\tkey.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer\n",
      "\tmax.partition.fetch.bytes = 1048576\n",
      "\tmax.poll.interval.ms = 300000\n",
      "\tmax.poll.records = 1\n",
      "\tmetadata.max.age.ms = 300000\n",
      "\tmetric.reporters = []\n",
      "\tmetrics.num.samples = 2\n",
      "\tmetrics.recording.level = INFO\n",
      "\tmetrics.sample.window.ms = 30000\n",
      "\tpartition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]\n",
      "\treceive.buffer.bytes = 65536\n",
      "\treconnect.backoff.max.ms = 1000\n",
      "\treconnect.backoff.ms = 50\n",
      "\trequest.timeout.ms = 30000\n",
      "\tretry.backoff.ms = 100\n",
      "\tsasl.client.callback.handler.class = null\n",
      "\tsasl.jaas.config = null\n",
      "\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n",
      "\tsasl.kerberos.min.time.before.relogin = 60000\n",
      "\tsasl.kerberos.service.name = null\n",
      "\tsasl.kerberos.ticket.renew.jitter = 0.05\n",
      "\tsasl.kerberos.ticket.renew.window.factor = 0.8\n",
      "\tsasl.login.callback.handler.class = null\n",
      "\tsasl.login.class = null\n",
      "\tsasl.login.refresh.buffer.seconds = 300\n",
      "\tsasl.login.refresh.min.period.seconds = 60\n",
      "\tsasl.login.refresh.window.factor = 0.8\n",
      "\tsasl.login.refresh.window.jitter = 0.05\n",
      "\tsasl.mechanism = GSSAPI\n",
      "\tsecurity.protocol = PLAINTEXT\n",
      "\tsecurity.providers = null\n",
      "\tsend.buffer.bytes = 131072\n",
      "\tsession.timeout.ms = 10000\n",
      "\tssl.cipher.suites = null\n",
      "\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n",
      "\tssl.endpoint.identification.algorithm = https\n",
      "\tssl.engine.factory.class = null\n",
      "\tssl.key.password = null\n",
      "\tssl.keymanager.algorithm = SunX509\n",
      "\tssl.keystore.location = null\n",
      "\tssl.keystore.password = null\n",
      "\tssl.keystore.type = JKS\n",
      "\tssl.protocol = TLSv1.3\n",
      "\tssl.provider = null\n",
      "\tssl.secure.random.implementation = null\n",
      "\tssl.trustmanager.algorithm = PKIX\n",
      "\tssl.truststore.location = null\n",
      "\tssl.truststore.password = null\n",
      "\tssl.truststore.type = JKS\n",
      "\tvalue.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer\n",
      "\n",
      "23/06/22 21:38:55 INFO AppInfoParser: Kafka version: 2.6.0\n",
      "23/06/22 21:38:55 INFO AppInfoParser: Kafka commitId: 62abe01bee039651\n",
      "23/06/22 21:38:55 INFO AppInfoParser: Kafka startTimeMs: 1687487935442\n",
      "23/06/22 21:38:55 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Subscribed to topic(s): ticketmaster\n",
      "23/06/22 21:38:55 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Cluster ID: kJYfpPSDQYKOEac6knVYNg\n",
      "23/06/22 21:38:55 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Discovered group coordinator 127.0.0.1:9092 (id: 2147483646 rack: null)\n",
      "23/06/22 21:38:55 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] (Re-)joining group\n",
      "23/06/22 21:38:55 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group.\n",
      "23/06/22 21:38:55 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] (Re-)joining group\n",
      "23/06/22 21:38:58 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Finished assignment for group at generation 1: {consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53-06f04b31-f7c7-476b-a83e-35a936cb4ac4=Assignment(partitions=[ticketmaster-0])}\n",
      "23/06/22 21:38:58 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Successfully joined group with generation 1\n",
      "23/06/22 21:38:58 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Notifying assignor about the new Assignment(partitions=[ticketmaster-0])\n",
      "23/06/22 21:38:58 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Adding newly assigned partitions: ticketmaster-0\n",
      "23/06/22 21:38:58 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Found no committed offset for partition ticketmaster-0\n",
      "23/06/22 21:38:58 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:38:58 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:38:58 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 1672.\n",
      "23/06/22 21:38:58 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/182 using temp file gs://kafka-spark-data/spark-metadata/offsets/.182.617b305b-fabe-475c-8739-8bcdf5aaf000.tmp\n",
      "23/06/22 21:38:59 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.182.617b305b-fabe-475c-8739-8bcdf5aaf000.tmp to gs://kafka-spark-data/spark-metadata/offsets/182\n",
      "23/06/22 21:38:59 INFO MicroBatchExecution: Committed offsets for batch 182. Metadata OffsetSeqMetadata(0,1687487938483,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:39:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 1678.\n",
      "23/06/22 21:39:00 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/104 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.104.eb80c424-502d-455e-b105-2f479a547e8d.tmp\n",
      "23/06/22 21:39:00 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.104.eb80c424-502d-455e-b105-2f479a547e8d.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/104\n",
      "23/06/22 21:39:00 INFO MicroBatchExecution: Committed offsets for batch 104. Metadata OffsetSeqMetadata(0,1687487940028,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:39:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:00 INFO WriteToDataSourceV2Exec: Start processing data source write support: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@480f534b. The input RDD has 1 partitions.\n",
      "23/06/22 21:39:00 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:39:00 INFO DAGScheduler: Got job 220 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:39:00 INFO DAGScheduler: Final stage: ResultStage 221 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:39:00 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:39:00 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:39:00 INFO DAGScheduler: Submitting ResultStage 221 (MapPartitionsRDD[1165] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:39:00 INFO MemoryStore: Block broadcast_220 stored as values in memory (estimated size 23.0 KiB, free 434.4 MiB)\n",
      "23/06/22 21:39:00 INFO MemoryStore: Block broadcast_220_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 434.4 MiB)\n",
      "23/06/22 21:39:00 INFO BlockManagerInfo: Added broadcast_220_piece0 in memory on 192.168.4.24:51040 (size: 9.9 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:39:00 INFO SparkContext: Created broadcast 220 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:39:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 221 (MapPartitionsRDD[1165] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:39:00 INFO TaskSchedulerImpl: Adding task set 221.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:39:00 INFO TaskSetManager: Starting task 0.0 in stage 221.0 (TID 220) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:39:00 INFO Executor: Running task 0.0 in stage 221.0 (TID 220)\n",
      "23/06/22 21:39:00 INFO ConsumerConfig: ConsumerConfig values: \n",
      "\tallow.auto.create.topics = true\n",
      "\tauto.commit.interval.ms = 5000\n",
      "\tauto.offset.reset = none\n",
      "\tbootstrap.servers = [localhost:9092]\n",
      "\tcheck.crcs = true\n",
      "\tclient.dns.lookup = use_all_dns_ips\n",
      "\tclient.id = consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54\n",
      "\tclient.rack = \n",
      "\tconnections.max.idle.ms = 540000\n",
      "\tdefault.api.timeout.ms = 60000\n",
      "\tenable.auto.commit = false\n",
      "\texclude.internal.topics = true\n",
      "\tfetch.max.bytes = 52428800\n",
      "\tfetch.max.wait.ms = 500\n",
      "\tfetch.min.bytes = 1\n",
      "\tgroup.id = spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor\n",
      "\tgroup.instance.id = null\n",
      "\theartbeat.interval.ms = 3000\n",
      "\tinterceptor.classes = []\n",
      "\tinternal.leave.group.on.close = true\n",
      "\tinternal.throw.on.fetch.stable.offset.unsupported = false\n",
      "\tisolation.level = read_uncommitted\n",
      "\tkey.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer\n",
      "\tmax.partition.fetch.bytes = 1048576\n",
      "\tmax.poll.interval.ms = 300000\n",
      "\tmax.poll.records = 500\n",
      "\tmetadata.max.age.ms = 300000\n",
      "\tmetric.reporters = []\n",
      "\tmetrics.num.samples = 2\n",
      "\tmetrics.recording.level = INFO\n",
      "\tmetrics.sample.window.ms = 30000\n",
      "\tpartition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]\n",
      "\treceive.buffer.bytes = 65536\n",
      "\treconnect.backoff.max.ms = 1000\n",
      "\treconnect.backoff.ms = 50\n",
      "\trequest.timeout.ms = 30000\n",
      "\tretry.backoff.ms = 100\n",
      "\tsasl.client.callback.handler.class = null\n",
      "\tsasl.jaas.config = null\n",
      "\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n",
      "\tsasl.kerberos.min.time.before.relogin = 60000\n",
      "\tsasl.kerberos.service.name = null\n",
      "\tsasl.kerberos.ticket.renew.jitter = 0.05\n",
      "\tsasl.kerberos.ticket.renew.window.factor = 0.8\n",
      "\tsasl.login.callback.handler.class = null\n",
      "\tsasl.login.class = null\n",
      "\tsasl.login.refresh.buffer.seconds = 300\n",
      "\tsasl.login.refresh.min.period.seconds = 60\n",
      "\tsasl.login.refresh.window.factor = 0.8\n",
      "\tsasl.login.refresh.window.jitter = 0.05\n",
      "\tsasl.mechanism = GSSAPI\n",
      "\tsecurity.protocol = PLAINTEXT\n",
      "\tsecurity.providers = null\n",
      "\tsend.buffer.bytes = 131072\n",
      "\tsession.timeout.ms = 10000\n",
      "\tssl.cipher.suites = null\n",
      "\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n",
      "\tssl.endpoint.identification.algorithm = https\n",
      "\tssl.engine.factory.class = null\n",
      "\tssl.key.password = null\n",
      "\tssl.keymanager.algorithm = SunX509\n",
      "\tssl.keystore.location = null\n",
      "\tssl.keystore.password = null\n",
      "\tssl.keystore.type = JKS\n",
      "\tssl.protocol = TLSv1.3\n",
      "\tssl.provider = null\n",
      "\tssl.secure.random.implementation = null\n",
      "\tssl.trustmanager.algorithm = PKIX\n",
      "\tssl.truststore.location = null\n",
      "\tssl.truststore.password = null\n",
      "\tssl.truststore.type = JKS\n",
      "\tvalue.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer\n",
      "\n",
      "23/06/22 21:39:00 INFO AppInfoParser: Kafka version: 2.6.0\n",
      "23/06/22 21:39:00 INFO AppInfoParser: Kafka commitId: 62abe01bee039651\n",
      "23/06/22 21:39:00 INFO AppInfoParser: Kafka startTimeMs: 1687487940186\n",
      "23/06/22 21:39:00 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Subscribed to partition(s): ticketmaster-0\n",
      "23/06/22 21:39:00 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 1646 for partition ticketmaster-0\n",
      "23/06/22 21:39:00 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Cluster ID: kJYfpPSDQYKOEac6knVYNg\n",
      "23/06/22 21:39:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:39:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 1679.\n",
      "23/06/22 21:39:00 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 220, attempt 0, stage 221.0)\n",
      "23/06/22 21:39:00 INFO DataWritingSparkTask: Committed partition 0 (task 220, attempt 0, stage 221.0)\n",
      "23/06/22 21:39:00 INFO Executor: Finished task 0.0 in stage 221.0 (TID 220). 29290 bytes result sent to driver\n",
      "23/06/22 21:39:00 INFO TaskSetManager: Finished task 0.0 in stage 221.0 (TID 220) in 44 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:39:00 INFO TaskSchedulerImpl: Removed TaskSet 221.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:39:00 INFO DAGScheduler: ResultStage 221 (start at NativeMethodAccessorImpl.java:0) finished in 0.061 s\n",
      "23/06/22 21:39:00 INFO DAGScheduler: Job 220 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:39:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 221: Stage finished\n",
      "23/06/22 21:39:00 INFO DAGScheduler: Job 220 finished: start at NativeMethodAccessorImpl.java:0, took 0.062195 s\n",
      "23/06/22 21:39:00 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@480f534b is committing.\n",
      "-------------------------------------------\n",
      "Batch: 104\n",
      "-------------------------------------------\n",
      "+--------------------+----------+-------------+--------------------+------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+-------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|          event_name|event_type|     event_id|           event_url|        venue_name|    venue_id|venue_zipcode|venues_timezone|venue_city|venue_state_full|venue_state_short|  venue_country_name|venue_country_short|      venue_address|venue_longitude|venue_latitude|     attraction_name|attraction_type|attraction_id|      attraction_url|attraction_segment_id|attraction_segment_name|attraction_genre_id|attraction_genre_name|attraction_subgenre_id|attraction_subgenre_name|event_start_date|ticket_status|event_start_time|currency|min_price|max_price|\n",
      "+--------------------+----------+-------------+--------------------+------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+-------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|BEYONCÉ - RENAISS...|  standard|G5dIZ9NX30Scs|https://www.ticke...|       NRG Stadium|KovZpZAEdFeA|        77054|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|       One NRG Park|     -95.410875|     29.684885|             Beyoncé|     attraction|  K8vZ9175rX7|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAee|                  R&B|   KZazBEonSMnZfZ7vkIt|                     R&B|      2023-09-23|       onsale|        19:00:00|     USD|     50.5|    595.0|\n",
      "|BEYONCÉ - RENAISS...|  standard|G5dIZ9015E3iq|https://www.ticke...|       NRG Stadium|KovZpZAEdFeA|        77054|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|       One NRG Park|     -95.410875|     29.684885|             Beyoncé|     attraction|  K8vZ9175rX7|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAee|                  R&B|   KZazBEonSMnZfZ7vkIt|                     R&B|      2023-09-24|       onsale|        19:00:00|     USD|     50.5|    595.0|\n",
      "|P!NK: Summer Carn...|  standard|G5dIZ9p9z5bkM|https://www.ticke...|  Minute Maid Park|KovZpZAJJAtA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|       501 Crawford|     -95.356607|        29.757|                P!NK|     attraction|  K8vZ9171Jo7|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-09-27|       onsale|        18:30:00|     USD|    39.95|   349.95|\n",
      "|Houston Texans vs...|  standard|G5dIZ9twBtfLi|https://www.ticke...|       NRG Stadium|KovZpZAEdFeA|        77054|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|       One NRG Park|     -95.410875|     29.684885|      Houston Texans|     attraction|  K8vZ91756Kf|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdE|             Football|   KZazBEonSMnZfZ7vFE1|                     NFL|      2023-10-01|       onsale|        12:00:00|     USD|    175.0|    825.0|\n",
      "|Houston Texans vs...|  standard|G5dIZ9twBIfLn|https://www.ticke...|       NRG Stadium|KovZpZAEdFeA|        77054|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|       One NRG Park|     -95.410875|     29.684885|      Houston Texans|     attraction|  K8vZ91756Kf|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdE|             Football|   KZazBEonSMnZfZ7vFE1|                     NFL|      2023-10-15|       onsale|        12:00:00|     USD|     85.0|    565.0|\n",
      "|Houston Texans vs...|  standard|G5dIZ9twBxfr-|https://www.ticke...|       NRG Stadium|KovZpZAEdFeA|        77054|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|       One NRG Park|     -95.410875|     29.684885|      Houston Texans|     attraction|  K8vZ91756Kf|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdE|             Football|   KZazBEonSMnZfZ7vFE1|                     NFL|      2023-09-17|       onsale|        12:00:00|     USD|     65.0|    445.0|\n",
      "|Houston Texans v ...|  standard|G5dIZ9twBnfLV|https://www.ticke...|       NRG Stadium|KovZpZAEdFeA|        77054|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|       One NRG Park|     -95.410875|     29.684885|      Houston Texans|     attraction|  K8vZ91756Kf|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdE|             Football|   KZazBEonSMnZfZ7vFE1|                     NFL|      2023-08-19|       onsale|        15:00:00|     USD|     60.0|    380.0|\n",
      "|Houston Texans vs...|  standard|G5dIZ9twBEfLh|https://www.ticke...|       NRG Stadium|KovZpZAEdFeA|        77054|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|       One NRG Park|     -95.410875|     29.684885|      Houston Texans|     attraction|  K8vZ91756Kf|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdE|             Football|   KZazBEonSMnZfZ7vFE1|                     NFL|      2023-12-03|       onsale|        15:00:00|     USD|     75.0|    500.0|\n",
      "|Houston Astros vs...|     \"NaN\"|Z7r9jZ1AdpZOe|https://www.ticke...|  Minute Maid Park|  Z6r9jZkeke|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|501 Crawford Street|     -95.362999|     29.759399|      Houston Astros|     attraction|  K8vZ91718zV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdv|             Baseball|   KZazBEonSMnZfZ7vF1n|                     MLB|      2023-09-01|       onsale|        19:10:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Astros vs...|     \"NaN\"|Z7r9jZ1AdpZr7|https://www.ticke...|  Minute Maid Park|  Z6r9jZkeke|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|501 Crawford Street|     -95.362999|     29.759399|      Houston Astros|     attraction|  K8vZ91718zV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdv|             Baseball|   KZazBEonSMnZfZ7vF1n|                     MLB|      2023-09-02|       onsale|        18:10:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Texans vs...|  standard|G5dIZ9twBlfLM|https://www.ticke...|       NRG Stadium|KovZpZAEdFeA|        77054|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|       One NRG Park|     -95.410875|     29.684885|      Houston Texans|     attraction|  K8vZ91756Kf|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdE|             Football|   KZazBEonSMnZfZ7vFE1|                     NFL|      2023-11-05|       onsale|        12:00:00|     USD|     60.0|    395.0|\n",
      "|Houston Texans vs...|  standard|G5dIZ9twBJ0L2|https://www.ticke...|       NRG Stadium|KovZpZAEdFeA|        77054|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|       One NRG Park|     -95.410875|     29.684885|      Houston Texans|     attraction|  K8vZ91756Kf|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdE|             Football|   KZazBEonSMnZfZ7vFE1|                     NFL|      2023-12-24|       onsale|        12:00:00|     USD|     60.0|    410.0|\n",
      "|Houston Texans vs...|  standard|G5dIZ9twBPfL1|https://www.ticke...|       NRG Stadium|KovZpZAEdFeA|        77054|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|       One NRG Park|     -95.410875|     29.684885|      Houston Texans|     attraction|  K8vZ91756Kf|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdE|             Football|   KZazBEonSMnZfZ7vFE1|                     NFL|      2023-11-19|       onsale|        12:00:00|     USD|     65.0|    445.0|\n",
      "|Houston Texans vs...|  standard|G5dIZ9twBN0rg|https://www.ticke...|       NRG Stadium|KovZpZAEdFeA|        77054|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|       One NRG Park|     -95.410875|     29.684885|      Houston Texans|     attraction|  K8vZ91756Kf|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdE|             Football|   KZazBEonSMnZfZ7vFE1|                     NFL|      2023-11-26|       onsale|        12:00:00|     USD|     60.0|    380.0|\n",
      "|Houston Texans vs...|  standard|G5dIZ9twB00rX|https://www.ticke...|       NRG Stadium|KovZpZAEdFeA|        77054|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|       One NRG Park|     -95.410875|     29.684885|      Houston Texans|     attraction|  K8vZ91756Kf|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdE|             Football|   KZazBEonSMnZfZ7vFE1|                     NFL|      2023-12-31|       onsale|        12:00:00|     USD|     60.0|    410.0|\n",
      "|Houston Astros vs...|     \"NaN\"|Z7r9jZ1AdpZrK|https://www.ticke...|  Minute Maid Park|  Z6r9jZkeke|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|501 Crawford Street|     -95.362999|     29.759399|      Houston Astros|     attraction|  K8vZ91718zV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdv|             Baseball|   KZazBEonSMnZfZ7vF1n|                     MLB|      2023-09-03|       onsale|        13:10:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Cougars F...|     \"NaN\"|Z7r9jZ1AdqwaP|https://www.ticke...|     TDECU Stadium|  ZFr9jZddvv|        77004|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 3874 Holman Street|     -95.363197|       29.7248|University of Hou...|     attraction|  K8vZ9171MWf|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdE|             Football|   KZazBEonSMnZfZ7vFE6|                 College|      2023-10-21|       onsale|           \"NaN\"|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Concacaf Gold Cup...|  standard|G5dIZ9IwAf-WJ|https://www.ticke...|       NRG Stadium|KovZpZAEdFeA|        77054|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|       One NRG Park|     -95.410875|     29.684885|   CONCACAF Gold Cup|     attraction|  K8vZ9175bU7|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vA7E|               Soccer|   KZazBEonSMnZfZ7vFtt|                  Soccer|      2023-06-25|       onsale|        17:00:00|     USD|     55.0|    210.0|\n",
      "|Morgan Wallen: On...|  standard|G5dIZ99DsbAA5|https://www.ticke...|  Minute Maid Park|KovZpZAJJAtA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|       501 Crawford|     -95.356607|        29.757|       Morgan Wallen|     attraction|  K8vZ9174qlV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv6|              Country|   KZazBEonSMnZfZ7vAFa|                 Country|      2023-11-18|  rescheduled|        17:30:00|     USD|    69.75|   349.75|\n",
      "|Drake: It's All A...|     \"NaN\"|Z7r9jZ1AdO_fw|https://www.ticke...|Toyota Center - TX|  ZFr9jZ7v7v|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|       1510 Polk St|     -95.362999|     29.759399|               Drake|     attraction|  K8vZ917Gp47|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkdA|                   Urban|      2023-09-17|  rescheduled|        19:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "+--------------------+----------+-------------+--------------------+------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+-------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "23/06/22 21:39:00 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@480f534b committed.\n",
      "23/06/22 21:39:00 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/104 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.104.4bef6491-9d3c-4228-88d2-70454aa11123.tmp\n",
      "23/06/22 21:39:00 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.104.4bef6491-9d3c-4228-88d2-70454aa11123.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/104\n",
      "23/06/22 21:39:00 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:39:00.001Z\",\n",
      "  \"batchId\" : 104,\n",
      "  \"numInputRows\" : 32,\n",
      "  \"inputRowsPerSecond\" : 3.200640128025605,\n",
      "  \"processedRowsPerSecond\" : 101.91082802547771,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 82,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 27,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 314,\n",
      "    \"walCommit\" : 120\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1646\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1678\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 32,\n",
      "    \"inputRowsPerSecond\" : 3.200640128025605,\n",
      "    \"processedRowsPerSecond\" : 101.91082802547771\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 32\n",
      "  }\n",
      "}\n",
      "23/06/22 21:39:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:01 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:39:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:39:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:39:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:39:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:39:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:39:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:39:01 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:39:01 INFO DAGScheduler: Got job 221 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:39:01 INFO DAGScheduler: Final stage: ResultStage 222 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:39:01 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:39:01 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:39:01 INFO DAGScheduler: Submitting ResultStage 222 (MapPartitionsRDD[1172] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:39:01 INFO MemoryStore: Block broadcast_221 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/22 21:39:01 INFO MemoryStore: Block broadcast_221_piece0 stored as bytes in memory (estimated size 94.8 KiB, free 434.0 MiB)\n",
      "23/06/22 21:39:01 INFO BlockManagerInfo: Added broadcast_221_piece0 in memory on 192.168.4.24:51040 (size: 94.8 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:39:01 INFO SparkContext: Created broadcast 221 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:39:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 222 (MapPartitionsRDD[1172] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:39:01 INFO TaskSchedulerImpl: Adding task set 222.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:39:01 INFO TaskSetManager: Starting task 0.0 in stage 222.0 (TID 221) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:39:01 INFO Executor: Running task 0.0 in stage 222.0 (TID 221)\n",
      "23/06/22 21:39:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:39:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:39:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:39:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:39:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:39:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:39:01 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:39:01 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:39:01 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/22 21:39:01 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/22 21:39:01 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/22 21:39:01 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/22 21:39:01 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/22 21:39:02 INFO ConsumerConfig: ConsumerConfig values: \n",
      "\tallow.auto.create.topics = true\n",
      "\tauto.commit.interval.ms = 5000\n",
      "\tauto.offset.reset = none\n",
      "\tbootstrap.servers = [localhost:9092]\n",
      "\tcheck.crcs = true\n",
      "\tclient.dns.lookup = use_all_dns_ips\n",
      "\tclient.id = consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55\n",
      "\tclient.rack = \n",
      "\tconnections.max.idle.ms = 540000\n",
      "\tdefault.api.timeout.ms = 60000\n",
      "\tenable.auto.commit = false\n",
      "\texclude.internal.topics = true\n",
      "\tfetch.max.bytes = 52428800\n",
      "\tfetch.max.wait.ms = 500\n",
      "\tfetch.min.bytes = 1\n",
      "\tgroup.id = spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor\n",
      "\tgroup.instance.id = null\n",
      "\theartbeat.interval.ms = 3000\n",
      "\tinterceptor.classes = []\n",
      "\tinternal.leave.group.on.close = true\n",
      "\tinternal.throw.on.fetch.stable.offset.unsupported = false\n",
      "\tisolation.level = read_uncommitted\n",
      "\tkey.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer\n",
      "\tmax.partition.fetch.bytes = 1048576\n",
      "\tmax.poll.interval.ms = 300000\n",
      "\tmax.poll.records = 500\n",
      "\tmetadata.max.age.ms = 300000\n",
      "\tmetric.reporters = []\n",
      "\tmetrics.num.samples = 2\n",
      "\tmetrics.recording.level = INFO\n",
      "\tmetrics.sample.window.ms = 30000\n",
      "\tpartition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]\n",
      "\treceive.buffer.bytes = 65536\n",
      "\treconnect.backoff.max.ms = 1000\n",
      "\treconnect.backoff.ms = 50\n",
      "\trequest.timeout.ms = 30000\n",
      "\tretry.backoff.ms = 100\n",
      "\tsasl.client.callback.handler.class = null\n",
      "\tsasl.jaas.config = null\n",
      "\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n",
      "\tsasl.kerberos.min.time.before.relogin = 60000\n",
      "\tsasl.kerberos.service.name = null\n",
      "\tsasl.kerberos.ticket.renew.jitter = 0.05\n",
      "\tsasl.kerberos.ticket.renew.window.factor = 0.8\n",
      "\tsasl.login.callback.handler.class = null\n",
      "\tsasl.login.class = null\n",
      "\tsasl.login.refresh.buffer.seconds = 300\n",
      "\tsasl.login.refresh.min.period.seconds = 60\n",
      "\tsasl.login.refresh.window.factor = 0.8\n",
      "\tsasl.login.refresh.window.jitter = 0.05\n",
      "\tsasl.mechanism = GSSAPI\n",
      "\tsecurity.protocol = PLAINTEXT\n",
      "\tsecurity.providers = null\n",
      "\tsend.buffer.bytes = 131072\n",
      "\tsession.timeout.ms = 10000\n",
      "\tssl.cipher.suites = null\n",
      "\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n",
      "\tssl.endpoint.identification.algorithm = https\n",
      "\tssl.engine.factory.class = null\n",
      "\tssl.key.password = null\n",
      "\tssl.keymanager.algorithm = SunX509\n",
      "\tssl.keystore.location = null\n",
      "\tssl.keystore.password = null\n",
      "\tssl.keystore.type = JKS\n",
      "\tssl.protocol = TLSv1.3\n",
      "\tssl.provider = null\n",
      "\tssl.secure.random.implementation = null\n",
      "\tssl.trustmanager.algorithm = PKIX\n",
      "\tssl.truststore.location = null\n",
      "\tssl.truststore.password = null\n",
      "\tssl.truststore.type = JKS\n",
      "\tvalue.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer\n",
      "\n",
      "23/06/22 21:39:02 INFO AppInfoParser: Kafka version: 2.6.0\n",
      "23/06/22 21:39:02 INFO AppInfoParser: Kafka commitId: 62abe01bee039651\n",
      "23/06/22 21:39:02 INFO AppInfoParser: Kafka startTimeMs: 1687487942110\n",
      "23/06/22 21:39:02 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Subscribed to partition(s): ticketmaster-0\n",
      "23/06/22 21:39:02 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 1646 for partition ticketmaster-0\n",
      "23/06/22 21:39:02 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Cluster ID: kJYfpPSDQYKOEac6knVYNg\n",
      "23/06/22 21:39:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:39:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 1687.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 222:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:39:03 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-1c296931-c548-4a86-ac0b-a9c16ec7b8fa/_temporary/0/_temporary/' directory.\n",
      "23/06/22 21:39:03 INFO FileOutputCommitter: Saved output of task 'attempt_202306222139018453926043173608051_0222_m_000000_221' to gs://kafka-spark-data/.spark-bigquery-local-1687482506437-1c296931-c548-4a86-ac0b-a9c16ec7b8fa/_temporary/0/task_202306222139018453926043173608051_0222_m_000000\n",
      "23/06/22 21:39:03 INFO SparkHadoopMapRedUtil: attempt_202306222139018453926043173608051_0222_m_000000_221: Committed. Elapsed time: 918 ms.\n",
      "23/06/22 21:39:03 INFO Executor: Finished task 0.0 in stage 222.0 (TID 221). 2579 bytes result sent to driver\n",
      "23/06/22 21:39:03 INFO TaskSetManager: Finished task 0.0 in stage 222.0 (TID 221) in 1701 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:39:03 INFO TaskSchedulerImpl: Removed TaskSet 222.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:39:03 INFO DAGScheduler: ResultStage 222 (start at NativeMethodAccessorImpl.java:0) finished in 1.724 s\n",
      "23/06/22 21:39:03 INFO DAGScheduler: Job 221 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:39:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 222: Stage finished\n",
      "23/06/22 21:39:03 INFO DAGScheduler: Job 221 finished: start at NativeMethodAccessorImpl.java:0, took 1.724660 s\n",
      "23/06/22 21:39:03 INFO FileFormatWriter: Start to commit write Job 529209d2-ab96-4545-9dad-a3eb556d548d.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:39:04 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-1c296931-c548-4a86-ac0b-a9c16ec7b8fa/_temporary/0/task_202306222139018453926043173608051_0222_m_000000/' directory.\n",
      "23/06/22 21:39:05 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-1c296931-c548-4a86-ac0b-a9c16ec7b8fa/' directory.\n",
      "23/06/22 21:39:05 INFO FileFormatWriter: Write Job 529209d2-ab96-4545-9dad-a3eb556d548d committed. Elapsed time: 2166 ms.\n",
      "23/06/22 21:39:05 INFO FileFormatWriter: Finished processing stats for write job 529209d2-ab96-4545-9dad-a3eb556d548d.\n",
      "23/06/22 21:39:06 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687482506437-1c296931-c548-4a86-ac0b-a9c16ec7b8fa/part-00000-065b1a32-b5a2-4c41-866c-d692fa97e8d9-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=0d29c447-df1b-4f72-9fcb-61ee71ec9f44, location=US}\n",
      "23/06/22 21:39:09 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=0d29c447-df1b-4f72-9fcb-61ee71ec9f44, location=US}\n",
      "23/06/22 21:39:09 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/182 using temp file gs://kafka-spark-data/spark-metadata/commits/.182.d6cf3d65-167e-476e-a2dc-6f24b81afeb4.tmp\n",
      "23/06/22 21:39:09 INFO BlockManagerInfo: Removed broadcast_220_piece0 on 192.168.4.24:51040 in memory (size: 9.9 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:39:09 INFO BlockManagerInfo: Removed broadcast_221_piece0 on 192.168.4.24:51040 in memory (size: 94.8 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:39:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 1717.\n",
      "23/06/22 21:39:10 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/105 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.105.468fdafd-8cf5-498e-ae58-b8e05271b943.tmp\n",
      "23/06/22 21:39:10 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.105.468fdafd-8cf5-498e-ae58-b8e05271b943.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/105\n",
      "23/06/22 21:39:10 INFO MicroBatchExecution: Committed offsets for batch 105. Metadata OffsetSeqMetadata(0,1687487950005,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:39:10 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:10 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:10 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:10 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:10 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:10 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:10 INFO WriteToDataSourceV2Exec: Start processing data source write support: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@2d20676. The input RDD has 1 partitions.\n",
      "23/06/22 21:39:10 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:39:10 INFO DAGScheduler: Got job 222 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:39:10 INFO DAGScheduler: Final stage: ResultStage 223 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:39:10 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:39:10 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:39:10 INFO DAGScheduler: Submitting ResultStage 223 (MapPartitionsRDD[1175] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:39:10 INFO MemoryStore: Block broadcast_222 stored as values in memory (estimated size 23.0 KiB, free 434.4 MiB)\n",
      "23/06/22 21:39:10 INFO MemoryStore: Block broadcast_222_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 434.4 MiB)\n",
      "23/06/22 21:39:10 INFO BlockManagerInfo: Added broadcast_222_piece0 in memory on 192.168.4.24:51040 (size: 9.9 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:39:10 INFO SparkContext: Created broadcast 222 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:39:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 223 (MapPartitionsRDD[1175] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:39:10 INFO TaskSchedulerImpl: Adding task set 223.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:39:10 INFO TaskSetManager: Starting task 0.0 in stage 223.0 (TID 222) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:39:10 INFO Executor: Running task 0.0 in stage 223.0 (TID 222)\n",
      "23/06/22 21:39:10 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 1678 for partition ticketmaster-0\n",
      "23/06/22 21:39:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:39:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 1717.\n",
      "23/06/22 21:39:10 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 1679 for partition ticketmaster-0\n",
      "23/06/22 21:39:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:39:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 1718.\n",
      "23/06/22 21:39:10 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 222, attempt 0, stage 223.0)\n",
      "23/06/22 21:39:10 INFO DataWritingSparkTask: Committed partition 0 (task 222, attempt 0, stage 223.0)\n",
      "23/06/22 21:39:10 INFO Executor: Finished task 0.0 in stage 223.0 (TID 222). 35852 bytes result sent to driver\n",
      "23/06/22 21:39:10 INFO TaskSetManager: Finished task 0.0 in stage 223.0 (TID 222) in 80 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:39:10 INFO TaskSchedulerImpl: Removed TaskSet 223.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:39:10 INFO DAGScheduler: ResultStage 223 (start at NativeMethodAccessorImpl.java:0) finished in 0.082 s\n",
      "23/06/22 21:39:10 INFO DAGScheduler: Job 222 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:39:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 223: Stage finished\n",
      "23/06/22 21:39:10 INFO DAGScheduler: Job 222 finished: start at NativeMethodAccessorImpl.java:0, took 0.084271 s\n",
      "23/06/22 21:39:10 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@2d20676 is committing.\n",
      "-------------------------------------------\n",
      "Batch: 105\n",
      "-------------------------------------------\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+-----------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|          event_name|event_type|     event_id|           event_url|          venue_name|    venue_id|venue_zipcode|venues_timezone|venue_city|venue_state_full|venue_state_short|  venue_country_name|venue_country_short|       venue_address|venue_longitude|venue_latitude|  attraction_name|attraction_type|attraction_id|      attraction_url|attraction_segment_id|attraction_segment_name|attraction_genre_id|attraction_genre_name|attraction_subgenre_id|attraction_subgenre_name|event_start_date|ticket_status|event_start_time|currency|min_price|max_price|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+-----------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|Concacaf Gold Cup...|     \"NaN\"|Z7r9jZ1Ad-t-U|https://www.ticke...|Shell Energy Stadium|  ZFr9jZa61F|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|South Rice Avenue...|     -95.362999|     29.759399|CONCACAF Gold Cup|     attraction|  K8vZ9175bU7|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vA7E|               Soccer|   KZazBEonSMnZfZ7vFtt|                  Soccer|      2023-07-04|       onsale|        17:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|             WWE RAW|     \"NaN\"|Z7r9jZ1Ad-AqE|https://www.ticke...|  Toyota Center - TX|  ZFr9jZ7v7v|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        1510 Polk St|     -95.362999|     29.759399|              WWE|     attraction|  K8vZ91718zf|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAAk|            Wrestling|   KZazBEonSMnZfZ7vFna|               Wrestling|      2023-07-31|       onsale|        18:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Daniel Caesar Pre...|  standard|G5dIZ9iGms_16|https://concerts....|      713 Music Hall| KovZ917APwH|        77201|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 401 Franklin Street|      -95.36416|      29.76539|    Daniel Caesar|     attraction|  K8vZ917fLyV|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAee|                  R&B|   KZazBEonSMnZfZ7vkIt|                     R&B|      2023-09-12|       onsale|        20:00:00|     USD|     69.5|    109.5|\n",
      "|Reneé Rapp - Snow...|  standard|G5dIZ9iUowvtr|https://concerts....|  Bayou Music Center|KovZpZAEkIIA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      520 Texas Ave.|    -95.3672891|    29.7628087|       Reneé Rapp|     attraction|  K8vZ917heM7|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAev|                  Pop|   KZazBEonSMnZfZ7vk1t|                     Pop|      2023-09-15|      offsale|        19:00:00|     USD|     40.0|     59.5|\n",
      "|Concacaf Gold Cup...|     \"NaN\"|Z7r9jZ1Ad-SZp|https://www.ticke...|Shell Energy Stadium|  ZFr9jZa61F|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|South Rice Avenue...|     -95.362999|     29.759399|CONCACAF Gold Cup|     attraction|  K8vZ9175bU7|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vA7E|               Soccer|   KZazBEonSMnZfZ7vFtt|                  Soccer|      2023-07-01|       onsale|        18:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|       Illenium Live|  standard|G5dIZ9N6WJMMF|https://concerts....|      713 Music Hall| KovZ917APwH|        77201|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 401 Franklin Street|      -95.36416|      29.76539|         ILLENIUM|     attraction|  K8vZ9173V70|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvF|     Dance/Electronic|   KZazBEonSMnZfZ7vAJ1|              Club Dance|      2023-07-02|       onsale|        20:00:00|     USD|     59.5|     99.5|\n",
      "|ZHU - The Grace T...|  standard|G5dIZ9iUBIAB9|https://concerts....|  Bayou Music Center|KovZpZAEkIIA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      520 Texas Ave.|    -95.3672891|    29.7628087|              ZHU|     attraction|  K8vZ917KoI0|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvF|     Dance/Electronic|   KZazBEonSMnZfZ7vAJ1|              Club Dance|      2023-10-06|      offsale|        20:00:00|     USD|    43.25|    63.25|\n",
      "|BABYMETAL & DETHK...|  standard|G5dIZ9INs_PWJ|https://concerts....|      713 Music Hall| KovZ917APwH|        77201|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 401 Franklin Street|      -95.36416|      29.76539|        BABYMETAL|     attraction|  K8vZ9173qDV|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvt|                Metal|   KZazBEonSMnZfZ7vkFd|             Heavy Metal|      2023-08-30|       onsale|        19:00:00|     USD|     55.0|     85.0|\n",
      "|Pixies: North Ame...|  standard|G5dIZ9NNOxaVW|https://concerts....|  Bayou Music Center|KovZpZAEkIIA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      520 Texas Ave.|    -95.3672891|    29.7628087|           Pixies|     attraction|  K8vZ9171F7V|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6dt|        Alternative Rock|      2023-06-23|       onsale|        19:00:00|     USD|     49.5|     99.5|\n",
      "|Bad Omens - Concr...|  standard|G5dIZ9EScifXA|https://concerts....|  Bayou Music Center|KovZpZAEkIIA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      520 Texas Ave.|    -95.3672891|    29.7628087|        Bad Omens|     attraction|  K8vZ917f2Zf|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvv|          Alternative|   KZazBEonSMnZfZ7vAvt|       Alternative Metal|      2023-09-01|       onsale|        19:00:00|     USD|     38.0|     38.0|\n",
      "|SOULDED OUT DATES...|  standard|G5dIZ9c2IxPoV|https://www.ticke...|White Oak Music H...| KovZ917AiGZ|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      2915 N Main St|      -95.36562|      29.78627|      Drake Night|     attraction|  K8vZ917hafV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkdA|                   Urban|      2023-07-08|       onsale|        21:00:00|     USD|     22.0|     22.0|\n",
      "|Houston Astros vs...|     \"NaN\"|Z7r9jZ1AdpZjV|https://www.ticke...|    Minute Maid Park|  Z6r9jZkeke|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Crawford Street|     -95.362999|     29.759399|   Houston Astros|     attraction|  K8vZ91718zV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdv|             Baseball|   KZazBEonSMnZfZ7vF1n|                     MLB|      2023-07-04|       onsale|        15:10:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Dirty Heads - Isl...|  standard|G5dIZ9JkrhNOg|https://concerts....|  Bayou Music Center|KovZpZAEkIIA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      520 Texas Ave.|    -95.3672891|    29.7628087|      Dirty Heads|     attraction|  K8vZ917GJYV|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-06-22|      offsale|        18:00:00|     USD|     49.5|     79.5|\n",
      "|    Edición Especial|  standard|G5dIZ9tR3g42l|https://www.ticke...|       Arena Theatre|KovZpZAJJ7FA|        77074|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 7326 Southwest Fwy,|     -95.517765|     29.702271| Edición Especial|     attraction|  K8vZ917Q9l7|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAJ6|                Latin|   KZazBEonSMnZfZ7va1a|                   Latin|      2023-10-07|      offsale|        20:00:00|     USD|     59.5|    139.5|\n",
      "|    Wicked (Touring)|  standard|G5dIZ991tM0KZ|https://www.ticke...|        Hobby Center|KovZpZAJJEaA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|           800 Bagby|     -95.368798|    29.7617639| Wicked (Touring)|     attraction|  K8vZ91754JV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-06-24|       onsale|        14:00:00|     USD|     54.0|    204.0|\n",
      "|         Luis Miguel|     \"NaN\"|Z7r9jZ1Adxefa|https://www.ticke...|  Toyota Center - TX|  ZFr9jZ7v7v|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        1510 Polk St|     -95.362999|     29.759399|      Luis Miguel|     attraction|  K8vZ9171ajV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeF|                World|   KZazBEonSMnZfZ7vFdJ|                   Latin|      2023-11-02|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|    Wicked (Touring)|  standard|G5dIZ991tU03U|https://www.ticke...|        Hobby Center|KovZpZAJJEaA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|           800 Bagby|     -95.368798|    29.7617639| Wicked (Touring)|     attraction|  K8vZ91754JV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-06-22|      offsale|        19:30:00|     USD|     54.0|    174.0|\n",
      "|Tenacious D: The ...|  standard|G5dIZ9lXsT0-8|https://www.ticke...|White Oak Music H...| KovZ917Ata1|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|  2915 N Main Street|     -95.366997|     29.785971|      Tenacious D|     attraction|  K8vZ9171jXf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-09-13|       onsale|        17:30:00|     USD|     89.0|    129.0|\n",
      "|    Wicked (Touring)|  standard|G5dIZ991tB7KN|https://www.ticke...|        Hobby Center|KovZpZAJJEaA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|           800 Bagby|     -95.368798|    29.7617639| Wicked (Touring)|     attraction|  K8vZ91754JV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-06-27|       onsale|        19:30:00|     USD|     54.0|    174.0|\n",
      "|Bailey Zimmerman:...|  standard|G5dIZ9iEyxMOz|https://concerts....|      713 Music Hall| KovZ917APwH|        77201|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 401 Franklin Street|      -95.36416|      29.76539| Bailey Zimmerman|     attraction|  K8vZ917Q0Zf|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv6|              Country|   KZazBEonSMnZfZ7vAFa|                 Country|      2024-04-12|       onsale|        19:30:00|     USD|    39.75|   149.75|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+-----------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "23/06/22 21:39:10 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@2d20676 committed.\n",
      "23/06/22 21:39:10 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/105 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.105.30b214c4-b2c0-4502-9902-6fef8f39076b.tmp\n",
      "23/06/22 21:39:10 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.105.30b214c4-b2c0-4502-9902-6fef8f39076b.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/105\n",
      "23/06/22 21:39:10 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:39:10.003Z\",\n",
      "  \"batchId\" : 105,\n",
      "  \"numInputRows\" : 39,\n",
      "  \"inputRowsPerSecond\" : 3.899220155968806,\n",
      "  \"processedRowsPerSecond\" : 144.9814126394052,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 110,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 2,\n",
      "    \"queryPlanning\" : 9,\n",
      "    \"triggerExecution\" : 269,\n",
      "    \"walCommit\" : 88\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1678\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1717\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 39,\n",
      "    \"inputRowsPerSecond\" : 3.899220155968806,\n",
      "    \"processedRowsPerSecond\" : 144.9814126394052\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 39\n",
      "  }\n",
      "}\n",
      "23/06/22 21:39:11 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.182.d6cf3d65-167e-476e-a2dc-6f24b81afeb4.tmp to gs://kafka-spark-data/spark-metadata/commits/182\n",
      "23/06/22 21:39:11 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:38:54.321Z\",\n",
      "  \"batchId\" : 182,\n",
      "  \"numInputRows\" : 26,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 1.5339233038348083,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 8625,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 3045,\n",
      "    \"queryPlanning\" : 16,\n",
      "    \"triggerExecution\" : 16950,\n",
      "    \"walCommit\" : 2499\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1646\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1672\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 26,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 1.5339233038348083\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:39:11 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 16952 milliseconds\n",
      "23/06/22 21:39:11 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:11 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 1722.\n",
      "23/06/22 21:39:11 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/183 using temp file gs://kafka-spark-data/spark-metadata/offsets/.183.7b8656fc-4b04-4460-87d1-f47726fda8f3.tmp\n",
      "23/06/22 21:39:11 INFO BlockManagerInfo: Removed broadcast_222_piece0 on 192.168.4.24:51040 in memory (size: 9.9 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:39:12 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.183.7b8656fc-4b04-4460-87d1-f47726fda8f3.tmp to gs://kafka-spark-data/spark-metadata/offsets/183\n",
      "23/06/22 21:39:12 INFO MicroBatchExecution: Committed offsets for batch 183. Metadata OffsetSeqMetadata(0,1687487951292,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:39:13 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:13 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:13 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:13 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:13 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:39:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:39:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:39:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:39:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:39:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:39:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:39:13 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:39:13 INFO DAGScheduler: Got job 223 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:39:13 INFO DAGScheduler: Final stage: ResultStage 224 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:39:13 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:39:13 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:39:13 INFO DAGScheduler: Submitting ResultStage 224 (MapPartitionsRDD[1182] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:39:13 INFO MemoryStore: Block broadcast_223 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/22 21:39:13 INFO MemoryStore: Block broadcast_223_piece0 stored as bytes in memory (estimated size 94.8 KiB, free 434.0 MiB)\n",
      "23/06/22 21:39:13 INFO BlockManagerInfo: Added broadcast_223_piece0 in memory on 192.168.4.24:51040 (size: 94.8 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:39:13 INFO SparkContext: Created broadcast 223 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:39:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 224 (MapPartitionsRDD[1182] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:39:13 INFO TaskSchedulerImpl: Adding task set 224.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:39:13 INFO TaskSetManager: Starting task 0.0 in stage 224.0 (TID 223) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:39:13 INFO Executor: Running task 0.0 in stage 224.0 (TID 223)\n",
      "23/06/22 21:39:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:39:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:39:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:39:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:39:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:39:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:39:13 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:39:13 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:39:13 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/22 21:39:13 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/22 21:39:13 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/22 21:39:13 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/22 21:39:13 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 224:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:39:14 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 1686 for partition ticketmaster-0\n",
      "23/06/22 21:39:14 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:14 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:39:14 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:14 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 1735.\n",
      "23/06/22 21:39:14 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 1687 for partition ticketmaster-0\n",
      "23/06/22 21:39:14 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:14 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:39:14 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:14 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 1736.\n",
      "23/06/22 21:39:15 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-4b5e1a4d-0940-4aaf-8f04-151108e919c5/_temporary/0/_temporary/' directory.\n",
      "23/06/22 21:39:15 INFO FileOutputCommitter: Saved output of task 'attempt_20230622213913101829703990907872_0224_m_000000_223' to gs://kafka-spark-data/.spark-bigquery-local-1687482506437-4b5e1a4d-0940-4aaf-8f04-151108e919c5/_temporary/0/task_20230622213913101829703990907872_0224_m_000000\n",
      "23/06/22 21:39:15 INFO SparkHadoopMapRedUtil: attempt_20230622213913101829703990907872_0224_m_000000_223: Committed. Elapsed time: 845 ms.\n",
      "23/06/22 21:39:15 INFO Executor: Finished task 0.0 in stage 224.0 (TID 223). 2536 bytes result sent to driver\n",
      "23/06/22 21:39:15 INFO TaskSetManager: Finished task 0.0 in stage 224.0 (TID 223) in 2052 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:39:15 INFO TaskSchedulerImpl: Removed TaskSet 224.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:39:15 INFO DAGScheduler: ResultStage 224 (start at NativeMethodAccessorImpl.java:0) finished in 2.076 s\n",
      "23/06/22 21:39:15 INFO DAGScheduler: Job 223 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:39:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 224: Stage finished\n",
      "23/06/22 21:39:15 INFO DAGScheduler: Job 223 finished: start at NativeMethodAccessorImpl.java:0, took 2.082482 s\n",
      "23/06/22 21:39:15 INFO FileFormatWriter: Start to commit write Job 25aabd0f-f8e3-469a-9d84-4f7534857293.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:39:16 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-4b5e1a4d-0940-4aaf-8f04-151108e919c5/_temporary/0/task_20230622213913101829703990907872_0224_m_000000/' directory.\n",
      "23/06/22 21:39:17 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-4b5e1a4d-0940-4aaf-8f04-151108e919c5/' directory.\n",
      "23/06/22 21:39:17 INFO FileFormatWriter: Write Job 25aabd0f-f8e3-469a-9d84-4f7534857293 committed. Elapsed time: 1964 ms.\n",
      "23/06/22 21:39:17 INFO FileFormatWriter: Finished processing stats for write job 25aabd0f-f8e3-469a-9d84-4f7534857293.\n",
      "23/06/22 21:39:18 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687482506437-4b5e1a4d-0940-4aaf-8f04-151108e919c5/part-00000-15afd61f-1635-4448-b805-d51eee60d52e-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=611fdd96-c3b3-4654-9ce4-3859ba903dd3, location=US}\n",
      "23/06/22 21:39:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 1756.\n",
      "23/06/22 21:39:20 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/106 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.106.77722e53-6c69-4162-a70d-6d80186d7392.tmp\n",
      "23/06/22 21:39:20 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.106.77722e53-6c69-4162-a70d-6d80186d7392.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/106\n",
      "23/06/22 21:39:20 INFO MicroBatchExecution: Committed offsets for batch 106. Metadata OffsetSeqMetadata(0,1687487960011,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:39:20 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:20 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:20 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:20 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:20 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:20 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:20 INFO WriteToDataSourceV2Exec: Start processing data source write support: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@192290cd. The input RDD has 1 partitions.\n",
      "23/06/22 21:39:20 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:39:20 INFO DAGScheduler: Got job 224 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:39:20 INFO DAGScheduler: Final stage: ResultStage 225 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:39:20 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:39:20 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:39:20 INFO DAGScheduler: Submitting ResultStage 225 (MapPartitionsRDD[1185] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:39:20 INFO MemoryStore: Block broadcast_224 stored as values in memory (estimated size 23.0 KiB, free 434.0 MiB)\n",
      "23/06/22 21:39:20 INFO MemoryStore: Block broadcast_224_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 434.0 MiB)\n",
      "23/06/22 21:39:20 INFO BlockManagerInfo: Added broadcast_224_piece0 in memory on 192.168.4.24:51040 (size: 9.9 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:39:20 INFO SparkContext: Created broadcast 224 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:39:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 225 (MapPartitionsRDD[1185] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:39:20 INFO TaskSchedulerImpl: Adding task set 225.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:39:20 INFO TaskSetManager: Starting task 0.0 in stage 225.0 (TID 224) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:39:20 INFO Executor: Running task 0.0 in stage 225.0 (TID 224)\n",
      "23/06/22 21:39:20 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 1717 for partition ticketmaster-0\n",
      "23/06/22 21:39:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:39:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 1756.\n",
      "23/06/22 21:39:20 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 1718 for partition ticketmaster-0\n",
      "23/06/22 21:39:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:39:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 1757.\n",
      "23/06/22 21:39:20 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 224, attempt 0, stage 225.0)\n",
      "23/06/22 21:39:20 INFO DataWritingSparkTask: Committed partition 0 (task 224, attempt 0, stage 225.0)\n",
      "23/06/22 21:39:20 INFO Executor: Finished task 0.0 in stage 225.0 (TID 224). 35337 bytes result sent to driver\n",
      "23/06/22 21:39:20 INFO TaskSetManager: Finished task 0.0 in stage 225.0 (TID 224) in 63 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:39:20 INFO TaskSchedulerImpl: Removed TaskSet 225.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:39:20 INFO DAGScheduler: ResultStage 225 (start at NativeMethodAccessorImpl.java:0) finished in 0.071 s\n",
      "23/06/22 21:39:20 INFO DAGScheduler: Job 224 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:39:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 225: Stage finished\n",
      "23/06/22 21:39:20 INFO DAGScheduler: Job 224 finished: start at NativeMethodAccessorImpl.java:0, took 0.073063 s\n",
      "23/06/22 21:39:20 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@192290cd is committing.\n",
      "-------------------------------------------\n",
      "Batch: 106\n",
      "-------------------------------------------\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+----------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|          event_name|event_type|     event_id|           event_url|          venue_name|    venue_id|venue_zipcode|venues_timezone|venue_city|venue_state_full|venue_state_short|  venue_country_name|venue_country_short|       venue_address|venue_longitude|venue_latitude| attraction_name|attraction_type|attraction_id|      attraction_url|attraction_segment_id|attraction_segment_name|attraction_genre_id|attraction_genre_name|attraction_subgenre_id|attraction_subgenre_name|event_start_date|ticket_status|event_start_time|currency|min_price|max_price|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+----------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|Katt Williams: Th...|  standard|G5dIZ9l0PFZ00|https://www.ticke...|           NRG Arena|KovZpZAJaEaA|        77054|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        One NRG Park|   -95.40880499|   29.68516717|   Katt Williams|     attraction|  K8vZ9175Nk0|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-09-30|       onsale|        20:00:00|     USD|     59.0|    350.0|\n",
      "|             TV Girl|  standard|G5dIZ9lxjf3Dz|https://www.ticke...|White Oak Music H...| KovZ917Ata1|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|  2915 N Main Street|     -95.366997|     29.785971|         TV Girl|     attraction|  K8vZ91728t0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAe6|            Undefined|   KZazBEonSMnZfZ7v6JI|               Undefined|      2023-09-23|       onsale|        18:00:00|     USD|     35.0|     35.0|\n",
      "|    Wicked (Touring)|  standard|G5dIZ991tHfKH|https://www.ticke...|        Hobby Center|KovZpZAJJEaA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|           800 Bagby|     -95.368798|    29.7617639|Wicked (Touring)|     attraction|  K8vZ91754JV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-06-30|       onsale|        20:00:00|     USD|     54.0|    194.0|\n",
      "|        Stevie Nicks|     \"NaN\"|Z7r9jZ1Adx4eF|https://www.ticke...|  Toyota Center - TX|  ZFr9jZ7v7v|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        1510 Polk St|     -95.362999|     29.759399|    Stevie Nicks|     attraction|  K8vZ91712s0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-08-12|       onsale|        19:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Greta Van Fleet -...|     \"NaN\"|Z7r9jZ1Ad-3Ox|https://www.ticke...|  Toyota Center - TX|  ZFr9jZ7v7v|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        1510 Polk St|     -95.362999|     29.759399| Greta Van Fleet|     attraction|  K8vZ91738o0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-07-28|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|6LACK - Since I H...|  standard|G5dIZ9t3qw0iX|https://concerts....|  Bayou Music Center|KovZpZAEkIIA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      520 Texas Ave.|    -95.3672891|    29.7628087|           6LACK|     attraction|  K8vZ9174IH0|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkvl|             Hip-Hop/Rap|      2023-10-25|       onsale|        20:00:00|     USD|     45.5|     59.5|\n",
      "|Laufey: The Bewit...|  standard|G5dIZ9nJhIxXQ|https://www.ticke...|White Oak Music H...| KovZ917AiGZ|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      2915 N Main St|      -95.36562|      29.78627|          Laufey|     attraction|  K8vZ917_Qv0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-11-09|       onsale|        20:00:00|     USD|     27.5|     27.5|\n",
      "|    Wicked (Touring)|  standard|G5dIZ991tXVf4|https://www.ticke...|        Hobby Center|KovZpZAJJEaA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|           800 Bagby|     -95.368798|    29.7617639|Wicked (Touring)|     attraction|  K8vZ91754JV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-07-02|       onsale|        14:00:00|     USD|     54.0|    204.0|\n",
      "|Toosii: Naujour Tour|  standard|G5dIZ9naTlo4e|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797|          Toosii|     attraction|  K8vZ917bJa0|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkvl|             Hip-Hop/Rap|      2023-08-05|       onsale|        19:00:00|     USD|     39.5|     39.5|\n",
      "|Houston Astros vs...|     \"NaN\"|Z7r9jZ1AdpZqk|https://www.ticke...|    Minute Maid Park|  Z6r9jZkeke|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Crawford Street|     -95.362999|     29.759399|  Houston Astros|     attraction|  K8vZ91718zV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdv|             Baseball|   KZazBEonSMnZfZ7vF1n|                     MLB|      2023-07-08|       onsale|        18:15:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|        The National|  standard|G5dIZ9tOsKEf6|https://www.ticke...|White Oak Music H...| KovZ917Ata1|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|  2915 N Main Street|     -95.366997|     29.785971|    The National|     attraction|  K8vZ9175SH0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-11-18|       onsale|        19:00:00|     USD|     52.0|     52.0|\n",
      "|Madonna - The Cel...|     \"NaN\"|Z7r9jZ1Adq6_7|https://www.ticke...|  Toyota Center - TX|  ZFr9jZ7v7v|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        1510 Polk St|     -95.362999|     29.759399|         Madonna|     attraction|  K8vZ9171ub0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-09-13|       onsale|        20:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|      Bop To The Top|  standard|G5dIZ9IK6MSiv|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797|  Bop To The Top|     attraction|  K8vZ917hCFf|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvF|     Dance/Electronic|   KZazBEonSMnZfZ7vA1E|        Dance/Electronic|      2023-07-07|       onsale|        21:00:00|     USD|     18.0|     25.0|\n",
      "|Jimmy Eat World &...|  standard|G5dIZ9JnmFV98|https://concerts....|      713 Music Hall| KovZ917APwH|        77201|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 401 Franklin Street|      -95.36416|      29.76539| Jimmy Eat World|     attraction|  K8vZ9171hzV|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6dt|        Alternative Rock|      2023-08-07|       onsale|        19:00:00|     USD|     39.5|     69.5|\n",
      "|    Wicked (Touring)|  standard|G5dIZ991tT0f9|https://www.ticke...|        Hobby Center|KovZpZAJJEaA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|           800 Bagby|     -95.368798|    29.7617639|Wicked (Touring)|     attraction|  K8vZ91754JV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-07-02|       onsale|        19:30:00|     USD|     54.0|    194.0|\n",
      "|Anita Baker - The...|     \"NaN\"|Z7r9jZ1AdQepe|https://www.ticke...|  Toyota Center - TX|  ZFr9jZ7v7v|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        1510 Polk St|     -95.362999|     29.759399|     Anita Baker|     attraction|  K8vZ9171aXf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAee|                  R&B|   KZazBEonSMnZfZ7vkIt|                     R&B|      2023-12-15|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|    Wicked (Touring)|  standard|G5dIZ991tX7f8|https://www.ticke...|        Hobby Center|KovZpZAJJEaA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|           800 Bagby|     -95.368798|    29.7617639|Wicked (Touring)|     attraction|  K8vZ91754JV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-07-01|       onsale|        20:00:00|     USD|     54.0|    204.0|\n",
      "|$UICIDEBOY$ w/ Gh...|     \"NaN\"|Z7r9jZ1AdxbpF|https://www.ticke...|  Toyota Center - TX|  ZFr9jZ7v7v|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        1510 Polk St|     -95.362999|     29.759399|     $UICIDEBOY$|     attraction|  K8vZ917f2N7|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkvl|             Hip-Hop/Rap|      2023-09-03|       onsale|        18:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|    La India Yuridia|  standard|G5dIZ9i51J9YA|https://www.ticke...|       Arena Theatre|KovZpZAJJ7FA|        77074|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 7326 Southwest Fwy,|     -95.517765|     29.702271|La India Yuridia|     attraction|  K8vZ917pQdV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-12-02|       onsale|        21:00:00|     USD|     81.8|    164.6|\n",
      "|              Davido|     \"NaN\"|Z7r9jZ1Ad-98O|https://www.ticke...|  Toyota Center - TX|  ZFr9jZ7v7v|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        1510 Polk St|     -95.362999|     29.759399|          Davido|     attraction|  K8vZ9173mOf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeF|                World|   KZazBEonSMnZfZ7v6Jt|                   World|      2023-07-07|       onsale|        19:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+----------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "23/06/22 21:39:20 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@192290cd committed.\n",
      "23/06/22 21:39:20 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/106 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.106.027dcd17-c8b9-4365-8878-900a7d41ad02.tmp\n",
      "23/06/22 21:39:20 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=611fdd96-c3b3-4654-9ce4-3859ba903dd3, location=US}\n",
      "23/06/22 21:39:20 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.106.027dcd17-c8b9-4365-8878-900a7d41ad02.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/106\n",
      "23/06/22 21:39:20 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:39:20.006Z\",\n",
      "  \"batchId\" : 106,\n",
      "  \"numInputRows\" : 39,\n",
      "  \"inputRowsPerSecond\" : 3.8988303508947317,\n",
      "  \"processedRowsPerSecond\" : 133.10580204778157,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 97,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 5,\n",
      "    \"queryPlanning\" : 8,\n",
      "    \"triggerExecution\" : 293,\n",
      "    \"walCommit\" : 60\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1717\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1756\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 39,\n",
      "    \"inputRowsPerSecond\" : 3.8988303508947317,\n",
      "    \"processedRowsPerSecond\" : 133.10580204778157\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 39\n",
      "  }\n",
      "}\n",
      "23/06/22 21:39:20 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/183 using temp file gs://kafka-spark-data/spark-metadata/commits/.183.3f3c99b1-b0c9-4319-b96f-606a25394125.tmp\n",
      "23/06/22 21:39:21 INFO BlockManagerInfo: Removed broadcast_224_piece0 on 192.168.4.24:51040 in memory (size: 9.9 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:39:21 INFO BlockManagerInfo: Removed broadcast_223_piece0 on 192.168.4.24:51040 in memory (size: 94.8 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:39:22 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.183.3f3c99b1-b0c9-4319-b96f-606a25394125.tmp to gs://kafka-spark-data/spark-metadata/commits/183\n",
      "23/06/22 21:39:22 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:39:11.274Z\",\n",
      "  \"batchId\" : 183,\n",
      "  \"numInputRows\" : 50,\n",
      "  \"inputRowsPerSecond\" : 2.9493305019760516,\n",
      "  \"processedRowsPerSecond\" : 4.626630887387804,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7312,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 18,\n",
      "    \"queryPlanning\" : 4,\n",
      "    \"triggerExecution\" : 10807,\n",
      "    \"walCommit\" : 2002\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1672\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1722\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 50,\n",
      "    \"inputRowsPerSecond\" : 2.9493305019760516,\n",
      "    \"processedRowsPerSecond\" : 4.626630887387804\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:39:22 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 10808 milliseconds\n",
      "23/06/22 21:39:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 1764.\n",
      "23/06/22 21:39:22 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/184 using temp file gs://kafka-spark-data/spark-metadata/offsets/.184.d721003e-cfd0-4984-a7e3-3ddd4f9f5d98.tmp\n",
      "23/06/22 21:39:23 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.184.d721003e-cfd0-4984-a7e3-3ddd4f9f5d98.tmp to gs://kafka-spark-data/spark-metadata/offsets/184\n",
      "23/06/22 21:39:23 INFO MicroBatchExecution: Committed offsets for batch 184. Metadata OffsetSeqMetadata(0,1687487962084,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:39:24 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:24 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:24 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:24 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:24 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:39:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:39:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:39:24 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:39:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:39:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:39:24 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:39:24 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:39:24 INFO DAGScheduler: Got job 225 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:39:24 INFO DAGScheduler: Final stage: ResultStage 226 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:39:24 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:39:24 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:39:24 INFO DAGScheduler: Submitting ResultStage 226 (MapPartitionsRDD[1192] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:39:24 INFO MemoryStore: Block broadcast_225 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/22 21:39:24 INFO MemoryStore: Block broadcast_225_piece0 stored as bytes in memory (estimated size 94.8 KiB, free 434.0 MiB)\n",
      "23/06/22 21:39:24 INFO BlockManagerInfo: Added broadcast_225_piece0 in memory on 192.168.4.24:51040 (size: 94.8 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:39:24 INFO SparkContext: Created broadcast 225 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:39:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 226 (MapPartitionsRDD[1192] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:39:24 INFO TaskSchedulerImpl: Adding task set 226.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:39:24 INFO TaskSetManager: Starting task 0.0 in stage 226.0 (TID 225) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:39:24 INFO Executor: Running task 0.0 in stage 226.0 (TID 225)\n",
      "23/06/22 21:39:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:39:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:39:24 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:39:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:39:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:39:24 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:39:24 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:39:24 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:39:24 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/22 21:39:24 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/22 21:39:24 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/22 21:39:24 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/22 21:39:24 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/22 21:39:25 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 1735 for partition ticketmaster-0\n",
      "23/06/22 21:39:25 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:25 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:39:25 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:25 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 1776.\n",
      "23/06/22 21:39:25 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 1736 for partition ticketmaster-0\n",
      "23/06/22 21:39:25 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:25 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:39:25 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:25 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 1777.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 226:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:39:26 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-c8535f08-bb5c-406b-8c56-f1e27de4bf77/_temporary/0/_temporary/' directory.\n",
      "23/06/22 21:39:26 INFO FileOutputCommitter: Saved output of task 'attempt_202306222139249144214109976605893_0226_m_000000_225' to gs://kafka-spark-data/.spark-bigquery-local-1687482506437-c8535f08-bb5c-406b-8c56-f1e27de4bf77/_temporary/0/task_202306222139249144214109976605893_0226_m_000000\n",
      "23/06/22 21:39:26 INFO SparkHadoopMapRedUtil: attempt_202306222139249144214109976605893_0226_m_000000_225: Committed. Elapsed time: 876 ms.\n",
      "23/06/22 21:39:26 INFO Executor: Finished task 0.0 in stage 226.0 (TID 225). 2536 bytes result sent to driver\n",
      "23/06/22 21:39:26 INFO TaskSetManager: Finished task 0.0 in stage 226.0 (TID 225) in 1777 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:39:26 INFO TaskSchedulerImpl: Removed TaskSet 226.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:39:26 INFO DAGScheduler: ResultStage 226 (start at NativeMethodAccessorImpl.java:0) finished in 1.802 s\n",
      "23/06/22 21:39:26 INFO DAGScheduler: Job 225 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:39:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 226: Stage finished\n",
      "23/06/22 21:39:26 INFO DAGScheduler: Job 225 finished: start at NativeMethodAccessorImpl.java:0, took 1.804149 s\n",
      "23/06/22 21:39:26 INFO FileFormatWriter: Start to commit write Job 0d821953-c129-458a-bd4e-b4245f4cac2b.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:39:27 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-c8535f08-bb5c-406b-8c56-f1e27de4bf77/_temporary/0/task_202306222139249144214109976605893_0226_m_000000/' directory.\n",
      "23/06/22 21:39:28 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-c8535f08-bb5c-406b-8c56-f1e27de4bf77/' directory.\n",
      "23/06/22 21:39:28 INFO BlockManagerInfo: Removed broadcast_225_piece0 on 192.168.4.24:51040 in memory (size: 94.8 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:39:28 INFO FileFormatWriter: Write Job 0d821953-c129-458a-bd4e-b4245f4cac2b committed. Elapsed time: 2010 ms.\n",
      "23/06/22 21:39:28 INFO FileFormatWriter: Finished processing stats for write job 0d821953-c129-458a-bd4e-b4245f4cac2b.\n",
      "23/06/22 21:39:28 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687482506437-c8535f08-bb5c-406b-8c56-f1e27de4bf77/part-00000-da0c00dc-14de-46eb-97dd-a7d7c0a7cb87-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=559681c5-959f-419c-bc2f-e69c243520df, location=US}\n",
      "23/06/22 21:39:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 1795.\n",
      "23/06/22 21:39:30 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/107 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.107.059d41a4-4f23-4b2b-8f56-d7d159d3bbaa.tmp\n",
      "23/06/22 21:39:30 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.107.059d41a4-4f23-4b2b-8f56-d7d159d3bbaa.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/107\n",
      "23/06/22 21:39:30 INFO MicroBatchExecution: Committed offsets for batch 107. Metadata OffsetSeqMetadata(0,1687487970004,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:39:30 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:30 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:30 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:30 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:30 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:30 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:30 INFO WriteToDataSourceV2Exec: Start processing data source write support: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@23e895bf. The input RDD has 1 partitions.\n",
      "23/06/22 21:39:30 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:39:30 INFO DAGScheduler: Got job 226 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:39:30 INFO DAGScheduler: Final stage: ResultStage 227 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:39:30 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:39:30 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:39:30 INFO DAGScheduler: Submitting ResultStage 227 (MapPartitionsRDD[1195] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:39:30 INFO MemoryStore: Block broadcast_226 stored as values in memory (estimated size 23.0 KiB, free 434.4 MiB)\n",
      "23/06/22 21:39:30 INFO MemoryStore: Block broadcast_226_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 434.4 MiB)\n",
      "23/06/22 21:39:30 INFO BlockManagerInfo: Added broadcast_226_piece0 in memory on 192.168.4.24:51040 (size: 9.9 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:39:30 INFO SparkContext: Created broadcast 226 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:39:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 227 (MapPartitionsRDD[1195] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:39:30 INFO TaskSchedulerImpl: Adding task set 227.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:39:30 INFO TaskSetManager: Starting task 0.0 in stage 227.0 (TID 226) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:39:30 INFO Executor: Running task 0.0 in stage 227.0 (TID 226)\n",
      "23/06/22 21:39:30 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 1756 for partition ticketmaster-0\n",
      "23/06/22 21:39:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:39:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 1795.\n",
      "23/06/22 21:39:30 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 1757 for partition ticketmaster-0\n",
      "23/06/22 21:39:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:39:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 1796.\n",
      "23/06/22 21:39:30 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 226, attempt 0, stage 227.0)\n",
      "23/06/22 21:39:30 INFO DataWritingSparkTask: Committed partition 0 (task 226, attempt 0, stage 227.0)\n",
      "23/06/22 21:39:30 INFO Executor: Finished task 0.0 in stage 227.0 (TID 226). 36001 bytes result sent to driver\n",
      "23/06/22 21:39:30 INFO TaskSetManager: Finished task 0.0 in stage 227.0 (TID 226) in 46 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:39:30 INFO TaskSchedulerImpl: Removed TaskSet 227.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:39:30 INFO DAGScheduler: ResultStage 227 (start at NativeMethodAccessorImpl.java:0) finished in 0.050 s\n",
      "23/06/22 21:39:30 INFO DAGScheduler: Job 226 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:39:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 227: Stage finished\n",
      "23/06/22 21:39:30 INFO DAGScheduler: Job 226 finished: start at NativeMethodAccessorImpl.java:0, took 0.051094 s\n",
      "23/06/22 21:39:30 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@23e895bf is committing.\n",
      "-------------------------------------------\n",
      "Batch: 107\n",
      "-------------------------------------------\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|          event_name|event_type|     event_id|           event_url|          venue_name|    venue_id|venue_zipcode|venues_timezone|venue_city|venue_state_full|venue_state_short|  venue_country_name|venue_country_short|       venue_address|venue_longitude|venue_latitude|     attraction_name|attraction_type|attraction_id|      attraction_url|attraction_segment_id|attraction_segment_name|attraction_genre_id|attraction_genre_name|attraction_subgenre_id|attraction_subgenre_name|event_start_date|ticket_status|event_start_time|currency|min_price|max_price|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|Thomas Rhett: Hom...|     \"NaN\"|Z7r9jZ1Ad_sp3|https://www.ticke...|  Toyota Center - TX|  ZFr9jZ7v7v|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        1510 Polk St|     -95.362999|     29.759399|        Thomas Rhett|     attraction|  K8vZ917Cqe0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv6|              Country|   KZazBEonSMnZfZ7vAFa|                 Country|      2023-08-04|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Motionless In Whi...|  standard|G5dIZ9tKZ8km-|https://www.ticke...|White Oak Music H...| KovZ917Ata1|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|  2915 N Main Street|     -95.366997|     29.785971| Motionless In White|     attraction|  K8vZ917u750|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvt|                Metal|   KZazBEonSMnZfZ7vk6E|                   Metal|      2023-10-11|       onsale|        17:00:00|     USD|     49.5|     99.0|\n",
      "|   Elevation Worship|     \"NaN\"|Z7r9jZ1AdOOQ3|https://www.ticke...|  Toyota Center - TX|  ZFr9jZ7v7v|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        1510 Polk St|     -95.362999|     29.759399|   Elevation Worship|     attraction|  K8vZ917fsHf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAe7|            Religious|   KZazBEonSMnZfZ7v6vI|               Religious|      2023-10-12|       onsale|        19:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|50 Cent: The Fina...|     \"NaN\"|Z7r9jZ1Adxea8|https://www.ticke...|  Toyota Center - TX|  ZFr9jZ7v7v|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        1510 Polk St|     -95.362999|     29.759399|             50 Cent|     attraction|  K8vZ9175fm7|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkdA|                   Urban|      2023-08-24|       onsale|        19:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Kenny Wayne Shepherd|  standard|G5dIZ9PN7Oglm|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797|Kenny Wayne Shepherd|     attraction|  K8vZ9171fEf|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvd|                Blues|   KZazBEonSMnZfZ7vAAd|                   Blues|      2023-07-21|       onsale|        19:00:00|     USD|     35.0|     99.5|\n",
      "|Sorry Papi Tour: ...|  standard|G5dIZ9nw7Nwnd|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797|Sorry Papi Tour: ...|     attraction|  K8vZ917Q_x0|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAJ6|                Latin|   KZazBEonSMnZfZ7va1a|                   Latin|      2023-07-15|       onsale|        21:00:00|     USD|     25.0|     40.0|\n",
      "|Janelle Monáe - A...|  standard|G5dIZ9lRkbxiW|https://concerts....|  Bayou Music Center|KovZpZAEkIIA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      520 Texas Ave.|    -95.3672891|    29.7628087|       Janelle Monáe|     attraction|  K8vZ917GSwV|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAee|                  R&B|   KZazBEonSMnZfZ7vkIt|                     R&B|      2023-10-10|       onsale|        20:00:00|     USD|     61.5|     91.5|\n",
      "|Iliza: Hard Feeli...|  standard|G5dIZ9InHHwiy|https://concerts....|  Bayou Music Center|KovZpZAEkIIA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      520 Texas Ave.|    -95.3672891|    29.7628087|    Iliza Shlesinger|     attraction|  K8vZ917GIB7|https://www.liven...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-09-14|       onsale|        19:00:00|     USD|     39.5|     79.5|\n",
      "|Jesse & Joy Summe...|  standard|G5dIZ9EOpDyvm|https://concerts....|      713 Music Hall| KovZ917APwH|        77201|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 401 Franklin Street|      -95.36416|      29.76539|         Jesse & Joy|     attraction|  K8vZ917G1wV|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAve|     Ballads/Romantic|   KZazBEonSMnZfZ7vAAe|        Ballads/Romantic|      2023-08-05|       onsale|        20:00:00|     USD|     49.0|    139.0|\n",
      "|Houston Astros vs...|     \"NaN\"|Z7r9jZ1AdpZq4|https://www.ticke...|    Minute Maid Park|  Z6r9jZkeke|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Crawford Street|     -95.362999|     29.759399|      Houston Astros|     attraction|  K8vZ91718zV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdv|             Baseball|   KZazBEonSMnZfZ7vF1n|                     MLB|      2023-07-29|       onsale|        18:15:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|         Ace Frehley|  standard|G5dIZ9PdPF6Ay|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797|         Ace Frehley|     attraction|  K8vZ9171un7|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-07-14|       onsale|        19:00:00|     USD|     39.5|     62.5|\n",
      "|Houston Astros vs...|     \"NaN\"|Z7r9jZ1AdpZqA|https://www.ticke...|    Minute Maid Park|  Z6r9jZkeke|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Crawford Street|     -95.362999|     29.759399|      Houston Astros|     attraction|  K8vZ91718zV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdv|             Baseball|   KZazBEonSMnZfZ7vF1n|                     MLB|      2023-07-09|       onsale|        13:10:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|             Madonna|     \"NaN\"|Z7r9jZ1AdqKQ7|https://www.ticke...|  Toyota Center - TX|  ZFr9jZ7v7v|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        1510 Polk St|     -95.362999|     29.759399|             Madonna|     attraction|  K8vZ9171ub0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-09-14|       onsale|        20:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Explosions In The...|  standard|G5dIZ9IYngz9O|https://www.ticke...|White Oak Music H...| KovZ917Ata1|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|  2915 N Main Street|     -95.366997|     29.785971|Explosions In the...|     attraction|  K8vZ9171B17|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6dt|        Alternative Rock|      2023-09-15|       onsale|        19:00:00|     USD|     32.0|     32.0|\n",
      "|Houston Astros vs...|     \"NaN\"|Z7r9jZ1AdpZjU|https://www.ticke...|    Minute Maid Park|  Z6r9jZkeke|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Crawford Street|     -95.362999|     29.759399|      Houston Astros|     attraction|  K8vZ91718zV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdv|             Baseball|   KZazBEonSMnZfZ7vF1n|                     MLB|      2023-07-06|       onsale|        19:10:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|   Dance Gavin Dance|  standard|G5dIZ9nRqUUgQ|https://www.ticke...|White Oak Music H...| KovZ917Ata1|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|  2915 N Main Street|     -95.366997|     29.785971|   Dance Gavin Dance|     attraction|  K8vZ917GLFf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-09-08|       onsale|        17:30:00|     USD|     39.0|     99.0|\n",
      "|Jurassic World Li...|  standard|G5dIZ9J2UuQxc|https://www.ticke...|         NRG Stadium|KovZpZAEdFeA|        77054|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        One NRG Park|     -95.410875|     29.684885|Jurassic World Li...|     attraction|  K8vZ9179ScV|https://www.ticke...|   KZFzniwnSyZfZ7v7n1|          Miscellaneous|        KnvZfZ7vA1n|               Family|   KZazBEonSMnZfZ7vaav|                   Other|      2023-08-04|       onsale|        11:00:00|     USD|     20.0|    175.0|\n",
      "|              Danzig|  standard|G5dIZ9lObh_Ar|https://www.ticke...|White Oak Music H...| KovZ917Ata1|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|  2915 N Main Street|     -95.366997|     29.785971|              Danzig|     attraction|  K8vZ9171Gf0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvt|                Metal|   KZazBEonSMnZfZ7vkFd|             Heavy Metal|      2023-09-03|       onsale|        16:00:00|     USD|     45.0|     45.0|\n",
      "|       The Mavericks|  standard|G5dIZ902ovpp1|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797|       The Mavericks|     attraction|  K8vZ9171FbV|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv6|              Country|   KZazBEonSMnZfZ7vAFa|                 Country|      2023-09-30|       onsale|        19:00:00|     USD|     40.0|     79.5|\n",
      "|TATE MCRAE: ARE W...|  standard|G5dIZ9iwjEvQT|https://concerts....|  Bayou Music Center|KovZpZAEkIIA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      520 Texas Ave.|    -95.3672891|    29.7628087|          Tate McRae|     attraction|  K8vZ917bcy0|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAev|                  Pop|   KZazBEonSMnZfZ7vk1t|                     Pop|      2023-09-29|      offsale|        19:00:00|     USD|     35.0|     35.0|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "23/06/22 21:39:30 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@23e895bf committed.\n",
      "23/06/22 21:39:30 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/107 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.107.6f03e09c-8e06-4e84-be50-8f1473bb7e43.tmp\n",
      "23/06/22 21:39:30 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.107.6f03e09c-8e06-4e84-be50-8f1473bb7e43.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/107\n",
      "23/06/22 21:39:30 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:39:30.002Z\",\n",
      "  \"batchId\" : 107,\n",
      "  \"numInputRows\" : 39,\n",
      "  \"inputRowsPerSecond\" : 3.9015606242497,\n",
      "  \"processedRowsPerSecond\" : 178.89908256880733,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 66,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 2,\n",
      "    \"queryPlanning\" : 4,\n",
      "    \"triggerExecution\" : 218,\n",
      "    \"walCommit\" : 58\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1756\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1795\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 39,\n",
      "    \"inputRowsPerSecond\" : 3.9015606242497,\n",
      "    \"processedRowsPerSecond\" : 178.89908256880733\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 39\n",
      "  }\n",
      "}\n",
      "23/06/22 21:39:31 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=559681c5-959f-419c-bc2f-e69c243520df, location=US}\n",
      "23/06/22 21:39:32 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/184 using temp file gs://kafka-spark-data/spark-metadata/commits/.184.a41800c5-a55f-4b82-83f8-def8ff35b0e4.tmp\n",
      "23/06/22 21:39:33 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.184.a41800c5-a55f-4b82-83f8-def8ff35b0e4.tmp to gs://kafka-spark-data/spark-metadata/commits/184\n",
      "23/06/22 21:39:33 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:39:22.082Z\",\n",
      "  \"batchId\" : 184,\n",
      "  \"numInputRows\" : 42,\n",
      "  \"inputRowsPerSecond\" : 3.8860103626943006,\n",
      "  \"processedRowsPerSecond\" : 3.5611327793793452,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 8033,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 2,\n",
      "    \"queryPlanning\" : 4,\n",
      "    \"triggerExecution\" : 11794,\n",
      "    \"walCommit\" : 2034\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1722\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1764\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 42,\n",
      "    \"inputRowsPerSecond\" : 3.8860103626943006,\n",
      "    \"processedRowsPerSecond\" : 3.5611327793793452\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:39:33 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 11796 milliseconds\n",
      "23/06/22 21:39:33 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:33 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 1810.\n",
      "23/06/22 21:39:34 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/185 using temp file gs://kafka-spark-data/spark-metadata/offsets/.185.40de539f-5816-410d-a4db-efd9458f5572.tmp\n",
      "23/06/22 21:39:35 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.185.40de539f-5816-410d-a4db-efd9458f5572.tmp to gs://kafka-spark-data/spark-metadata/offsets/185\n",
      "23/06/22 21:39:35 INFO MicroBatchExecution: Committed offsets for batch 185. Metadata OffsetSeqMetadata(0,1687487973899,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:39:36 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:36 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:36 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:36 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:36 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:39:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:39:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:39:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:39:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:39:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:39:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:39:36 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:39:36 INFO DAGScheduler: Got job 227 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:39:36 INFO DAGScheduler: Final stage: ResultStage 228 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:39:36 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:39:36 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:39:36 INFO DAGScheduler: Submitting ResultStage 228 (MapPartitionsRDD[1202] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:39:37 INFO MemoryStore: Block broadcast_227 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/22 21:39:37 INFO MemoryStore: Block broadcast_227_piece0 stored as bytes in memory (estimated size 94.8 KiB, free 434.0 MiB)\n",
      "23/06/22 21:39:37 INFO BlockManagerInfo: Added broadcast_227_piece0 in memory on 192.168.4.24:51040 (size: 94.8 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:39:37 INFO SparkContext: Created broadcast 227 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:39:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 228 (MapPartitionsRDD[1202] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:39:37 INFO TaskSchedulerImpl: Adding task set 228.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:39:37 INFO TaskSetManager: Starting task 0.0 in stage 228.0 (TID 227) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:39:37 INFO Executor: Running task 0.0 in stage 228.0 (TID 227)\n",
      "23/06/22 21:39:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:39:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:39:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:39:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:39:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:39:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:39:37 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:39:37 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:39:37 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/22 21:39:37 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/22 21:39:37 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/22 21:39:37 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/22 21:39:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/22 21:39:37 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 1776 for partition ticketmaster-0\n",
      "23/06/22 21:39:37 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:37 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:39:37 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:37 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 1824.\n",
      "23/06/22 21:39:37 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 1777 for partition ticketmaster-0\n",
      "23/06/22 21:39:37 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:37 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:39:37 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:37 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 1825.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 228:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:39:38 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-c1c158d9-ebc3-44ce-b8a3-5b500d452dcc/_temporary/0/_temporary/' directory.\n",
      "23/06/22 21:39:38 INFO FileOutputCommitter: Saved output of task 'attempt_202306222139364710196216076407123_0228_m_000000_227' to gs://kafka-spark-data/.spark-bigquery-local-1687482506437-c1c158d9-ebc3-44ce-b8a3-5b500d452dcc/_temporary/0/task_202306222139364710196216076407123_0228_m_000000\n",
      "23/06/22 21:39:38 INFO SparkHadoopMapRedUtil: attempt_202306222139364710196216076407123_0228_m_000000_227: Committed. Elapsed time: 886 ms.\n",
      "23/06/22 21:39:38 INFO Executor: Finished task 0.0 in stage 228.0 (TID 227). 2536 bytes result sent to driver\n",
      "23/06/22 21:39:38 INFO TaskSetManager: Finished task 0.0 in stage 228.0 (TID 227) in 1752 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:39:38 INFO TaskSchedulerImpl: Removed TaskSet 228.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:39:38 INFO DAGScheduler: ResultStage 228 (start at NativeMethodAccessorImpl.java:0) finished in 1.776 s\n",
      "23/06/22 21:39:38 INFO DAGScheduler: Job 227 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:39:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 228: Stage finished\n",
      "23/06/22 21:39:38 INFO DAGScheduler: Job 227 finished: start at NativeMethodAccessorImpl.java:0, took 1.777011 s\n",
      "23/06/22 21:39:38 INFO FileFormatWriter: Start to commit write Job c3077c63-3b5e-4aa3-87f4-e4a924cc6d59.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:39:39 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-c1c158d9-ebc3-44ce-b8a3-5b500d452dcc/_temporary/0/task_202306222139364710196216076407123_0228_m_000000/' directory.\n",
      "23/06/22 21:39:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 1834.\n",
      "23/06/22 21:39:40 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/108 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.108.cbc560bc-e06c-4879-85a3-dbd1ba2b5213.tmp\n",
      "23/06/22 21:39:40 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.108.cbc560bc-e06c-4879-85a3-dbd1ba2b5213.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/108\n",
      "23/06/22 21:39:40 INFO MicroBatchExecution: Committed offsets for batch 108. Metadata OffsetSeqMetadata(0,1687487980008,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:39:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:40 INFO BlockManagerInfo: Removed broadcast_227_piece0 on 192.168.4.24:51040 in memory (size: 94.8 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:39:40 INFO BlockManagerInfo: Removed broadcast_226_piece0 on 192.168.4.24:51040 in memory (size: 9.9 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:39:40 INFO WriteToDataSourceV2Exec: Start processing data source write support: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@45dc6a93. The input RDD has 1 partitions.\n",
      "23/06/22 21:39:40 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:39:40 INFO DAGScheduler: Got job 228 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:39:40 INFO DAGScheduler: Final stage: ResultStage 229 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:39:40 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:39:40 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:39:40 INFO DAGScheduler: Submitting ResultStage 229 (MapPartitionsRDD[1205] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:39:40 INFO MemoryStore: Block broadcast_228 stored as values in memory (estimated size 23.0 KiB, free 434.4 MiB)\n",
      "23/06/22 21:39:40 INFO MemoryStore: Block broadcast_228_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 434.4 MiB)\n",
      "23/06/22 21:39:40 INFO BlockManagerInfo: Added broadcast_228_piece0 in memory on 192.168.4.24:51040 (size: 9.9 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:39:40 INFO SparkContext: Created broadcast 228 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:39:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 229 (MapPartitionsRDD[1205] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:39:40 INFO TaskSchedulerImpl: Adding task set 229.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:39:40 INFO TaskSetManager: Starting task 0.0 in stage 229.0 (TID 228) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:39:40 INFO Executor: Running task 0.0 in stage 229.0 (TID 228)\n",
      "23/06/22 21:39:40 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 1795 for partition ticketmaster-0\n",
      "23/06/22 21:39:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:39:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 1835.\n",
      "23/06/22 21:39:40 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 1796 for partition ticketmaster-0\n",
      "23/06/22 21:39:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:40 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-c1c158d9-ebc3-44ce-b8a3-5b500d452dcc/' directory.\n",
      "23/06/22 21:39:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:39:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 1836.\n",
      "23/06/22 21:39:40 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 228, attempt 0, stage 229.0)\n",
      "23/06/22 21:39:40 INFO DataWritingSparkTask: Committed partition 0 (task 228, attempt 0, stage 229.0)\n",
      "23/06/22 21:39:40 INFO Executor: Finished task 0.0 in stage 229.0 (TID 228). 36531 bytes result sent to driver\n",
      "23/06/22 21:39:40 INFO TaskSetManager: Finished task 0.0 in stage 229.0 (TID 228) in 224 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:39:40 INFO TaskSchedulerImpl: Removed TaskSet 229.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:39:40 INFO DAGScheduler: ResultStage 229 (start at NativeMethodAccessorImpl.java:0) finished in 0.226 s\n",
      "23/06/22 21:39:40 INFO DAGScheduler: Job 228 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:39:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 229: Stage finished\n",
      "23/06/22 21:39:40 INFO DAGScheduler: Job 228 finished: start at NativeMethodAccessorImpl.java:0, took 0.227373 s\n",
      "23/06/22 21:39:40 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@45dc6a93 is committing.\n",
      "-------------------------------------------\n",
      "Batch: 108\n",
      "-------------------------------------------\n",
      "23/06/22 21:39:40 INFO BlockManagerInfo: Removed broadcast_228_piece0 on 192.168.4.24:51040 in memory (size: 9.9 KiB, free: 434.4 MiB)\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|          event_name|event_type|     event_id|           event_url|          venue_name|    venue_id|venue_zipcode|venues_timezone|venue_city|venue_state_full|venue_state_short|  venue_country_name|venue_country_short|       venue_address|venue_longitude|venue_latitude|     attraction_name|attraction_type|attraction_id|      attraction_url|attraction_segment_id|attraction_segment_name|attraction_genre_id|attraction_genre_name|attraction_subgenre_id|attraction_subgenre_name|event_start_date|ticket_status|event_start_time|currency|min_price|max_price|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|PAW Patrol Live! ...|  standard|G5dIZ9ib7MtuH|https://www.ticke...|        Hobby Center|KovZpZAJJEaA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|           800 Bagby|     -95.368798|    29.7617639|PAW Patrol Live! ...|     attraction|  K8vZ917bVxV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7na|   Children's Theatre|   KZazBEonSMnZfZ7v7na|      Children's Theatre|      2023-11-04|      offsale|        14:00:00|     USD|     45.0|    170.0|\n",
      "|Static-X and Seve...|  standard|G5dIZ9ijRfbX2|https://concerts....|      713 Music Hall| KovZ917APwH|        77201|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 401 Franklin Street|      -95.36416|      29.76539|            Static-X|     attraction|  K8vZ9171N3V|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvt|                Metal|   KZazBEonSMnZfZ7vkFd|             Heavy Metal|      2023-10-06|       onsale|        18:15:00|     USD|     35.0|     59.5|\n",
      "|Jurassic World Li...|  standard|G5dIZ9J2U_QxU|https://www.ticke...|         NRG Stadium|KovZpZAEdFeA|        77054|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        One NRG Park|     -95.410875|     29.684885|Jurassic World Li...|     attraction|  K8vZ9179ScV|https://www.ticke...|   KZFzniwnSyZfZ7v7n1|          Miscellaneous|        KnvZfZ7vA1n|               Family|   KZazBEonSMnZfZ7vaav|                   Other|      2023-08-04|       onsale|        19:30:00|     USD|     20.0|    175.0|\n",
      "|     Stephen Sanchez|  standard|G5dIZ9N3E471Q|https://www.ticke...|White Oak Music H...| KovZ917Ata1|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|  2915 N Main Street|     -95.366997|     29.785971|     Stephen Sanchez|     attraction|  K8vZ917QKLf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-11-10|       onsale|        18:00:00|     USD|     30.0|     30.0|\n",
      "|Sam Smith - GLORI...|     \"NaN\"|Z7r9jZ1AdjUb7|https://www.ticke...|  Toyota Center - TX|  ZFr9jZ7v7v|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        1510 Polk St|     -95.362999|     29.759399|           Sam Smith|     attraction|  K8vZ9178pt7|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-09-08|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Take On Me - 80s ...|  standard|G5dIZ9E2llxDG|https://www.ticke...|White Oak Music H...| KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|Take On Me - 80s ...|     attraction|  K8vZ917QyK0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvF|     Dance/Electronic|   KZazBEonSMnZfZ7vAJ1|              Club Dance|      2023-07-01|  rescheduled|        21:00:00|     USD|     15.0|     15.0|\n",
      "|Boywithuke with s...|  standard|G5dIZ9ttueyim|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797|          BoyWithUke|     attraction|  K8vZ917_TEV|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAev|                  Pop|   KZazBEonSMnZfZ7vk1t|                     Pop|      2023-09-06|       onsale|        19:00:00|     USD|     25.0|     25.0|\n",
      "|LL COOL J: The F....|     \"NaN\"|Z7r9jZ1Ad-SaZ|https://www.ticke...|  Toyota Center - TX|  ZFr9jZ7v7v|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        1510 Polk St|     -95.362999|     29.759399|           LL COOL J|     attraction|  K8vZ9171G50|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkdA|                   Urban|      2023-08-25|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Kathleen Madigan:...|  standard|G5dIZ9Eb_GML2|https://concerts....|      713 Music Hall| KovZ917APwH|        77201|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 401 Franklin Street|      -95.36416|      29.76539|    Kathleen Madigan|     attraction|  K8vZ9171B-0|https://www.liven...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-10-28|       onsale|        20:00:00|     USD|    34.75|    59.75|\n",
      "|Ice Nine Kills: F...|  standard|G5dIZ9nRIJ6py|https://concerts....|  Bayou Music Center|KovZpZAEkIIA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      520 Texas Ave.|    -95.3672891|    29.7628087|      Ice Nine Kills|     attraction|  K8vZ917uqZ7|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-08-22|       onsale|        19:00:00|     USD|     44.5|     89.5|\n",
      "|             Dariush|  standard|G5dIZ981m_4Ns|https://www.ticke...|        Hobby Center|KovZpZAJJEaA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|           800 Bagby|     -95.368798|    29.7617639|             Dariush|     attraction|  K8vZ9171BYV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeF|                World|   KZazBEonSMnZfZ7v6Jt|                   World|      2023-09-16|  rescheduled|        20:30:00|     USD|     64.0|    230.0|\n",
      "|PAW Patrol Live! ...|  standard|G5dIZ9ib7Utuz|https://www.ticke...|        Hobby Center|KovZpZAJJEaA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|           800 Bagby|     -95.368798|    29.7617639|PAW Patrol Live! ...|     attraction|  K8vZ917bVxV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7na|   Children's Theatre|   KZazBEonSMnZfZ7v7na|      Children's Theatre|      2023-11-04|      offsale|        10:00:00|     USD|     45.0|    170.0|\n",
      "|            Owl City|  standard|G5dIZ9JJr-wwv|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797|            Owl City|     attraction|  K8vZ917G4mV|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6dt|        Alternative Rock|      2023-10-11|       onsale|        19:00:00|     USD|     29.5|     29.5|\n",
      "|       Willy Chirino|  standard|G5dIZ9E6k5fQ_|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797|       Willy Chirino|     attraction|  K8vZ917GbSV|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAe6|            Undefined|   KZazBEonSMnZfZ7v6JI|               Undefined|      2023-06-30|       onsale|        19:00:00|     USD|     39.5|     55.0|\n",
      "|Houston Astros vs...|     \"NaN\"|Z7r9jZ1AdpZqd|https://www.ticke...|    Minute Maid Park|  Z6r9jZkeke|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Crawford Street|     -95.362999|     29.759399|      Houston Astros|     attraction|  K8vZ91718zV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdv|             Baseball|   KZazBEonSMnZfZ7vF1n|                     MLB|      2023-07-28|       onsale|        19:10:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Asking Alexandria...|  standard|G5dIZ9i0sEabf|https://concerts....|      713 Music Hall| KovZ917APwH|        77201|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 401 Franklin Street|      -95.36416|      29.76539|   Asking Alexandria|     attraction|  K8vZ917GI6V|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-09-03|       onsale|        18:30:00|     USD|     45.0|     69.5|\n",
      "|              Demola|  standard|G5dIZ9n9wZbJV|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797|              Demola|     attraction|  K8vZ917hbP7|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAee|                  R&B|   KZazBEonSMnZfZ7vkIt|                     R&B|      2023-08-19|       onsale|        19:00:00|     USD|     39.5|     69.5|\n",
      "|          Black Flag|  standard|G5dIZ9I63OkhO|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797|          Black Flag|     attraction|  K8vZ9178Xkf|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6a6|                    Punk|      2023-08-04|       onsale|        20:00:00|     USD|     25.0|     25.0|\n",
      "|Whoreible Decisio...|  standard|G5dIZ9tQxOdnF|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797| Wh**eible Decisions|     attraction|  K8vZ917b-Cf|https://www.liven...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-07-06|       onsale|        20:00:00|     USD|     35.0|     65.0|\n",
      "|Jurassic World Li...|  standard|G5dIZ9J2Uq1xW|https://www.ticke...|         NRG Stadium|KovZpZAEdFeA|        77054|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        One NRG Park|     -95.410875|     29.684885|Jurassic World Li...|     attraction|  K8vZ9179ScV|https://www.ticke...|   KZFzniwnSyZfZ7v7n1|          Miscellaneous|        KnvZfZ7vA1n|               Family|   KZazBEonSMnZfZ7vaav|                   Other|      2023-08-05|       onsale|        19:00:00|     USD|     20.0|    175.0|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "23/06/22 21:39:40 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@45dc6a93 committed.\n",
      "23/06/22 21:39:40 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/108 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.108.c305f454-68d8-4cb4-bcd8-33f6c7ad8587.tmp\n",
      "23/06/22 21:39:40 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.108.c305f454-68d8-4cb4-bcd8-33f6c7ad8587.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/108\n",
      "23/06/22 21:39:40 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:39:40.005Z\",\n",
      "  \"batchId\" : 108,\n",
      "  \"numInputRows\" : 39,\n",
      "  \"inputRowsPerSecond\" : 3.8988303508947317,\n",
      "  \"processedRowsPerSecond\" : 92.63657957244656,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 253,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 3,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 421,\n",
      "    \"walCommit\" : 79\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1795\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1834\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 39,\n",
      "    \"inputRowsPerSecond\" : 3.8988303508947317,\n",
      "    \"processedRowsPerSecond\" : 92.63657957244656\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 39\n",
      "  }\n",
      "}\n",
      "23/06/22 21:39:40 INFO FileFormatWriter: Write Job c3077c63-3b5e-4aa3-87f4-e4a924cc6d59 committed. Elapsed time: 1915 ms.\n",
      "23/06/22 21:39:40 INFO FileFormatWriter: Finished processing stats for write job c3077c63-3b5e-4aa3-87f4-e4a924cc6d59.\n",
      "23/06/22 21:39:41 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687482506437-c1c158d9-ebc3-44ce-b8a3-5b500d452dcc/part-00000-b99979c1-6355-48cd-a828-fb3c1448e7c5-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=7706cc31-b902-41e2-9724-bd317c5685e3, location=US}\n",
      "23/06/22 21:39:42 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=7706cc31-b902-41e2-9724-bd317c5685e3, location=US}\n",
      "23/06/22 21:39:43 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/185 using temp file gs://kafka-spark-data/spark-metadata/commits/.185.186fdd3a-84b0-4826-af81-fede1bfdcaf2.tmp\n",
      "23/06/22 21:39:44 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.185.186fdd3a-84b0-4826-af81-fede1bfdcaf2.tmp to gs://kafka-spark-data/spark-metadata/commits/185\n",
      "23/06/22 21:39:44 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:39:33.878Z\",\n",
      "  \"batchId\" : 185,\n",
      "  \"numInputRows\" : 46,\n",
      "  \"inputRowsPerSecond\" : 3.899626992200746,\n",
      "  \"processedRowsPerSecond\" : 4.183339396144052,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6881,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 20,\n",
      "    \"queryPlanning\" : 7,\n",
      "    \"triggerExecution\" : 10996,\n",
      "    \"walCommit\" : 2274\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1764\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1810\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 46,\n",
      "    \"inputRowsPerSecond\" : 3.899626992200746,\n",
      "    \"processedRowsPerSecond\" : 4.183339396144052\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:39:44 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 11005 milliseconds\n",
      "23/06/22 21:39:44 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:44 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 1853.\n",
      "23/06/22 21:39:45 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/186 using temp file gs://kafka-spark-data/spark-metadata/offsets/.186.282826ed-8f60-4296-8c51-00fc5fb96e6e.tmp\n",
      "23/06/22 21:39:46 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.186.282826ed-8f60-4296-8c51-00fc5fb96e6e.tmp to gs://kafka-spark-data/spark-metadata/offsets/186\n",
      "23/06/22 21:39:46 INFO MicroBatchExecution: Committed offsets for batch 186. Metadata OffsetSeqMetadata(0,1687487984891,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:39:47 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:47 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:47 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:47 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:47 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:39:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:39:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:39:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:39:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:39:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:39:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:39:47 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:39:47 INFO DAGScheduler: Got job 229 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:39:47 INFO DAGScheduler: Final stage: ResultStage 230 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:39:47 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:39:47 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:39:47 INFO DAGScheduler: Submitting ResultStage 230 (MapPartitionsRDD[1212] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:39:47 INFO MemoryStore: Block broadcast_229 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/22 21:39:47 INFO MemoryStore: Block broadcast_229_piece0 stored as bytes in memory (estimated size 94.8 KiB, free 434.0 MiB)\n",
      "23/06/22 21:39:47 INFO BlockManagerInfo: Added broadcast_229_piece0 in memory on 192.168.4.24:51040 (size: 94.8 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:39:47 INFO SparkContext: Created broadcast 229 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:39:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 230 (MapPartitionsRDD[1212] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:39:47 INFO TaskSchedulerImpl: Adding task set 230.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:39:47 INFO TaskSetManager: Starting task 0.0 in stage 230.0 (TID 229) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:39:47 INFO Executor: Running task 0.0 in stage 230.0 (TID 229)\n",
      "23/06/22 21:39:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:39:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:39:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:39:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:39:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:39:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:39:47 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:39:47 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:39:47 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/22 21:39:47 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/22 21:39:47 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/22 21:39:47 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/22 21:39:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/22 21:39:47 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 1824 for partition ticketmaster-0\n",
      "23/06/22 21:39:47 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:47 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:39:47 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:47 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 1866.\n",
      "23/06/22 21:39:47 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 1825 for partition ticketmaster-0\n",
      "23/06/22 21:39:47 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 230:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:39:48 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:39:48 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:48 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 1867.\n",
      "23/06/22 21:39:49 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-51e5f9b0-e65f-4224-8f3c-a9884a02be4e/_temporary/0/_temporary/' directory.\n",
      "23/06/22 21:39:49 INFO FileOutputCommitter: Saved output of task 'attempt_20230622213947663736911554730772_0230_m_000000_229' to gs://kafka-spark-data/.spark-bigquery-local-1687482506437-51e5f9b0-e65f-4224-8f3c-a9884a02be4e/_temporary/0/task_20230622213947663736911554730772_0230_m_000000\n",
      "23/06/22 21:39:49 INFO SparkHadoopMapRedUtil: attempt_20230622213947663736911554730772_0230_m_000000_229: Committed. Elapsed time: 867 ms.\n",
      "23/06/22 21:39:49 INFO Executor: Finished task 0.0 in stage 230.0 (TID 229). 2536 bytes result sent to driver\n",
      "23/06/22 21:39:49 INFO TaskSetManager: Finished task 0.0 in stage 230.0 (TID 229) in 1910 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:39:49 INFO TaskSchedulerImpl: Removed TaskSet 230.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:39:49 INFO DAGScheduler: ResultStage 230 (start at NativeMethodAccessorImpl.java:0) finished in 1.930 s\n",
      "23/06/22 21:39:49 INFO DAGScheduler: Job 229 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:39:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 230: Stage finished\n",
      "23/06/22 21:39:49 INFO DAGScheduler: Job 229 finished: start at NativeMethodAccessorImpl.java:0, took 1.931706 s\n",
      "23/06/22 21:39:49 INFO FileFormatWriter: Start to commit write Job ee0c4e8f-60f3-4508-b194-fbc49ea4489a.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:39:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 1874.\n",
      "23/06/22 21:39:50 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/109 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.109.47bb04c9-9ba2-4259-a32e-da0b4ce62066.tmp\n",
      "23/06/22 21:39:50 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.109.47bb04c9-9ba2-4259-a32e-da0b4ce62066.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/109\n",
      "23/06/22 21:39:50 INFO MicroBatchExecution: Committed offsets for batch 109. Metadata OffsetSeqMetadata(0,1687487990006,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:39:50 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:50 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:50 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:50 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:50 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:50 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:39:50 INFO WriteToDataSourceV2Exec: Start processing data source write support: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@4a946fd0. The input RDD has 1 partitions.\n",
      "23/06/22 21:39:50 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:39:50 INFO DAGScheduler: Got job 230 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:39:50 INFO DAGScheduler: Final stage: ResultStage 231 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:39:50 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:39:50 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:39:50 INFO DAGScheduler: Submitting ResultStage 231 (MapPartitionsRDD[1215] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:39:50 INFO MemoryStore: Block broadcast_230 stored as values in memory (estimated size 23.0 KiB, free 434.0 MiB)\n",
      "23/06/22 21:39:50 INFO MemoryStore: Block broadcast_230_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 434.0 MiB)\n",
      "23/06/22 21:39:50 INFO BlockManagerInfo: Added broadcast_230_piece0 in memory on 192.168.4.24:51040 (size: 9.9 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:39:50 INFO SparkContext: Created broadcast 230 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:39:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 231 (MapPartitionsRDD[1215] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:39:50 INFO TaskSchedulerImpl: Adding task set 231.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:39:50 INFO TaskSetManager: Starting task 0.0 in stage 231.0 (TID 230) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:39:50 INFO Executor: Running task 0.0 in stage 231.0 (TID 230)\n",
      "23/06/22 21:39:50 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 1835 for partition ticketmaster-0\n",
      "23/06/22 21:39:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:39:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 1874.\n",
      "23/06/22 21:39:50 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 1836 for partition ticketmaster-0\n",
      "23/06/22 21:39:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:39:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 1875.\n",
      "23/06/22 21:39:50 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 230, attempt 0, stage 231.0)\n",
      "23/06/22 21:39:50 INFO DataWritingSparkTask: Committed partition 0 (task 230, attempt 0, stage 231.0)\n",
      "23/06/22 21:39:50 INFO Executor: Finished task 0.0 in stage 231.0 (TID 230). 37156 bytes result sent to driver\n",
      "23/06/22 21:39:50 INFO TaskSetManager: Finished task 0.0 in stage 231.0 (TID 230) in 139 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:39:50 INFO TaskSchedulerImpl: Removed TaskSet 231.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:39:50 INFO DAGScheduler: ResultStage 231 (start at NativeMethodAccessorImpl.java:0) finished in 0.142 s\n",
      "23/06/22 21:39:50 INFO DAGScheduler: Job 230 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:39:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 231: Stage finished\n",
      "23/06/22 21:39:50 INFO DAGScheduler: Job 230 finished: start at NativeMethodAccessorImpl.java:0, took 0.143242 s\n",
      "23/06/22 21:39:50 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@4a946fd0 is committing.\n",
      "-------------------------------------------\n",
      "Batch: 109\n",
      "-------------------------------------------\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|          event_name|event_type|     event_id|           event_url|          venue_name|    venue_id|venue_zipcode|venues_timezone|venue_city|venue_state_full|venue_state_short|  venue_country_name|venue_country_short|       venue_address|venue_longitude|venue_latitude|     attraction_name|attraction_type|attraction_id|      attraction_url|attraction_segment_id|attraction_segment_name|attraction_genre_id|attraction_genre_name|attraction_subgenre_id|attraction_subgenre_name|event_start_date|ticket_status|event_start_time|currency|min_price|max_price|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|            La Mafia|  standard|G5dIZ9tRum46S|https://www.ticke...|       Arena Theatre|KovZpZAJJ7FA|        77074|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 7326 Southwest Fwy,|     -95.517765|     29.702271|            La Mafia|     attraction|  K8vZ9171QXV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeF|                World|   KZazBEonSMnZfZ7vFdJ|                   Latin|      2023-10-21|       onsale|        20:30:00|     USD|    48.65|   116.96|\n",
      "|Hold My Beer & Wa...|  standard|G5dIZ9nBnKxi3|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797|        Randy Rogers|     attraction|  K8vZ9174gyV|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv6|              Country|   KZazBEonSMnZfZ7vAFa|                 Country|      2023-08-17|       onsale|        19:00:00|     USD|     25.0|     59.5|\n",
      "|     Charlie Robison|  standard|G5dIZ9irp_wlr|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797|     Charlie Robison|     attraction|  K8vZ9171HQf|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv6|              Country|   KZazBEonSMnZfZ7vAFa|                 Country|      2023-08-26|       onsale|        19:00:00|     USD|     39.5|     55.0|\n",
      "|Lupita D'Alessio ...|  standard|G5dIZ9tuRvof0|https://concerts....|  Bayou Music Center|KovZpZAEkIIA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      520 Texas Ave.|    -95.3672891|    29.7628087|    Lupita D'alessio|     attraction|  K8vZ917Gunf|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAev|                  Pop|   KZazBEonSMnZfZ7vk1t|                     Pop|      2023-10-15|       onsale|        20:00:00|     USD|    78.25|   198.25|\n",
      "|Los Huracanes del...|  standard|G5dIZ9l_DOvhW|https://www.ticke...|       Arena Theatre|KovZpZAJJ7FA|        77074|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 7326 Southwest Fwy,|     -95.517765|     29.702271|Los Huracanes del...|     attraction|  K8vZ917G6t7|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeF|                World|   KZazBEonSMnZfZ7vFdJ|                   Latin|      2023-09-29|       onsale|        20:00:00|     USD|     49.5|    119.5|\n",
      "|LP - Love Lines Tour|  standard|G5dIZ9nK4aFG7|https://concerts....|  Bayou Music Center|KovZpZAEkIIA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      520 Texas Ave.|    -95.3672891|    29.7628087|                  LP|     attraction|  K8vZ9172MA0|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6dt|        Alternative Rock|      2023-11-18|       onsale|        20:00:00|     USD|     37.5|     69.5|\n",
      "|Nothing More - Sp...|  standard|G5dIZ9ihSoID3|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797|        Nothing More|     attraction|  K8vZ9172tCf|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-09-15|       onsale|        17:30:00|     USD|     39.5|     64.5|\n",
      "|Houston Astros vs...|     \"NaN\"|Z7r9jZ1AdpZrf|https://www.ticke...|    Minute Maid Park|  Z6r9jZkeke|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Crawford Street|     -95.362999|     29.759399|      Houston Astros|     attraction|  K8vZ91718zV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdv|             Baseball|   KZazBEonSMnZfZ7vF1n|                     MLB|      2023-08-20|       onsale|        12:05:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "| The Molly Ringwalds|  standard|G5dIZ9trQkNvp|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797| The Molly Ringwalds|     attraction|  K8vZ917GI37|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAe6|            Undefined|   KZazBEonSMnZfZ7v6JI|               Undefined|      2023-08-18|       onsale|        19:00:00|     USD|     12.5|     42.5|\n",
      "|  Hannah Berner Live|  standard|G5dIZ9tIdGywL|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797|       Hannah Berner|     attraction|  K8vZ917bRU7|https://www.liven...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-09-17|       onsale|        19:00:00|     USD|     40.0|     69.5|\n",
      "|Jurassic World Li...|  standard|G5dIZ9J2Un1NF|https://www.ticke...|         NRG Stadium|KovZpZAEdFeA|        77054|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        One NRG Park|     -95.410875|     29.684885|Jurassic World Li...|     attraction|  K8vZ9179ScV|https://www.ticke...|   KZFzniwnSyZfZ7v7n1|          Miscellaneous|        KnvZfZ7vA1n|               Family|   KZazBEonSMnZfZ7vaav|                   Other|      2023-08-06|       onsale|        17:00:00|     USD|     20.0|    175.0|\n",
      "|RAYE: My 21st Cen...|  standard|G5dIZ9iaTcg0o|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797|                RAYE|     attraction|  K8vZ917Kvt7|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAev|                  Pop|   KZazBEonSMnZfZ7vk1t|                     Pop|      2023-10-14|       onsale|        19:00:00|     USD|     29.5|     59.5|\n",
      "|     Christian Nodal|     \"NaN\"|Z7r9jZ1Adx6Zf|https://www.ticke...|  Toyota Center - TX|  ZFr9jZ7v7v|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        1510 Polk St|     -95.362999|     29.759399|     Christian Nodal|     attraction|  K8vZ917p2Pf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeF|                World|   KZazBEonSMnZfZ7vFdJ|                   Latin|      2023-09-21|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Wizkid - More Lov...|  standard|G5dIZ9tSmd9bu|https://concerts....|      713 Music Hall| KovZ917APwH|        77201|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 401 Franklin Street|      -95.36416|      29.76539|              Wizkid|     attraction|  K8vZ917COs0|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkdA|                   Urban|      2023-11-25|       onsale|        19:30:00|     USD|     49.5|    149.5|\n",
      "|          Maria Jose|  standard|G5dIZ9n2_jk_o|https://www.ticke...|       Arena Theatre|KovZpZAJJ7FA|        77074|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 7326 Southwest Fwy,|     -95.517765|     29.702271|          Maria Jose|     attraction|  K8vZ917CMWV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeF|                World|   KZazBEonSMnZfZ7vFdJ|                   Latin|      2023-11-18|       onsale|        20:00:00|     USD|    36.23|   129.38|\n",
      "|Wheeler Walker, J...|  standard|G5dIZ9tRvf7M5|https://www.ticke...|White Oak Music H...| KovZ917AiGZ|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      2915 N Main St|      -95.36562|      29.78627|  Wheeler Walker Jr.|     attraction|  K8vZ917fIMf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv6|              Country|   KZazBEonSMnZfZ7vAFa|                 Country|      2023-11-16|       onsale|        19:00:00|     USD|     35.0|     35.0|\n",
      "|Bruno Major: Tour...|  standard|G5dIZ9nCJ5Ka-|https://www.ticke...|White Oak Music H...| KovZ917AiGZ|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      2915 N Main St|      -95.36562|      29.78627|         Bruno Major|     attraction|  K8vZ9173Pt0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-09-20|       onsale|        19:00:00|     USD|     29.0|     29.0|\n",
      "|THE MATT AND KIM ...|  standard|G5dIZ9JOUAz5Y|https://www.ticke...|White Oak Music H...| KovZ917AiGZ|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      2915 N Main St|      -95.36562|      29.78627|        Matt and Kim|     attraction|  K8vZ917GlK0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-09-13|       onsale|        19:00:00|     USD|     30.0|     30.0|\n",
      "|       Chumel Torres|  standard|G5dIZ9IMMZFaE|https://www.ticke...|       Arena Theatre|KovZpZAJJ7FA|        77074|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 7326 Southwest Fwy,|     -95.517765|     29.702271|       Chumel Torres|     attraction|  K8vZ917hZ1V|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-06-24|       onsale|        20:30:00|     USD|    36.23|    93.15|\n",
      "|Akaash Singh Live...|  standard|G5dIZ9ibnE_WP|https://www.ticke...|White Oak Music H...| KovZ917AiGZ|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      2915 N Main St|      -95.36562|      29.78627|        Akaash Singh|     attraction|  K8vZ917bPzV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-09-02|       onsale|        17:30:00|     USD|     20.0|     20.0|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "23/06/22 21:39:50 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@4a946fd0 committed.\n",
      "23/06/22 21:39:50 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/109 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.109.c9bf1abd-e878-464b-b4c1-5743cf112b0e.tmp\n",
      "23/06/22 21:39:50 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.109.c9bf1abd-e878-464b-b4c1-5743cf112b0e.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/109\n",
      "23/06/22 21:39:50 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:39:50.003Z\",\n",
      "  \"batchId\" : 109,\n",
      "  \"numInputRows\" : 40,\n",
      "  \"inputRowsPerSecond\" : 4.000800160032006,\n",
      "  \"processedRowsPerSecond\" : 102.82776349614396,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 172,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 3,\n",
      "    \"queryPlanning\" : 9,\n",
      "    \"triggerExecution\" : 389,\n",
      "    \"walCommit\" : 86\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1834\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1874\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 40,\n",
      "    \"inputRowsPerSecond\" : 4.000800160032006,\n",
      "    \"processedRowsPerSecond\" : 102.82776349614396\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 40\n",
      "  }\n",
      "}\n",
      "23/06/22 21:39:50 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-51e5f9b0-e65f-4224-8f3c-a9884a02be4e/_temporary/0/task_20230622213947663736911554730772_0230_m_000000/' directory.\n",
      "23/06/22 21:39:51 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-51e5f9b0-e65f-4224-8f3c-a9884a02be4e/' directory.\n",
      "23/06/22 21:39:51 INFO FileFormatWriter: Write Job ee0c4e8f-60f3-4508-b194-fbc49ea4489a committed. Elapsed time: 2023 ms.\n",
      "23/06/22 21:39:51 INFO FileFormatWriter: Finished processing stats for write job ee0c4e8f-60f3-4508-b194-fbc49ea4489a.\n",
      "23/06/22 21:39:51 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687482506437-51e5f9b0-e65f-4224-8f3c-a9884a02be4e/part-00000-64200c24-8a3f-4c9f-bc0f-30670d738f17-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=f569a5cc-2b20-46cd-acd4-85f9c37a3a0c, location=US}\n",
      "23/06/22 21:39:54 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=f569a5cc-2b20-46cd-acd4-85f9c37a3a0c, location=US}\n",
      "23/06/22 21:39:55 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/186 using temp file gs://kafka-spark-data/spark-metadata/commits/.186.f0eb2d79-2b25-4d9d-a2d1-857b31b92910.tmp\n",
      "23/06/22 21:39:56 INFO BlockManagerInfo: Removed broadcast_229_piece0 on 192.168.4.24:51040 in memory (size: 94.8 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:39:56 INFO BlockManagerInfo: Removed broadcast_230_piece0 on 192.168.4.24:51040 in memory (size: 9.9 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:39:57 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.186.f0eb2d79-2b25-4d9d-a2d1-857b31b92910.tmp to gs://kafka-spark-data/spark-metadata/commits/186\n",
      "23/06/22 21:39:57 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:39:44.883Z\",\n",
      "  \"batchId\" : 186,\n",
      "  \"numInputRows\" : 43,\n",
      "  \"inputRowsPerSecond\" : 3.9073148568832345,\n",
      "  \"processedRowsPerSecond\" : 3.402975625197848,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 8325,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 6,\n",
      "    \"queryPlanning\" : 34,\n",
      "    \"triggerExecution\" : 12635,\n",
      "    \"walCommit\" : 2080\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1810\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1853\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 43,\n",
      "    \"inputRowsPerSecond\" : 3.9073148568832345,\n",
      "    \"processedRowsPerSecond\" : 3.402975625197848\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:39:57 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 12636 milliseconds\n",
      "23/06/22 21:39:57 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:39:57 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 1903.\n",
      "23/06/22 21:39:58 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/187 using temp file gs://kafka-spark-data/spark-metadata/offsets/.187.2213b26f-4045-447f-abea-346f0c50c41f.tmp\n",
      "23/06/22 21:39:59 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.187.2213b26f-4045-447f-abea-346f0c50c41f.tmp to gs://kafka-spark-data/spark-metadata/offsets/187\n",
      "23/06/22 21:39:59 INFO MicroBatchExecution: Committed offsets for batch 187. Metadata OffsetSeqMetadata(0,1687487997524,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:40:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 1913.\n",
      "23/06/22 21:40:00 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/110 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.110.35a4cb23-9c5c-44c1-ba1c-6ec7cb3acfe5.tmp\n",
      "23/06/22 21:40:00 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.110.35a4cb23-9c5c-44c1-ba1c-6ec7cb3acfe5.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/110\n",
      "23/06/22 21:40:00 INFO MicroBatchExecution: Committed offsets for batch 110. Metadata OffsetSeqMetadata(0,1687488000006,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:40:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:00 INFO WriteToDataSourceV2Exec: Start processing data source write support: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@4f7af0f2. The input RDD has 1 partitions.\n",
      "23/06/22 21:40:00 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:40:00 INFO DAGScheduler: Got job 231 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:40:00 INFO DAGScheduler: Final stage: ResultStage 232 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:40:00 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:40:00 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:40:00 INFO DAGScheduler: Submitting ResultStage 232 (MapPartitionsRDD[1218] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:40:00 INFO MemoryStore: Block broadcast_231 stored as values in memory (estimated size 23.0 KiB, free 434.4 MiB)\n",
      "23/06/22 21:40:00 INFO MemoryStore: Block broadcast_231_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 434.4 MiB)\n",
      "23/06/22 21:40:00 INFO BlockManagerInfo: Added broadcast_231_piece0 in memory on 192.168.4.24:51040 (size: 9.9 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:40:00 INFO SparkContext: Created broadcast 231 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:40:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 232 (MapPartitionsRDD[1218] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:40:00 INFO TaskSchedulerImpl: Adding task set 232.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:40:00 INFO TaskSetManager: Starting task 0.0 in stage 232.0 (TID 231) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:40:00 INFO Executor: Running task 0.0 in stage 232.0 (TID 231)\n",
      "23/06/22 21:40:00 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 1874 for partition ticketmaster-0\n",
      "23/06/22 21:40:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:40:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 1913.\n",
      "23/06/22 21:40:00 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 1875 for partition ticketmaster-0\n",
      "23/06/22 21:40:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:40:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 1914.\n",
      "23/06/22 21:40:00 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 231, attempt 0, stage 232.0)\n",
      "23/06/22 21:40:00 INFO DataWritingSparkTask: Committed partition 0 (task 231, attempt 0, stage 232.0)\n",
      "23/06/22 21:40:00 INFO Executor: Finished task 0.0 in stage 232.0 (TID 231). 36785 bytes result sent to driver\n",
      "23/06/22 21:40:00 INFO TaskSetManager: Finished task 0.0 in stage 232.0 (TID 231) in 120 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:40:00 INFO TaskSchedulerImpl: Removed TaskSet 232.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:40:00 INFO DAGScheduler: ResultStage 232 (start at NativeMethodAccessorImpl.java:0) finished in 0.122 s\n",
      "23/06/22 21:40:00 INFO DAGScheduler: Job 231 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:40:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 232: Stage finished\n",
      "23/06/22 21:40:00 INFO DAGScheduler: Job 231 finished: start at NativeMethodAccessorImpl.java:0, took 0.122850 s\n",
      "23/06/22 21:40:00 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@4f7af0f2 is committing.\n",
      "-------------------------------------------\n",
      "Batch: 110\n",
      "-------------------------------------------\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|          event_name|event_type|     event_id|           event_url|          venue_name|    venue_id|venue_zipcode|venues_timezone|venue_city|venue_state_full|venue_state_short|  venue_country_name|venue_country_short|       venue_address|venue_longitude|venue_latitude|     attraction_name|attraction_type|attraction_id|      attraction_url|attraction_segment_id|attraction_segment_name|attraction_genre_id|attraction_genre_name|attraction_subgenre_id|attraction_subgenre_name|event_start_date|ticket_status|event_start_time|currency|min_price|max_price|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|Thunder From Down...|  standard|G5dIZ9l9eCd1Z|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797|Thunder From Down...|     attraction|  K8vZ9171Pv7|https://www.liven...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7ld| Miscellaneous The...|   KZazBEonSMnZfZ7v7lk|    Miscellaneous The...|      2023-08-02|       onsale|        19:00:00|     USD|     25.0|     45.0|\n",
      "|Ain't Too Proud -...|  standard|G5dIZ9Pbrz_-6|https://www.ticke...|        Hobby Center|KovZpZAJJEaA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|           800 Bagby|     -95.368798|    29.7617639|Ain't Too Proud -...|     attraction|  K8vZ917bgM7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-08-10|       onsale|        19:30:00|     USD|     40.0|    150.0|\n",
      "|Bishop Briggs & M...|  standard|G5dIZ9tcZPF_a|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797|       Bishop Briggs|     attraction|  K8vZ917fI17|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvv|          Alternative|   KZazBEonSMnZfZ7vAvn|        Alternative Rock|      2023-10-04|       onsale|        18:00:00|     USD|     39.5|     49.5|\n",
      "|         Nicole Byer|  standard|G5dIZ9ihxpIaM|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797|         Nicole Byer|     attraction|  K8vZ917f9T7|https://www.liven...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-10-20|       onsale|        19:00:00|     USD|     30.0|     69.5|\n",
      "|           Ann Marie|  standard|G5dIZ9isepb_F|https://concerts....|The Bronze Peacoc...| KovZ917A58V|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|     -95.364056|     29.753929|           Ann Marie|     attraction|  K8vZ9179D30|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAee|                  R&B|   KZazBEonSMnZfZ7vkIt|                     R&B|      2023-07-27|       onsale|        19:00:00|     USD|     25.0|     25.0|\n",
      "|Hulvey - The Beau...|  standard|G5dIZ9nRk1JGR|https://concerts....|The Bronze Peacoc...| KovZ917A58V|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|     -95.364056|     29.753929|              Hulvey|     attraction|  K8vZ917h_n0|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkdA|                   Urban|      2023-08-11|       onsale|        19:00:00|     USD|     20.0|     20.0|\n",
      "|Carousel Club Bur...|  standard|G5dIZ9t1Hyfct|https://concerts....|The Bronze Peacoc...| KovZ917A58V|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|     -95.364056|     29.753929|Carousel Club Bur...|     attraction|  K8vZ917_nG7|https://www.liven...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7lJ|              Variety|   KZazBEonSMnZfZ7vAv7|                 Cabaret|      2023-06-30|       onsale|        19:00:00|     USD|     25.0|     50.0|\n",
      "|Aly & AJ: With Lo...|  standard|G5dIZ9l-Xdvbw|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797|            Aly & AJ|     attraction|  K8vZ9175gP0|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-09-14|       onsale|        19:00:00|     USD|     39.5|     49.5|\n",
      "|Houston Astros vs...|     \"NaN\"|Z7r9jZ1AdpZq3|https://www.ticke...|    Minute Maid Park|  Z6r9jZkeke|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Crawford Street|     -95.362999|     29.759399|      Houston Astros|     attraction|  K8vZ91718zV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdv|             Baseball|   KZazBEonSMnZfZ7vF1n|                     MLB|      2023-08-12|       onsale|        18:15:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Ain't Too Proud -...|  standard|G5dIZ9PbrWa-4|https://www.ticke...|        Hobby Center|KovZpZAJJEaA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|           800 Bagby|     -95.368798|    29.7617639|Ain't Too Proud -...|     attraction|  K8vZ917bgM7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-08-11|       onsale|        20:00:00|     USD|     40.0|    150.0|\n",
      "|       Edith Marquez|  standard|G5dIZ9tK3j6bL|https://www.ticke...|       Arena Theatre|KovZpZAJJ7FA|        77074|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 7326 Southwest Fwy,|     -95.517765|     29.702271|       Edith Marquez|     attraction|  K8vZ917GGo7|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeF|                World|   KZazBEonSMnZfZ7vFdJ|                   Latin|      2023-10-13|       onsale|        21:00:00|     USD|     49.0|    199.0|\n",
      "|Ain't Too Proud -...|  standard|G5dIZ9PbriyOe|https://www.ticke...|        Hobby Center|KovZpZAJJEaA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|           800 Bagby|     -95.368798|    29.7617639|Ain't Too Proud -...|     attraction|  K8vZ917bgM7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-08-08|       onsale|        19:30:00|     USD|     40.0|    150.0|\n",
      "|Killer Mike and t...|  standard|G5dIZ9tiwMz5W|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797|         Killer Mike|     attraction|  K8vZ9175fwV|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkdA|                   Urban|      2023-08-03|       onsale|        19:00:00|     USD|     35.0|     55.0|\n",
      "|Houston Astros vs...|     \"NaN\"|Z7r9jZ1AdpZqf|https://www.ticke...|    Minute Maid Park|  Z6r9jZkeke|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Crawford Street|     -95.362999|     29.759399|      Houston Astros|     attraction|  K8vZ91718zV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdv|             Baseball|   KZazBEonSMnZfZ7vF1n|                     MLB|      2023-07-26|       onsale|        19:10:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Peter McPoland: T...|  standard|G5dIZ9lmPbvg0|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797|      Peter McPoland|     attraction|  K8vZ917_hNf|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvv|          Alternative|   KZazBEonSMnZfZ7vAdv|               Indie Pop|      2023-11-11|       onsale|        19:00:00|     USD|     25.0|     25.0|\n",
      "|PAW Patrol Live! ...|  standard|G5dIZ9ib7ByCk|https://www.ticke...|        Hobby Center|KovZpZAJJEaA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|           800 Bagby|     -95.368798|    29.7617639|PAW Patrol Live! ...|     attraction|  K8vZ917bVxV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7na|   Children's Theatre|   KZazBEonSMnZfZ7v7na|      Children's Theatre|      2023-11-05|      offsale|        16:00:00|     USD|     45.0|    170.0|\n",
      "|Los Gemelos de Si...|  standard|G5dIZ9lENTPls|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797|Los Gemelos De Si...|     attraction|  K8vZ917Q9lf|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAJ6|                Latin|   KZazBEonSMnZfZ7va1a|                   Latin|      2023-07-08|       onsale|        19:00:00|     USD|     75.0|    125.0|\n",
      "|Ain't Too Proud -...|  standard|G5dIZ9PbrwtOm|https://www.ticke...|        Hobby Center|KovZpZAJJEaA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|           800 Bagby|     -95.368798|    29.7617639|Ain't Too Proud -...|     attraction|  K8vZ917bgM7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-08-09|       onsale|        19:30:00|     USD|     40.0|    150.0|\n",
      "|Jidenna - The Sil...|  standard|G5dIZ9ELfzP6A|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797|             Jidenna|     attraction|  K8vZ917K_80|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAee|                  R&B|   KZazBEonSMnZfZ7vkIt|                     R&B|      2023-07-28|    cancelled|        19:00:00|     USD|     30.0|     49.5|\n",
      "|              Hojean|  standard|G5dIZ9ibRNtTp|https://www.ticke...|White Oak Music H...| KovZ917AiGZ|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      2915 N Main St|      -95.36562|      29.78627|              Hojean|     attraction|  K8vZ917Q-90|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAee|                  R&B|   KZazBEonSMnZfZ7vkIt|                     R&B|      2023-10-25|       onsale|        19:00:00|     USD|     18.0|     18.0|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "23/06/22 21:40:00 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@4f7af0f2 committed.\n",
      "23/06/22 21:40:00 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/110 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.110.2e4fdf83-4495-4a96-a288-0319c0fc6c77.tmp\n",
      "23/06/22 21:40:00 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.110.2e4fdf83-4495-4a96-a288-0319c0fc6c77.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/110\n",
      "23/06/22 21:40:00 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:40:00.004Z\",\n",
      "  \"batchId\" : 110,\n",
      "  \"numInputRows\" : 39,\n",
      "  \"inputRowsPerSecond\" : 3.8996100389961006,\n",
      "  \"processedRowsPerSecond\" : 139.78494623655914,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 140,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 2,\n",
      "    \"queryPlanning\" : 4,\n",
      "    \"triggerExecution\" : 279,\n",
      "    \"walCommit\" : 76\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1874\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1913\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 39,\n",
      "    \"inputRowsPerSecond\" : 3.8996100389961006,\n",
      "    \"processedRowsPerSecond\" : 139.78494623655914\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 39\n",
      "  }\n",
      "}\n",
      "23/06/22 21:40:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:01 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:40:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:40:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:40:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:40:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:40:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:40:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:40:01 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:40:01 INFO DAGScheduler: Got job 232 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:40:01 INFO DAGScheduler: Final stage: ResultStage 233 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:40:01 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:40:01 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:40:01 INFO DAGScheduler: Submitting ResultStage 233 (MapPartitionsRDD[1225] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:40:01 INFO MemoryStore: Block broadcast_232 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/22 21:40:01 INFO BlockManagerInfo: Removed broadcast_231_piece0 on 192.168.4.24:51040 in memory (size: 9.9 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:40:01 INFO MemoryStore: Block broadcast_232_piece0 stored as bytes in memory (estimated size 94.8 KiB, free 434.0 MiB)\n",
      "23/06/22 21:40:01 INFO BlockManagerInfo: Added broadcast_232_piece0 in memory on 192.168.4.24:51040 (size: 94.8 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:40:01 INFO SparkContext: Created broadcast 232 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:40:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 233 (MapPartitionsRDD[1225] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:40:01 INFO TaskSchedulerImpl: Adding task set 233.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:40:01 INFO TaskSetManager: Starting task 0.0 in stage 233.0 (TID 232) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:40:01 INFO Executor: Running task 0.0 in stage 233.0 (TID 232)\n",
      "23/06/22 21:40:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:40:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:40:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:40:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:40:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:40:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:40:01 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:40:01 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:40:01 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/22 21:40:01 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/22 21:40:01 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/22 21:40:01 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/22 21:40:01 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/22 21:40:01 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 1866 for partition ticketmaster-0\n",
      "23/06/22 21:40:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:40:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 1920.\n",
      "23/06/22 21:40:01 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 1867 for partition ticketmaster-0\n",
      "23/06/22 21:40:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:40:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 1921.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 233:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:40:03 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-399c3eec-cf8a-4e10-a690-4e413240b0e2/_temporary/0/_temporary/' directory.\n",
      "23/06/22 21:40:03 INFO FileOutputCommitter: Saved output of task 'attempt_202306222140015689680010981364093_0233_m_000000_232' to gs://kafka-spark-data/.spark-bigquery-local-1687482506437-399c3eec-cf8a-4e10-a690-4e413240b0e2/_temporary/0/task_202306222140015689680010981364093_0233_m_000000\n",
      "23/06/22 21:40:03 INFO SparkHadoopMapRedUtil: attempt_202306222140015689680010981364093_0233_m_000000_232: Committed. Elapsed time: 1071 ms.\n",
      "23/06/22 21:40:03 INFO Executor: Finished task 0.0 in stage 233.0 (TID 232). 2536 bytes result sent to driver\n",
      "23/06/22 21:40:03 INFO TaskSetManager: Finished task 0.0 in stage 233.0 (TID 232) in 2111 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:40:03 INFO TaskSchedulerImpl: Removed TaskSet 233.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:40:03 INFO DAGScheduler: ResultStage 233 (start at NativeMethodAccessorImpl.java:0) finished in 2.134 s\n",
      "23/06/22 21:40:03 INFO DAGScheduler: Job 232 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:40:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 233: Stage finished\n",
      "23/06/22 21:40:03 INFO DAGScheduler: Job 232 finished: start at NativeMethodAccessorImpl.java:0, took 2.134965 s\n",
      "23/06/22 21:40:03 INFO FileFormatWriter: Start to commit write Job 500db6a1-1027-4f32-b56c-ce40aa80a3a6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:40:04 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-399c3eec-cf8a-4e10-a690-4e413240b0e2/_temporary/0/task_202306222140015689680010981364093_0233_m_000000/' directory.\n",
      "23/06/22 21:40:05 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-399c3eec-cf8a-4e10-a690-4e413240b0e2/' directory.\n",
      "23/06/22 21:40:06 INFO FileFormatWriter: Write Job 500db6a1-1027-4f32-b56c-ce40aa80a3a6 committed. Elapsed time: 2610 ms.\n",
      "23/06/22 21:40:06 INFO FileFormatWriter: Finished processing stats for write job 500db6a1-1027-4f32-b56c-ce40aa80a3a6.\n",
      "23/06/22 21:40:06 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687482506437-399c3eec-cf8a-4e10-a690-4e413240b0e2/part-00000-3cdb38db-d90e-4b3e-89bc-509e120784ae-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=0833225c-e078-4403-87b3-10c58c330ae0, location=US}\n",
      "23/06/22 21:40:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 1952.\n",
      "23/06/22 21:40:10 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/111 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.111.95eb01bc-e5f7-4241-9bc2-ebc36c9363e2.tmp\n",
      "23/06/22 21:40:10 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=0833225c-e078-4403-87b3-10c58c330ae0, location=US}\n",
      "23/06/22 21:40:10 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.111.95eb01bc-e5f7-4241-9bc2-ebc36c9363e2.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/111\n",
      "23/06/22 21:40:10 INFO MicroBatchExecution: Committed offsets for batch 111. Metadata OffsetSeqMetadata(0,1687488010007,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:40:10 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:10 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:10 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:10 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:10 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:10 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:10 INFO WriteToDataSourceV2Exec: Start processing data source write support: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@14c59fd7. The input RDD has 1 partitions.\n",
      "23/06/22 21:40:10 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:40:10 INFO DAGScheduler: Got job 233 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:40:10 INFO DAGScheduler: Final stage: ResultStage 234 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:40:10 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:40:10 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:40:10 INFO DAGScheduler: Submitting ResultStage 234 (MapPartitionsRDD[1228] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:40:10 INFO MemoryStore: Block broadcast_233 stored as values in memory (estimated size 23.0 KiB, free 434.0 MiB)\n",
      "23/06/22 21:40:10 INFO MemoryStore: Block broadcast_233_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 434.0 MiB)\n",
      "23/06/22 21:40:10 INFO BlockManagerInfo: Added broadcast_233_piece0 in memory on 192.168.4.24:51040 (size: 9.9 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:40:10 INFO SparkContext: Created broadcast 233 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:40:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 234 (MapPartitionsRDD[1228] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:40:10 INFO TaskSchedulerImpl: Adding task set 234.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:40:10 INFO TaskSetManager: Starting task 0.0 in stage 234.0 (TID 233) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:40:10 INFO Executor: Running task 0.0 in stage 234.0 (TID 233)\n",
      "23/06/22 21:40:10 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 1913 for partition ticketmaster-0\n",
      "23/06/22 21:40:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:40:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 1952.\n",
      "23/06/22 21:40:10 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 1914 for partition ticketmaster-0\n",
      "23/06/22 21:40:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:40:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 1953.\n",
      "23/06/22 21:40:10 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 233, attempt 0, stage 234.0)\n",
      "23/06/22 21:40:10 INFO DataWritingSparkTask: Committed partition 0 (task 233, attempt 0, stage 234.0)\n",
      "23/06/22 21:40:10 INFO Executor: Finished task 0.0 in stage 234.0 (TID 233). 36195 bytes result sent to driver\n",
      "23/06/22 21:40:10 INFO TaskSetManager: Finished task 0.0 in stage 234.0 (TID 233) in 57 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:40:10 INFO TaskSchedulerImpl: Removed TaskSet 234.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:40:10 INFO DAGScheduler: ResultStage 234 (start at NativeMethodAccessorImpl.java:0) finished in 0.059 s\n",
      "23/06/22 21:40:10 INFO DAGScheduler: Job 233 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:40:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 234: Stage finished\n",
      "23/06/22 21:40:10 INFO DAGScheduler: Job 233 finished: start at NativeMethodAccessorImpl.java:0, took 0.060013 s\n",
      "23/06/22 21:40:10 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@14c59fd7 is committing.\n",
      "-------------------------------------------\n",
      "Batch: 111\n",
      "-------------------------------------------\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|          event_name|event_type|     event_id|           event_url|          venue_name|    venue_id|venue_zipcode|venues_timezone|venue_city|venue_state_full|venue_state_short|  venue_country_name|venue_country_short|       venue_address|venue_longitude|venue_latitude|     attraction_name|attraction_type|attraction_id|      attraction_url|attraction_segment_id|attraction_segment_name|attraction_genre_id|attraction_genre_name|attraction_subgenre_id|attraction_subgenre_name|event_start_date|ticket_status|event_start_time|currency|min_price|max_price|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|      Próxima Parada|  standard|G5dIZ9iV-PFZp|https://www.ticke...|White Oak Music H...| KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|      Proxima Parada|     attraction|  K8vZ917orPV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAee|                  R&B|   KZazBEonSMnZfZ7vknE|                    Soul|      2023-11-02|      offsale|        19:00:00|     USD|     17.0|     17.0|\n",
      "|Broken Social Sce...|  standard|G5dIZ9iagmgGX|https://www.ticke...|White Oak Music H...| KovZ917AiGZ|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      2915 N Main St|      -95.36562|      29.78627| Broken Social Scene|     attraction|  K8vZ9175U7V|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-09-21|       onsale|        19:00:00|     USD|     30.0|     30.0|\n",
      "|Lil Darkie and th...|  standard|G5dIZ9ipfEvyQ|https://www.ticke...|White Oak Music H...| KovZ917AiGZ|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      2915 N Main St|      -95.36562|      29.78627|          Lil Darkie|     attraction|  K8vZ917_xgV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkvl|             Hip-Hop/Rap|      2023-12-09|       onsale|        18:00:00|     USD|     35.0|     35.0|\n",
      "|Jai Wolf: Blue Ba...|  standard|G5dIZ9nw89KvC|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797|            Jai Wolf|     attraction|  K8vZ917KAS7|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvF|     Dance/Electronic|   KZazBEonSMnZfZ7vAJ1|              Club Dance|      2023-08-13|       onsale|        19:00:00|     USD|     29.5|     29.5|\n",
      "|Houston Astros vs...|     \"NaN\"|Z7r9jZ1AdpZqp|https://www.ticke...|    Minute Maid Park|  Z6r9jZkeke|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Crawford Street|     -95.362999|     29.759399|      Houston Astros|     attraction|  K8vZ91718zV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdv|             Baseball|   KZazBEonSMnZfZ7vF1n|                     MLB|      2023-08-11|       onsale|        19:10:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "| Tanner Usrey wit...|  standard|G5dIZ9lCn74be|https://www.ticke...|White Oak Music H...| KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|        Tanner Usrey|     attraction|  K8vZ917_Yh7|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv6|              Country|   KZazBEonSMnZfZ7vAFa|                 Country|      2023-07-16|       onsale|        19:00:00|     USD|     20.0|     20.0|\n",
      "|Unknown Mortal Or...|  standard|G5dIZ9lrEwSDi|https://www.ticke...|White Oak Music H...| KovZ917AiGZ|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      2915 N Main St|      -95.36562|      29.78627|Unknown Mortal Or...|     attraction|  K8vZ917CZ-V|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-10-26|       onsale|        19:00:00|     USD|     32.0|     32.0|\n",
      "|Piso 21: Los Much...|  standard|G5dIZ9tFA5al1|https://www.ticke...|White Oak Music H...| KovZ917AiGZ|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      2915 N Main St|      -95.36562|      29.78627|             Piso 21|     attraction|  K8vZ9174WPf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvl|                Other|   KZazBEonSMnZfZ7vk1I|                   Other|      2023-09-30|       onsale|        19:00:00|     USD|     60.0|     60.0|\n",
      "|Gable Price And F...|  standard|G5dIZ9I6iq90v|https://concerts....|The Bronze Peacoc...| KovZ917A58V|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|     -95.364056|     29.753929|Gable Price And F...|     attraction|  K8vZ917QSf7|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvv|          Alternative|   KZazBEonSMnZfZ7vAvn|        Alternative Rock|      2023-07-07|       onsale|        19:00:00|     USD|     20.0|     20.0|\n",
      "|      American Fangs|  standard|G5dIZ9c6PBgvK|https://www.ticke...|White Oak Music H...| KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|      American Fangs|     attraction|  K8vZ917Gmmf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6dt|        Alternative Rock|      2023-08-19|       onsale|        19:00:00|     USD|     20.0|     20.0|\n",
      "|Trae Tha Truth pr...|  standard|G5dIZ9cFizpN7|https://www.ticke...|White Oak Music H...| KovZ917AiGZ|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      2915 N Main St|      -95.36562|      29.78627|           Tony Rock|     attraction|  K8vZ9175od7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-07-23|       onsale|        19:00:00|     USD|     42.0|    102.0|\n",
      "|               binki|  standard|G5dIZ9IpAlsq4|https://www.ticke...|White Oak Music H...| KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|               binki|     attraction|  K8vZ917_9Of|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkvl|             Hip-Hop/Rap|      2023-07-14|       onsale|        20:00:00|     USD|     16.0|     16.0|\n",
      "|Peter Gabriel: i/...|     \"NaN\"|Z7r9jZ1AdOEeA|https://www.ticke...|  Toyota Center - TX|  ZFr9jZ7v7v|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        1510 Polk St|     -95.362999|     29.759399|       Peter Gabriel|     attraction|  K8vZ91712N7|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-10-21|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|The Devil Wears P...|  standard|G5dIZ9nO309MT|https://www.ticke...|White Oak Music H...| KovZ917AiGZ|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      2915 N Main St|      -95.36562|      29.78627|      Fit for a King|     attraction|  K8vZ9178xmf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvt|                Metal|   KZazBEonSMnZfZ7vkFd|             Heavy Metal|      2023-10-13|       onsale|        18:00:00|     USD|     36.0|     36.0|\n",
      "|               Ruger|  standard|G5dIZ9lr-2NI_|https://www.ticke...|White Oak Music H...| KovZ917AiGZ|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      2915 N Main St|      -95.36562|      29.78627|               Ruger|     attraction|  K8vZ917QwL0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkdA|                   Urban|      2023-08-19|       onsale|        19:00:00|     USD|    36.99|    91.99|\n",
      "|Phum Viphurit x M...|  standard|G5dIZ9iQsrfPc|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797|       Phum Viphurit|     attraction|  K8vZ917bdx7|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvv|          Alternative|   KZazBEonSMnZfZ7vAdv|               Indie Pop|      2023-08-24|       onsale|        19:00:00|     USD|     27.5|     27.5|\n",
      "|              Lamorn|  standard|G5dIZ9I6Lq97K|https://concerts....|The Bronze Peacoc...| KovZ917A58V|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|     -95.364056|     29.753929|              Lamorn|     attraction|  K8vZ917Qi00|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvF|     Dance/Electronic|   KZazBEonSMnZfZ7vA1E|        Dance/Electronic|      2023-06-22|      offsale|        19:00:00|     USD|     12.5|     12.5|\n",
      "|    Lauren Weintraub|  standard|G5dIZ9PEwube1|https://concerts....|The Bronze Peacoc...| KovZ917A58V|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|     -95.364056|     29.753929|    Lauren Weintraub|     attraction|  K8vZ917_nGV|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv6|              Country|   KZazBEonSMnZfZ7vAFa|                 Country|      2023-06-24|       onsale|        19:00:00|     USD|     15.0|     15.0|\n",
      "|         Senses Fail|  standard|G5dIZ9iLEkJH5|https://www.ticke...|White Oak Music H...| KovZ917AiGZ|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      2915 N Main St|      -95.36562|      29.78627|         Senses Fail|     attraction|  K8vZ9175_of|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-09-06|       onsale|        18:00:00|     USD|     27.0|     27.0|\n",
      "|Houston Astros vs...|     \"NaN\"|Z7r9jZ1AdpZq6|https://www.ticke...|    Minute Maid Park|  Z6r9jZkeke|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Crawford Street|     -95.362999|     29.759399|      Houston Astros|     attraction|  K8vZ91718zV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdv|             Baseball|   KZazBEonSMnZfZ7vF1n|                     MLB|      2023-07-30|       onsale|        13:10:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "23/06/22 21:40:10 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@14c59fd7 committed.\n",
      "23/06/22 21:40:10 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/111 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.111.d7ae11b5-b3c6-4d5e-8193-fc152564b8f0.tmp\n",
      "23/06/22 21:40:10 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.111.d7ae11b5-b3c6-4d5e-8193-fc152564b8f0.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/111\n",
      "23/06/22 21:40:10 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:40:10.002Z\",\n",
      "  \"batchId\" : 111,\n",
      "  \"numInputRows\" : 39,\n",
      "  \"inputRowsPerSecond\" : 3.9007801560312063,\n",
      "  \"processedRowsPerSecond\" : 117.46987951807229,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 83,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 5,\n",
      "    \"queryPlanning\" : 4,\n",
      "    \"triggerExecution\" : 332,\n",
      "    \"walCommit\" : 115\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1913\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1952\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 39,\n",
      "    \"inputRowsPerSecond\" : 3.9007801560312063,\n",
      "    \"processedRowsPerSecond\" : 117.46987951807229\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 39\n",
      "  }\n",
      "}\n",
      "23/06/22 21:40:11 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/187 using temp file gs://kafka-spark-data/spark-metadata/commits/.187.663a1832-69c8-4c0f-968b-edb18c1f40de.tmp\n",
      "23/06/22 21:40:11 INFO BlockManagerInfo: Removed broadcast_232_piece0 on 192.168.4.24:51040 in memory (size: 94.8 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:40:11 INFO BlockManagerInfo: Removed broadcast_233_piece0 on 192.168.4.24:51040 in memory (size: 9.9 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:40:12 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.187.663a1832-69c8-4c0f-968b-edb18c1f40de.tmp to gs://kafka-spark-data/spark-metadata/commits/187\n",
      "23/06/22 21:40:12 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:39:57.519Z\",\n",
      "  \"batchId\" : 187,\n",
      "  \"numInputRows\" : 50,\n",
      "  \"inputRowsPerSecond\" : 3.956948401392846,\n",
      "  \"processedRowsPerSecond\" : 3.2829940906106367,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 10448,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 4,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 15230,\n",
      "    \"walCommit\" : 2825\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1853\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1903\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 50,\n",
      "    \"inputRowsPerSecond\" : 3.956948401392846,\n",
      "    \"processedRowsPerSecond\" : 3.2829940906106367\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:40:12 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 15231 milliseconds\n",
      "23/06/22 21:40:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 1963.\n",
      "23/06/22 21:40:13 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/188 using temp file gs://kafka-spark-data/spark-metadata/offsets/.188.2075c56f-ce75-4b69-8a40-c0389f84aa65.tmp\n",
      "23/06/22 21:40:14 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.188.2075c56f-ce75-4b69-8a40-c0389f84aa65.tmp to gs://kafka-spark-data/spark-metadata/offsets/188\n",
      "23/06/22 21:40:14 INFO MicroBatchExecution: Committed offsets for batch 188. Metadata OffsetSeqMetadata(0,1687488012757,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:40:15 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:15 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:15 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:15 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:15 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:40:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:40:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:40:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:40:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:40:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:40:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:40:16 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:40:16 INFO DAGScheduler: Got job 234 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:40:16 INFO DAGScheduler: Final stage: ResultStage 235 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:40:16 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:40:16 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:40:16 INFO DAGScheduler: Submitting ResultStage 235 (MapPartitionsRDD[1235] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:40:16 INFO MemoryStore: Block broadcast_234 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/22 21:40:16 INFO MemoryStore: Block broadcast_234_piece0 stored as bytes in memory (estimated size 94.8 KiB, free 434.0 MiB)\n",
      "23/06/22 21:40:16 INFO BlockManagerInfo: Added broadcast_234_piece0 in memory on 192.168.4.24:51040 (size: 94.8 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:40:16 INFO SparkContext: Created broadcast 234 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:40:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 235 (MapPartitionsRDD[1235] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:40:16 INFO TaskSchedulerImpl: Adding task set 235.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:40:16 INFO TaskSetManager: Starting task 0.0 in stage 235.0 (TID 234) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:40:16 INFO Executor: Running task 0.0 in stage 235.0 (TID 234)\n",
      "23/06/22 21:40:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:40:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:40:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:40:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:40:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:40:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:40:16 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:40:16 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:40:16 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/22 21:40:16 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/22 21:40:16 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/22 21:40:16 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/22 21:40:16 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/22 21:40:16 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 1920 for partition ticketmaster-0\n",
      "23/06/22 21:40:16 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:16 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:40:16 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:16 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 1978.\n",
      "23/06/22 21:40:16 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 1921 for partition ticketmaster-0\n",
      "23/06/22 21:40:16 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:16 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:40:16 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:16 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 1979.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 235:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:40:18 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-f8b3e03b-a075-4879-a97f-c966e522fe25/_temporary/0/_temporary/' directory.\n",
      "23/06/22 21:40:18 INFO FileOutputCommitter: Saved output of task 'attempt_202306222140165735374150728176644_0235_m_000000_234' to gs://kafka-spark-data/.spark-bigquery-local-1687482506437-f8b3e03b-a075-4879-a97f-c966e522fe25/_temporary/0/task_202306222140165735374150728176644_0235_m_000000\n",
      "23/06/22 21:40:18 INFO SparkHadoopMapRedUtil: attempt_202306222140165735374150728176644_0235_m_000000_234: Committed. Elapsed time: 977 ms.\n",
      "23/06/22 21:40:18 INFO Executor: Finished task 0.0 in stage 235.0 (TID 234). 2536 bytes result sent to driver\n",
      "23/06/22 21:40:18 INFO TaskSetManager: Finished task 0.0 in stage 235.0 (TID 234) in 2091 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:40:18 INFO TaskSchedulerImpl: Removed TaskSet 235.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:40:18 INFO DAGScheduler: ResultStage 235 (start at NativeMethodAccessorImpl.java:0) finished in 2.112 s\n",
      "23/06/22 21:40:18 INFO DAGScheduler: Job 234 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:40:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 235: Stage finished\n",
      "23/06/22 21:40:18 INFO DAGScheduler: Job 234 finished: start at NativeMethodAccessorImpl.java:0, took 2.113591 s\n",
      "23/06/22 21:40:18 INFO FileFormatWriter: Start to commit write Job 10e9c954-be4a-4ce2-9ded-05c2f9362a1c.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:40:19 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-f8b3e03b-a075-4879-a97f-c966e522fe25/_temporary/0/task_202306222140165735374150728176644_0235_m_000000/' directory.\n",
      "23/06/22 21:40:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 1991.\n",
      "23/06/22 21:40:20 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/112 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.112.6c7953a5-2907-4fcc-b091-2923a4be6e79.tmp\n",
      "23/06/22 21:40:20 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.112.6c7953a5-2907-4fcc-b091-2923a4be6e79.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/112\n",
      "23/06/22 21:40:20 INFO MicroBatchExecution: Committed offsets for batch 112. Metadata OffsetSeqMetadata(0,1687488020007,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:40:20 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:20 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:20 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:20 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:20 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:20 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:20 INFO WriteToDataSourceV2Exec: Start processing data source write support: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@6d64c178. The input RDD has 1 partitions.\n",
      "23/06/22 21:40:20 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:40:20 INFO DAGScheduler: Got job 235 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:40:20 INFO DAGScheduler: Final stage: ResultStage 236 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:40:20 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:40:20 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:40:20 INFO DAGScheduler: Submitting ResultStage 236 (MapPartitionsRDD[1238] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:40:20 INFO MemoryStore: Block broadcast_235 stored as values in memory (estimated size 23.0 KiB, free 434.0 MiB)\n",
      "23/06/22 21:40:20 INFO MemoryStore: Block broadcast_235_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 434.0 MiB)\n",
      "23/06/22 21:40:20 INFO BlockManagerInfo: Added broadcast_235_piece0 in memory on 192.168.4.24:51040 (size: 9.9 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:40:20 INFO SparkContext: Created broadcast 235 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:40:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 236 (MapPartitionsRDD[1238] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:40:20 INFO TaskSchedulerImpl: Adding task set 236.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:40:20 INFO TaskSetManager: Starting task 0.0 in stage 236.0 (TID 235) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:40:20 INFO Executor: Running task 0.0 in stage 236.0 (TID 235)\n",
      "23/06/22 21:40:20 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 1952 for partition ticketmaster-0\n",
      "23/06/22 21:40:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:40:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 1991.\n",
      "23/06/22 21:40:20 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 1953 for partition ticketmaster-0\n",
      "23/06/22 21:40:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:40:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 1992.\n",
      "23/06/22 21:40:20 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 235, attempt 0, stage 236.0)\n",
      "23/06/22 21:40:20 INFO DataWritingSparkTask: Committed partition 0 (task 235, attempt 0, stage 236.0)\n",
      "23/06/22 21:40:20 INFO Executor: Finished task 0.0 in stage 236.0 (TID 235). 35705 bytes result sent to driver\n",
      "23/06/22 21:40:20 INFO TaskSetManager: Finished task 0.0 in stage 236.0 (TID 235) in 24 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:40:20 INFO TaskSchedulerImpl: Removed TaskSet 236.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:40:20 INFO DAGScheduler: ResultStage 236 (start at NativeMethodAccessorImpl.java:0) finished in 0.028 s\n",
      "23/06/22 21:40:20 INFO DAGScheduler: Job 235 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:40:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 236: Stage finished\n",
      "23/06/22 21:40:20 INFO DAGScheduler: Job 235 finished: start at NativeMethodAccessorImpl.java:0, took 0.028244 s\n",
      "23/06/22 21:40:20 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@6d64c178 is committing.\n",
      "-------------------------------------------\n",
      "Batch: 112\n",
      "-------------------------------------------\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+---------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|          event_name|event_type|     event_id|           event_url|          venue_name|    venue_id|venue_zipcode|venues_timezone|venue_city|venue_state_full|venue_state_short|  venue_country_name|venue_country_short|       venue_address|venue_longitude|venue_latitude|attraction_name|attraction_type|attraction_id|      attraction_url|attraction_segment_id|attraction_segment_name|attraction_genre_id|attraction_genre_name|attraction_subgenre_id|attraction_subgenre_name|event_start_date|ticket_status|event_start_time|currency|min_price|max_price|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+---------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|          Pour Minds|  standard|G5dIZ9E63V7we|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797|     Pour Minds|     attraction|  K8vZ917Qh37|https://www.liven...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vaaJ|                 Podcast|      2023-11-25|       onsale|        19:00:00|     USD|     30.0|     75.0|\n",
      "|      John R. Miller|  standard|G5dIZ9iUk2o9y|https://www.ticke...|White Oak Music H...| KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627| John R. Miller|     attraction|  K8vZ9179hV0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv6|              Country|   KZazBEonSMnZfZ7vAFa|                 Country|      2023-10-25|      offsale|        19:00:00|     USD|     18.0|     18.0|\n",
      "|        Todrick Hall|  standard|G5dIZ9tllZ6f8|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797|   Todrick Hall|     attraction|  K8vZ9173tA0|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAee|                  R&B|   KZazBEonSMnZfZ7vkIt|                     R&B|      2023-09-27|       onsale|        19:00:00|     USD|     32.5|     45.0|\n",
      "|The Dirty Nil & D...|  standard|G5dIZ900n5tRd|https://www.ticke...|White Oak Music H...| KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|  The Dirty Nil|     attraction|  K8vZ9173IzV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-06-29|       onsale|        18:00:00|     USD|     18.0|     18.0|\n",
      "|Misfit: Gary Gulm...|  standard|G5dIZ9tMrGACY|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797|    Gary Gulman|     attraction|  K8vZ917CDyV|https://www.liven...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-12-01|       onsale|        18:00:00|     USD|     36.0|     54.0|\n",
      "|                 IDK|  standard|G5dIZ9txRoSaw|https://concerts....|The Bronze Peacoc...| KovZ917A58V|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|     -95.364056|     29.753929|            IDK|     attraction|  K8vZ917pp6V|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkvl|             Hip-Hop/Rap|      2023-10-06|       onsale|        19:00:00|     USD|     27.5|     27.5|\n",
      "|           Zella Day|  standard|G5dIZ9I-Bwsp1|https://www.ticke...|White Oak Music H...| KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|      Zella Day|     attraction|  K8vZ917K6Kf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-08-11|       onsale|        20:00:00|     USD|     20.0|     20.0|\n",
      "|           Horsegirl|  standard|G5dIZ9P4gKsY9|https://www.ticke...|White Oak Music H...| KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|      Horsegirl|     attraction|  K8vZ917Q5q7|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-08-03|       onsale|        19:00:00|     USD|     18.0|     18.0|\n",
      "|           Cub Sport|  standard|G5dIZ9PiDpbm-|https://www.ticke...|White Oak Music H...| KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|      Cub Sport|     attraction|  K8vZ917phj0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAev|                  Pop|   KZazBEonSMnZfZ7vkEk|               Indie Pop|      2023-06-30|       onsale|        20:00:00|     USD|     15.0|     15.0|\n",
      "|              Sparta|  standard|G5dIZ9Iitma_3|https://www.ticke...|White Oak Music H...| KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|         Sparta|     attraction|  K8vZ9175eOV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6dt|        Alternative Rock|      2023-07-27|       onsale|        19:00:00|     USD|     25.0|     25.0|\n",
      "|            CupcakKe|     \"NaN\"|Z7r9jZ1AdxAxk|https://www.ticke...|Warehouse Live-Ba...|  ZFr9jZAva6|        77003|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|813 St. Emanuel S...|     -95.345596|     29.748899|       CupcakKe|     attraction|  K8vZ9174yp0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkvl|             Hip-Hop/Rap|      2023-07-23|       onsale|        21:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|       BROADWAY RAVE|  standard|G5dIZ9n1uPvl4|https://www.ticke...|White Oak Music H...| KovZ917AiGZ|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      2915 N Main St|      -95.36562|      29.78627|  Broadway Rave|     attraction|  K8vZ917Qzc0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvF|     Dance/Electronic|   KZazBEonSMnZfZ7vAJJ|               Dance Pop|      2023-07-14|       onsale|        21:00:00|     USD|     15.0|     15.0|\n",
      "|Twin Shadow: Very...|  standard|G5dIZ9t6avKc7|https://www.ticke...|White Oak Music H...| KovZ917AiGZ|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      2915 N Main St|      -95.36562|      29.78627|    Twin Shadow|     attraction|  K8vZ917GnJV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-09-16|       onsale|        20:00:00|     USD|     19.5|     19.5|\n",
      "|        Romeo Santos|     \"NaN\"|Z7r9jZ1AdrKa4|https://www.ticke...|    Minute Maid Park|  Z6r9jZkeke|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Crawford Street|     -95.362999|     29.759399|   Romeo Santos|     attraction|  K8vZ9172820|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeF|                World|   KZazBEonSMnZfZ7vFdJ|                   Latin|      2023-06-24|       onsale|        21:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Noah Reid - The \"...|  standard|G5dIZ9tIuMaVY|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797|      Noah Reid|     attraction|  K8vZ917bN17|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAev|                  Pop|   KZazBEonSMnZfZ7vkIk|       Singer-Songwriter|      2024-01-27|       onsale|        19:00:00|     USD|     39.5|     49.5|\n",
      "|          Jimmy Dore|  standard|G5dIZ9irdA--K|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797|     Jimmy Dore|     attraction|  K8vZ9175RP7|https://www.liven...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-10-13|       onsale|        19:00:00|     USD|     30.0|     40.0|\n",
      "|              Porter|  standard|G5dIZ9tmNyS0I|https://concerts....|House of Blues Ho...|KovZpZAE6k1A|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|   -95.36381697|   29.75377797|         Porter|     attraction|  K8vZ917oNef|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6dt|        Alternative Rock|      2023-08-10|       onsale|        19:00:00|     USD|     25.0|     25.0|\n",
      "|     The Steel Woods|  standard|G5dIZ9tpaTVhA|https://www.ticke...|White Oak Music H...| KovZ917AiGZ|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      2915 N Main St|      -95.36562|      29.78627|The Steel Woods|     attraction|  K8vZ9174c-0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v61J|           Southern Rock|      2023-09-15|       onsale|        20:00:00|     USD|     25.0|     25.0|\n",
      "|Houston Dynamo vs...|     \"NaN\"|Z7r9jZ1AdjJQa|https://www.ticke...|Shell Energy Stadium|  ZFr9jZa61F|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|South Rice Avenue...|     -95.362999|     29.759399| Houston Dynamo|     attraction|  K8vZ9175MiV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vA7E|               Soccer|   KZazBEonSMnZfZ7vFtI|                     MLS|      2023-07-08|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Astros vs...|     \"NaN\"|Z7r9jZ1AdpZra|https://www.ticke...|    Minute Maid Park|  Z6r9jZkeke|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Crawford Street|     -95.362999|     29.759399| Houston Astros|     attraction|  K8vZ91718zV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdv|             Baseball|   KZazBEonSMnZfZ7vF1n|                     MLB|      2023-08-21|       onsale|        19:10:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+---------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "23/06/22 21:40:20 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@6d64c178 committed.\n",
      "23/06/22 21:40:20 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/112 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.112.58c1fe4c-f43a-4dac-b332-c14a3a7cd7bb.tmp\n",
      "23/06/22 21:40:20 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.112.58c1fe4c-f43a-4dac-b332-c14a3a7cd7bb.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/112\n",
      "23/06/22 21:40:20 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:40:20.005Z\",\n",
      "  \"batchId\" : 112,\n",
      "  \"numInputRows\" : 39,\n",
      "  \"inputRowsPerSecond\" : 3.8988303508947317,\n",
      "  \"processedRowsPerSecond\" : 161.82572614107883,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 51,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 2,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 241,\n",
      "    \"walCommit\" : 64\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1952\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1991\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 39,\n",
      "    \"inputRowsPerSecond\" : 3.8988303508947317,\n",
      "    \"processedRowsPerSecond\" : 161.82572614107883\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 39\n",
      "  }\n",
      "}\n",
      "23/06/22 21:40:20 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-f8b3e03b-a075-4879-a97f-c966e522fe25/' directory.\n",
      "23/06/22 21:40:21 INFO FileFormatWriter: Write Job 10e9c954-be4a-4ce2-9ded-05c2f9362a1c committed. Elapsed time: 2622 ms.\n",
      "23/06/22 21:40:21 INFO FileFormatWriter: Finished processing stats for write job 10e9c954-be4a-4ce2-9ded-05c2f9362a1c.\n",
      "23/06/22 21:40:21 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687482506437-f8b3e03b-a075-4879-a97f-c966e522fe25/part-00000-d13ecf1e-e5a0-4843-8fc7-1924f7a5bb25-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=cb859404-0d16-4770-8bbd-38ef9898a8f6, location=US}\n",
      "23/06/22 21:40:24 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=cb859404-0d16-4770-8bbd-38ef9898a8f6, location=US}\n",
      "23/06/22 21:40:25 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/188 using temp file gs://kafka-spark-data/spark-metadata/commits/.188.78d4de00-ce76-4554-8e99-383cd6d22825.tmp\n",
      "23/06/22 21:40:25 INFO BlockManagerInfo: Removed broadcast_234_piece0 on 192.168.4.24:51040 in memory (size: 94.8 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:40:25 INFO BlockManagerInfo: Removed broadcast_235_piece0 on 192.168.4.24:51040 in memory (size: 9.9 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:40:27 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.188.78d4de00-ce76-4554-8e99-383cd6d22825.tmp to gs://kafka-spark-data/spark-metadata/commits/188\n",
      "23/06/22 21:40:27 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:40:12.750Z\",\n",
      "  \"batchId\" : 188,\n",
      "  \"numInputRows\" : 60,\n",
      "  \"inputRowsPerSecond\" : 3.9393342525113257,\n",
      "  \"processedRowsPerSecond\" : 4.2055092170743675,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 9567,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 7,\n",
      "    \"queryPlanning\" : 13,\n",
      "    \"triggerExecution\" : 14267,\n",
      "    \"walCommit\" : 2638\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1903\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1963\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 60,\n",
      "    \"inputRowsPerSecond\" : 3.9393342525113257,\n",
      "    \"processedRowsPerSecond\" : 4.2055092170743675\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:40:27 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 14268 milliseconds\n",
      "23/06/22 21:40:27 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:27 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 2019.\n",
      "23/06/22 21:40:27 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/189 using temp file gs://kafka-spark-data/spark-metadata/offsets/.189.bf181b7d-3502-4bc1-a82f-ceffd22953e0.tmp\n",
      "23/06/22 21:40:28 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.189.bf181b7d-3502-4bc1-a82f-ceffd22953e0.tmp to gs://kafka-spark-data/spark-metadata/offsets/189\n",
      "23/06/22 21:40:28 INFO MicroBatchExecution: Committed offsets for batch 189. Metadata OffsetSeqMetadata(0,1687488027020,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:40:29 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:29 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:29 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:29 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:29 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:40:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:40:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:40:29 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:40:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:40:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:40:29 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:40:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 2030.\n",
      "23/06/22 21:40:30 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/113 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.113.776e59d7-b55c-4f89-b264-c76dceb4423b.tmp\n",
      "23/06/22 21:40:30 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.113.776e59d7-b55c-4f89-b264-c76dceb4423b.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/113\n",
      "23/06/22 21:40:30 INFO MicroBatchExecution: Committed offsets for batch 113. Metadata OffsetSeqMetadata(0,1687488030006,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:40:30 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:30 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:30 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:30 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:30 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:30 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:30 INFO WriteToDataSourceV2Exec: Start processing data source write support: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@6a18e9c5. The input RDD has 1 partitions.\n",
      "23/06/22 21:40:30 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:40:30 INFO DAGScheduler: Got job 236 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:40:30 INFO DAGScheduler: Final stage: ResultStage 237 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:40:30 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:40:30 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:40:30 INFO DAGScheduler: Submitting ResultStage 237 (MapPartitionsRDD[1247] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:40:30 INFO MemoryStore: Block broadcast_236 stored as values in memory (estimated size 23.0 KiB, free 434.4 MiB)\n",
      "23/06/22 21:40:30 INFO MemoryStore: Block broadcast_236_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 434.4 MiB)\n",
      "23/06/22 21:40:30 INFO BlockManagerInfo: Added broadcast_236_piece0 in memory on 192.168.4.24:51040 (size: 9.9 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:40:30 INFO SparkContext: Created broadcast 236 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:40:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 237 (MapPartitionsRDD[1247] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:40:30 INFO TaskSchedulerImpl: Adding task set 237.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:40:30 INFO TaskSetManager: Starting task 0.0 in stage 237.0 (TID 236) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:40:30 INFO Executor: Running task 0.0 in stage 237.0 (TID 236)\n",
      "23/06/22 21:40:30 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 1991 for partition ticketmaster-0\n",
      "23/06/22 21:40:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:40:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 2031.\n",
      "23/06/22 21:40:30 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 1992 for partition ticketmaster-0\n",
      "23/06/22 21:40:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:40:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 2032.\n",
      "23/06/22 21:40:30 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 236, attempt 0, stage 237.0)\n",
      "23/06/22 21:40:30 INFO DataWritingSparkTask: Committed partition 0 (task 236, attempt 0, stage 237.0)\n",
      "23/06/22 21:40:30 INFO Executor: Finished task 0.0 in stage 237.0 (TID 236). 35321 bytes result sent to driver\n",
      "23/06/22 21:40:30 INFO TaskSetManager: Finished task 0.0 in stage 237.0 (TID 236) in 186 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:40:30 INFO TaskSchedulerImpl: Removed TaskSet 237.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:40:30 INFO DAGScheduler: ResultStage 237 (start at NativeMethodAccessorImpl.java:0) finished in 0.192 s\n",
      "23/06/22 21:40:30 INFO DAGScheduler: Job 236 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:40:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 237: Stage finished\n",
      "23/06/22 21:40:30 INFO DAGScheduler: Job 236 finished: start at NativeMethodAccessorImpl.java:0, took 0.193037 s\n",
      "23/06/22 21:40:30 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@6a18e9c5 is committing.\n",
      "-------------------------------------------\n",
      "Batch: 113\n",
      "-------------------------------------------\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|          event_name|event_type|     event_id|           event_url|          venue_name|    venue_id|venue_zipcode|venues_timezone|venue_city|venue_state_full|venue_state_short|  venue_country_name|venue_country_short|       venue_address|venue_longitude|venue_latitude|     attraction_name|attraction_type|attraction_id|      attraction_url|attraction_segment_id|attraction_segment_name|attraction_genre_id|attraction_genre_name|attraction_subgenre_id|attraction_subgenre_name|event_start_date|ticket_status|event_start_time|currency|min_price|max_price|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|                flor|  standard|G5dIZ9lZSpQ0R|https://www.ticke...|White Oak Music H...| KovZ917AiGZ|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      2915 N Main St|      -95.36562|      29.78627|                flor|     attraction|  K8vZ917KoPV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-07-26|       onsale|        19:00:00|     USD|     18.0|     18.0|\n",
      "|       Generationals|  standard|G5dIZ9JXaRw7Q|https://www.ticke...|White Oak Music H...| KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|       Generationals|     attraction|  K8vZ917uAWf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-09-07|       onsale|        19:00:00|     USD|     22.0|     22.0|\n",
      "|        Youth Lagoon|  standard|G5dIZ9EwFrslz|https://www.ticke...|White Oak Music H...| KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|        Youth Lagoon|     attraction|  K8vZ917C0Lf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-09-28|       onsale|        20:00:00|     USD|     25.0|     25.0|\n",
      "|          Bonny Doon|  standard|G5dIZ9I-MyvfR|https://www.ticke...|White Oak Music H...| KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|          Bonny Doon|     attraction|  K8vZ917pMhf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvv|          Alternative|   KZazBEonSMnZfZ7vAvJ|             Alternative|      2023-06-26|       onsale|        19:00:00|     USD|     12.0|     12.0|\n",
      "|Houston Astros vs...|     \"NaN\"|Z7r9jZ1AdpZrF|https://www.ticke...|    Minute Maid Park|  Z6r9jZkeke|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Crawford Street|     -95.362999|     29.759399|      Houston Astros|     attraction|  K8vZ91718zV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdv|             Baseball|   KZazBEonSMnZfZ7vF1n|                     MLB|      2023-09-09|       onsale|        18:10:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Astros vs...|     \"NaN\"|Z7r9jZ1AdpZrp|https://www.ticke...|    Minute Maid Park|  Z6r9jZkeke|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Crawford Street|     -95.362999|     29.759399|      Houston Astros|     attraction|  K8vZ91718zV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdv|             Baseball|   KZazBEonSMnZfZ7vF1n|                     MLB|      2023-08-24|       onsale|        13:10:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Los monólogos de ...|  standard|G5dIZ9lMBIJfF|https://www.ticke...|       Arena Theatre|KovZpZAJJ7FA|        77074|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 7326 Southwest Fwy,|     -95.517765|     29.702271|Los monólogos de ...|     attraction|  K8vZ917GZi7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7v7lI|                  Comedy|      2023-09-22|       onsale|        20:30:00|     USD|    36.23|   108.68|\n",
      "|       Dylan Matthew|  standard|G5dIZ9txY7S1E|https://www.ticke...|White Oak Music H...| KovZ917AiGZ|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      2915 N Main St|      -95.36562|      29.78627|       Dylan Matthew|     attraction|  K8vZ917bEa0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAee|                  R&B|   KZazBEonSMnZfZ7vkIt|                     R&B|      2023-09-27|       onsale|        19:00:00|     USD|     20.0|     20.0|\n",
      "|Mo Lowda & The Hu...|  standard|G5dIZ9JBfG35v|https://www.ticke...|White Oak Music H...| KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|Mo Lowda & The Hu...|     attraction|  K8vZ9174mFV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvv|          Alternative|   KZazBEonSMnZfZ7vAvn|        Alternative Rock|      2023-09-23|       onsale|        20:00:00|     USD|     18.0|     18.0|\n",
      "|  Nation of Language|  standard|G5dIZ9J5Qik6k|https://www.ticke...|White Oak Music H...| KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|  Nation of Language|     attraction|  K8vZ917p0DV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvv|          Alternative|   KZazBEonSMnZfZ7vAvn|        Alternative Rock|      2023-11-04|       onsale|        20:00:00|     USD|     15.0|     15.0|\n",
      "|Leagues Cup Houst...|     \"NaN\"|Z7r9jZ1Ad-Uv6|https://www.ticke...|Shell Energy Stadium|  ZFr9jZa61F|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|South Rice Avenue...|     -95.362999|     29.759399|      Houston Dynamo|     attraction|  K8vZ9175MiV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vA7E|               Soccer|   KZazBEonSMnZfZ7vFtI|                     MLS|      2023-07-25|       onsale|        19:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|     Remember Sports|  standard|G5dIZ9PQZ6waQ|https://www.ticke...|White Oak Music H...| KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|     Remember Sports|     attraction|  K8vZ91799LV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvv|          Alternative|   KZazBEonSMnZfZ7vAvn|        Alternative Rock|      2023-07-17|       onsale|        19:00:00|     USD|     17.0|     17.0|\n",
      "|           Lastlings|  standard|G5dIZ9tcodILM|https://concerts....|The Bronze Peacoc...| KovZ917A58V|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|     -95.364056|     29.753929|           Lastlings|     attraction|  K8vZ917_2R7|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAev|                  Pop|   KZazBEonSMnZfZ7vk1t|                     Pop|      2023-09-26|       onsale|        19:30:00|     USD|     25.0|     25.0|\n",
      "|Flamingos in the ...|  standard|G5dIZ9nJfZexR|https://www.ticke...|White Oak Music H...| KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|Flamingos in the ...|     attraction|  K8vZ917QDkf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvv|          Alternative|   KZazBEonSMnZfZ7vAvn|        Alternative Rock|      2023-07-25|       onsale|        18:00:00|     USD|     15.0|     15.0|\n",
      "|Houston Astros vs...|     \"NaN\"|Z7r9jZ1AdpZr6|https://www.ticke...|    Minute Maid Park|  Z6r9jZkeke|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Crawford Street|     -95.362999|     29.759399|      Houston Astros|     attraction|  K8vZ91718zV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdv|             Baseball|   KZazBEonSMnZfZ7vF1n|                     MLB|      2023-08-19|       onsale|        18:10:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Dynamo vs...|     \"NaN\"|Z7r9jZ1AdjJQ8|https://www.ticke...|Shell Energy Stadium|  ZFr9jZa61F|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|South Rice Avenue...|     -95.362999|     29.759399|      Houston Dynamo|     attraction|  K8vZ9175MiV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vA7E|               Soccer|   KZazBEonSMnZfZ7vFtI|                     MLS|      2023-07-12|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Astros vs...|     \"NaN\"|Z7r9jZ1AdpZq9|https://www.ticke...|    Minute Maid Park|  Z6r9jZkeke|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Crawford Street|     -95.362999|     29.759399|      Houston Astros|     attraction|  K8vZ91718zV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdv|             Baseball|   KZazBEonSMnZfZ7vF1n|                     MLB|      2023-08-02|       onsale|        13:10:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Astros vs...|     \"NaN\"|Z7r9jZ1AdpZr9|https://www.ticke...|    Minute Maid Park|  Z6r9jZkeke|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Crawford Street|     -95.362999|     29.759399|      Houston Astros|     attraction|  K8vZ91718zV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdv|             Baseball|   KZazBEonSMnZfZ7vF1n|                     MLB|      2023-09-08|       onsale|        19:10:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Tom The Mail Man ...|  standard|G5dIZ9JFtbFnP|https://www.ticke...|White Oak Music H...| KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|    Tom the Mail Man|     attraction|  K8vZ917Qhdf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkdA|                   Urban|      2023-10-20|       onsale|        20:00:00|     USD|     15.0|     15.0|\n",
      "|Houston Cougars F...|     \"NaN\"|Z7r9jZ1Adqwas|https://www.ticke...|       TDECU Stadium|  ZFr9jZddvv|        77004|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|  3874 Holman Street|     -95.363197|       29.7248|University of Hou...|     attraction|  K8vZ9171MWf|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdE|             Football|   KZazBEonSMnZfZ7vFE6|                 College|      2023-09-02|       onsale|           \"NaN\"|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "23/06/22 21:40:30 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@6a18e9c5 committed.\n",
      "23/06/22 21:40:30 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/113 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.113.834c2189-7792-4e6d-8c9c-da241944ccd9.tmp\n",
      "23/06/22 21:40:30 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.113.834c2189-7792-4e6d-8c9c-da241944ccd9.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/113\n",
      "23/06/22 21:40:30 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:40:30.004Z\",\n",
      "  \"batchId\" : 113,\n",
      "  \"numInputRows\" : 39,\n",
      "  \"inputRowsPerSecond\" : 3.9003900390039004,\n",
      "  \"processedRowsPerSecond\" : 98.2367758186398,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 211,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 1,\n",
      "    \"queryPlanning\" : 4,\n",
      "    \"triggerExecution\" : 397,\n",
      "    \"walCommit\" : 87\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1991\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2030\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 39,\n",
      "    \"inputRowsPerSecond\" : 3.9003900390039004,\n",
      "    \"processedRowsPerSecond\" : 98.2367758186398\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 39\n",
      "  }\n",
      "}\n",
      "23/06/22 21:40:30 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:40:30 INFO DAGScheduler: Got job 237 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:40:30 INFO DAGScheduler: Final stage: ResultStage 238 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:40:30 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:40:30 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:40:30 INFO DAGScheduler: Submitting ResultStage 238 (MapPartitionsRDD[1248] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:40:30 INFO MemoryStore: Block broadcast_237 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/22 21:40:30 INFO MemoryStore: Block broadcast_237_piece0 stored as bytes in memory (estimated size 94.8 KiB, free 434.0 MiB)\n",
      "23/06/22 21:40:30 INFO BlockManagerInfo: Added broadcast_237_piece0 in memory on 192.168.4.24:51040 (size: 94.8 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:40:30 INFO SparkContext: Created broadcast 237 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:40:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 238 (MapPartitionsRDD[1248] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:40:30 INFO TaskSchedulerImpl: Adding task set 238.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:40:30 INFO TaskSetManager: Starting task 0.0 in stage 238.0 (TID 237) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:40:30 INFO Executor: Running task 0.0 in stage 238.0 (TID 237)\n",
      "23/06/22 21:40:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:40:30 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:40:30 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:40:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:40:30 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:40:30 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:40:30 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:40:30 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:40:30 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/22 21:40:30 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/22 21:40:30 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/22 21:40:30 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/22 21:40:30 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/22 21:40:30 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 1978 for partition ticketmaster-0\n",
      "23/06/22 21:40:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:40:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 2033.\n",
      "23/06/22 21:40:30 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 1979 for partition ticketmaster-0\n",
      "23/06/22 21:40:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:40:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 2034.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 238:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:40:32 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-643e5396-8a5c-4d84-a84f-d8905b29db36/_temporary/0/_temporary/' directory.\n",
      "23/06/22 21:40:32 INFO FileOutputCommitter: Saved output of task 'attempt_202306222140302860539106559591086_0238_m_000000_237' to gs://kafka-spark-data/.spark-bigquery-local-1687482506437-643e5396-8a5c-4d84-a84f-d8905b29db36/_temporary/0/task_202306222140302860539106559591086_0238_m_000000\n",
      "23/06/22 21:40:32 INFO SparkHadoopMapRedUtil: attempt_202306222140302860539106559591086_0238_m_000000_237: Committed. Elapsed time: 1156 ms.\n",
      "23/06/22 21:40:32 INFO Executor: Finished task 0.0 in stage 238.0 (TID 237). 2536 bytes result sent to driver\n",
      "23/06/22 21:40:32 INFO TaskSetManager: Finished task 0.0 in stage 238.0 (TID 237) in 2142 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:40:32 INFO TaskSchedulerImpl: Removed TaskSet 238.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:40:32 INFO DAGScheduler: ResultStage 238 (start at NativeMethodAccessorImpl.java:0) finished in 2.158 s\n",
      "23/06/22 21:40:32 INFO DAGScheduler: Job 237 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:40:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 238: Stage finished\n",
      "23/06/22 21:40:32 INFO DAGScheduler: Job 237 finished: start at NativeMethodAccessorImpl.java:0, took 2.158903 s\n",
      "23/06/22 21:40:32 INFO FileFormatWriter: Start to commit write Job a41e2461-f1ea-42aa-bb82-fd427fb8e4f6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:40:33 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-643e5396-8a5c-4d84-a84f-d8905b29db36/_temporary/0/task_202306222140302860539106559591086_0238_m_000000/' directory.\n",
      "23/06/22 21:40:34 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-643e5396-8a5c-4d84-a84f-d8905b29db36/' directory.\n",
      "23/06/22 21:40:34 INFO FileFormatWriter: Write Job a41e2461-f1ea-42aa-bb82-fd427fb8e4f6 committed. Elapsed time: 2281 ms.\n",
      "23/06/22 21:40:34 INFO FileFormatWriter: Finished processing stats for write job a41e2461-f1ea-42aa-bb82-fd427fb8e4f6.\n",
      "23/06/22 21:40:36 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687482506437-643e5396-8a5c-4d84-a84f-d8905b29db36/part-00000-35b19dc9-57cb-4573-be41-de4799bdd298-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=b0755ea2-e1d0-44e3-856c-78cd2433b980, location=US}\n",
      "23/06/22 21:40:37 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=b0755ea2-e1d0-44e3-856c-78cd2433b980, location=US}\n",
      "23/06/22 21:40:39 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/189 using temp file gs://kafka-spark-data/spark-metadata/commits/.189.645abc94-be20-47ad-b3a6-c0926bc79afd.tmp\n",
      "23/06/22 21:40:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 2070.\n",
      "23/06/22 21:40:40 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/114 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.114.08fe40f6-32e9-46a2-9d2b-6d2b7dd59ed9.tmp\n",
      "23/06/22 21:40:40 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.114.08fe40f6-32e9-46a2-9d2b-6d2b7dd59ed9.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/114\n",
      "23/06/22 21:40:40 INFO MicroBatchExecution: Committed offsets for batch 114. Metadata OffsetSeqMetadata(0,1687488040019,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:40:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:40 INFO WriteToDataSourceV2Exec: Start processing data source write support: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@2370fc4d. The input RDD has 1 partitions.\n",
      "23/06/22 21:40:40 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:40:40 INFO DAGScheduler: Got job 238 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:40:40 INFO DAGScheduler: Final stage: ResultStage 239 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:40:40 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:40:40 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:40:40 INFO DAGScheduler: Submitting ResultStage 239 (MapPartitionsRDD[1251] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:40:40 INFO MemoryStore: Block broadcast_238 stored as values in memory (estimated size 23.0 KiB, free 434.0 MiB)\n",
      "23/06/22 21:40:40 INFO MemoryStore: Block broadcast_238_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 434.0 MiB)\n",
      "23/06/22 21:40:40 INFO BlockManagerInfo: Added broadcast_238_piece0 in memory on 192.168.4.24:51040 (size: 9.9 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:40:40 INFO SparkContext: Created broadcast 238 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:40:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 239 (MapPartitionsRDD[1251] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:40:40 INFO TaskSchedulerImpl: Adding task set 239.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:40:40 INFO TaskSetManager: Starting task 0.0 in stage 239.0 (TID 238) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:40:40 INFO Executor: Running task 0.0 in stage 239.0 (TID 238)\n",
      "23/06/22 21:40:40 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 2031 for partition ticketmaster-0\n",
      "23/06/22 21:40:40 INFO BlockManagerInfo: Removed broadcast_236_piece0 on 192.168.4.24:51040 in memory (size: 9.9 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:40:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:40 INFO BlockManagerInfo: Removed broadcast_237_piece0 on 192.168.4.24:51040 in memory (size: 94.8 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:40:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:40:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 2070.\n",
      "23/06/22 21:40:40 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 2032 for partition ticketmaster-0\n",
      "23/06/22 21:40:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:40:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 2071.\n",
      "23/06/22 21:40:40 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 238, attempt 0, stage 239.0)\n",
      "23/06/22 21:40:40 INFO DataWritingSparkTask: Committed partition 0 (task 238, attempt 0, stage 239.0)\n",
      "23/06/22 21:40:40 INFO Executor: Finished task 0.0 in stage 239.0 (TID 238). 35178 bytes result sent to driver\n",
      "23/06/22 21:40:40 INFO TaskSetManager: Finished task 0.0 in stage 239.0 (TID 238) in 152 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:40:40 INFO TaskSchedulerImpl: Removed TaskSet 239.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:40:40 INFO DAGScheduler: ResultStage 239 (start at NativeMethodAccessorImpl.java:0) finished in 0.155 s\n",
      "23/06/22 21:40:40 INFO DAGScheduler: Job 238 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:40:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 239: Stage finished\n",
      "23/06/22 21:40:40 INFO DAGScheduler: Job 238 finished: start at NativeMethodAccessorImpl.java:0, took 0.155400 s\n",
      "23/06/22 21:40:40 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@2370fc4d is committing.\n",
      "-------------------------------------------\n",
      "Batch: 114\n",
      "-------------------------------------------\n",
      "+--------------------+----------+-------------+--------------------+--------------------+-----------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|          event_name|event_type|     event_id|           event_url|          venue_name|   venue_id|venue_zipcode|venues_timezone|venue_city|venue_state_full|venue_state_short|  venue_country_name|venue_country_short|       venue_address|venue_longitude|venue_latitude|     attraction_name|attraction_type|attraction_id|      attraction_url|attraction_segment_id|attraction_segment_name|attraction_genre_id|attraction_genre_name|attraction_subgenre_id|attraction_subgenre_name|event_start_date|ticket_status|event_start_time|currency|min_price|max_price|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+-----------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|         Nascar Aloe|     \"NaN\"|Z7r9jZ1Ad-S7P|https://www.ticke...|Warehouse Live-St...| ZFr9jZav7e|        77003|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|813 St. Emanuel S...|     -95.345596|     29.748899|         Nascar Aloe|     attraction|  K8vZ917bndV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkdA|                   Urban|      2023-06-26|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|          Gilla Band|  standard|G5dIZ9IlJh0jn|https://www.ticke...|White Oak Music H...|KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|               \"NaN\"|          \"NaN\"|        \"NaN\"|               \"NaN\"|                \"NaN\"|                  \"NaN\"|              \"NaN\"|                \"NaN\"|                 \"NaN\"|                   \"NaN\"|      2023-10-31|       onsale|        19:00:00|     USD|     19.0|     19.0|\n",
      "|  Quarters of Change|  standard|G5dIZ9iaMnA2Z|https://www.ticke...|White Oak Music H...|KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|  Quarters of Change|     attraction|  K8vZ917pXyf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6da|                    Rock|      2023-09-27|       onsale|        18:00:00|     USD|     16.0|     16.0|\n",
      "|Houston Astros vs...|     \"NaN\"|Z7r9jZ1AdpZOZ|https://www.ticke...|    Minute Maid Park| Z6r9jZkeke|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Crawford Street|     -95.362999|     29.759399|      Houston Astros|     attraction|  K8vZ91718zV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdv|             Baseball|   KZazBEonSMnZfZ7vF1n|                     MLB|      2023-09-23|       onsale|        18:10:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Drumming Bird & A...|  standard|G5dIZ9nOGNEnf|https://www.ticke...|White Oak Music H...|KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|       Drumming Bird|     attraction|  K8vZ917hbmV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvv|          Alternative|   KZazBEonSMnZfZ7vAdv|               Indie Pop|      2023-08-09|       onsale|        19:00:00|     USD|     12.0|     12.0|\n",
      "|        Hobo Johnson|     \"NaN\"|Z7r9jZ1Ad-_Fv|https://www.ticke...|Warehouse Live-St...| ZFr9jZav7e|        77003|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|813 St. Emanuel S...|     -95.345596|     29.748899|Hobo Johnson & Th...|     attraction|  K8vZ917pEW7|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkvl|             Hip-Hop/Rap|      2023-06-29|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|             Doe Boy|  standard|G5dIZ9iAMwsty|https://concerts....|The Bronze Peacoc...|KovZ917A58V|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|     -95.364056|     29.753929|             Doe Boy|     attraction|  K8vZ9174Ny7|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkvl|             Hip-Hop/Rap|      2023-08-14|       onsale|        19:00:00|     USD|     25.0|     25.0|\n",
      "|All Time Low w/ G...|     \"NaN\"|Z7r9jZ1Ad-Vro|https://www.ticke...|Warehouse Live-Ba...| ZFr9jZAva6|        77003|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|813 St. Emanuel S...|     -95.345596|     29.748899|        All Time Low|     attraction|  K8vZ917G5gV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6dt|        Alternative Rock|      2023-10-03|      offsale|        18:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|        Tanya Tucker|     \"NaN\"|Z7r9jZ1Ad-M70|https://www.ticke...|     Heights Theater| Z7r9jZad5d|        77008|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|339 W 19th St, Ho...|     -95.418297|     29.798201|        Tanya Tucker|     attraction|  K8vZ91711df|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv6|              Country|   KZazBEonSMnZfZ7vAFa|                 Country|      2023-06-28|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|      George Clanton|  standard|G5dIZ9i297VDZ|https://www.ticke...|White Oak Music H...|KovZ917AiGZ|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      2915 N Main St|      -95.36562|      29.78627|      George Clanton|     attraction|  K8vZ917bAwV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-10-18|       onsale|        19:00:00|     USD|     26.0|     26.0|\n",
      "|          Dean Lewis|     \"NaN\"|Z7r9jZ1Adxeev|https://www.ticke...|Warehouse Live-Ba...| ZFr9jZAva6|        77003|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|813 St. Emanuel S...|     -95.345596|     29.748899|          Dean Lewis|     attraction|  K8vZ917pNd0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-11-01|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|PROFANATICA with ...|  standard|G5dIZ9ntUG-_a|https://www.ticke...|White Oak Music H...|KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|         Profanatica|     attraction|  K8vZ917p-5V|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvt|                Metal|   KZazBEonSMnZfZ7vk6t|    Death Metal/Black...|      2023-07-31|       onsale|        19:00:00|     USD|     20.0|     20.0|\n",
      "|Houston Astros vs...|     \"NaN\"|Z7r9jZ1AdpZrk|https://www.ticke...|    Minute Maid Park| Z6r9jZkeke|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Crawford Street|     -95.362999|     29.759399|      Houston Astros|     attraction|  K8vZ91718zV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdv|             Baseball|   KZazBEonSMnZfZ7vF1n|                     MLB|      2023-09-10|       onsale|        13:10:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Astros vs...|     \"NaN\"|Z7r9jZ1AdpZqo|https://www.ticke...|    Minute Maid Park| Z6r9jZkeke|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Crawford Street|     -95.362999|     29.759399|      Houston Astros|     attraction|  K8vZ91718zV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdv|             Baseball|   KZazBEonSMnZfZ7vF1n|                     MLB|      2023-07-31|       onsale|        19:10:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Deja Vu Tour 2023...|  standard|G5dIZ9leTrI9f|https://www.ticke...|White Oak Music H...|KovZ917AiGZ|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      2915 N Main St|      -95.36562|      29.78627|      The Mission UK|     attraction|  K8vZ9171FZV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6dt|        Alternative Rock|      2023-09-14|       onsale|        19:00:00|     USD|     35.0|     35.0|\n",
      "|        Blossom Aloe|  standard|G5dIZ9lTH0EkY|https://www.ticke...|White Oak Music H...|KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|               \"NaN\"|          \"NaN\"|        \"NaN\"|               \"NaN\"|                \"NaN\"|                  \"NaN\"|              \"NaN\"|                \"NaN\"|                 \"NaN\"|                   \"NaN\"|      2023-07-22|       onsale|        19:00:00|     USD|     10.0|     10.0|\n",
      "|Stop Light Observ...|  standard|G5dIZ9IBa9oBM|https://www.ticke...|White Oak Music H...|KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|Stop Light Observ...|     attraction|  K8vZ917Kaef|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6dt|        Alternative Rock|      2023-11-18|       onsale|        19:00:00|     USD|     15.0|     15.0|\n",
      "|                Ishi|  standard|G5dIZ9nKZ3Jgm|https://www.ticke...|White Oak Music H...|KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|                Ishi|     attraction|  K8vZ9172uL0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-07-15|       onsale|        20:00:00|     USD|     15.0|     15.0|\n",
      "|        Wednesday 13|     \"NaN\"|Z7r9jZ1Ad-S7Y|https://www.ticke...|Warehouse Live-St...| ZFr9jZav7e|        77003|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|813 St. Emanuel S...|     -95.345596|     29.748899|        Wednesday 13|     attraction|  K8vZ9175tB0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvt|                Metal|   KZazBEonSMnZfZ7vkFd|             Heavy Metal|      2023-11-04|       onsale|        18:45:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Sunrise & Ammunition|  standard|G5dIZ9n6sV4lu|https://www.ticke...|White Oak Music H...|KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|Sunrise & Ammunition|     attraction|  K8vZ917hbo7|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6aA|             Psychedelic|      2023-07-06|       onsale|        19:00:00|     USD|     15.0|     15.0|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+-----------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "23/06/22 21:40:40 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@2370fc4d committed.\n",
      "23/06/22 21:40:40 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/114 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.114.aa220a56-4a95-4a0a-8b23-23807b046278.tmp\n",
      "23/06/22 21:40:40 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.114.aa220a56-4a95-4a0a-8b23-23807b046278.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/114\n",
      "23/06/22 21:40:40 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:40:40.005Z\",\n",
      "  \"batchId\" : 114,\n",
      "  \"numInputRows\" : 40,\n",
      "  \"inputRowsPerSecond\" : 3.9996000399960008,\n",
      "  \"processedRowsPerSecond\" : 109.2896174863388,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 178,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 14,\n",
      "    \"queryPlanning\" : 4,\n",
      "    \"triggerExecution\" : 366,\n",
      "    \"walCommit\" : 62\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2030\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2070\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 40,\n",
      "    \"inputRowsPerSecond\" : 3.9996000399960008,\n",
      "    \"processedRowsPerSecond\" : 109.2896174863388\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 40\n",
      "  }\n",
      "}\n",
      "23/06/22 21:40:43 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.189.645abc94-be20-47ad-b3a6-c0926bc79afd.tmp to gs://kafka-spark-data/spark-metadata/commits/189\n",
      "23/06/22 21:40:43 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:40:27.018Z\",\n",
      "  \"batchId\" : 189,\n",
      "  \"numInputRows\" : 56,\n",
      "  \"inputRowsPerSecond\" : 3.924866834875245,\n",
      "  \"processedRowsPerSecond\" : 3.4877927254608867,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 9254,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 2,\n",
      "    \"queryPlanning\" : 6,\n",
      "    \"triggerExecution\" : 16056,\n",
      "    \"walCommit\" : 2505\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1963\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2019\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 56,\n",
      "    \"inputRowsPerSecond\" : 3.924866834875245,\n",
      "    \"processedRowsPerSecond\" : 3.4877927254608867\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:40:43 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 16057 milliseconds\n",
      "23/06/22 21:40:43 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:43 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 2082.\n",
      "23/06/22 21:40:43 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/190 using temp file gs://kafka-spark-data/spark-metadata/offsets/.190.8eae1049-7493-4bc2-9846-422d44e75adb.tmp\n",
      "23/06/22 21:40:43 INFO BlockManagerInfo: Removed broadcast_238_piece0 on 192.168.4.24:51040 in memory (size: 9.9 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:40:45 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.190.8eae1049-7493-4bc2-9846-422d44e75adb.tmp to gs://kafka-spark-data/spark-metadata/offsets/190\n",
      "23/06/22 21:40:45 INFO MicroBatchExecution: Committed offsets for batch 190. Metadata OffsetSeqMetadata(0,1687488043080,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:40:46 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:46 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:46 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:46 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:47 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:40:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:40:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:40:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:40:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:40:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:40:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:40:47 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:40:47 INFO DAGScheduler: Got job 239 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:40:47 INFO DAGScheduler: Final stage: ResultStage 240 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:40:47 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:40:47 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:40:47 INFO DAGScheduler: Submitting ResultStage 240 (MapPartitionsRDD[1258] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:40:47 INFO MemoryStore: Block broadcast_239 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/22 21:40:47 INFO MemoryStore: Block broadcast_239_piece0 stored as bytes in memory (estimated size 94.8 KiB, free 434.0 MiB)\n",
      "23/06/22 21:40:47 INFO BlockManagerInfo: Added broadcast_239_piece0 in memory on 192.168.4.24:51040 (size: 94.8 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:40:47 INFO SparkContext: Created broadcast 239 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:40:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 240 (MapPartitionsRDD[1258] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:40:47 INFO TaskSchedulerImpl: Adding task set 240.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:40:47 INFO TaskSetManager: Starting task 0.0 in stage 240.0 (TID 239) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:40:47 INFO Executor: Running task 0.0 in stage 240.0 (TID 239)\n",
      "23/06/22 21:40:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:40:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:40:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:40:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:40:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:40:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:40:47 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:40:47 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:40:47 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/22 21:40:47 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/22 21:40:47 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/22 21:40:47 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/22 21:40:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/22 21:40:48 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 2033 for partition ticketmaster-0\n",
      "23/06/22 21:40:48 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:48 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:40:48 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:48 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 2103.\n",
      "23/06/22 21:40:48 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 2034 for partition ticketmaster-0\n",
      "23/06/22 21:40:48 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 240:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:40:48 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:40:48 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:48 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 2104.\n",
      "23/06/22 21:40:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 2109.\n",
      "23/06/22 21:40:50 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/115 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.115.35367de0-77fc-4577-a5e3-5b0ee87739cc.tmp\n",
      "23/06/22 21:40:50 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.115.35367de0-77fc-4577-a5e3-5b0ee87739cc.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/115\n",
      "23/06/22 21:40:50 INFO MicroBatchExecution: Committed offsets for batch 115. Metadata OffsetSeqMetadata(0,1687488050015,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:40:50 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:50 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:50 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:50 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:50 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:50 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:40:50 INFO WriteToDataSourceV2Exec: Start processing data source write support: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1fede75a. The input RDD has 1 partitions.\n",
      "23/06/22 21:40:50 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:40:50 INFO DAGScheduler: Got job 240 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:40:50 INFO DAGScheduler: Final stage: ResultStage 241 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:40:50 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:40:50 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:40:50 INFO DAGScheduler: Submitting ResultStage 241 (MapPartitionsRDD[1261] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:40:50 INFO MemoryStore: Block broadcast_240 stored as values in memory (estimated size 23.0 KiB, free 434.0 MiB)\n",
      "23/06/22 21:40:50 INFO MemoryStore: Block broadcast_240_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 434.0 MiB)\n",
      "23/06/22 21:40:50 INFO BlockManagerInfo: Added broadcast_240_piece0 in memory on 192.168.4.24:51040 (size: 9.9 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:40:50 INFO SparkContext: Created broadcast 240 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:40:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 241 (MapPartitionsRDD[1261] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:40:50 INFO TaskSchedulerImpl: Adding task set 241.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:40:50 INFO TaskSetManager: Starting task 0.0 in stage 241.0 (TID 240) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:40:50 INFO Executor: Running task 0.0 in stage 241.0 (TID 240)\n",
      "23/06/22 21:40:50 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 2070 for partition ticketmaster-0\n",
      "23/06/22 21:40:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:40:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 2109.\n",
      "23/06/22 21:40:50 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 2071 for partition ticketmaster-0\n",
      "23/06/22 21:40:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:40:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:40:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 2110.\n",
      "23/06/22 21:40:50 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 240, attempt 0, stage 241.0)\n",
      "23/06/22 21:40:50 INFO DataWritingSparkTask: Committed partition 0 (task 240, attempt 0, stage 241.0)\n",
      "23/06/22 21:40:50 INFO Executor: Finished task 0.0 in stage 241.0 (TID 240). 34364 bytes result sent to driver\n",
      "23/06/22 21:40:50 INFO TaskSetManager: Finished task 0.0 in stage 241.0 (TID 240) in 78 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:40:50 INFO TaskSchedulerImpl: Removed TaskSet 241.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:40:50 INFO DAGScheduler: ResultStage 241 (start at NativeMethodAccessorImpl.java:0) finished in 0.081 s\n",
      "23/06/22 21:40:50 INFO DAGScheduler: Job 240 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:40:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 241: Stage finished\n",
      "23/06/22 21:40:50 INFO DAGScheduler: Job 240 finished: start at NativeMethodAccessorImpl.java:0, took 0.081560 s\n",
      "23/06/22 21:40:50 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1fede75a is committing.\n",
      "-------------------------------------------\n",
      "Batch: 115\n",
      "-------------------------------------------\n",
      "+--------------------+----------+-------------+--------------------+--------------------+-----------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|          event_name|event_type|     event_id|           event_url|          venue_name|   venue_id|venue_zipcode|venues_timezone|venue_city|venue_state_full|venue_state_short|  venue_country_name|venue_country_short|       venue_address|venue_longitude|venue_latitude|     attraction_name|attraction_type|attraction_id|      attraction_url|attraction_segment_id|attraction_segment_name|attraction_genre_id|attraction_genre_name|attraction_subgenre_id|attraction_subgenre_name|event_start_date|ticket_status|event_start_time|currency|min_price|max_price|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+-----------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|Lojay - Gangster ...|  standard|G5dIZ9nUYhfIJ|https://concerts....|The Bronze Peacoc...|KovZ917A58V|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|     -95.364056|     29.753929|               Lojay|     attraction|  K8vZ917h8ef|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeF|                World|   KZazBEonSMnZfZ7v6Ek|               Afro-Beat|      2023-07-09|    cancelled|        19:00:00|     USD|     27.5|     27.5|\n",
      "|         Will Sparks|     \"NaN\"|Z7r9jZ1Ad-Ube|https://www.ticke...|Stereo Live - Hou...| ZFr9jZa7A6|        77057|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|   6400 Richmond Ave|     -95.489304|     29.745001|         Will Sparks|     attraction|  K8vZ917oxdV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvF|     Dance/Electronic|   KZazBEonSMnZfZ7vAJ1|              Club Dance|      2023-06-23|       onsale|        22:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|The Servant of Tw...|     \"NaN\"|Z7r9jZ1AdjV-3|https://www.ticke...|Alley Theatre-Hub...| Zkr9jZAdeL|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|       615 Texas Ave|     -95.362999|     29.759399|The Servant of Tw...|     attraction|   ZFr9jZeaFe|               \"NaN\"|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l6|      Performance Art|   KZazBEonSMnZfZ7v7l1|         Performance Art|      2023-06-24|       onsale|        14:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Astros vs...|     \"NaN\"|Z7r9jZ1AdpZr3|https://www.ticke...|    Minute Maid Park| Z6r9jZkeke|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Crawford Street|     -95.362999|     29.759399|      Houston Astros|     attraction|  K8vZ91718zV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdv|             Baseball|   KZazBEonSMnZfZ7vF1n|                     MLB|      2023-08-22|       onsale|        19:10:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Astros vs...|     \"NaN\"|Z7r9jZ1AdpZre|https://www.ticke...|    Minute Maid Park| Z6r9jZkeke|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Crawford Street|     -95.362999|     29.759399|      Houston Astros|     attraction|  K8vZ91718zV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdv|             Baseball|   KZazBEonSMnZfZ7vF1n|                     MLB|      2023-09-11|       onsale|        19:10:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Cougars F...|     \"NaN\"|Z7r9jZ1AdqwaY|https://www.ticke...|       TDECU Stadium| ZFr9jZddvv|        77004|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|  3874 Holman Street|     -95.363197|       29.7248|University of Hou...|     attraction|  K8vZ9171MWf|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdE|             Football|   KZazBEonSMnZfZ7vFE6|                 College|      2023-09-16|       onsale|           \"NaN\"|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|          Carin Leon|     \"NaN\"|Z7r9jZ1Adx7vb|https://www.ticke...|  Toyota Center - TX| ZFr9jZ7v7v|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        1510 Polk St|     -95.362999|     29.759399|          Carin Leon|     attraction|  K8vZ917_m_f|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAJ6|                Latin|   KZazBEonSMnZfZ7va1a|                   Latin|      2023-08-26|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Astros vs...|     \"NaN\"|Z7r9jZ1AdpZr4|https://www.ticke...|    Minute Maid Park| Z6r9jZkeke|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Crawford Street|     -95.362999|     29.759399|      Houston Astros|     attraction|  K8vZ91718zV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdv|             Baseball|   KZazBEonSMnZfZ7vF1n|                     MLB|      2023-09-18|       onsale|        19:10:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|           Bongzilla|  standard|G5dIZ9ld7JILK|https://www.ticke...|White Oak Music H...|KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|           Bongzilla|     attraction|  K8vZ917KMFf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvt|                Metal|   KZazBEonSMnZfZ7vkFt|            Stoner Metal|      2023-09-06|       onsale|        19:00:00|     USD|     20.0|     20.0|\n",
      "|The Servant of Tw...|     \"NaN\"|Z7r9jZ1AdjV-f|https://www.ticke...|Alley Theatre-Hub...| Zkr9jZAdeL|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|       615 Texas Ave|     -95.362999|     29.759399|The Servant of Tw...|     attraction|   ZFr9jZeaFe|               \"NaN\"|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l6|      Performance Art|   KZazBEonSMnZfZ7v7l1|         Performance Art|      2023-06-23|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|               GAYLE|     \"NaN\"|Z7r9jZ1Ad0J7f|https://www.ticke...|Warehouse Live-St...| ZFr9jZav7e|        77003|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|813 St. Emanuel S...|     -95.345596|     29.748899|               Gayle|     attraction|  K8vZ917_JbV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAev|                  Pop|   KZazBEonSMnZfZ7vk1t|                     Pop|      2023-10-19|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|The Anchor - US/C...|  standard|G5dIZ9nUiUfh2|https://concerts....|The Bronze Peacoc...|KovZ917A58V|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|     -95.364056|     29.753929|          The Anchor|     attraction|  K8vZ917KZU0|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6a6|                    Punk|      2023-08-29|       onsale|        19:00:00|     USD|     15.0|     15.0|\n",
      "|     Escape the Fate|     \"NaN\"|Z7r9jZ1Ad07Gp|https://www.ticke...|Warehouse Live-Ba...| ZFr9jZAva6|        77003|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|813 St. Emanuel S...|     -95.345596|     29.748899|     Escape the Fate|     attraction|  K8vZ9175TaV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvt|                Metal|   KZazBEonSMnZfZ7vkFd|             Heavy Metal|      2023-09-22|       onsale|        19:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|           AC Slater|     \"NaN\"|Z7r9jZ1Ad-Oux|https://www.ticke...|Stereo Live - Hou...| ZFr9jZa7A6|        77057|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|   6400 Richmond Ave|     -95.489304|     29.745001|           AC Slater|     attraction|  K8vZ917uec7|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvF|     Dance/Electronic|   KZazBEonSMnZfZ7vAJ1|              Club Dance|      2023-08-11|       onsale|        22:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|              Igorrr|     \"NaN\"|Z7r9jZ1AdjIos|https://www.ticke...|Warehouse Live-St...| ZFr9jZav7e|        77003|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|813 St. Emanuel S...|     -95.345596|     29.748899|              Igorrr|     attraction|  K8vZ917pZ90|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvF|     Dance/Electronic|   KZazBEonSMnZfZ7vAI1|    Intelligent Dance...|      2023-09-13|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|         Molly Burch|  standard|G5dIZ9l2AiJKD|https://www.ticke...|White Oak Music H...|KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|         Molly Burch|     attraction|  K8vZ9174M_f|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAev|                  Pop|   KZazBEonSMnZfZ7vk1t|                     Pop|      2023-09-30|       onsale|        20:00:00|     USD|     20.0|     20.0|\n",
      "|Houston Dynamo vs...|     \"NaN\"|Z7r9jZ1AdjJQo|https://www.ticke...|Shell Energy Stadium| ZFr9jZa61F|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|South Rice Avenue...|     -95.362999|     29.759399|      Houston Dynamo|     attraction|  K8vZ9175MiV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vA7E|               Soccer|   KZazBEonSMnZfZ7vFtI|                     MLS|      2023-08-20|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|         Steve Earle|     \"NaN\"|Z7r9jZ1AdxK_A|https://www.ticke...|     Heights Theater| Z7r9jZad5d|        77008|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|339 W 19th St, Ho...|     -95.418297|     29.798201|Steve Earle & the...|     attraction|  K8vZ917os57|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv6|              Country|   KZazBEonSMnZfZ7vAFa|                 Country|      2023-07-06|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|    96 Bitter Beings|  standard|G5dIZ9isiDOWJ|https://www.ticke...|White Oak Music H...|KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|    96 Bitter Beings|     attraction|  K8vZ917btN7|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6an|             Rock & Roll|      2023-08-29|       onsale|        18:30:00|     USD|     20.0|     20.0|\n",
      "|            Yam Haus|  standard|G5dIZ9n3vK-Ok|https://www.ticke...|White Oak Music H...|KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|            Yam Haus|     attraction|  K8vZ917bf60|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAev|                  Pop|   KZazBEonSMnZfZ7vkIa|               Synth Pop|      2023-10-26|       onsale|        19:00:00|     USD|     17.0|     17.0|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+-----------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "23/06/22 21:40:50 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1fede75a committed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:40:50 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/115 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.115.b8c9d2d9-a0ac-41f7-91f0-dd5bfe13c7d6.tmp\n",
      "23/06/22 21:40:50 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.115.b8c9d2d9-a0ac-41f7-91f0-dd5bfe13c7d6.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/115\n",
      "23/06/22 21:40:50 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:40:50.005Z\",\n",
      "  \"batchId\" : 115,\n",
      "  \"numInputRows\" : 39,\n",
      "  \"inputRowsPerSecond\" : 3.9,\n",
      "  \"processedRowsPerSecond\" : 130.43478260869566,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 101,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 9,\n",
      "    \"queryPlanning\" : 5,\n",
      "    \"triggerExecution\" : 299,\n",
      "    \"walCommit\" : 80\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2070\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2109\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 39,\n",
      "    \"inputRowsPerSecond\" : 3.9,\n",
      "    \"processedRowsPerSecond\" : 130.43478260869566\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 39\n",
      "  }\n",
      "}\n",
      "23/06/22 21:40:50 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-367a2af5-ec67-4915-a929-7f46cdab270b/_temporary/0/_temporary/' directory.\n",
      "23/06/22 21:40:50 INFO FileOutputCommitter: Saved output of task 'attempt_202306222140472542493641253014766_0240_m_000000_239' to gs://kafka-spark-data/.spark-bigquery-local-1687482506437-367a2af5-ec67-4915-a929-7f46cdab270b/_temporary/0/task_202306222140472542493641253014766_0240_m_000000\n",
      "23/06/22 21:40:50 INFO SparkHadoopMapRedUtil: attempt_202306222140472542493641253014766_0240_m_000000_239: Committed. Elapsed time: 1194 ms.\n",
      "23/06/22 21:40:50 INFO Executor: Finished task 0.0 in stage 240.0 (TID 239). 2536 bytes result sent to driver\n",
      "23/06/22 21:40:50 INFO TaskSetManager: Finished task 0.0 in stage 240.0 (TID 239) in 2505 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:40:50 INFO TaskSchedulerImpl: Removed TaskSet 240.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:40:50 INFO DAGScheduler: ResultStage 240 (start at NativeMethodAccessorImpl.java:0) finished in 2.527 s\n",
      "23/06/22 21:40:50 INFO DAGScheduler: Job 239 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:40:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 240: Stage finished\n",
      "23/06/22 21:40:50 INFO DAGScheduler: Job 239 finished: start at NativeMethodAccessorImpl.java:0, took 2.528419 s\n",
      "23/06/22 21:40:50 INFO FileFormatWriter: Start to commit write Job 7f9b9ece-c4c5-4873-a90e-76db51d162a8.\n",
      "23/06/22 21:40:52 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-367a2af5-ec67-4915-a929-7f46cdab270b/_temporary/0/task_202306222140472542493641253014766_0240_m_000000/' directory.\n",
      "23/06/22 21:40:53 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-367a2af5-ec67-4915-a929-7f46cdab270b/' directory.\n",
      "23/06/22 21:40:54 INFO FileFormatWriter: Write Job 7f9b9ece-c4c5-4873-a90e-76db51d162a8 committed. Elapsed time: 3871 ms.\n",
      "23/06/22 21:40:54 INFO FileFormatWriter: Finished processing stats for write job 7f9b9ece-c4c5-4873-a90e-76db51d162a8.\n",
      "23/06/22 21:40:54 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687482506437-367a2af5-ec67-4915-a929-7f46cdab270b/part-00000-71ca5ae2-d098-4f02-b1dc-8832065a597c-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=0ff92d08-9899-4235-b095-3b18672fb6f8, location=US}\n",
      "23/06/22 21:40:58 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=0ff92d08-9899-4235-b095-3b18672fb6f8, location=US}\n",
      "23/06/22 21:40:58 INFO BlockManagerInfo: Removed broadcast_240_piece0 on 192.168.4.24:51040 in memory (size: 9.9 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:40:58 INFO BlockManagerInfo: Removed broadcast_239_piece0 on 192.168.4.24:51040 in memory (size: 94.8 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:40:59 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/190 using temp file gs://kafka-spark-data/spark-metadata/commits/.190.cf1ed42c-1617-4848-b8a8-c6340dc52696.tmp\n",
      "23/06/22 21:41:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 2148.\n",
      "23/06/22 21:41:00 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/116 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.116.af71032c-34b3-4414-a9d6-348a24dcb8a0.tmp\n",
      "23/06/22 21:41:00 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.116.af71032c-34b3-4414-a9d6-348a24dcb8a0.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/116\n",
      "23/06/22 21:41:00 INFO MicroBatchExecution: Committed offsets for batch 116. Metadata OffsetSeqMetadata(0,1687488060017,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:41:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:00 INFO WriteToDataSourceV2Exec: Start processing data source write support: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@5e5ce2da. The input RDD has 1 partitions.\n",
      "23/06/22 21:41:00 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:41:00 INFO DAGScheduler: Got job 241 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:41:00 INFO DAGScheduler: Final stage: ResultStage 242 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:41:00 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:41:00 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:41:00 INFO DAGScheduler: Submitting ResultStage 242 (MapPartitionsRDD[1264] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:41:00 INFO MemoryStore: Block broadcast_241 stored as values in memory (estimated size 23.0 KiB, free 434.4 MiB)\n",
      "23/06/22 21:41:00 INFO MemoryStore: Block broadcast_241_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 434.4 MiB)\n",
      "23/06/22 21:41:00 INFO BlockManagerInfo: Added broadcast_241_piece0 in memory on 192.168.4.24:51040 (size: 9.9 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:41:00 INFO SparkContext: Created broadcast 241 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:41:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 242 (MapPartitionsRDD[1264] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:41:00 INFO TaskSchedulerImpl: Adding task set 242.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:41:00 INFO TaskSetManager: Starting task 0.0 in stage 242.0 (TID 241) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:41:00 INFO Executor: Running task 0.0 in stage 242.0 (TID 241)\n",
      "23/06/22 21:41:00 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 2109 for partition ticketmaster-0\n",
      "23/06/22 21:41:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:41:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 2148.\n",
      "23/06/22 21:41:00 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 2110 for partition ticketmaster-0\n",
      "23/06/22 21:41:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:41:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 2149.\n",
      "23/06/22 21:41:00 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 241, attempt 0, stage 242.0)\n",
      "23/06/22 21:41:00 INFO DataWritingSparkTask: Committed partition 0 (task 241, attempt 0, stage 242.0)\n",
      "23/06/22 21:41:00 INFO Executor: Finished task 0.0 in stage 242.0 (TID 241). 33911 bytes result sent to driver\n",
      "23/06/22 21:41:00 INFO TaskSetManager: Finished task 0.0 in stage 242.0 (TID 241) in 56 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:41:00 INFO TaskSchedulerImpl: Removed TaskSet 242.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:41:00 INFO DAGScheduler: ResultStage 242 (start at NativeMethodAccessorImpl.java:0) finished in 0.058 s\n",
      "23/06/22 21:41:00 INFO DAGScheduler: Job 241 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:41:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 242: Stage finished\n",
      "23/06/22 21:41:00 INFO DAGScheduler: Job 241 finished: start at NativeMethodAccessorImpl.java:0, took 0.058628 s\n",
      "23/06/22 21:41:00 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@5e5ce2da is committing.\n",
      "-------------------------------------------\n",
      "Batch: 116\n",
      "-------------------------------------------\n",
      "23/06/22 21:41:00 INFO BlockManagerInfo: Removed broadcast_241_piece0 on 192.168.4.24:51040 in memory (size: 9.9 KiB, free: 434.4 MiB)\n",
      "+--------------------+----------+-------------+--------------------+--------------------+-----------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|          event_name|event_type|     event_id|           event_url|          venue_name|   venue_id|venue_zipcode|venues_timezone|venue_city|venue_state_full|venue_state_short|  venue_country_name|venue_country_short|       venue_address|venue_longitude|venue_latitude|     attraction_name|attraction_type|attraction_id|      attraction_url|attraction_segment_id|attraction_segment_name|attraction_genre_id|attraction_genre_name|attraction_subgenre_id|attraction_subgenre_name|event_start_date|ticket_status|event_start_time|currency|min_price|max_price|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+-----------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|The Servant of Tw...|     \"NaN\"|Z7r9jZ1AdjV-a|https://www.ticke...|Alley Theatre-Hub...| Zkr9jZAdeL|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|       615 Texas Ave|     -95.362999|     29.759399|The Servant of Tw...|     attraction|   ZFr9jZeaFe|               \"NaN\"|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l6|      Performance Art|   KZazBEonSMnZfZ7v7l1|         Performance Art|      2023-06-25|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|      Chase & Status|     \"NaN\"|Z7r9jZ1Ad-Upp|https://www.ticke...|Stereo Live - Hou...| ZFr9jZa7A6|        77057|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|   6400 Richmond Ave|     -95.489304|     29.745001|      Chase & Status|     attraction|  K8vZ917Gxgf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvF|     Dance/Electronic|   KZazBEonSMnZfZ7vAJ1|              Club Dance|      2023-07-01|       onsale|        22:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Astros vs...|     \"NaN\"|Z7r9jZ1AdpZr8|https://www.ticke...|    Minute Maid Park| Z6r9jZkeke|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Crawford Street|     -95.362999|     29.759399|      Houston Astros|     attraction|  K8vZ91718zV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdv|             Baseball|   KZazBEonSMnZfZ7vF1n|                     MLB|      2023-09-20|       onsale|        13:10:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|        Estereomance|  standard|G5dIZ9nmeQwQr|https://concerts....|The Bronze Peacoc...|KovZ917A58V|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|     -95.364056|     29.753929|        Estereomance|     attraction|  K8vZ917h_eV|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvv|          Alternative|   KZazBEonSMnZfZ7vAde|              Indie Rock|      2023-08-12|       onsale|        19:00:00|     USD|     15.0|     15.0|\n",
      "|   Souls of Mischief|     \"NaN\"|Z7r9jZ1Ad-gqt|https://www.ticke...|   Last Concert Cafe| ZFr9jZkeaA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|       1403 Nance St|     -95.362999|     29.759399|   Souls of Mischief|     attraction|  K8vZ9171tqf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkdA|                   Urban|      2023-07-18|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|            Sungazer|  standard|G5dIZ9ntz1s_s|https://www.ticke...|White Oak Music H...|KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|            Sungazer|     attraction|  K8vZ917Q-Gf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvE|                 Jazz|   KZazBEonSMnZfZ7vkA6|                  Fusion|      2023-10-19|       onsale|        19:00:00|     USD|     20.0|     20.0|\n",
      "|Doobie - SOMEWHAT...|  standard|G5dIZ9iBvm-sw|https://concerts....|The Bronze Peacoc...|KovZ917A58V|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|     -95.364056|     29.753929|              Doobie|     attraction|  K8vZ917ff2V|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkvl|             Hip-Hop/Rap|      2023-10-27|       onsale|        19:00:00|     USD|     22.5|     22.5|\n",
      "|The Servant of Tw...|     \"NaN\"|Z7r9jZ1AdjV-_|https://www.ticke...|Alley Theatre-Hub...| Zkr9jZAdeL|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|       615 Texas Ave|     -95.362999|     29.759399|The Servant of Tw...|     attraction|   ZFr9jZeaFe|               \"NaN\"|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l6|      Performance Art|   KZazBEonSMnZfZ7v7l1|         Performance Art|      2023-06-30|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|       Whipped Cream|     \"NaN\"|Z7r9jZ1Ad-daU|https://www.ticke...|Stereo Live - Hou...| ZFr9jZa7A6|        77057|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|   6400 Richmond Ave|     -95.489304|     29.745001|       Whipped Cream|     attraction|   Z7r9jZaGHU|               \"NaN\"|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvl|                Other|   KZazBEonSMnZfZ7vk1I|                   Other|      2023-07-08|       onsale|        22:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|The Servant of Tw...|     \"NaN\"|Z7r9jZ1AdjV-9|https://www.ticke...|Alley Theatre-Hub...| Zkr9jZAdeL|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|       615 Texas Ave|     -95.362999|     29.759399|The Servant of Tw...|     attraction|   ZFr9jZeaFe|               \"NaN\"|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l6|      Performance Art|   KZazBEonSMnZfZ7v7l1|         Performance Art|      2023-06-27|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Dynamo vs...|     \"NaN\"|Z7r9jZ1AdjV16|https://www.ticke...|Shell Energy Stadium| ZFr9jZa61F|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|South Rice Avenue...|     -95.362999|     29.759399|      Houston Dynamo|     attraction|  K8vZ9175MiV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vA7E|               Soccer|   KZazBEonSMnZfZ7vFtI|                     MLS|      2023-09-16|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Sean McConnell w/...|     \"NaN\"|Z7r9jZ1Ad-sq_|https://www.ticke...|     Heights Theater| Z7r9jZad5d|        77008|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|339 W 19th St, Ho...|     -95.418297|     29.798201|      Sean McConnell|     attraction|  K8vZ917u3pV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-08-19|       onsale|        19:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|     Hello Seahorse!|     \"NaN\"|Z7r9jZ1Ad-ofd|https://www.ticke...|Warehouse Live-St...| ZFr9jZav7e|        77003|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|813 St. Emanuel S...|     -95.345596|     29.748899|     Hello Seahorse!|     attraction|  K8vZ917KHX0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6dt|        Alternative Rock|      2023-06-28|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|     Forgotten Space|     \"NaN\"|Z7r9jZ1Ad-MGp|https://www.ticke...|   Last Concert Cafe| ZFr9jZkeaA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|       1403 Nance St|     -95.362999|     29.759399|     Forgotten Space|     attraction|  K8vZ917oPB7|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAe6|            Undefined|   KZazBEonSMnZfZ7v6JI|               Undefined|      2023-06-23|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|The Servant of Tw...|     \"NaN\"|Z7r9jZ1AdjV-0|https://www.ticke...|Alley Theatre-Hub...| Zkr9jZAdeL|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|       615 Texas Ave|     -95.362999|     29.759399|The Servant of Tw...|     attraction|   ZFr9jZeaFe|               \"NaN\"|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l6|      Performance Art|   KZazBEonSMnZfZ7v7l1|         Performance Art|      2023-07-01|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|The Servant of Tw...|     \"NaN\"|Z7r9jZ1AdjV-P|https://www.ticke...|Alley Theatre-Hub...| Zkr9jZAdeL|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|       615 Texas Ave|     -95.362999|     29.759399|The Servant of Tw...|     attraction|   ZFr9jZeaFe|               \"NaN\"|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l6|      Performance Art|   KZazBEonSMnZfZ7v7l1|         Performance Art|      2023-07-01|       onsale|        14:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|         Boldy James|     \"NaN\"|Z7r9jZ1Ad0e0o|https://www.ticke...|Warehouse Live-Ba...| ZFr9jZAva6|        77003|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|813 St. Emanuel S...|     -95.345596|     29.748899|         Boldy James|     attraction|   Z7r9jZa2yX|               \"NaN\"|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvl|                Other|   KZazBEonSMnZfZ7vk1I|                   Other|      2023-07-19|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|The Servant of Tw...|     \"NaN\"|Z7r9jZ1AdjV-p|https://www.ticke...|Alley Theatre-Hub...| Zkr9jZAdeL|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|       615 Texas Ave|     -95.362999|     29.759399|The Servant of Tw...|     attraction|   ZFr9jZeaFe|               \"NaN\"|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l6|      Performance Art|   KZazBEonSMnZfZ7v7l1|         Performance Art|      2023-06-28|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|      Element Eighty|     \"NaN\"|Z7r9jZ1Ad-Yra|https://www.ticke...|Warehouse Live-St...| ZFr9jZav7e|        77003|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|813 St. Emanuel S...|     -95.345596|     29.748899|      Element Eighty|     attraction|   Z7r9jZaooj|               \"NaN\"|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvl|                Other|   KZazBEonSMnZfZ7vk1I|                   Other|      2023-07-22|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Dynamo vs...|     \"NaN\"|Z7r9jZ1AdjJQF|https://www.ticke...|Shell Energy Stadium| ZFr9jZa61F|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|South Rice Avenue...|     -95.362999|     29.759399|      Houston Dynamo|     attraction|  K8vZ9175MiV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vA7E|               Soccer|   KZazBEonSMnZfZ7vFtI|                     MLS|      2023-08-30|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+-----------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "23/06/22 21:41:00 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@5e5ce2da committed.\n",
      "23/06/22 21:41:00 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/116 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.116.12de1424-d559-4570-92c8-bc46a921f4bf.tmp\n",
      "23/06/22 21:41:00 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.116.12de1424-d559-4570-92c8-bc46a921f4bf.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/116\n",
      "23/06/22 21:41:00 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:41:00.001Z\",\n",
      "  \"batchId\" : 116,\n",
      "  \"numInputRows\" : 39,\n",
      "  \"inputRowsPerSecond\" : 3.9015606242497,\n",
      "  \"processedRowsPerSecond\" : 175.67567567567568,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 80,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 15,\n",
      "    \"queryPlanning\" : 4,\n",
      "    \"triggerExecution\" : 222,\n",
      "    \"walCommit\" : 67\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2109\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2148\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 39,\n",
      "    \"inputRowsPerSecond\" : 3.9015606242497,\n",
      "    \"processedRowsPerSecond\" : 175.67567567567568\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 39\n",
      "  }\n",
      "}\n",
      "23/06/22 21:41:01 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.190.cf1ed42c-1617-4848-b8a8-c6340dc52696.tmp to gs://kafka-spark-data/spark-metadata/commits/190\n",
      "23/06/22 21:41:01 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:40:43.075Z\",\n",
      "  \"batchId\" : 190,\n",
      "  \"numInputRows\" : 63,\n",
      "  \"inputRowsPerSecond\" : 3.9235224512673605,\n",
      "  \"processedRowsPerSecond\" : 3.3533826582211104,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 12546,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 5,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 18787,\n",
      "    \"walCommit\" : 3420\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2019\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2082\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 63,\n",
      "    \"inputRowsPerSecond\" : 3.9235224512673605,\n",
      "    \"processedRowsPerSecond\" : 3.3533826582211104\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:41:01 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 18787 milliseconds\n",
      "23/06/22 21:41:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 2155.\n",
      "23/06/22 21:41:02 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/191 using temp file gs://kafka-spark-data/spark-metadata/offsets/.191.488314ac-602b-4882-861c-521a51ad1091.tmp\n",
      "23/06/22 21:41:04 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.191.488314ac-602b-4882-861c-521a51ad1091.tmp to gs://kafka-spark-data/spark-metadata/offsets/191\n",
      "23/06/22 21:41:04 INFO MicroBatchExecution: Committed offsets for batch 191. Metadata OffsetSeqMetadata(0,1687488061866,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:41:04 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:04 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:04 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:04 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:05 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:41:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:41:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:41:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:41:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:41:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:41:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:41:06 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:41:06 INFO DAGScheduler: Got job 242 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:41:06 INFO DAGScheduler: Final stage: ResultStage 243 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:41:06 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:41:06 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:41:06 INFO DAGScheduler: Submitting ResultStage 243 (MapPartitionsRDD[1271] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:41:06 INFO MemoryStore: Block broadcast_242 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/22 21:41:06 INFO MemoryStore: Block broadcast_242_piece0 stored as bytes in memory (estimated size 94.8 KiB, free 434.0 MiB)\n",
      "23/06/22 21:41:06 INFO BlockManagerInfo: Added broadcast_242_piece0 in memory on 192.168.4.24:51040 (size: 94.8 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:41:06 INFO SparkContext: Created broadcast 242 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:41:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 243 (MapPartitionsRDD[1271] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:41:06 INFO TaskSchedulerImpl: Adding task set 243.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:41:06 INFO TaskSetManager: Starting task 0.0 in stage 243.0 (TID 242) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:41:06 INFO Executor: Running task 0.0 in stage 243.0 (TID 242)\n",
      "23/06/22 21:41:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:41:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:41:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:41:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:41:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:41:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:41:06 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:41:06 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:41:06 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/22 21:41:06 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/22 21:41:06 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/22 21:41:06 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/22 21:41:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/22 21:41:06 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 2103 for partition ticketmaster-0\n",
      "23/06/22 21:41:06 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:06 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:41:06 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:06 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 2174.\n",
      "23/06/22 21:41:06 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 2104 for partition ticketmaster-0\n",
      "23/06/22 21:41:06 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:06 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:41:06 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:06 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 2175.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 243:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:41:08 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-efcc22fa-6acd-4640-be29-ee2bbe7a78dd/_temporary/0/_temporary/' directory.\n",
      "23/06/22 21:41:08 INFO FileOutputCommitter: Saved output of task 'attempt_202306222141069129607150070399735_0243_m_000000_242' to gs://kafka-spark-data/.spark-bigquery-local-1687482506437-efcc22fa-6acd-4640-be29-ee2bbe7a78dd/_temporary/0/task_202306222141069129607150070399735_0243_m_000000\n",
      "23/06/22 21:41:08 INFO SparkHadoopMapRedUtil: attempt_202306222141069129607150070399735_0243_m_000000_242: Committed. Elapsed time: 1187 ms.\n",
      "23/06/22 21:41:08 INFO Executor: Finished task 0.0 in stage 243.0 (TID 242). 2536 bytes result sent to driver\n",
      "23/06/22 21:41:08 INFO TaskSetManager: Finished task 0.0 in stage 243.0 (TID 242) in 2513 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:41:08 INFO TaskSchedulerImpl: Removed TaskSet 243.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:41:08 INFO DAGScheduler: ResultStage 243 (start at NativeMethodAccessorImpl.java:0) finished in 2.537 s\n",
      "23/06/22 21:41:08 INFO DAGScheduler: Job 242 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:41:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 243: Stage finished\n",
      "23/06/22 21:41:08 INFO DAGScheduler: Job 242 finished: start at NativeMethodAccessorImpl.java:0, took 2.538499 s\n",
      "23/06/22 21:41:08 INFO FileFormatWriter: Start to commit write Job 2eb0b958-9fc9-46d9-b755-0adfc6a3b46f.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:41:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 2187.\n",
      "23/06/22 21:41:10 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/117 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.117.6e73653e-4e24-4173-98fb-6274217e91ef.tmp\n",
      "23/06/22 21:41:10 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.117.6e73653e-4e24-4173-98fb-6274217e91ef.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/117\n",
      "23/06/22 21:41:10 INFO MicroBatchExecution: Committed offsets for batch 117. Metadata OffsetSeqMetadata(0,1687488070007,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:41:10 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:10 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:10 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:10 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:10 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:10 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:10 INFO WriteToDataSourceV2Exec: Start processing data source write support: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1986520c. The input RDD has 1 partitions.\n",
      "23/06/22 21:41:10 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:41:10 INFO DAGScheduler: Got job 243 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:41:10 INFO DAGScheduler: Final stage: ResultStage 244 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:41:10 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:41:10 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:41:10 INFO DAGScheduler: Submitting ResultStage 244 (MapPartitionsRDD[1274] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:41:10 INFO MemoryStore: Block broadcast_243 stored as values in memory (estimated size 23.0 KiB, free 434.0 MiB)\n",
      "23/06/22 21:41:10 INFO MemoryStore: Block broadcast_243_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 434.0 MiB)\n",
      "23/06/22 21:41:10 INFO BlockManagerInfo: Added broadcast_243_piece0 in memory on 192.168.4.24:51040 (size: 9.9 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:41:10 INFO SparkContext: Created broadcast 243 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:41:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 244 (MapPartitionsRDD[1274] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:41:10 INFO TaskSchedulerImpl: Adding task set 244.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:41:10 INFO TaskSetManager: Starting task 0.0 in stage 244.0 (TID 243) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:41:10 INFO Executor: Running task 0.0 in stage 244.0 (TID 243)\n",
      "23/06/22 21:41:10 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 2148 for partition ticketmaster-0\n",
      "23/06/22 21:41:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:41:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 2188.\n",
      "23/06/22 21:41:10 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 2149 for partition ticketmaster-0\n",
      "23/06/22 21:41:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:41:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 2188.\n",
      "23/06/22 21:41:10 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 243, attempt 0, stage 244.0)\n",
      "23/06/22 21:41:10 INFO DataWritingSparkTask: Committed partition 0 (task 243, attempt 0, stage 244.0)\n",
      "23/06/22 21:41:10 INFO Executor: Finished task 0.0 in stage 244.0 (TID 243). 34849 bytes result sent to driver\n",
      "23/06/22 21:41:10 INFO TaskSetManager: Finished task 0.0 in stage 244.0 (TID 243) in 21 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:41:10 INFO TaskSchedulerImpl: Removed TaskSet 244.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:41:10 INFO DAGScheduler: ResultStage 244 (start at NativeMethodAccessorImpl.java:0) finished in 0.024 s\n",
      "23/06/22 21:41:10 INFO DAGScheduler: Job 243 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:41:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 244: Stage finished\n",
      "23/06/22 21:41:10 INFO DAGScheduler: Job 243 finished: start at NativeMethodAccessorImpl.java:0, took 0.023982 s\n",
      "23/06/22 21:41:10 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1986520c is committing.\n",
      "-------------------------------------------\n",
      "Batch: 117\n",
      "-------------------------------------------\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|          event_name|event_type|     event_id|           event_url|          venue_name|    venue_id|venue_zipcode|venues_timezone|venue_city|venue_state_full|venue_state_short|  venue_country_name|venue_country_short|       venue_address|venue_longitude|venue_latitude|     attraction_name|attraction_type|attraction_id|      attraction_url|attraction_segment_id|attraction_segment_name|attraction_genre_id|attraction_genre_name|attraction_subgenre_id|attraction_subgenre_name|event_start_date|ticket_status|event_start_time|currency|min_price|max_price|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|         Bruce Bruce|     \"NaN\"|G5e0Z9lAeX-_d|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|         Bruce Bruce|     attraction|  K8vZ9171HaV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-06-25|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|       Annie DiRusso|  standard|G5dIZ90zHZtRX|https://wl.seetic...|White Oak Music H...| KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|       Annie DiRusso|     attraction|  K8vZ917_NsV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAva|                 Folk|   KZazBEonSMnZfZ7vAn7|                    Folk|      2023-06-27|      offsale|        19:00:00|     USD|     18.0|     18.0|\n",
      "|          Paul Virzi|     \"NaN\"|G5e0Z9IfrKo65|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|          Paul Virzi|     attraction|  K8vZ917uuH7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-06-28|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Sauce Walka Birth...|  standard|G5dIZ9cokzzdy|https://www.ticke...|White Oak Music H...| KovZ917AiGZ|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      2915 N Main St|      -95.36562|      29.78627|               \"NaN\"|          \"NaN\"|        \"NaN\"|               \"NaN\"|                \"NaN\"|                  \"NaN\"|              \"NaN\"|                \"NaN\"|                 \"NaN\"|                   \"NaN\"|      2023-06-29|       onsale|        21:00:00|     USD|     6.29|     6.29|\n",
      "|Kevin James Thornton|     \"NaN\"|G5e0Z9NHmsOw3|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|Kevin James Thornton|     attraction|  K8vZ917_NL0|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-06-29|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|       Marlon Wayans|     \"NaN\"|G5e0Z9NjT9SG8|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|       Marlon Wayans|     attraction|  K8vZ917u6-0|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-06-30|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|       Marlon Wayans|     \"NaN\"|G5e0Z9NjTbdGH|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|       Marlon Wayans|     attraction|  K8vZ917u6-0|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-06-30|       onsale|        21:45:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "| Dave Chappelle Live|     \"NaN\"|G5dIZ9i1DDE-S|https://www.toyot...|       Toyota Center|KovZpZAJJIIA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|    1510 Polk Street|    -95.3623133|    29.7520386|      Dave Chappelle|     attraction|  K8vZ9171rcf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-07-01|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|       Marlon Wayans|     \"NaN\"|G5e0Z9NjT9SGG|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|       Marlon Wayans|     attraction|  K8vZ917u6-0|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-07-01|       onsale|        19:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|       Marlon Wayans|     \"NaN\"|G5e0Z9NjT9SGU|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|       Marlon Wayans|     attraction|  K8vZ917u6-0|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-07-01|       onsale|        21:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|       Marlon Wayans|     \"NaN\"|G5e0Z9NjT9SGi|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|       Marlon Wayans|     attraction|  K8vZ917u6-0|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-07-02|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Boris w/ The Melvins|     \"NaN\"|Z7r9jZ1Ad0NZk|https://www.ticke...|Warehouse Live-St...|  ZFr9jZav7e|        77003|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|813 St. Emanuel S...|     -95.345596|     29.748899|               Boris|     attraction|  K8vZ917fREV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvt|                Metal|   KZazBEonSMnZfZ7vkFd|             Heavy Metal|      2023-10-02|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|              Davido|     \"NaN\"|G5dIZ9tLbyU-w|https://www.toyot...|       Toyota Center|KovZpZAJJIIA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|    1510 Polk Street|    -95.3623133|    29.7520386|              Davido|     attraction|  K8vZ9173mOf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeF|                World|   KZazBEonSMnZfZ7v6Jt|                   World|      2023-07-07|       onsale|        19:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|    Donnell Rawlings|     \"NaN\"|G5e0Z906zksv_|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|    Donnell Rawlings|     attraction|  K8vZ917GlQV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-07-07|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|    Donnell Rawlings|     \"NaN\"|G5e0Z906zksvx|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|    Donnell Rawlings|     attraction|  K8vZ917GlQV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-07-07|       onsale|        21:45:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "| blink-182 Tour 2023|     \"NaN\"|G5dIZ9fSbCPMg|https://www.toyot...|       Toyota Center|KovZpZAJJIIA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|    1510 Polk Street|    -95.3623133|    29.7520386|           blink-182|     attraction|  K8vZ9171pNf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-07-08|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|    Donnell Rawlings|     \"NaN\"|G5e0Z906zk-vk|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|    Donnell Rawlings|     attraction|  K8vZ917GlQV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-07-08|       onsale|        19:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|    Donnell Rawlings|     \"NaN\"|G5e0Z906zksvO|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|    Donnell Rawlings|     attraction|  K8vZ917GlQV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-07-08|       onsale|        21:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|    Donnell Rawlings|     \"NaN\"|G5e0Z906zksvc|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|    Donnell Rawlings|     attraction|  K8vZ917GlQV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-07-09|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|            Paramore|     \"NaN\"|G5dIZ9pGxiIuG|https://hes32-ctp...|       Toyota Center|KovZpZAJJIIA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|    1510 Polk Street|    -95.3623133|    29.7520386|               Foals|     attraction|  K8vZ917GF37|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-07-11|       onsale|        19:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "23/06/22 21:41:10 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1986520c committed.\n",
      "23/06/22 21:41:10 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/117 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.117.d0053f6a-909a-414b-a0d8-e6b3a1bf6479.tmp\n",
      "23/06/22 21:41:10 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.117.d0053f6a-909a-414b-a0d8-e6b3a1bf6479.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/117\n",
      "23/06/22 21:41:10 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:41:10.005Z\",\n",
      "  \"batchId\" : 117,\n",
      "  \"numInputRows\" : 39,\n",
      "  \"inputRowsPerSecond\" : 3.8984406237505,\n",
      "  \"processedRowsPerSecond\" : 207.4468085106383,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 47,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 2,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 188,\n",
      "    \"walCommit\" : 65\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2148\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2187\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 39,\n",
      "    \"inputRowsPerSecond\" : 3.8984406237505,\n",
      "    \"processedRowsPerSecond\" : 207.4468085106383\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 39\n",
      "  }\n",
      "}\n",
      "23/06/22 21:41:10 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-efcc22fa-6acd-4640-be29-ee2bbe7a78dd/_temporary/0/task_202306222141069129607150070399735_0243_m_000000/' directory.\n",
      "23/06/22 21:41:11 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-efcc22fa-6acd-4640-be29-ee2bbe7a78dd/' directory.\n",
      "23/06/22 21:41:12 INFO FileFormatWriter: Write Job 2eb0b958-9fc9-46d9-b755-0adfc6a3b46f committed. Elapsed time: 3426 ms.\n",
      "23/06/22 21:41:12 INFO FileFormatWriter: Finished processing stats for write job 2eb0b958-9fc9-46d9-b755-0adfc6a3b46f.\n",
      "23/06/22 21:41:12 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687482506437-efcc22fa-6acd-4640-be29-ee2bbe7a78dd/part-00000-cb9c2e28-65b6-482a-8d51-4dc4d743c6a3-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=21bdc0b0-e995-4d35-bbac-c10fa2e3e09b, location=US}\n",
      "23/06/22 21:41:16 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=21bdc0b0-e995-4d35-bbac-c10fa2e3e09b, location=US}\n",
      "23/06/22 21:41:18 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/191 using temp file gs://kafka-spark-data/spark-metadata/commits/.191.8e132ff3-bc34-4d28-b904-a9394f1bcab6.tmp\n",
      "23/06/22 21:41:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 2226.\n",
      "23/06/22 21:41:20 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/118 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.118.70c05c00-b17d-4562-8d57-b7a58a074a3f.tmp\n",
      "23/06/22 21:41:20 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.118.70c05c00-b17d-4562-8d57-b7a58a074a3f.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/118\n",
      "23/06/22 21:41:20 INFO MicroBatchExecution: Committed offsets for batch 118. Metadata OffsetSeqMetadata(0,1687488080007,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:41:20 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:20 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:20 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:20 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:20 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:20 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:20 INFO WriteToDataSourceV2Exec: Start processing data source write support: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1a6bcc1. The input RDD has 1 partitions.\n",
      "23/06/22 21:41:20 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:41:20 INFO DAGScheduler: Got job 244 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:41:20 INFO DAGScheduler: Final stage: ResultStage 245 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:41:20 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:41:20 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:41:20 INFO DAGScheduler: Submitting ResultStage 245 (MapPartitionsRDD[1277] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:41:20 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.191.8e132ff3-bc34-4d28-b904-a9394f1bcab6.tmp to gs://kafka-spark-data/spark-metadata/commits/191\n",
      "23/06/22 21:41:20 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:41:01.862Z\",\n",
      "  \"batchId\" : 191,\n",
      "  \"numInputRows\" : 73,\n",
      "  \"inputRowsPerSecond\" : 3.885665619843509,\n",
      "  \"processedRowsPerSecond\" : 3.9956212370005475,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 12474,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 4,\n",
      "    \"queryPlanning\" : 7,\n",
      "    \"triggerExecution\" : 18270,\n",
      "    \"walCommit\" : 3042\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2082\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2155\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 73,\n",
      "    \"inputRowsPerSecond\" : 3.885665619843509,\n",
      "    \"processedRowsPerSecond\" : 3.9956212370005475\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:41:20 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 18272 milliseconds\n",
      "23/06/22 21:41:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:20 INFO MemoryStore: Block broadcast_244 stored as values in memory (estimated size 23.0 KiB, free 434.0 MiB)\n",
      "23/06/22 21:41:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 2227.\n",
      "23/06/22 21:41:20 INFO MemoryStore: Block broadcast_244_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 434.0 MiB)\n",
      "23/06/22 21:41:20 INFO BlockManagerInfo: Added broadcast_244_piece0 in memory on 192.168.4.24:51040 (size: 9.9 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:41:20 INFO SparkContext: Created broadcast 244 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:41:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 245 (MapPartitionsRDD[1277] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:41:20 INFO TaskSchedulerImpl: Adding task set 245.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:41:20 INFO TaskSetManager: Starting task 0.0 in stage 245.0 (TID 244) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:41:20 INFO Executor: Running task 0.0 in stage 245.0 (TID 244)\n",
      "23/06/22 21:41:20 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 2187 for partition ticketmaster-0\n",
      "23/06/22 21:41:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:41:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 2227.\n",
      "23/06/22 21:41:20 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 2188 for partition ticketmaster-0\n",
      "23/06/22 21:41:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:41:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 2228.\n",
      "23/06/22 21:41:20 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 244, attempt 0, stage 245.0)\n",
      "23/06/22 21:41:20 INFO DataWritingSparkTask: Committed partition 0 (task 244, attempt 0, stage 245.0)\n",
      "23/06/22 21:41:20 INFO Executor: Finished task 0.0 in stage 245.0 (TID 244). 34860 bytes result sent to driver\n",
      "23/06/22 21:41:20 INFO TaskSetManager: Finished task 0.0 in stage 245.0 (TID 244) in 191 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:41:20 INFO TaskSchedulerImpl: Removed TaskSet 245.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:41:20 INFO DAGScheduler: ResultStage 245 (start at NativeMethodAccessorImpl.java:0) finished in 0.206 s\n",
      "23/06/22 21:41:20 INFO DAGScheduler: Job 244 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:41:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 245: Stage finished\n",
      "23/06/22 21:41:20 INFO DAGScheduler: Job 244 finished: start at NativeMethodAccessorImpl.java:0, took 0.214903 s\n",
      "23/06/22 21:41:20 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1a6bcc1 is committing.\n",
      "-------------------------------------------\n",
      "Batch: 118\n",
      "-------------------------------------------\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+----------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|          event_name|event_type|     event_id|           event_url|          venue_name|    venue_id|venue_zipcode|venues_timezone|venue_city|venue_state_full|venue_state_short|  venue_country_name|venue_country_short|       venue_address|venue_longitude|venue_latitude| attraction_name|attraction_type|attraction_id|      attraction_url|attraction_segment_id|attraction_segment_name|attraction_genre_id|attraction_genre_name|attraction_subgenre_id|attraction_subgenre_name|event_start_date|ticket_status|event_start_time|currency|min_price|max_price|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+----------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|Houston Dynamo vs...|     \"NaN\"|Z7r9jZ1AdjJQ3|https://www.ticke...|Shell Energy Stadium|  ZFr9jZa61F|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|South Rice Avenue...|     -95.362999|     29.759399|  Houston Dynamo|     attraction|  K8vZ9175MiV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vA7E|               Soccer|   KZazBEonSMnZfZ7vFtI|                     MLS|      2023-10-07|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Dave Lawson & Ali...|     \"NaN\"|G5e0Z9lGV1dqH|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|           \"NaN\"|          \"NaN\"|        \"NaN\"|               \"NaN\"|                \"NaN\"|                  \"NaN\"|              \"NaN\"|                \"NaN\"|                 \"NaN\"|                   \"NaN\"|      2023-07-26|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Dynamo vs...|     \"NaN\"|Z7r9jZ1AdjJQK|https://www.ticke...|Shell Energy Stadium|  ZFr9jZa61F|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|South Rice Avenue...|     -95.362999|     29.759399|  Houston Dynamo|     attraction|  K8vZ9175MiV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vA7E|               Soccer|   KZazBEonSMnZfZ7vFtI|                     MLS|      2023-09-20|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|           Deer Tick|     \"NaN\"|Z7r9jZ1AdOSZY|https://www.ticke...|     Heights Theater|  Z7r9jZad5d|        77008|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|339 W 19th St, Ho...|     -95.418297|     29.798201|       Deer Tick|     attraction|  K8vZ917GEz0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAva|                 Folk|   KZazBEonSMnZfZ7vAn7|                    Folk|      2023-10-20|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Greta Van Fleet -...|     \"NaN\"|G5dIZ9t6geJ_H|https://www.toyot...|       Toyota Center|KovZpZAJJIIA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|    1510 Polk Street|    -95.3623133|    29.7520386| Greta Van Fleet|     attraction|  K8vZ91738o0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-07-28|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|    Frankie Quinones|     \"NaN\"|G5e0Z9I2nReWk|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|Frankie Quinones|     attraction|  K8vZ917CDRV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-07-28|       onsale|        21:45:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|    Frankie Quinones|     \"NaN\"|G5e0Z9I2nmwHk|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|Frankie Quinones|     attraction|  K8vZ917CDRV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-07-28|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|    Frankie Quinones|     \"NaN\"|G5e0Z9I2nR3WU|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|Frankie Quinones|     attraction|  K8vZ917CDRV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-07-29|       onsale|        21:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|    Frankie Quinones|     \"NaN\"|G5e0Z9I2nR3Wn|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|Frankie Quinones|     attraction|  K8vZ917CDRV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-07-29|       onsale|        19:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|      Karlous Miller|     \"NaN\"|Z7r9jZ1Adqzus|https://www.ticke...|Cullen Performanc...|  ZFr9jZ7Fa6|        77004|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|   4800 Calhoun Road|     -95.363197|       29.7248|  Karlous Miller|     attraction|  K8vZ9178oF7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-07-29|       onsale|        19:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|          Switchfoot|     \"NaN\"|Z7r9jZ1Ad-gZx|https://www.ticke...|     Heights Theater|  Z7r9jZad5d|        77008|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|339 W 19th St, Ho...|     -95.418297|     29.798201|      SWITCHFOOT|     attraction|  K8vZ9171nkV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-09-22|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|    Frankie Quinones|     \"NaN\"|G5e0Z9I2nReWG|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|Frankie Quinones|     attraction|  K8vZ917CDRV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-07-30|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|            Son Volt|     \"NaN\"|Z7r9jZ1Ad-ZGZ|https://www.ticke...|     Heights Theater|  Z7r9jZad5d|        77008|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|339 W 19th St, Ho...|     -95.418297|     29.798201|        Son Volt|     attraction|  K8vZ91713SV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6dt|        Alternative Rock|      2023-08-25|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "| Two D*Kes and a Mic|     \"NaN\"|G5e0Z9lDRAYPh|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|           \"NaN\"|          \"NaN\"|        \"NaN\"|               \"NaN\"|                \"NaN\"|                  \"NaN\"|              \"NaN\"|                \"NaN\"|                 \"NaN\"|                   \"NaN\"|      2023-08-01|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|      Bert Kreischer|     \"NaN\"|Z7r9jZ1Adxv1F|https://www.ticke...|  Toyota Center - TX|  ZFr9jZ7v7v|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        1510 Polk St|     -95.362999|     29.759399|  Bert Kreischer|     attraction|  K8vZ917oyN0|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-09-24|       onsale|        19:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|        Jerry Garcia|     \"NaN\"|G5e0Z9n0Qj-ZW|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|           \"NaN\"|          \"NaN\"|        \"NaN\"|               \"NaN\"|                \"NaN\"|                  \"NaN\"|              \"NaN\"|                \"NaN\"|                 \"NaN\"|                   \"NaN\"|      2023-08-02|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|       Riki Rachtman|  standard|G5dIZ9cKuh4bo|https://concerts....|The Bronze Peacoc...| KovZ917A58V|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|     -95.364056|     29.753929|   Riki Rachtman|     attraction|  K8vZ917hLMf|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvt|                Metal|   KZazBEonSMnZfZ7vkFd|             Heavy Metal|      2023-08-04|      offsale|        19:30:00|     USD|     25.0|     35.0|\n",
      "|Thomas Rhett: Hom...|     \"NaN\"|G5dIZ9pK_dAKE|https://www.toyot...|       Toyota Center|KovZpZAJJIIA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|    1510 Polk Street|    -95.3623133|    29.7520386|    Thomas Rhett|     attraction|  K8vZ917Cqe0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv6|              Country|   KZazBEonSMnZfZ7vAFa|                 Country|      2023-08-04|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|         Matteo Lane|     \"NaN\"|G5e0Z9ljYg8UT|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|     Matteo Lane|     attraction|  K8vZ9173Fa0|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-08-04|       onsale|        21:45:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|         Matteo Lane|     \"NaN\"|G5e0Z9ljYgOzp|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|     Matteo Lane|     attraction|  K8vZ9173Fa0|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-08-04|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+----------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "23/06/22 21:41:20 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1a6bcc1 committed.\n",
      "23/06/22 21:41:20 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/118 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.118.f47da94c-d062-4a6c-b98c-adcba943604a.tmp\n",
      "23/06/22 21:41:20 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.118.f47da94c-d062-4a6c-b98c-adcba943604a.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/118\n",
      "23/06/22 21:41:20 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:41:20.000Z\",\n",
      "  \"batchId\" : 118,\n",
      "  \"numInputRows\" : 39,\n",
      "  \"inputRowsPerSecond\" : 3.901950975487744,\n",
      "  \"processedRowsPerSecond\" : 94.20289855072464,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 253,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 5,\n",
      "    \"queryPlanning\" : 13,\n",
      "    \"triggerExecution\" : 414,\n",
      "    \"walCommit\" : 82\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2187\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2226\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 39,\n",
      "    \"inputRowsPerSecond\" : 3.901950975487744,\n",
      "    \"processedRowsPerSecond\" : 94.20289855072464\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 39\n",
      "  }\n",
      "}\n",
      "23/06/22 21:41:20 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/192 using temp file gs://kafka-spark-data/spark-metadata/offsets/.192.9749fc48-73a9-4278-a7fd-3761e7e2f4e8.tmp\n",
      "23/06/22 21:41:22 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.192.9749fc48-73a9-4278-a7fd-3761e7e2f4e8.tmp to gs://kafka-spark-data/spark-metadata/offsets/192\n",
      "23/06/22 21:41:22 INFO MicroBatchExecution: Committed offsets for batch 192. Metadata OffsetSeqMetadata(0,1687488080138,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:41:24 INFO BlockManagerInfo: Removed broadcast_242_piece0 on 192.168.4.24:51040 in memory (size: 94.8 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:41:24 INFO BlockManagerInfo: Removed broadcast_243_piece0 on 192.168.4.24:51040 in memory (size: 9.9 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:41:24 INFO BlockManagerInfo: Removed broadcast_244_piece0 on 192.168.4.24:51040 in memory (size: 9.9 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:41:24 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:24 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:24 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:24 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:25 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:41:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:41:25 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:41:25 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:41:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:41:25 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:41:25 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:41:25 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:41:25 INFO DAGScheduler: Got job 245 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:41:25 INFO DAGScheduler: Final stage: ResultStage 246 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:41:25 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:41:25 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:41:25 INFO DAGScheduler: Submitting ResultStage 246 (MapPartitionsRDD[1284] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:41:25 INFO MemoryStore: Block broadcast_245 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/22 21:41:25 INFO MemoryStore: Block broadcast_245_piece0 stored as bytes in memory (estimated size 94.8 KiB, free 434.0 MiB)\n",
      "23/06/22 21:41:25 INFO BlockManagerInfo: Added broadcast_245_piece0 in memory on 192.168.4.24:51040 (size: 94.8 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:41:25 INFO SparkContext: Created broadcast 245 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:41:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 246 (MapPartitionsRDD[1284] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:41:25 INFO TaskSchedulerImpl: Adding task set 246.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:41:25 INFO TaskSetManager: Starting task 0.0 in stage 246.0 (TID 245) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:41:25 INFO Executor: Running task 0.0 in stage 246.0 (TID 245)\n",
      "23/06/22 21:41:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:41:25 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:41:25 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:41:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:41:25 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:41:25 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:41:25 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:41:25 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:41:25 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/22 21:41:25 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/22 21:41:25 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/22 21:41:25 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/22 21:41:25 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/22 21:41:26 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 2174 for partition ticketmaster-0\n",
      "23/06/22 21:41:26 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:26 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:41:26 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:26 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 2251.\n",
      "23/06/22 21:41:26 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 2175 for partition ticketmaster-0\n",
      "23/06/22 21:41:26 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:26 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:41:26 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:26 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 2252.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 246:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:41:28 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-39a4ba70-fa3f-4daf-944f-84525d17f390/_temporary/0/_temporary/' directory.\n",
      "23/06/22 21:41:28 INFO FileOutputCommitter: Saved output of task 'attempt_20230622214125342101580015608478_0246_m_000000_245' to gs://kafka-spark-data/.spark-bigquery-local-1687482506437-39a4ba70-fa3f-4daf-944f-84525d17f390/_temporary/0/task_20230622214125342101580015608478_0246_m_000000\n",
      "23/06/22 21:41:28 INFO SparkHadoopMapRedUtil: attempt_20230622214125342101580015608478_0246_m_000000_245: Committed. Elapsed time: 1133 ms.\n",
      "23/06/22 21:41:28 INFO Executor: Finished task 0.0 in stage 246.0 (TID 245). 2536 bytes result sent to driver\n",
      "23/06/22 21:41:28 INFO TaskSetManager: Finished task 0.0 in stage 246.0 (TID 245) in 2285 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:41:28 INFO TaskSchedulerImpl: Removed TaskSet 246.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:41:28 INFO DAGScheduler: ResultStage 246 (start at NativeMethodAccessorImpl.java:0) finished in 2.310 s\n",
      "23/06/22 21:41:28 INFO DAGScheduler: Job 245 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:41:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 246: Stage finished\n",
      "23/06/22 21:41:28 INFO DAGScheduler: Job 245 finished: start at NativeMethodAccessorImpl.java:0, took 2.314011 s\n",
      "23/06/22 21:41:28 INFO FileFormatWriter: Start to commit write Job 4ce4fe71-57c3-47ec-8f1e-3728cb864b5d.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:41:29 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-39a4ba70-fa3f-4daf-944f-84525d17f390/_temporary/0/task_20230622214125342101580015608478_0246_m_000000/' directory.\n",
      "23/06/22 21:41:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 2265.\n",
      "23/06/22 21:41:30 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/119 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.119.bec161e9-3015-4708-9f55-03515d62e910.tmp\n",
      "23/06/22 21:41:30 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.119.bec161e9-3015-4708-9f55-03515d62e910.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/119\n",
      "23/06/22 21:41:30 INFO MicroBatchExecution: Committed offsets for batch 119. Metadata OffsetSeqMetadata(0,1687488090003,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:41:30 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:30 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:30 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:30 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:30 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:30 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:30 INFO WriteToDataSourceV2Exec: Start processing data source write support: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@583b845d. The input RDD has 1 partitions.\n",
      "23/06/22 21:41:30 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:41:30 INFO DAGScheduler: Got job 246 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:41:30 INFO DAGScheduler: Final stage: ResultStage 247 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:41:30 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:41:30 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:41:30 INFO DAGScheduler: Submitting ResultStage 247 (MapPartitionsRDD[1287] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:41:30 INFO MemoryStore: Block broadcast_246 stored as values in memory (estimated size 23.0 KiB, free 434.0 MiB)\n",
      "23/06/22 21:41:30 INFO MemoryStore: Block broadcast_246_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 434.0 MiB)\n",
      "23/06/22 21:41:30 INFO BlockManagerInfo: Added broadcast_246_piece0 in memory on 192.168.4.24:51040 (size: 9.9 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:41:30 INFO SparkContext: Created broadcast 246 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:41:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 247 (MapPartitionsRDD[1287] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:41:30 INFO TaskSchedulerImpl: Adding task set 247.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:41:30 INFO TaskSetManager: Starting task 0.0 in stage 247.0 (TID 246) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:41:30 INFO Executor: Running task 0.0 in stage 247.0 (TID 246)\n",
      "23/06/22 21:41:30 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 2227 for partition ticketmaster-0\n",
      "23/06/22 21:41:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:41:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 2266.\n",
      "23/06/22 21:41:30 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 2228 for partition ticketmaster-0\n",
      "23/06/22 21:41:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:41:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 2267.\n",
      "23/06/22 21:41:30 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 246, attempt 0, stage 247.0)\n",
      "23/06/22 21:41:30 INFO DataWritingSparkTask: Committed partition 0 (task 246, attempt 0, stage 247.0)\n",
      "23/06/22 21:41:30 INFO Executor: Finished task 0.0 in stage 247.0 (TID 246). 34804 bytes result sent to driver\n",
      "23/06/22 21:41:30 INFO TaskSetManager: Finished task 0.0 in stage 247.0 (TID 246) in 229 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:41:30 INFO TaskSchedulerImpl: Removed TaskSet 247.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:41:30 INFO DAGScheduler: ResultStage 247 (start at NativeMethodAccessorImpl.java:0) finished in 0.231 s\n",
      "23/06/22 21:41:30 INFO DAGScheduler: Job 246 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:41:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 247: Stage finished\n",
      "23/06/22 21:41:30 INFO DAGScheduler: Job 246 finished: start at NativeMethodAccessorImpl.java:0, took 0.231966 s\n",
      "23/06/22 21:41:30 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@583b845d is committing.\n",
      "-------------------------------------------\n",
      "Batch: 119\n",
      "-------------------------------------------\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|          event_name|event_type|     event_id|           event_url|          venue_name|    venue_id|venue_zipcode|venues_timezone|venue_city|venue_state_full|venue_state_short|  venue_country_name|venue_country_short|       venue_address|venue_longitude|venue_latitude|     attraction_name|attraction_type|attraction_id|      attraction_url|attraction_segment_id|attraction_segment_name|attraction_genre_id|attraction_genre_name|attraction_subgenre_id|attraction_subgenre_name|event_start_date|ticket_status|event_start_time|currency|min_price|max_price|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|Houston Ballet w/...|     \"NaN\"|Z7r9jZ1Ad-tZ3|https://www.ticke...|Brown Theatre-Wor...|  Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        501 Texas St|     -95.362999|     29.759399|      Houston Ballet|     attraction|  K8vZ9171oIf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2023-09-30|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Lil Durk - Sorry ...|     \"NaN\"|G5dIZ9leKOEFP|https://www.toyot...|       Toyota Center|KovZpZAJJIIA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|    1510 Polk Street|    -95.3623133|    29.7520386|            Lil Durk|     attraction|  K8vZ9173A9f|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkdA|                   Urban|      2023-08-21|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|          Man On Man|  standard|G5dIZ9iwwlvz0|https://www.ticke...|White Oak Music H...| KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|          Man On Man|     attraction|  K8vZ917Qd60|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v66A|              Indie Rock|      2023-10-12|       onsale|        19:00:00|     USD|     20.0|     20.0|\n",
      "|Houston Ballet w/...|     \"NaN\"|Z7r9jZ1Ad-MAN|https://www.ticke...|Brown Theatre-Wor...|  Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        501 Texas St|     -95.362999|     29.759399|      Houston Ballet|     attraction|  K8vZ9171oIf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2023-10-01|       onsale|        14:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Ballet w/...|     \"NaN\"|Z7r9jZ1Ad-MAK|https://www.ticke...|Brown Theatre-Wor...|  Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        501 Texas St|     -95.362999|     29.759399|      Houston Ballet|     attraction|  K8vZ9171oIf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2023-09-15|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|           ALEXSUCKS|  standard|G5dIZ9c7U_9rE|https://www.ticke...|White Oak Music H...| KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|           ALEXSUCKS|     attraction|  K8vZ917QcX7|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-08-23|       onsale|        19:00:00|     USD|     13.0|     13.0|\n",
      "|  Sir Richard Bishop|  standard|G5dIZ9cKD8pWn|https://www.ticke...|White Oak Music H...| KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|  Sir Richard Bishop|     attraction|  K8vZ917CL00|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-08-24|       onsale|        19:00:00|     USD|     15.0|     15.0|\n",
      "|50 Cent: The Fina...|     \"NaN\"|G5dIZ9nC0Vddy|https://www.toyot...|       Toyota Center|KovZpZAJJIIA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|    1510 Polk Street|    -95.3623133|    29.7520386|             50 Cent|     attraction|  K8vZ9175fm7|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkdA|                   Urban|      2023-08-24|       onsale|        19:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Ballet w/...|     \"NaN\"|Z7r9jZ1Ad-Iv7|https://www.ticke...|Brown Theatre-Wor...|  Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        501 Texas St|     -95.362999|     29.759399|      Houston Ballet|     attraction|  K8vZ9171oIf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2023-09-16|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|LL COOL J: The F....|     \"NaN\"|G5dIZ9tPsU-l7|https://www.toyot...|       Toyota Center|KovZpZAJJIIA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|    1510 Polk Street|    -95.3623133|    29.7520386|           LL COOL J|     attraction|  K8vZ9171G50|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkdA|                   Urban|      2023-08-25|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|       Corey Holcomb|     \"NaN\"|G5e0Z9NOV0Ow_|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|       Corey Holcomb|     attraction|  K8vZ917utO7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-08-25|       onsale|        21:45:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|       Corey Holcomb|     \"NaN\"|G5e0Z9NOVPZgI|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|       Corey Holcomb|     attraction|  K8vZ917utO7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-08-25|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|       Corey Holcomb|     \"NaN\"|G5e0Z9NOV08sD|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|       Corey Holcomb|     attraction|  K8vZ917utO7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-08-26|       onsale|        21:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|       Corey Holcomb|     \"NaN\"|G5e0Z9NOV08sk|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|       Corey Holcomb|     attraction|  K8vZ917utO7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-08-26|       onsale|        19:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Cougars F...|     \"NaN\"|Z7r9jZ1Adqwat|https://www.ticke...|       TDECU Stadium|  ZFr9jZddvv|        77004|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|  3874 Holman Street|     -95.363197|       29.7248|University of Hou...|     attraction|  K8vZ9171MWf|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdE|             Football|   KZazBEonSMnZfZ7vFE6|                 College|      2023-11-18|       onsale|           \"NaN\"|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|       Corey Holcomb|     \"NaN\"|G5e0Z9NOV08ss|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|       Corey Holcomb|     attraction|  K8vZ917utO7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-08-27|       onsale|        19:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|       Corey Holcomb|     \"NaN\"|G5e0Z9NiL6sTj|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|       Corey Holcomb|     attraction|  K8vZ917utO7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-08-27|       onsale|        21:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Ballet w/...|     \"NaN\"|Z7r9jZ1Ad-y4_|https://www.ticke...|Brown Theatre-Wor...|  Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        501 Texas St|     -95.362999|     29.759399|      Houston Ballet|     attraction|  K8vZ9171oIf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2023-09-16|       onsale|        13:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Ballet w/...|     \"NaN\"|Z7r9jZ1Ad-MA8|https://www.ticke...|Brown Theatre-Wor...|  Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        501 Texas St|     -95.362999|     29.759399|      Houston Ballet|     attraction|  K8vZ9171oIf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2023-09-21|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|MANÁ: México Lind...|     \"NaN\"|G5dIZ9EGZXNld|https://www.toyot...|       Toyota Center|KovZpZAJJIIA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|    1510 Polk Street|    -95.3623133|    29.7520386|                MANÁ|     attraction|  K8vZ9171Kyf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeF|                World|   KZazBEonSMnZfZ7vFdJ|                   Latin|      2023-09-01|       onsale|        20:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "23/06/22 21:41:30 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@583b845d committed.\n",
      "23/06/22 21:41:30 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/119 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.119.861ce10c-2ca5-4ae5-b731-77eaa84b35e5.tmp\n",
      "23/06/22 21:41:30 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.119.861ce10c-2ca5-4ae5-b731-77eaa84b35e5.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/119\n",
      "23/06/22 21:41:30 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:41:30.001Z\",\n",
      "  \"batchId\" : 119,\n",
      "  \"numInputRows\" : 39,\n",
      "  \"inputRowsPerSecond\" : 3.8996100389961006,\n",
      "  \"processedRowsPerSecond\" : 100.25706940874036,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 254,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 2,\n",
      "    \"queryPlanning\" : 6,\n",
      "    \"triggerExecution\" : 389,\n",
      "    \"walCommit\" : 67\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2226\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2265\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 39,\n",
      "    \"inputRowsPerSecond\" : 3.8996100389961006,\n",
      "    \"processedRowsPerSecond\" : 100.25706940874036\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 39\n",
      "  }\n",
      "}\n",
      "23/06/22 21:41:30 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-39a4ba70-fa3f-4daf-944f-84525d17f390/' directory.\n",
      "23/06/22 21:41:30 INFO BlockManagerInfo: Removed broadcast_245_piece0 on 192.168.4.24:51040 in memory (size: 94.8 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:41:30 INFO BlockManagerInfo: Removed broadcast_246_piece0 on 192.168.4.24:51040 in memory (size: 9.9 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:41:31 INFO FileFormatWriter: Write Job 4ce4fe71-57c3-47ec-8f1e-3728cb864b5d committed. Elapsed time: 3123 ms.\n",
      "23/06/22 21:41:31 INFO FileFormatWriter: Finished processing stats for write job 4ce4fe71-57c3-47ec-8f1e-3728cb864b5d.\n",
      "23/06/22 21:41:31 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687482506437-39a4ba70-fa3f-4daf-944f-84525d17f390/part-00000-97a4c57e-3faf-4a4c-85d3-3081728b943f-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=c3526737-c8f5-4e07-a5d5-693e6f344f87, location=US}\n",
      "23/06/22 21:41:34 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=c3526737-c8f5-4e07-a5d5-693e6f344f87, location=US}\n",
      "23/06/22 21:41:35 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/192 using temp file gs://kafka-spark-data/spark-metadata/commits/.192.ad63d6fb-ed8b-4728-9315-df38f5e797ad.tmp\n",
      "23/06/22 21:41:37 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.192.ad63d6fb-ed8b-4728-9315-df38f5e797ad.tmp to gs://kafka-spark-data/spark-metadata/commits/192\n",
      "23/06/22 21:41:37 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:41:20.135Z\",\n",
      "  \"batchId\" : 192,\n",
      "  \"numInputRows\" : 72,\n",
      "  \"inputRowsPerSecond\" : 3.9402396979149565,\n",
      "  \"processedRowsPerSecond\" : 4.123711340206185,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 10872,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 3,\n",
      "    \"queryPlanning\" : 9,\n",
      "    \"triggerExecution\" : 17460,\n",
      "    \"walCommit\" : 4200\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2155\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2227\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 72,\n",
      "    \"inputRowsPerSecond\" : 3.9402396979149565,\n",
      "    \"processedRowsPerSecond\" : 4.123711340206185\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:41:37 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 17461 milliseconds\n",
      "23/06/22 21:41:37 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:37 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 2295.\n",
      "23/06/22 21:41:38 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/193 using temp file gs://kafka-spark-data/spark-metadata/offsets/.193.622145c0-8d5f-47f0-aa9c-d90f2d222c4e.tmp\n",
      "23/06/22 21:41:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 2304.\n",
      "23/06/22 21:41:40 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/120 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.120.4a4440bd-c187-4792-91e3-d5ea882cec69.tmp\n",
      "23/06/22 21:41:40 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.120.4a4440bd-c187-4792-91e3-d5ea882cec69.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/120\n",
      "23/06/22 21:41:40 INFO MicroBatchExecution: Committed offsets for batch 120. Metadata OffsetSeqMetadata(0,1687488100004,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:41:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:40 INFO WriteToDataSourceV2Exec: Start processing data source write support: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@75cd4e55. The input RDD has 1 partitions.\n",
      "23/06/22 21:41:40 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:41:40 INFO DAGScheduler: Got job 247 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:41:40 INFO DAGScheduler: Final stage: ResultStage 248 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:41:40 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:41:40 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:41:40 INFO DAGScheduler: Submitting ResultStage 248 (MapPartitionsRDD[1290] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:41:40 INFO MemoryStore: Block broadcast_247 stored as values in memory (estimated size 23.0 KiB, free 434.4 MiB)\n",
      "23/06/22 21:41:40 INFO MemoryStore: Block broadcast_247_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 434.4 MiB)\n",
      "23/06/22 21:41:40 INFO BlockManagerInfo: Added broadcast_247_piece0 in memory on 192.168.4.24:51040 (size: 9.9 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:41:40 INFO SparkContext: Created broadcast 247 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:41:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 248 (MapPartitionsRDD[1290] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:41:40 INFO TaskSchedulerImpl: Adding task set 248.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:41:40 INFO TaskSetManager: Starting task 0.0 in stage 248.0 (TID 247) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:41:40 INFO Executor: Running task 0.0 in stage 248.0 (TID 247)\n",
      "23/06/22 21:41:40 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 2266 for partition ticketmaster-0\n",
      "23/06/22 21:41:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:41:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 2305.\n",
      "23/06/22 21:41:40 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 2267 for partition ticketmaster-0\n",
      "23/06/22 21:41:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:41:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 2306.\n",
      "23/06/22 21:41:40 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 247, attempt 0, stage 248.0)\n",
      "23/06/22 21:41:40 INFO DataWritingSparkTask: Committed partition 0 (task 247, attempt 0, stage 248.0)\n",
      "23/06/22 21:41:40 INFO Executor: Finished task 0.0 in stage 248.0 (TID 247). 34713 bytes result sent to driver\n",
      "23/06/22 21:41:40 INFO TaskSetManager: Finished task 0.0 in stage 248.0 (TID 247) in 234 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:41:40 INFO TaskSchedulerImpl: Removed TaskSet 248.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:41:40 INFO DAGScheduler: ResultStage 248 (start at NativeMethodAccessorImpl.java:0) finished in 0.236 s\n",
      "23/06/22 21:41:40 INFO DAGScheduler: Job 247 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:41:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 248: Stage finished\n",
      "23/06/22 21:41:40 INFO DAGScheduler: Job 247 finished: start at NativeMethodAccessorImpl.java:0, took 0.236537 s\n",
      "23/06/22 21:41:40 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@75cd4e55 is committing.\n",
      "-------------------------------------------\n",
      "Batch: 120\n",
      "-------------------------------------------\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+---------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|          event_name|event_type|     event_id|           event_url|          venue_name|    venue_id|venue_zipcode|venues_timezone|venue_city|venue_state_full|venue_state_short|  venue_country_name|venue_country_short|       venue_address|venue_longitude|venue_latitude|attraction_name|attraction_type|attraction_id|      attraction_url|attraction_segment_id|attraction_segment_name|attraction_genre_id|attraction_genre_name|attraction_subgenre_id|attraction_subgenre_name|event_start_date|ticket_status|event_start_time|currency|min_price|max_price|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+---------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|Madonna - The Cel...|     \"NaN\"|G5dIZ9xDOT7to|https://www.toyot...|       Toyota Center|KovZpZAJJIIA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|    1510 Polk Street|    -95.3623133|    29.7520386|        Madonna|     attraction|  K8vZ9171ub0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-09-13|       onsale|        20:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|      Stanzi Potenza|     \"NaN\"|G5e0Z9lEFlvq0|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|          \"NaN\"|          \"NaN\"|        \"NaN\"|               \"NaN\"|                \"NaN\"|                  \"NaN\"|              \"NaN\"|                \"NaN\"|                 \"NaN\"|                   \"NaN\"|      2023-09-13|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|             Madonna|     \"NaN\"|G5dIZ9N2aS0be|https://www.toyot...|       Toyota Center|KovZpZAJJIIA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|    1510 Polk Street|    -95.3623133|    29.7520386|        Madonna|     attraction|  K8vZ9171ub0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-09-14|       onsale|        20:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|         Aaron Weber|     \"NaN\"|G5e0Z9E_edvk4|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|    Aaron Weber|     attraction|  K8vZ917bgr7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-09-14|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Test Event-Do Not...|     \"NaN\"|G5dIZ9bL-YAI1|https://tmtravel....|   Renaissance Hotel|KovZpZAJJ1JA|        77046|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|    6 Greenway Plaza|     -95.432726|     29.730876|    Test artist|     attraction|  K8vZ917pkj7|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAev|                  Pop|   KZazBEonSMnZfZ7vkJ6|             British Pop|      2023-09-15|       onsale|        14:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|T.J. Miller: the ...|     \"NaN\"|G5e0Z9N0y8oGf|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|    T.J. Miller|     attraction|  K8vZ917ugH7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-09-15|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|T.J. Miller: the ...|     \"NaN\"|G5e0Z9N0z7sa4|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|    T.J. Miller|     attraction|  K8vZ917ugH7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-09-15|       onsale|        21:45:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|The Nutcracker w/...|     \"NaN\"|Z7r9jZ1Ad-UJo|https://www.ticke...|Brown Theatre-Wor...|  Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        501 Texas St|     -95.362999|     29.759399| The Nutcracker|     attraction|  K8vZ917138f|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2023-12-09|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|T.J. Miller: the ...|     \"NaN\"|G5e0Z9N0z7sF_|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|    T.J. Miller|     attraction|  K8vZ917ugH7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-09-16|       onsale|        21:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|T.J. Miller: the ...|     \"NaN\"|G5e0Z9N0zAv10|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|    T.J. Miller|     attraction|  K8vZ917ugH7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-09-16|       onsale|        19:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Josh Ritter w/ Ro...|     \"NaN\"|Z7r9jZ1Adx87w|https://www.ticke...|     Heights Theater|  Z7r9jZad5d|        77008|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|339 W 19th St, Ho...|     -95.418297|     29.798201|    Josh Ritter|     attraction|  K8vZ9171LC7|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-09-30|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Drake: It's All A...|     \"NaN\"|G5dIZ9JSy7dQZ|https://www.toyot...|       Toyota Center|KovZpZAJJIIA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|    1510 Polk Street|    -95.3623133|    29.7520386|          Drake|     attraction|  K8vZ917Gp47|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkdA|                   Urban|      2023-09-17|       onsale|        19:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|             Islands|  standard|G5dIZ9iVJnze0|https://www.ticke...|White Oak Music H...| KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|        Islands|     attraction|  K8vZ9175Mp0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6dt|        Alternative Rock|      2023-09-17|      offsale|        19:00:00|     USD|     20.0|     20.0|\n",
      "|T.J. Miller: the ...|     \"NaN\"|G5e0Z9N0zAv1_|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|    T.J. Miller|     attraction|  K8vZ917ugH7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-09-17|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "| Tommy Emmanuel, CGP|     \"NaN\"|Z7r9jZ1AdOZv0|https://www.ticke...|Cullen Performanc...|  ZFr9jZ7Fa6|        77004|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|   4800 Calhoun Road|     -95.363197|       29.7248| Tommy Emmanuel|     attraction|  K8vZ9171Bvf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvE|                 Jazz|   KZazBEonSMnZfZ7vkda|                    Jazz|      2023-12-01|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Drake: It's All A...|     \"NaN\"|G5dIZ9EZ9CE8i|https://www.toyot...|       Toyota Center|KovZpZAJJIIA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|    1510 Polk Street|    -95.3623133|    29.7520386|          Drake|     attraction|  K8vZ917Gp47|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkdA|                   Urban|      2023-09-18|       onsale|        19:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|      Johnny Orlando|  standard|G5dIZ9iU9Q-wO|https://concerts....|The Bronze Peacoc...| KovZ917A58V|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|     -95.364056|     29.753929| Johnny Orlando|     attraction|  K8vZ9174Rkf|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-09-19|      offsale|        19:00:00|     USD|     25.0|     25.0|\n",
      "|          Ali Siddiq|     \"NaN\"|G5e0Z9nIcGowj|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|     Ali Siddiq|     attraction|  K8vZ917oPEf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-09-21|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "| Escape the Fate Vip|     \"NaN\"|G5e0Z9l86sdlG|https://www.ticke...|Warehouse Live Ba...|  KovZpafuee|        77003|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     813 St. Emanual|   -95.35469139|   29.75207174|          \"NaN\"|          \"NaN\"|        \"NaN\"|               \"NaN\"|                \"NaN\"|                  \"NaN\"|              \"NaN\"|                \"NaN\"|                 \"NaN\"|                   \"NaN\"|      2023-09-22|       onsale|        16:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|          Ali Siddiq|     \"NaN\"|G5e0Z9nIivosi|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|     Ali Siddiq|     attraction|  K8vZ917oPEf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-09-22|       onsale|        21:45:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+---------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "23/06/22 21:41:40 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@75cd4e55 committed.\n",
      "23/06/22 21:41:40 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/120 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.120.2c73c0ca-c07e-4eff-a625-c4032efa80d3.tmp\n",
      "23/06/22 21:41:40 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.120.2c73c0ca-c07e-4eff-a625-c4032efa80d3.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/120\n",
      "23/06/22 21:41:40 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:41:40.002Z\",\n",
      "  \"batchId\" : 120,\n",
      "  \"numInputRows\" : 39,\n",
      "  \"inputRowsPerSecond\" : 3.8996100389961006,\n",
      "  \"processedRowsPerSecond\" : 102.36220472440945,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 259,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 2,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 381,\n",
      "    \"walCommit\" : 62\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2265\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2304\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 39,\n",
      "    \"inputRowsPerSecond\" : 3.8996100389961006,\n",
      "    \"processedRowsPerSecond\" : 102.36220472440945\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 39\n",
      "  }\n",
      "}\n",
      "23/06/22 21:41:40 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.193.622145c0-8d5f-47f0-aa9c-d90f2d222c4e.tmp to gs://kafka-spark-data/spark-metadata/offsets/193\n",
      "23/06/22 21:41:40 INFO MicroBatchExecution: Committed offsets for batch 193. Metadata OffsetSeqMetadata(0,1687488097602,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:41:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:42 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:41:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:41:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:41:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:41:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:41:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:41:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:41:42 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:41:42 INFO DAGScheduler: Got job 248 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:41:42 INFO DAGScheduler: Final stage: ResultStage 249 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:41:42 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:41:42 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:41:42 INFO DAGScheduler: Submitting ResultStage 249 (MapPartitionsRDD[1297] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:41:42 INFO MemoryStore: Block broadcast_248 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/22 21:41:42 INFO MemoryStore: Block broadcast_248_piece0 stored as bytes in memory (estimated size 94.8 KiB, free 434.0 MiB)\n",
      "23/06/22 21:41:42 INFO BlockManagerInfo: Added broadcast_248_piece0 in memory on 192.168.4.24:51040 (size: 94.8 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:41:42 INFO SparkContext: Created broadcast 248 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:41:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 249 (MapPartitionsRDD[1297] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:41:42 INFO TaskSchedulerImpl: Adding task set 249.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:41:42 INFO TaskSetManager: Starting task 0.0 in stage 249.0 (TID 248) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:41:42 INFO Executor: Running task 0.0 in stage 249.0 (TID 248)\n",
      "23/06/22 21:41:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:41:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:41:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:41:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:41:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:41:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:41:42 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:41:42 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:41:42 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/22 21:41:42 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/22 21:41:42 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/22 21:41:42 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/22 21:41:42 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 249:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:41:43 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 2251 for partition ticketmaster-0\n",
      "23/06/22 21:41:43 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:43 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:41:43 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:43 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 2318.\n",
      "23/06/22 21:41:43 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 2252 for partition ticketmaster-0\n",
      "23/06/22 21:41:43 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:43 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:41:43 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:43 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 2319.\n",
      "23/06/22 21:41:45 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-0901425b-1e42-4cf0-9c2d-2baf68f3b2a1/_temporary/0/_temporary/' directory.\n",
      "23/06/22 21:41:45 INFO FileOutputCommitter: Saved output of task 'attempt_202306222141421261340789472140445_0249_m_000000_248' to gs://kafka-spark-data/.spark-bigquery-local-1687482506437-0901425b-1e42-4cf0-9c2d-2baf68f3b2a1/_temporary/0/task_202306222141421261340789472140445_0249_m_000000\n",
      "23/06/22 21:41:45 INFO SparkHadoopMapRedUtil: attempt_202306222141421261340789472140445_0249_m_000000_248: Committed. Elapsed time: 1245 ms.\n",
      "23/06/22 21:41:45 INFO Executor: Finished task 0.0 in stage 249.0 (TID 248). 2536 bytes result sent to driver\n",
      "23/06/22 21:41:45 INFO TaskSetManager: Finished task 0.0 in stage 249.0 (TID 248) in 2560 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:41:45 INFO TaskSchedulerImpl: Removed TaskSet 249.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:41:45 INFO DAGScheduler: ResultStage 249 (start at NativeMethodAccessorImpl.java:0) finished in 2.580 s\n",
      "23/06/22 21:41:45 INFO DAGScheduler: Job 248 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:41:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 249: Stage finished\n",
      "23/06/22 21:41:45 INFO DAGScheduler: Job 248 finished: start at NativeMethodAccessorImpl.java:0, took 2.581306 s\n",
      "23/06/22 21:41:45 INFO FileFormatWriter: Start to commit write Job 42a32d3c-6b3f-437d-9c05-bab335e09386.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:41:46 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-0901425b-1e42-4cf0-9c2d-2baf68f3b2a1/_temporary/0/task_202306222141421261340789472140445_0249_m_000000/' directory.\n",
      "23/06/22 21:41:47 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-0901425b-1e42-4cf0-9c2d-2baf68f3b2a1/' directory.\n",
      "23/06/22 21:41:48 INFO FileFormatWriter: Write Job 42a32d3c-6b3f-437d-9c05-bab335e09386 committed. Elapsed time: 3372 ms.\n",
      "23/06/22 21:41:48 INFO FileFormatWriter: Finished processing stats for write job 42a32d3c-6b3f-437d-9c05-bab335e09386.\n",
      "23/06/22 21:41:49 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687482506437-0901425b-1e42-4cf0-9c2d-2baf68f3b2a1/part-00000-e660b21a-ce8c-4785-bbad-6b11eb3c56a3-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=62dc911a-9e02-48ec-bc4a-949cadc9aefc, location=US}\n",
      "23/06/22 21:41:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 2343.\n",
      "23/06/22 21:41:50 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/121 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.121.6ff9071e-3c8b-4d05-a0c1-b6a4004dba40.tmp\n",
      "23/06/22 21:41:50 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.121.6ff9071e-3c8b-4d05-a0c1-b6a4004dba40.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/121\n",
      "23/06/22 21:41:50 INFO MicroBatchExecution: Committed offsets for batch 121. Metadata OffsetSeqMetadata(0,1687488110006,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:41:50 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:50 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:50 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:50 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:50 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:50 INFO BlockManagerInfo: Removed broadcast_248_piece0 on 192.168.4.24:51040 in memory (size: 94.8 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:41:50 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:50 INFO BlockManagerInfo: Removed broadcast_247_piece0 on 192.168.4.24:51040 in memory (size: 9.9 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:41:50 INFO WriteToDataSourceV2Exec: Start processing data source write support: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@7e5b6eb0. The input RDD has 1 partitions.\n",
      "23/06/22 21:41:50 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:41:50 INFO DAGScheduler: Got job 249 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:41:50 INFO DAGScheduler: Final stage: ResultStage 250 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:41:50 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:41:50 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:41:50 INFO DAGScheduler: Submitting ResultStage 250 (MapPartitionsRDD[1300] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:41:50 INFO MemoryStore: Block broadcast_249 stored as values in memory (estimated size 23.0 KiB, free 434.4 MiB)\n",
      "23/06/22 21:41:50 INFO MemoryStore: Block broadcast_249_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 434.4 MiB)\n",
      "23/06/22 21:41:50 INFO BlockManagerInfo: Added broadcast_249_piece0 in memory on 192.168.4.24:51040 (size: 9.9 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:41:50 INFO SparkContext: Created broadcast 249 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:41:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 250 (MapPartitionsRDD[1300] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:41:50 INFO TaskSchedulerImpl: Adding task set 250.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:41:50 INFO TaskSetManager: Starting task 0.0 in stage 250.0 (TID 249) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:41:50 INFO Executor: Running task 0.0 in stage 250.0 (TID 249)\n",
      "23/06/22 21:41:50 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 2305 for partition ticketmaster-0\n",
      "23/06/22 21:41:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:41:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 2344.\n",
      "23/06/22 21:41:50 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 2306 for partition ticketmaster-0\n",
      "23/06/22 21:41:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:41:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 2345.\n",
      "23/06/22 21:41:50 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 249, attempt 0, stage 250.0)\n",
      "23/06/22 21:41:50 INFO DataWritingSparkTask: Committed partition 0 (task 249, attempt 0, stage 250.0)\n",
      "23/06/22 21:41:50 INFO Executor: Finished task 0.0 in stage 250.0 (TID 249). 34652 bytes result sent to driver\n",
      "23/06/22 21:41:50 INFO TaskSetManager: Finished task 0.0 in stage 250.0 (TID 249) in 170 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:41:50 INFO TaskSchedulerImpl: Removed TaskSet 250.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:41:50 INFO DAGScheduler: ResultStage 250 (start at NativeMethodAccessorImpl.java:0) finished in 0.173 s\n",
      "23/06/22 21:41:50 INFO DAGScheduler: Job 249 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:41:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 250: Stage finished\n",
      "23/06/22 21:41:50 INFO DAGScheduler: Job 249 finished: start at NativeMethodAccessorImpl.java:0, took 0.174623 s\n",
      "23/06/22 21:41:50 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@7e5b6eb0 is committing.\n",
      "-------------------------------------------\n",
      "Batch: 121\n",
      "-------------------------------------------\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+-------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|          event_name|event_type|     event_id|           event_url|          venue_name|    venue_id|venue_zipcode|venues_timezone|venue_city|venue_state_full|venue_state_short|  venue_country_name|venue_country_short|       venue_address|venue_longitude|venue_latitude|    attraction_name|attraction_type|attraction_id|      attraction_url|attraction_segment_id|attraction_segment_name|attraction_genre_id|attraction_genre_name|attraction_subgenre_id|attraction_subgenre_name|event_start_date|ticket_status|event_start_time|currency|min_price|max_price|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+-------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|            Crankdat|     \"NaN\"|Z7r9jZ1Ad-UbZ|https://www.ticke...|Stereo Live - Hou...|  ZFr9jZa7A6|        77057|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|   6400 Richmond Ave|     -95.489304|     29.745001|           Crankdat|     attraction|  K8vZ9174XQV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvF|     Dance/Electronic|   KZazBEonSMnZfZ7vAJ1|              Club Dance|      2023-10-20|       onsale|        22:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|              Deeper|  standard|G5dIZ9i9kVd82|https://www.ticke...|White Oak Music H...| KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|             Deeper|     attraction|  K8vZ917u_dV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6dt|        Alternative Rock|      2023-10-05|       onsale|        19:00:00|     USD|     17.5|     17.5|\n",
      "|          Andrea Jin|     \"NaN\"|G5e0Z9n2m6v4W|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|              \"NaN\"|          \"NaN\"|        \"NaN\"|               \"NaN\"|                \"NaN\"|                  \"NaN\"|              \"NaN\"|                \"NaN\"|                 \"NaN\"|                   \"NaN\"|      2023-10-05|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Alejandro Fernánd...|     \"NaN\"|G5dIZ900m6ysz|https://www.toyot...|       Toyota Center|KovZpZAJJIIA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|    1510 Polk Street|    -95.3623133|    29.7520386|Alejandro Fernández|     attraction|  K8vZ9171afV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAJ6|                Latin|   KZazBEonSMnZfZ7va1a|                   Latin|      2023-10-06|       onsale|        21:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|   Alicia Villarreal|  standard|G5dIZ9iMoDJ1Y|https://www.ticke...|       Arena Theatre|KovZpZAJJ7FA|        77074|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 7326 Southwest Fwy,|     -95.517765|     29.702271|  Alicia Villarreal|     attraction|  K8vZ9175znf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeF|                World|   KZazBEonSMnZfZ7vFdJ|                   Latin|      2023-10-06|      offsale|        21:00:00|     USD|    51.75|    207.0|\n",
      "|        Ashley Gavin|     \"NaN\"|G5e0Z9t7EiduX|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|       Ashley Gavin|     attraction|  K8vZ917QeW7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-10-06|       onsale|        21:45:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|        Ashley Gavin|     \"NaN\"|G5e0Z9t7ElSuY|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|       Ashley Gavin|     attraction|  K8vZ917QeW7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-10-06|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Jonas Brothers: F...|     \"NaN\"|G5dIZ9naz5-Ca|https://www.toyot...|       Toyota Center|KovZpZAJJIIA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|    1510 Polk Street|    -95.3623133|    29.7520386|     Jonas Brothers|     attraction|  K8vZ9175T17|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-10-07|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|        Ashley Gavin|     \"NaN\"|G5e0Z9t7ElKu-|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|       Ashley Gavin|     attraction|  K8vZ917QeW7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-10-07|       onsale|        19:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|        Ashley Gavin|     \"NaN\"|G5e0Z9t7IUSCQ|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|       Ashley Gavin|     attraction|  K8vZ917QeW7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-10-07|       onsale|        21:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|        Ashley Gavin|     \"NaN\"|G5e0Z9t7EidC7|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|       Ashley Gavin|     attraction|  K8vZ917QeW7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-10-08|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|The Nutcracker w/...|     \"NaN\"|Z7r9jZ1Ad-MZY|https://www.ticke...|Brown Theatre-Wor...|  Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        501 Texas St|     -95.362999|     29.759399|     The Nutcracker|     attraction|  K8vZ917138f|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2023-12-22|       onsale|        14:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|          Morgan Jay|     \"NaN\"|G5e0Z9E41vOwu|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|              \"NaN\"|          \"NaN\"|        \"NaN\"|               \"NaN\"|                \"NaN\"|                  \"NaN\"|              \"NaN\"|                \"NaN\"|                 \"NaN\"|                   \"NaN\"|      2023-10-11|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Erin Rae - Lighte...|  standard|G5dIZ9cK6a4oW|https://concerts....|The Bronze Peacoc...| KovZ917A58V|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|     -95.364056|     29.753929|           Erin Rae|     attraction|  K8vZ9178OKV|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAva|                 Folk|   KZazBEonSMnZfZ7vAn7|                    Folk|      2023-10-13|      offsale|        19:00:00|     USD|     15.0|     15.0|\n",
      "|      SZA - SOS Tour|     \"NaN\"|G5dIZ9IIYV8Vw|https://www.toyot...|       Toyota Center|KovZpZAJJIIA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|    1510 Polk Street|    -95.3623133|    29.7520386|                SZA|     attraction|  K8vZ917o6G0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAee|                  R&B|   KZazBEonSMnZfZ7vkIt|                     R&B|      2023-10-14|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|The Nutcracker w/...|     \"NaN\"|Z7r9jZ1Ad-UJd|https://www.ticke...|Brown Theatre-Wor...|  Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        501 Texas St|     -95.362999|     29.759399|     The Nutcracker|     attraction|  K8vZ917138f|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2023-12-20|       onsale|        14:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|The Nutcracker w/...|     \"NaN\"|Z7r9jZ1Ad-fea|https://www.ticke...|Brown Theatre-Wor...|  Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        501 Texas St|     -95.362999|     29.759399|     The Nutcracker|     attraction|  K8vZ917138f|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2023-12-02|       onsale|        14:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "| Eric Dâ  Alessandro|     \"NaN\"|G5e0Z9t8qWsSe|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|              \"NaN\"|          \"NaN\"|        \"NaN\"|               \"NaN\"|                \"NaN\"|                  \"NaN\"|              \"NaN\"|                \"NaN\"|                 \"NaN\"|                   \"NaN\"|      2023-10-19|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|            Sun Room|     \"NaN\"|Z7r9jZ1Ad07Jk|https://www.ticke...|Warehouse Live-St...|  ZFr9jZav7e|        77003|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|813 St. Emanuel S...|     -95.345596|     29.748899|           Sun Room|     attraction|   Z7r9jZa8AU|               \"NaN\"|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvl|                Other|   KZazBEonSMnZfZ7vk1I|                   Other|      2023-11-02|       onsale|        19:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Peter Gabriel: i/...|     \"NaN\"|G5dIZ9E5yz4z7|https://www.toyot...|       Toyota Center|KovZpZAJJIIA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|    1510 Polk Street|    -95.3623133|    29.7520386|      Peter Gabriel|     attraction|  K8vZ91712N7|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-10-21|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+-------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "23/06/22 21:41:50 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@7e5b6eb0 committed.\n",
      "23/06/22 21:41:50 INFO BlockManagerInfo: Removed broadcast_249_piece0 on 192.168.4.24:51040 in memory (size: 9.9 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:41:50 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/121 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.121.c3938ad5-b481-41ed-8cdb-28bd151930f2.tmp\n",
      "23/06/22 21:41:50 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.121.c3938ad5-b481-41ed-8cdb-28bd151930f2.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/121\n",
      "23/06/22 21:41:50 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:41:50.002Z\",\n",
      "  \"batchId\" : 121,\n",
      "  \"numInputRows\" : 39,\n",
      "  \"inputRowsPerSecond\" : 3.9,\n",
      "  \"processedRowsPerSecond\" : 106.55737704918033,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 209,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 4,\n",
      "    \"queryPlanning\" : 9,\n",
      "    \"triggerExecution\" : 366,\n",
      "    \"walCommit\" : 84\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2304\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2343\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 39,\n",
      "    \"inputRowsPerSecond\" : 3.9,\n",
      "    \"processedRowsPerSecond\" : 106.55737704918033\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 39\n",
      "  }\n",
      "}\n",
      "23/06/22 21:41:52 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=62dc911a-9e02-48ec-bc4a-949cadc9aefc, location=US}\n",
      "23/06/22 21:41:54 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/193 using temp file gs://kafka-spark-data/spark-metadata/commits/.193.c73188f6-7829-48f9-adb1-a88faafd45d2.tmp\n",
      "23/06/22 21:41:56 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.193.c73188f6-7829-48f9-adb1-a88faafd45d2.tmp to gs://kafka-spark-data/spark-metadata/commits/193\n",
      "23/06/22 21:41:56 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:41:37.596Z\",\n",
      "  \"batchId\" : 193,\n",
      "  \"numInputRows\" : 68,\n",
      "  \"inputRowsPerSecond\" : 3.8943932191741597,\n",
      "  \"processedRowsPerSecond\" : 3.6016949152542375,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 12295,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 6,\n",
      "    \"queryPlanning\" : 31,\n",
      "    \"triggerExecution\" : 18880,\n",
      "    \"walCommit\" : 3683\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2227\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2295\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 68,\n",
      "    \"inputRowsPerSecond\" : 3.8943932191741597,\n",
      "    \"processedRowsPerSecond\" : 3.6016949152542375\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:41:56 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 18882 milliseconds\n",
      "23/06/22 21:41:56 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:41:56 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 2369.\n",
      "23/06/22 21:41:57 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/194 using temp file gs://kafka-spark-data/spark-metadata/offsets/.194.60006272-79a7-41a1-8a02-53e435f0b0db.tmp\n",
      "23/06/22 21:41:58 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.194.60006272-79a7-41a1-8a02-53e435f0b0db.tmp to gs://kafka-spark-data/spark-metadata/offsets/194\n",
      "23/06/22 21:41:58 INFO MicroBatchExecution: Committed offsets for batch 194. Metadata OffsetSeqMetadata(0,1687488116485,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:41:59 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:59 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:59 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:41:59 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:42:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 2382.\n",
      "23/06/22 21:42:00 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/122 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.122.d87b6a19-9c11-40d1-b155-b0d4af83f71b.tmp\n",
      "23/06/22 21:42:00 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.122.d87b6a19-9c11-40d1-b155-b0d4af83f71b.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/122\n",
      "23/06/22 21:42:00 INFO MicroBatchExecution: Committed offsets for batch 122. Metadata OffsetSeqMetadata(0,1687488120014,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:42:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:42:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:42:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:42:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:42:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:42:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:42:00 INFO WriteToDataSourceV2Exec: Start processing data source write support: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@4f98feba. The input RDD has 1 partitions.\n",
      "23/06/22 21:42:00 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:42:00 INFO DAGScheduler: Got job 250 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:42:00 INFO DAGScheduler: Final stage: ResultStage 251 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:42:00 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:42:00 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:42:00 INFO DAGScheduler: Submitting ResultStage 251 (MapPartitionsRDD[1309] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:42:00 INFO MemoryStore: Block broadcast_250 stored as values in memory (estimated size 23.0 KiB, free 434.4 MiB)\n",
      "23/06/22 21:42:00 INFO MemoryStore: Block broadcast_250_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 434.4 MiB)\n",
      "23/06/22 21:42:00 INFO BlockManagerInfo: Added broadcast_250_piece0 in memory on 192.168.4.24:51040 (size: 9.9 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:42:00 INFO SparkContext: Created broadcast 250 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:42:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 251 (MapPartitionsRDD[1309] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:42:00 INFO TaskSchedulerImpl: Adding task set 251.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:42:00 INFO TaskSetManager: Starting task 0.0 in stage 251.0 (TID 250) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:42:00 INFO Executor: Running task 0.0 in stage 251.0 (TID 250)\n",
      "23/06/22 21:42:00 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 2344 for partition ticketmaster-0\n",
      "23/06/22 21:42:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:42:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 2383.\n",
      "23/06/22 21:42:00 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 2345 for partition ticketmaster-0\n",
      "23/06/22 21:42:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:42:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 2384.\n",
      "23/06/22 21:42:00 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 250, attempt 0, stage 251.0)\n",
      "23/06/22 21:42:00 INFO DataWritingSparkTask: Committed partition 0 (task 250, attempt 0, stage 251.0)\n",
      "23/06/22 21:42:00 INFO Executor: Finished task 0.0 in stage 251.0 (TID 250). 34460 bytes result sent to driver\n",
      "23/06/22 21:42:00 INFO TaskSetManager: Finished task 0.0 in stage 251.0 (TID 250) in 177 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:42:00 INFO TaskSchedulerImpl: Removed TaskSet 251.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:42:00 INFO DAGScheduler: ResultStage 251 (start at NativeMethodAccessorImpl.java:0) finished in 0.183 s\n",
      "23/06/22 21:42:00 INFO DAGScheduler: Job 250 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:42:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 251: Stage finished\n",
      "23/06/22 21:42:00 INFO DAGScheduler: Job 250 finished: start at NativeMethodAccessorImpl.java:0, took 0.183512 s\n",
      "23/06/22 21:42:00 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@4f98feba is committing.\n",
      "-------------------------------------------\n",
      "Batch: 122\n",
      "-------------------------------------------\n",
      "+--------------------+----------+--------------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|          event_name|event_type|            event_id|           event_url|          venue_name|    venue_id|venue_zipcode|venues_timezone|venue_city|venue_state_full|venue_state_short|  venue_country_name|venue_country_short|       venue_address|venue_longitude|venue_latitude|     attraction_name|attraction_type|attraction_id|      attraction_url|attraction_segment_id|attraction_segment_name|attraction_genre_id|attraction_genre_name|attraction_subgenre_id|attraction_subgenre_name|event_start_date|ticket_status|event_start_time|currency|min_price|max_price|\n",
      "+--------------------+----------+--------------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|Eddie Izzard: The...|  standard|       G5dIZ9c8TTFe7|https://www.ticke...|Cullen Theater at...|KovZpZAJ1vAA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|5oo Prairie - Pra...|    -95.2557601|    29.6636425|        Eddie Izzard|     attraction|  K8vZ91719h7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-11-04|      offsale|        20:00:00|     USD|     60.0|     75.0|\n",
      "|       Brad Williams|     \"NaN\"|       G5e0Z9JLn_8EV|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|       Brad Williams|     attraction|  K8vZ917uABV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-11-04|       onsale|        21:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|       Brad Williams|     \"NaN\"|       G5e0Z9JLn_OIh|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|       Brad Williams|     attraction|  K8vZ917uABV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-11-04|       onsale|        19:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Gemini Syndrome -...|     \"NaN\"|       G5e0Z9n8lNe6i|https://www.ticke...|Warehouse Live Ba...|  KovZpafuee|        77003|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     813 St. Emanual|   -95.35469139|   29.75207174|               \"NaN\"|          \"NaN\"|        \"NaN\"|               \"NaN\"|                \"NaN\"|                  \"NaN\"|              \"NaN\"|                \"NaN\"|                 \"NaN\"|                   \"NaN\"|      2023-11-04|       onsale|        22:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Collect-A-Con (Ho...|     \"NaN\"|LvZ18bUyNWAvFCYZR...|https://www.unive...|George R Brown Co...|KovZpZAJ1vaA|        77010|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1001 Avenida De L...|     -95.356729|     29.753758|       Collect-A-Con|     attraction|  K8vZ917QeS0|https://www.ticke...|   KZFzniwnSyZfZ7v7n1|          Miscellaneous|        KnvZfZ7vAAJ| Hobby/Special Int...|   KZazBEonSMnZfZ7vFnl|    Hobby/Special Int...|      2023-11-04|       onsale|        10:00:00|     USD|    \"NaN\"|    \"NaN\"|\n",
      "|       Brad Williams|     \"NaN\"|       G5e0Z9JLn_8Eo|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|       Brad Williams|     attraction|  K8vZ917uABV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-11-05|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|       Billy Raffoul|  standard|       G5dIZ9ifzB9SU|https://www.ticke...|White Oak Music H...| KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|       Billy Raffoul|     attraction|  K8vZ917Kq4f|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-11-08|      offsale|        19:00:00|     USD|     20.0|     20.0|\n",
      "|The Nutcracker w/...|     \"NaN\"|       Z7r9jZ1Ad-UJ8|https://www.ticke...|Brown Theatre-Wor...|  Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        501 Texas St|     -95.362999|     29.759399|      The Nutcracker|     attraction|  K8vZ917138f|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2023-12-19|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|         Jason Cheny|     \"NaN\"|       G5e0Z9PLwgspN|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|         Jason Cheny|     attraction|  K8vZ9174TP7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-11-09|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|       Darren Knight|     \"NaN\"|       Z7r9jZ1AdOVvd|https://www.ticke...|Cullen Performanc...|  ZFr9jZ7Fa6|        77004|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|   4800 Calhoun Road|     -95.363197|       29.7248|Darren Knight aka...|     attraction|  K8vZ9174MB7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-11-11|       onsale|        19:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|        Faye Webster|  standard|       G5dIZ9iU9xowm|https://www.ticke...|White Oak Music H...| KovZ917AiGZ|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|      2915 N Main St|      -95.36562|      29.78627|        Faye Webster|     attraction|  K8vZ9178fLV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6dt|        Alternative Rock|      2023-11-13|      offsale|        19:00:00|     USD|     25.0|     25.0|\n",
      "|The Nutcracker w/...|     \"NaN\"|       Z7r9jZ1Ad-UJa|https://www.ticke...|Brown Theatre-Wor...|  Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        501 Texas St|     -95.362999|     29.759399|      The Nutcracker|     attraction|  K8vZ917138f|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2023-11-25|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Kim Petras: Feed ...|  standard|       G5dIZ9cCxcwwf|https://concerts....|      713 Music Hall| KovZ917APwH|        77201|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 401 Franklin Street|      -95.36416|      29.76539|          Kim Petras|     attraction|  K8vZ917pWpV|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-11-14|      offsale|        20:00:00|     USD|     49.5|     79.5|\n",
      "|The Nutcracker w/...|     \"NaN\"|       Z7r9jZ1Ad-UPU|https://www.ticke...|Brown Theatre-Wor...|  Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        501 Texas St|     -95.362999|     29.759399|      The Nutcracker|     attraction|  K8vZ917138f|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2023-11-26|       onsale|        13:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|The Nutcracker w/...|     \"NaN\"|       Z7r9jZ1Ad-MZd|https://www.ticke...|Brown Theatre-Wor...|  Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        501 Texas St|     -95.362999|     29.759399|      The Nutcracker|     attraction|  K8vZ917138f|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2023-11-26|       onsale|        18:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Alexander Nezlobi...|     \"NaN\"|       G5e0Z9nM4KNf0|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|               \"NaN\"|          \"NaN\"|        \"NaN\"|               \"NaN\"|                \"NaN\"|                  \"NaN\"|              \"NaN\"|                \"NaN\"|                 \"NaN\"|                   \"NaN\"|      2023-11-15|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Jack Kays - Goes ...|  standard|       G5dIZ9cenVdV7|https://concerts....|The Bronze Peacoc...| KovZ917A58V|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|1204 Caroline Street|     -95.364056|     29.753929|           Jack Kays|     attraction|  K8vZ917_x80|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvv|          Alternative|   KZazBEonSMnZfZ7vAde|              Indie Rock|      2023-11-16|      offsale|        19:00:00|     USD|     20.0|     20.0|\n",
      "|The Bald and the ...|  standard|       G5dIZ9iThS7ew|https://concerts....|      713 Music Hall| KovZ917APwH|        77201|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 401 Franklin Street|      -95.36416|      29.76539|The Bald and the ...|     attraction|  K8vZ917hrjf|https://www.liven...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vaaJ|                 Podcast|      2023-11-16|      offsale|        20:00:00|     USD|     43.0|     83.0|\n",
      "|The Nutcracker w/...|     \"NaN\"|       Z7r9jZ1Ad-UPM|https://www.ticke...|Brown Theatre-Wor...|  Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        501 Texas St|     -95.362999|     29.759399|      The Nutcracker|     attraction|  K8vZ917138f|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2023-12-20|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|The Nutcracker w/...|     \"NaN\"|       Z7r9jZ1Ad-UJf|https://www.ticke...|Brown Theatre-Wor...|  Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        501 Texas St|     -95.362999|     29.759399|      The Nutcracker|     attraction|  K8vZ917138f|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2023-12-26|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "+--------------------+----------+--------------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "23/06/22 21:42:00 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@4f98feba committed.\n",
      "23/06/22 21:42:00 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/122 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.122.fca15207-ef6b-4c2d-88f9-def978e6bdb5.tmp\n",
      "23/06/22 21:42:00 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:42:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:42:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:42:00 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:42:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:42:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:42:00 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:42:00 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.122.fca15207-ef6b-4c2d-88f9-def978e6bdb5.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/122\n",
      "23/06/22 21:42:00 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:42:00.003Z\",\n",
      "  \"batchId\" : 122,\n",
      "  \"numInputRows\" : 39,\n",
      "  \"inputRowsPerSecond\" : 3.8996100389961006,\n",
      "  \"processedRowsPerSecond\" : 99.48979591836735,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 211,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 11,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 392,\n",
      "    \"walCommit\" : 90\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2343\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2382\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 39,\n",
      "    \"inputRowsPerSecond\" : 3.8996100389961006,\n",
      "    \"processedRowsPerSecond\" : 99.48979591836735\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 39\n",
      "  }\n",
      "}\n",
      "23/06/22 21:42:00 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:42:00 INFO DAGScheduler: Got job 251 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:42:00 INFO DAGScheduler: Final stage: ResultStage 252 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:42:00 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:42:00 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:42:00 INFO DAGScheduler: Submitting ResultStage 252 (MapPartitionsRDD[1310] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:42:00 INFO MemoryStore: Block broadcast_251 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/22 21:42:00 INFO MemoryStore: Block broadcast_251_piece0 stored as bytes in memory (estimated size 94.8 KiB, free 434.0 MiB)\n",
      "23/06/22 21:42:00 INFO BlockManagerInfo: Added broadcast_251_piece0 in memory on 192.168.4.24:51040 (size: 94.8 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:42:00 INFO SparkContext: Created broadcast 251 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:42:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 252 (MapPartitionsRDD[1310] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:42:00 INFO TaskSchedulerImpl: Adding task set 252.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:42:00 INFO TaskSetManager: Starting task 0.0 in stage 252.0 (TID 251) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:42:00 INFO Executor: Running task 0.0 in stage 252.0 (TID 251)\n",
      "23/06/22 21:42:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:42:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:42:00 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:42:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:42:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:42:00 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:42:00 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:42:00 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:42:00 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/22 21:42:00 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/22 21:42:00 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/22 21:42:00 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/22 21:42:00 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/22 21:42:01 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 2318 for partition ticketmaster-0\n",
      "23/06/22 21:42:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:42:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 2388.\n",
      "23/06/22 21:42:01 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 2319 for partition ticketmaster-0\n",
      "23/06/22 21:42:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 252:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:42:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:42:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 2389.\n",
      "23/06/22 21:42:03 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-6bdb1355-dff0-4283-a046-175d98662545/_temporary/0/_temporary/' directory.\n",
      "23/06/22 21:42:03 INFO FileOutputCommitter: Saved output of task 'attempt_202306222142003047192753508802359_0252_m_000000_251' to gs://kafka-spark-data/.spark-bigquery-local-1687482506437-6bdb1355-dff0-4283-a046-175d98662545/_temporary/0/task_202306222142003047192753508802359_0252_m_000000\n",
      "23/06/22 21:42:03 INFO SparkHadoopMapRedUtil: attempt_202306222142003047192753508802359_0252_m_000000_251: Committed. Elapsed time: 1371 ms.\n",
      "23/06/22 21:42:03 INFO Executor: Finished task 0.0 in stage 252.0 (TID 251). 2536 bytes result sent to driver\n",
      "23/06/22 21:42:03 INFO TaskSetManager: Finished task 0.0 in stage 252.0 (TID 251) in 2633 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:42:03 INFO TaskSchedulerImpl: Removed TaskSet 252.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:42:03 INFO DAGScheduler: ResultStage 252 (start at NativeMethodAccessorImpl.java:0) finished in 2.662 s\n",
      "23/06/22 21:42:03 INFO DAGScheduler: Job 251 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:42:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 252: Stage finished\n",
      "23/06/22 21:42:03 INFO DAGScheduler: Job 251 finished: start at NativeMethodAccessorImpl.java:0, took 2.664605 s\n",
      "23/06/22 21:42:03 INFO FileFormatWriter: Start to commit write Job 03205a03-0cdc-4eec-b0b6-562e7c5043b5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:42:06 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-6bdb1355-dff0-4283-a046-175d98662545/_temporary/0/task_202306222142003047192753508802359_0252_m_000000/' directory.\n",
      "23/06/22 21:42:06 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-6bdb1355-dff0-4283-a046-175d98662545/' directory.\n",
      "23/06/22 21:42:07 INFO FileFormatWriter: Write Job 03205a03-0cdc-4eec-b0b6-562e7c5043b5 committed. Elapsed time: 4127 ms.\n",
      "23/06/22 21:42:07 INFO FileFormatWriter: Finished processing stats for write job 03205a03-0cdc-4eec-b0b6-562e7c5043b5.\n",
      "23/06/22 21:42:08 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687482506437-6bdb1355-dff0-4283-a046-175d98662545/part-00000-9c8ddfdd-4611-4e6f-a14d-ba9b2a987b66-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=a2fd9d28-7cea-4b0a-8548-0d7fa07c7a25, location=US}\n",
      "23/06/22 21:42:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 2421.\n",
      "23/06/22 21:42:10 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/123 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.123.f23736f7-36f4-46d4-9e6b-f7f31a71ff6f.tmp\n",
      "23/06/22 21:42:10 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.123.f23736f7-36f4-46d4-9e6b-f7f31a71ff6f.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/123\n",
      "23/06/22 21:42:10 INFO MicroBatchExecution: Committed offsets for batch 123. Metadata OffsetSeqMetadata(0,1687488130013,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:42:10 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:42:10 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:42:10 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:42:10 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:42:10 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:42:10 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:42:10 INFO WriteToDataSourceV2Exec: Start processing data source write support: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@5f79cc64. The input RDD has 1 partitions.\n",
      "23/06/22 21:42:10 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:42:10 INFO DAGScheduler: Got job 252 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:42:10 INFO DAGScheduler: Final stage: ResultStage 253 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:42:10 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:42:10 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:42:10 INFO DAGScheduler: Submitting ResultStage 253 (MapPartitionsRDD[1313] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:42:10 INFO MemoryStore: Block broadcast_252 stored as values in memory (estimated size 23.0 KiB, free 434.0 MiB)\n",
      "23/06/22 21:42:10 INFO MemoryStore: Block broadcast_252_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 434.0 MiB)\n",
      "23/06/22 21:42:10 INFO BlockManagerInfo: Added broadcast_252_piece0 in memory on 192.168.4.24:51040 (size: 9.9 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:42:10 INFO SparkContext: Created broadcast 252 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:42:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 253 (MapPartitionsRDD[1313] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:42:10 INFO TaskSchedulerImpl: Adding task set 253.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:42:10 INFO TaskSetManager: Starting task 0.0 in stage 253.0 (TID 252) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:42:10 INFO Executor: Running task 0.0 in stage 253.0 (TID 252)\n",
      "23/06/22 21:42:10 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 2383 for partition ticketmaster-0\n",
      "23/06/22 21:42:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:42:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 2422.\n",
      "23/06/22 21:42:10 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 2384 for partition ticketmaster-0\n",
      "23/06/22 21:42:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:42:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 2423.\n",
      "23/06/22 21:42:10 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 252, attempt 0, stage 253.0)\n",
      "23/06/22 21:42:10 INFO DataWritingSparkTask: Committed partition 0 (task 252, attempt 0, stage 253.0)\n",
      "23/06/22 21:42:10 INFO Executor: Finished task 0.0 in stage 253.0 (TID 252). 34308 bytes result sent to driver\n",
      "23/06/22 21:42:10 INFO TaskSetManager: Finished task 0.0 in stage 253.0 (TID 252) in 196 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:42:10 INFO TaskSchedulerImpl: Removed TaskSet 253.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:42:10 INFO DAGScheduler: ResultStage 253 (start at NativeMethodAccessorImpl.java:0) finished in 0.199 s\n",
      "23/06/22 21:42:10 INFO DAGScheduler: Job 252 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:42:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 253: Stage finished\n",
      "23/06/22 21:42:10 INFO DAGScheduler: Job 252 finished: start at NativeMethodAccessorImpl.java:0, took 0.199849 s\n",
      "23/06/22 21:42:10 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@5f79cc64 is committing.\n",
      "-------------------------------------------\n",
      "Batch: 123\n",
      "-------------------------------------------\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|          event_name|event_type|     event_id|           event_url|          venue_name|    venue_id|venue_zipcode|venues_timezone|venue_city|venue_state_full|venue_state_short|  venue_country_name|venue_country_short|       venue_address|venue_longitude|venue_latitude|     attraction_name|attraction_type|attraction_id|      attraction_url|attraction_segment_id|attraction_segment_name|attraction_genre_id|attraction_genre_name|attraction_subgenre_id|attraction_subgenre_name|event_start_date|ticket_status|event_start_time|currency|min_price|max_price|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|         Tommy Prine|  standard|G5dIZ9ijzpakR|https://www.ticke...|White Oak Music H...| KovZ917Ai5U|        77009|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|     2915 N Main St,|      -95.36562|      29.78627|         Tommy Prine|     attraction|  K8vZ917_-I0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAva|                 Folk|   KZazBEonSMnZfZ7vAn7|                    Folk|      2024-01-18|       onsale|        19:00:00|     USD|     18.0|     18.0|\n",
      "|The Nutcracker w/...|     \"NaN\"|Z7r9jZ1Ad-MZV|https://www.ticke...|Brown Theatre-Wor...|  Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        501 Texas St|     -95.362999|     29.759399|      The Nutcracker|     attraction|  K8vZ917138f|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2023-12-17|       onsale|        18:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|The Nutcracker w/...|     \"NaN\"|Z7r9jZ1Ad-MZs|https://www.ticke...|Brown Theatre-Wor...|  Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        501 Texas St|     -95.362999|     29.759399|      The Nutcracker|     attraction|  K8vZ917138f|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2023-12-15|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|The Nutcracker w/...|     \"NaN\"|Z7r9jZ1Ad-MZe|https://www.ticke...|Brown Theatre-Wor...|  Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        501 Texas St|     -95.362999|     29.759399|      The Nutcracker|     attraction|  K8vZ917138f|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2023-12-14|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|    Big Jay Oakerson|     \"NaN\"|G5e0Z9I2lBxX1|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|    Big Jay Oakerson|     attraction|  K8vZ917Gij7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-12-07|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|       Houston Rodeo|     \"NaN\"|Z7r9jZ1Ad-tfk|https://www.ticke...|         NRG Stadium|  ZFr9jZdAee|        77054|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        One NRG Park|     -95.400101|       29.6835|Houston Livestock...|     attraction|  K8vZ9171hu7|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAea|                Rodeo|   KZazBEonSMnZfZ7vF1d|                   Rodeo|      2024-02-27|      offsale|        18:45:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|    Big Jay Oakerson|     \"NaN\"|G5e0Z9I2lBxXm|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|    Big Jay Oakerson|     attraction|  K8vZ917Gij7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-12-08|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|    Big Jay Oakerson|     \"NaN\"|G5e0Z9I2lDdZ3|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|    Big Jay Oakerson|     attraction|  K8vZ917Gij7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-12-08|       onsale|        21:45:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|    Big Jay Oakerson|     \"NaN\"|G5e0Z9I2lBSZG|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|    Big Jay Oakerson|     attraction|  K8vZ917Gij7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-12-09|       onsale|        19:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|    Big Jay Oakerson|     \"NaN\"|G5e0Z9I2lBxXF|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|    Big Jay Oakerson|     attraction|  K8vZ917Gij7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-12-09|       onsale|        21:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|The Nutcracker w/...|     \"NaN\"|Z7r9jZ1Ad-fe9|https://www.ticke...|Brown Theatre-Wor...|  Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        501 Texas St|     -95.362999|     29.759399|      The Nutcracker|     attraction|  K8vZ917138f|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2023-12-17|       onsale|        13:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|The Nutcracker w/...|     \"NaN\"|Z7r9jZ1Ad-UJ4|https://www.ticke...|Brown Theatre-Wor...|  Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        501 Texas St|     -95.362999|     29.759399|      The Nutcracker|     attraction|  K8vZ917138f|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2023-12-21|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|    The Christi Show|     \"NaN\"|G5e0Z9iYNifdO|https://www.ticke...|      Houston Improv|KovZpZA67IeA|        77024|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|7620 Katy Freeway...|     -95.463962|     29.785454|               \"NaN\"|          \"NaN\"|        \"NaN\"|               \"NaN\"|                \"NaN\"|                  \"NaN\"|              \"NaN\"|                \"NaN\"|                 \"NaN\"|                   \"NaN\"|      2023-12-14|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|The Nutcracker w/...|     \"NaN\"|Z7r9jZ1Ad-MZS|https://www.ticke...|Brown Theatre-Wor...|  Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        501 Texas St|     -95.362999|     29.759399|      The Nutcracker|     attraction|  K8vZ917138f|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2023-12-22|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Anita Baker - The...|     \"NaN\"|G5dIZ9pcsCeZn|https://www.toyot...|       Toyota Center|KovZpZAJJIIA|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|    1510 Polk Street|    -95.3623133|    29.7520386|         Anita Baker|     attraction|  K8vZ9171aXf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAee|                  R&B|   KZazBEonSMnZfZ7vkIt|                     R&B|      2023-12-15|       onsale|        19:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|The Nutcracker w/...|     \"NaN\"|Z7r9jZ1Ad-UJA|https://www.ticke...|Brown Theatre-Wor...|  Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        501 Texas St|     -95.362999|     29.759399|      The Nutcracker|     attraction|  K8vZ917138f|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2023-12-23|       onsale|        14:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|The Nutcracker w/...|     \"NaN\"|Z7r9jZ1Ad-UPV|https://www.ticke...|Brown Theatre-Wor...|  Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        501 Texas St|     -95.362999|     29.759399|      The Nutcracker|     attraction|  K8vZ917138f|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2023-12-24|       onsale|        13:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|MANIA: The ABBA T...|     \"NaN\"|Z7r9jZ1Adxp39|https://www.ticke...|Cullen Performanc...|  ZFr9jZ7Fa6|        77004|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|   4800 Calhoun Road|     -95.363197|       29.7248|MANIA: The ABBA T...|     attraction|   Z7r9jZa8Rw|               \"NaN\"|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvl|                Other|   KZazBEonSMnZfZ7vk1I|                   Other|      2024-02-04|       onsale|        18:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Ballet w/...|     \"NaN\"|Z7r9jZ1Ad-f7Z|https://www.ticke...|Brown Theatre-Wor...|  Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        501 Texas St|     -95.362999|     29.759399|      Houston Ballet|     attraction|  K8vZ9171oIf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2024-02-24|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|       Houston Rodeo|     \"NaN\"|Z7r9jZ1Ad-tf6|https://www.ticke...|         NRG Stadium|  ZFr9jZdAee|        77054|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US|        One NRG Park|     -95.400101|       29.6835|Houston Livestock...|     attraction|  K8vZ9171hu7|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAea|                Rodeo|   KZazBEonSMnZfZ7vF1d|                   Rodeo|      2024-03-04|      offsale|        18:45:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "23/06/22 21:42:10 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@5f79cc64 committed.\n",
      "23/06/22 21:42:10 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/123 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.123.6c64df7c-090b-4227-9b12-619089bc5b30.tmp\n",
      "23/06/22 21:42:10 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.123.6c64df7c-090b-4227-9b12-619089bc5b30.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/123\n",
      "23/06/22 21:42:10 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:42:10.005Z\",\n",
      "  \"batchId\" : 123,\n",
      "  \"numInputRows\" : 39,\n",
      "  \"inputRowsPerSecond\" : 3.899220155968806,\n",
      "  \"processedRowsPerSecond\" : 100.51546391752576,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 240,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 8,\n",
      "    \"queryPlanning\" : 8,\n",
      "    \"triggerExecution\" : 388,\n",
      "    \"walCommit\" : 72\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2382\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2421\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 39,\n",
      "    \"inputRowsPerSecond\" : 3.899220155968806,\n",
      "    \"processedRowsPerSecond\" : 100.51546391752576\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 39\n",
      "  }\n",
      "}\n",
      "23/06/22 21:42:10 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=a2fd9d28-7cea-4b0a-8548-0d7fa07c7a25, location=US}\n",
      "23/06/22 21:42:11 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/194 using temp file gs://kafka-spark-data/spark-metadata/commits/.194.d90bdc82-fa72-4ee2-ba62-1f2db3389a32.tmp\n",
      "23/06/22 21:42:12 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.194.d90bdc82-fa72-4ee2-ba62-1f2db3389a32.tmp to gs://kafka-spark-data/spark-metadata/commits/194\n",
      "23/06/22 21:42:12 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:41:56.478Z\",\n",
      "  \"batchId\" : 194,\n",
      "  \"numInputRows\" : 74,\n",
      "  \"inputRowsPerSecond\" : 3.9190763690287045,\n",
      "  \"processedRowsPerSecond\" : 4.565646594274432,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 11622,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 7,\n",
      "    \"queryPlanning\" : 8,\n",
      "    \"triggerExecution\" : 16208,\n",
      "    \"walCommit\" : 3070\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2295\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2369\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 74,\n",
      "    \"inputRowsPerSecond\" : 3.9190763690287045,\n",
      "    \"processedRowsPerSecond\" : 4.565646594274432\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:42:12 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 16209 milliseconds\n",
      "23/06/22 21:42:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 2432.\n",
      "23/06/22 21:42:13 INFO BlockManagerInfo: Removed broadcast_250_piece0 on 192.168.4.24:51040 in memory (size: 9.9 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:42:13 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/195 using temp file gs://kafka-spark-data/spark-metadata/offsets/.195.0775004e-a325-4a83-b74d-dcc35227bec7.tmp\n",
      "23/06/22 21:42:13 INFO BlockManagerInfo: Removed broadcast_252_piece0 on 192.168.4.24:51040 in memory (size: 9.9 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:42:13 INFO BlockManagerInfo: Removed broadcast_251_piece0 on 192.168.4.24:51040 in memory (size: 94.8 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:42:14 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.195.0775004e-a325-4a83-b74d-dcc35227bec7.tmp to gs://kafka-spark-data/spark-metadata/offsets/195\n",
      "23/06/22 21:42:14 INFO MicroBatchExecution: Committed offsets for batch 195. Metadata OffsetSeqMetadata(0,1687488132694,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:42:15 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:42:15 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:42:15 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:42:15 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:42:15 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:42:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:42:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:42:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:42:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:42:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:42:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:42:16 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:42:16 INFO DAGScheduler: Got job 253 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:42:16 INFO DAGScheduler: Final stage: ResultStage 254 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:42:16 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:42:16 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:42:16 INFO DAGScheduler: Submitting ResultStage 254 (MapPartitionsRDD[1320] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:42:16 INFO MemoryStore: Block broadcast_253 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/22 21:42:16 INFO MemoryStore: Block broadcast_253_piece0 stored as bytes in memory (estimated size 94.8 KiB, free 434.0 MiB)\n",
      "23/06/22 21:42:16 INFO BlockManagerInfo: Added broadcast_253_piece0 in memory on 192.168.4.24:51040 (size: 94.8 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:42:16 INFO SparkContext: Created broadcast 253 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:42:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 254 (MapPartitionsRDD[1320] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:42:16 INFO TaskSchedulerImpl: Adding task set 254.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:42:16 INFO TaskSetManager: Starting task 0.0 in stage 254.0 (TID 253) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:42:16 INFO Executor: Running task 0.0 in stage 254.0 (TID 253)\n",
      "23/06/22 21:42:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:42:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:42:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:42:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:42:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:42:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:42:16 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:42:16 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:42:16 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/22 21:42:16 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/22 21:42:16 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/22 21:42:16 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/22 21:42:16 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/22 21:42:16 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 2388 for partition ticketmaster-0\n",
      "23/06/22 21:42:16 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:16 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:42:16 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:16 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 2447.\n",
      "23/06/22 21:42:16 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 2389 for partition ticketmaster-0\n",
      "23/06/22 21:42:16 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:16 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:42:16 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:16 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 2448.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 254:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:42:18 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-71938c02-8325-4db4-87bb-ac1f45b9983c/_temporary/0/_temporary/' directory.\n",
      "23/06/22 21:42:18 INFO FileOutputCommitter: Saved output of task 'attempt_202306222142166451934886109560755_0254_m_000000_253' to gs://kafka-spark-data/.spark-bigquery-local-1687482506437-71938c02-8325-4db4-87bb-ac1f45b9983c/_temporary/0/task_202306222142166451934886109560755_0254_m_000000\n",
      "23/06/22 21:42:18 INFO SparkHadoopMapRedUtil: attempt_202306222142166451934886109560755_0254_m_000000_253: Committed. Elapsed time: 950 ms.\n",
      "23/06/22 21:42:18 INFO Executor: Finished task 0.0 in stage 254.0 (TID 253). 2536 bytes result sent to driver\n",
      "23/06/22 21:42:18 INFO TaskSetManager: Finished task 0.0 in stage 254.0 (TID 253) in 1877 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:42:18 INFO TaskSchedulerImpl: Removed TaskSet 254.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:42:18 INFO DAGScheduler: ResultStage 254 (start at NativeMethodAccessorImpl.java:0) finished in 1.902 s\n",
      "23/06/22 21:42:18 INFO DAGScheduler: Job 253 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:42:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 254: Stage finished\n",
      "23/06/22 21:42:18 INFO DAGScheduler: Job 253 finished: start at NativeMethodAccessorImpl.java:0, took 1.903622 s\n",
      "23/06/22 21:42:18 INFO FileFormatWriter: Start to commit write Job 2f68e7ae-90e7-4cd3-b77c-4986e05a32f6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:42:19 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-71938c02-8325-4db4-87bb-ac1f45b9983c/_temporary/0/task_202306222142166451934886109560755_0254_m_000000/' directory.\n",
      "23/06/22 21:42:19 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-71938c02-8325-4db4-87bb-ac1f45b9983c/' directory.\n",
      "23/06/22 21:42:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 2455.\n",
      "23/06/22 21:42:20 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/124 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.124.87dc63db-9871-4c75-8b97-09116b8cc349.tmp\n",
      "23/06/22 21:42:20 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.124.87dc63db-9871-4c75-8b97-09116b8cc349.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/124\n",
      "23/06/22 21:42:20 INFO MicroBatchExecution: Committed offsets for batch 124. Metadata OffsetSeqMetadata(0,1687488140008,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:42:20 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:42:20 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:42:20 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:42:20 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:42:20 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:42:20 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:42:20 INFO WriteToDataSourceV2Exec: Start processing data source write support: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@6a9fe12. The input RDD has 1 partitions.\n",
      "23/06/22 21:42:20 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:42:20 INFO DAGScheduler: Got job 254 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:42:20 INFO DAGScheduler: Final stage: ResultStage 255 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:42:20 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:42:20 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:42:20 INFO DAGScheduler: Submitting ResultStage 255 (MapPartitionsRDD[1323] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:42:20 INFO MemoryStore: Block broadcast_254 stored as values in memory (estimated size 23.0 KiB, free 434.0 MiB)\n",
      "23/06/22 21:42:20 INFO MemoryStore: Block broadcast_254_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 434.0 MiB)\n",
      "23/06/22 21:42:20 INFO BlockManagerInfo: Added broadcast_254_piece0 in memory on 192.168.4.24:51040 (size: 9.9 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:42:20 INFO SparkContext: Created broadcast 254 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:42:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 255 (MapPartitionsRDD[1323] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:42:20 INFO TaskSchedulerImpl: Adding task set 255.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:42:20 INFO TaskSetManager: Starting task 0.0 in stage 255.0 (TID 254) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:42:20 INFO Executor: Running task 0.0 in stage 255.0 (TID 254)\n",
      "23/06/22 21:42:20 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 2422 for partition ticketmaster-0\n",
      "23/06/22 21:42:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:42:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 2455.\n",
      "23/06/22 21:42:20 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 2423 for partition ticketmaster-0\n",
      "23/06/22 21:42:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:20 INFO BlockManagerInfo: Removed broadcast_253_piece0 on 192.168.4.24:51040 in memory (size: 94.8 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:42:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:42:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 2455.\n",
      "23/06/22 21:42:20 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 254, attempt 0, stage 255.0)\n",
      "23/06/22 21:42:20 INFO DataWritingSparkTask: Committed partition 0 (task 254, attempt 0, stage 255.0)\n",
      "23/06/22 21:42:20 INFO Executor: Finished task 0.0 in stage 255.0 (TID 254). 29586 bytes result sent to driver\n",
      "23/06/22 21:42:20 INFO TaskSetManager: Finished task 0.0 in stage 255.0 (TID 254) in 527 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:42:20 INFO TaskSchedulerImpl: Removed TaskSet 255.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:42:20 INFO DAGScheduler: ResultStage 255 (start at NativeMethodAccessorImpl.java:0) finished in 0.535 s\n",
      "23/06/22 21:42:20 INFO DAGScheduler: Job 254 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:42:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 255: Stage finished\n",
      "23/06/22 21:42:20 INFO DAGScheduler: Job 254 finished: start at NativeMethodAccessorImpl.java:0, took 0.540787 s\n",
      "23/06/22 21:42:20 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@6a9fe12 is committing.\n",
      "-------------------------------------------\n",
      "Batch: 124\n",
      "-------------------------------------------\n",
      "+--------------------+----------+-------------+--------------------+--------------------+----------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+-------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|          event_name|event_type|     event_id|           event_url|          venue_name|  venue_id|venue_zipcode|venues_timezone|venue_city|venue_state_full|venue_state_short|  venue_country_name|venue_country_short|venue_address|venue_longitude|venue_latitude|     attraction_name|attraction_type|attraction_id|      attraction_url|attraction_segment_id|attraction_segment_name|attraction_genre_id|attraction_genre_name|attraction_subgenre_id|attraction_subgenre_name|event_start_date|ticket_status|event_start_time|currency|min_price|max_price|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+----------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+-------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|Houston Ballet w/...|     \"NaN\"|Z7r9jZ1Ad-Ivk|https://www.ticke...|Brown Theatre-Wor...|Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Texas St|     -95.362999|     29.759399|      Houston Ballet|     attraction|  K8vZ9171oIf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2024-03-10|       onsale|        14:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|       Houston Rodeo|     \"NaN\"|Z7r9jZ1Ad-tf8|https://www.ticke...|         NRG Stadium|ZFr9jZdAee|        77054|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| One NRG Park|     -95.400101|       29.6835|Houston Livestock...|     attraction|  K8vZ9171hu7|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAea|                Rodeo|   KZazBEonSMnZfZ7vF1d|                   Rodeo|      2024-03-17|      offsale|        15:45:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|       Houston Rodeo|     \"NaN\"|Z7r9jZ1Ad-tfb|https://www.ticke...|         NRG Stadium|ZFr9jZdAee|        77054|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| One NRG Park|     -95.400101|       29.6835|Houston Livestock...|     attraction|  K8vZ9171hu7|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAea|                Rodeo|   KZazBEonSMnZfZ7vF1d|                   Rodeo|      2024-03-11|      offsale|        18:45:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|       Houston Rodeo|     \"NaN\"|Z7r9jZ1Ad-tfF|https://www.ticke...|         NRG Stadium|ZFr9jZdAee|        77054|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| One NRG Park|     -95.400101|       29.6835|Houston Livestock...|     attraction|  K8vZ9171hu7|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAea|                Rodeo|   KZazBEonSMnZfZ7vF1d|                   Rodeo|      2024-03-12|      offsale|        18:45:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Ballet w/...|     \"NaN\"|Z7r9jZ1Ad-U8P|https://www.ticke...|Brown Theatre-Wor...|Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Texas St|     -95.362999|     29.759399|      Houston Ballet|     attraction|  K8vZ9171oIf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2024-03-07|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|       Houston Rodeo|     \"NaN\"|Z7r9jZ1Ad-tf-|https://www.ticke...|         NRG Stadium|ZFr9jZdAee|        77054|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| One NRG Park|     -95.400101|       29.6835|Houston Livestock...|     attraction|  K8vZ9171hu7|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAea|                Rodeo|   KZazBEonSMnZfZ7vF1d|                   Rodeo|      2024-03-14|      offsale|        18:45:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Ballet w/...|     \"NaN\"|Z7r9jZ1Ad-MA-|https://www.ticke...|Brown Theatre-Wor...|Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Texas St|     -95.362999|     29.759399|      Houston Ballet|     attraction|  K8vZ9171oIf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2024-03-17|       onsale|        14:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Ballet w/...|     \"NaN\"|Z7r9jZ1Ad-IvA|https://www.ticke...|Brown Theatre-Wor...|Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Texas St|     -95.362999|     29.759399|      Houston Ballet|     attraction|  K8vZ9171oIf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2024-03-09|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|       Houston Rodeo|     \"NaN\"|Z7r9jZ1Ad-tfA|https://www.ticke...|         NRG Stadium|ZFr9jZdAee|        77054|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| One NRG Park|     -95.400101|       29.6835|Houston Livestock...|     attraction|  K8vZ9171hu7|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAea|                Rodeo|   KZazBEonSMnZfZ7vF1d|                   Rodeo|      2024-03-16|      offsale|        15:45:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|       Houston Rodeo|     \"NaN\"|Z7r9jZ1Ad-tf4|https://www.ticke...|         NRG Stadium|ZFr9jZdAee|        77054|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| One NRG Park|     -95.400101|       29.6835|Houston Livestock...|     attraction|  K8vZ9171hu7|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAea|                Rodeo|   KZazBEonSMnZfZ7vF1d|                   Rodeo|      2024-03-15|      offsale|        18:45:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Ballet w/...|     \"NaN\"|Z7r9jZ1Ad-Iv6|https://www.ticke...|Brown Theatre-Wor...|Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Texas St|     -95.362999|     29.759399|      Houston Ballet|     attraction|  K8vZ9171oIf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2024-03-16|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Ballet w/...|     \"NaN\"|Z7r9jZ1Ad-y4O|https://www.ticke...|Brown Theatre-Wor...|Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Texas St|     -95.362999|     29.759399|      Houston Ballet|     attraction|  K8vZ9171oIf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2024-03-31|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Ballet w/...|     \"NaN\"|Z7r9jZ1Ad-U8t|https://www.ticke...|Brown Theatre-Wor...|Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Texas St|     -95.362999|     29.759399|      Houston Ballet|     attraction|  K8vZ9171oIf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2024-05-23|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Ballet w/...|     \"NaN\"|Z7r9jZ1Ad-gj6|https://www.ticke...|Brown Theatre-Wor...|Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Texas St|     -95.362999|     29.759399|      Houston Ballet|     attraction|  K8vZ9171oIf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2024-05-31|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|      Houston Ballet|     \"NaN\"|Z7r9jZ1Ad-y4b|https://www.ticke...|Brown Theatre-Wor...|Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Texas St|     -95.362999|     29.759399|      Houston Ballet|     attraction|  K8vZ9171oIf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2024-06-01|       onsale|        13:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Ballet w/...|     \"NaN\"|Z7r9jZ1Ad-f7d|https://www.ticke...|Brown Theatre-Wor...|Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Texas St|     -95.362999|     29.759399|      Houston Ballet|     attraction|  K8vZ9171oIf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2024-05-26|       onsale|        14:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Ballet w/...|     \"NaN\"|Z7r9jZ1Ad-f7e|https://www.ticke...|Brown Theatre-Wor...|Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Texas St|     -95.362999|     29.759399|      Houston Ballet|     attraction|  K8vZ9171oIf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2024-05-25|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Ballet w/...|     \"NaN\"|Z7r9jZ1Ad-f77|https://www.ticke...|Brown Theatre-Wor...|Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Texas St|     -95.362999|     29.759399|      Houston Ballet|     attraction|  K8vZ9171oIf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2024-06-01|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Ballet w/...|     \"NaN\"|Z7r9jZ1Ad-gj8|https://www.ticke...|Brown Theatre-Wor...|Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Texas St|     -95.362999|     29.759399|      Houston Ballet|     attraction|  K8vZ9171oIf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2024-06-02|       onsale|        14:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Houston Ballet w/...|     \"NaN\"|Z7r9jZ1Ad-tZ4|https://www.ticke...|Brown Theatre-Wor...|Z6r9jZdAee|        77002|America/Chicago|   Houston|           Texas|               TX|United States Of ...|                 US| 501 Texas St|     -95.362999|     29.759399|      Houston Ballet|     attraction|  K8vZ9171oIf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7nI|                Dance|   KZazBEonSMnZfZ7v7nl|                   Dance|      2024-06-15|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+----------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+-------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "23/06/22 21:42:20 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@6a9fe12 committed.\n",
      "23/06/22 21:42:20 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/124 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.124.75e05f4c-7e52-488c-aa6e-a0873ebd6b3d.tmp\n",
      "23/06/22 21:42:20 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.124.75e05f4c-7e52-488c-aa6e-a0873ebd6b3d.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/124\n",
      "23/06/22 21:42:20 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:42:20.005Z\",\n",
      "  \"batchId\" : 124,\n",
      "  \"numInputRows\" : 34,\n",
      "  \"inputRowsPerSecond\" : 3.4,\n",
      "  \"processedRowsPerSecond\" : 44.270833333333336,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 571,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 3,\n",
      "    \"queryPlanning\" : 6,\n",
      "    \"triggerExecution\" : 768,\n",
      "    \"walCommit\" : 115\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2421\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2455\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 34,\n",
      "    \"inputRowsPerSecond\" : 3.4,\n",
      "    \"processedRowsPerSecond\" : 44.270833333333336\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 34\n",
      "  }\n",
      "}\n",
      "23/06/22 21:42:20 INFO FileFormatWriter: Write Job 2f68e7ae-90e7-4cd3-b77c-4986e05a32f6 committed. Elapsed time: 2712 ms.\n",
      "23/06/22 21:42:20 INFO FileFormatWriter: Finished processing stats for write job 2f68e7ae-90e7-4cd3-b77c-4986e05a32f6.\n",
      "23/06/22 21:42:21 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687482506437-71938c02-8325-4db4-87bb-ac1f45b9983c/part-00000-cad939ae-b937-4207-bd55-d33b6ddfc843-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=2dcbb76a-e003-443a-94dd-fdfe63fbe192, location=US}\n",
      "23/06/22 21:42:23 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=2dcbb76a-e003-443a-94dd-fdfe63fbe192, location=US}\n",
      "23/06/22 21:42:25 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/195 using temp file gs://kafka-spark-data/spark-metadata/commits/.195.cde830fe-a5b7-4d78-9f8a-931278296f6c.tmp\n",
      "23/06/22 21:42:25 INFO BlockManagerInfo: Removed broadcast_254_piece0 on 192.168.4.24:51040 in memory (size: 9.9 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:42:26 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.195.cde830fe-a5b7-4d78-9f8a-931278296f6c.tmp to gs://kafka-spark-data/spark-metadata/commits/195\n",
      "23/06/22 21:42:26 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:42:12.687Z\",\n",
      "  \"batchId\" : 195,\n",
      "  \"numInputRows\" : 63,\n",
      "  \"inputRowsPerSecond\" : 3.886729594669628,\n",
      "  \"processedRowsPerSecond\" : 4.725827019728452,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 9418,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 7,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 13331,\n",
      "    \"walCommit\" : 2582\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2369\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2432\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 63,\n",
      "    \"inputRowsPerSecond\" : 3.886729594669628,\n",
      "    \"processedRowsPerSecond\" : 4.725827019728452\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:42:26 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 13331 milliseconds\n",
      "23/06/22 21:42:26 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:26 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 2455.\n",
      "23/06/22 21:42:26 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/196 using temp file gs://kafka-spark-data/spark-metadata/offsets/.196.24b838ab-bc43-45f3-a903-4e10e052cf6a.tmp\n",
      "23/06/22 21:42:27 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.196.24b838ab-bc43-45f3-a903-4e10e052cf6a.tmp to gs://kafka-spark-data/spark-metadata/offsets/196\n",
      "23/06/22 21:42:27 INFO MicroBatchExecution: Committed offsets for batch 196. Metadata OffsetSeqMetadata(0,1687488146021,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:42:27 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:42:27 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:42:27 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:42:27 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:42:28 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:42:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:42:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:42:28 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:42:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:42:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:42:28 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:42:28 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:42:28 INFO DAGScheduler: Got job 255 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:42:28 INFO DAGScheduler: Final stage: ResultStage 256 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:42:28 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:42:28 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:42:28 INFO DAGScheduler: Submitting ResultStage 256 (MapPartitionsRDD[1330] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:42:28 INFO MemoryStore: Block broadcast_255 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/22 21:42:28 INFO MemoryStore: Block broadcast_255_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/22 21:42:28 INFO BlockManagerInfo: Added broadcast_255_piece0 in memory on 192.168.4.24:51040 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:42:28 INFO SparkContext: Created broadcast 255 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:42:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 256 (MapPartitionsRDD[1330] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:42:28 INFO TaskSchedulerImpl: Adding task set 256.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:42:28 INFO TaskSetManager: Starting task 0.0 in stage 256.0 (TID 255) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:42:28 INFO Executor: Running task 0.0 in stage 256.0 (TID 255)\n",
      "23/06/22 21:42:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:42:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:42:28 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:42:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:42:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:42:28 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:42:28 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:42:28 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:42:28 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/22 21:42:28 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/22 21:42:28 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/22 21:42:28 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/22 21:42:28 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/22 21:42:28 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 2447 for partition ticketmaster-0\n",
      "23/06/22 21:42:28 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:28 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:42:28 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:28 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 2455.\n",
      "23/06/22 21:42:28 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 2448 for partition ticketmaster-0\n",
      "23/06/22 21:42:28 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 256:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:42:29 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:42:29 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:29 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 2455.\n",
      "23/06/22 21:42:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 2455.\n",
      "23/06/22 21:42:30 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-4f7fad3c-60ad-448e-9491-5361606e3b74/_temporary/0/_temporary/' directory.\n",
      "23/06/22 21:42:30 INFO FileOutputCommitter: Saved output of task 'attempt_202306222142288744568710034882029_0256_m_000000_255' to gs://kafka-spark-data/.spark-bigquery-local-1687482506437-4f7fad3c-60ad-448e-9491-5361606e3b74/_temporary/0/task_202306222142288744568710034882029_0256_m_000000\n",
      "23/06/22 21:42:30 INFO SparkHadoopMapRedUtil: attempt_202306222142288744568710034882029_0256_m_000000_255: Committed. Elapsed time: 916 ms.\n",
      "23/06/22 21:42:30 INFO Executor: Finished task 0.0 in stage 256.0 (TID 255). 2536 bytes result sent to driver\n",
      "23/06/22 21:42:30 INFO TaskSetManager: Finished task 0.0 in stage 256.0 (TID 255) in 1930 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:42:30 INFO TaskSchedulerImpl: Removed TaskSet 256.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:42:30 INFO DAGScheduler: ResultStage 256 (start at NativeMethodAccessorImpl.java:0) finished in 1.949 s\n",
      "23/06/22 21:42:30 INFO DAGScheduler: Job 255 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:42:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 256: Stage finished\n",
      "23/06/22 21:42:30 INFO DAGScheduler: Job 255 finished: start at NativeMethodAccessorImpl.java:0, took 1.949995 s\n",
      "23/06/22 21:42:30 INFO FileFormatWriter: Start to commit write Job a40a64a6-d25f-4c62-a526-a3c7a3fcc861.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:42:31 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-4f7fad3c-60ad-448e-9491-5361606e3b74/_temporary/0/task_202306222142288744568710034882029_0256_m_000000/' directory.\n",
      "23/06/22 21:42:31 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-4f7fad3c-60ad-448e-9491-5361606e3b74/' directory.\n",
      "23/06/22 21:42:32 INFO BlockManagerInfo: Removed broadcast_255_piece0 on 192.168.4.24:51040 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:42:32 INFO FileFormatWriter: Write Job a40a64a6-d25f-4c62-a526-a3c7a3fcc861 committed. Elapsed time: 2161 ms.\n",
      "23/06/22 21:42:32 INFO FileFormatWriter: Finished processing stats for write job a40a64a6-d25f-4c62-a526-a3c7a3fcc861.\n",
      "23/06/22 21:42:33 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687482506437-4f7fad3c-60ad-448e-9491-5361606e3b74/part-00000-1c9888e4-be49-4bde-8c62-e664511874ce-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=e6b8be58-aa05-4ea0-9d15-c96e1f3f25e7, location=US}\n",
      "23/06/22 21:42:36 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=e6b8be58-aa05-4ea0-9d15-c96e1f3f25e7, location=US}\n",
      "23/06/22 21:42:36 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/196 using temp file gs://kafka-spark-data/spark-metadata/commits/.196.05d1e1ab-bcee-4b97-bd33-b8fc9608604f.tmp\n",
      "23/06/22 21:42:37 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.196.05d1e1ab-bcee-4b97-bd33-b8fc9608604f.tmp to gs://kafka-spark-data/spark-metadata/commits/196\n",
      "23/06/22 21:42:37 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:42:26.019Z\",\n",
      "  \"batchId\" : 196,\n",
      "  \"numInputRows\" : 23,\n",
      "  \"inputRowsPerSecond\" : 1.7251725172517252,\n",
      "  \"processedRowsPerSecond\" : 1.9979152189020153,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 8731,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 2,\n",
      "    \"queryPlanning\" : 10,\n",
      "    \"triggerExecution\" : 11512,\n",
      "    \"walCommit\" : 1754\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2432\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2455\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 23,\n",
      "    \"inputRowsPerSecond\" : 1.7251725172517252,\n",
      "    \"processedRowsPerSecond\" : 1.9979152189020153\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:42:37 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 11515 milliseconds\n",
      "23/06/22 21:42:37 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:37 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 2455.\n",
      "23/06/22 21:42:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 2455.\n",
      "23/06/22 21:42:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 2455.\n",
      "23/06/22 21:42:40 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:42:40.005Z\",\n",
      "  \"batchId\" : 125,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 5,\n",
      "    \"triggerExecution\" : 6\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2455\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2455\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 0\n",
      "  }\n",
      "}\n",
      "23/06/22 21:42:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:42:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 2455.\n",
      "23/06/22 21:42:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 2455.\n",
      "23/06/22 21:42:50 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:42:50.003Z\",\n",
      "  \"batchId\" : 197,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 4,\n",
      "    \"triggerExecution\" : 5\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2455\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2455\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:43:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:43:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:43:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 2963.\n",
      "23/06/22 21:43:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 2963.\n",
      "23/06/22 21:43:00 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/125 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.125.55fb2c1f-f416-4232-867a-7405fbaf5c02.tmp\n",
      "23/06/22 21:43:00 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.125.55fb2c1f-f416-4232-867a-7405fbaf5c02.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/125\n",
      "23/06/22 21:43:00 INFO MicroBatchExecution: Committed offsets for batch 125. Metadata OffsetSeqMetadata(0,1687488180018,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:43:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:43:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:43:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:43:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:43:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:43:00 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:43:00 INFO WriteToDataSourceV2Exec: Start processing data source write support: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@38316fae. The input RDD has 1 partitions.\n",
      "23/06/22 21:43:00 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:43:00 INFO DAGScheduler: Got job 256 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:43:00 INFO DAGScheduler: Final stage: ResultStage 257 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:43:00 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:43:00 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:43:00 INFO DAGScheduler: Submitting ResultStage 257 (MapPartitionsRDD[1333] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:43:00 INFO MemoryStore: Block broadcast_256 stored as values in memory (estimated size 23.0 KiB, free 434.4 MiB)\n",
      "23/06/22 21:43:00 INFO MemoryStore: Block broadcast_256_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 434.4 MiB)\n",
      "23/06/22 21:43:00 INFO BlockManagerInfo: Added broadcast_256_piece0 in memory on 192.168.4.24:51040 (size: 9.9 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:43:00 INFO SparkContext: Created broadcast 256 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:43:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 257 (MapPartitionsRDD[1333] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:43:00 INFO TaskSchedulerImpl: Adding task set 257.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:43:00 INFO TaskSetManager: Starting task 0.0 in stage 257.0 (TID 256) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:43:00 INFO Executor: Running task 0.0 in stage 257.0 (TID 256)\n",
      "23/06/22 21:43:00 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 2455 for partition ticketmaster-0\n",
      "23/06/22 21:43:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:43:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:43:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:43:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:43:00 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 2955 for partition ticketmaster-0\n",
      "23/06/22 21:43:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:43:00 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/197 using temp file gs://kafka-spark-data/spark-metadata/offsets/.197.93dffd86-8092-499f-93b5-68200cad55c0.tmp\n",
      "23/06/22 21:43:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:43:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:43:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:43:00 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 256, attempt 0, stage 257.0)\n",
      "23/06/22 21:43:00 INFO DataWritingSparkTask: Committed partition 0 (task 256, attempt 0, stage 257.0)\n",
      "23/06/22 21:43:00 INFO Executor: Finished task 0.0 in stage 257.0 (TID 256). 435475 bytes result sent to driver\n",
      "23/06/22 21:43:00 INFO TaskSetManager: Finished task 0.0 in stage 257.0 (TID 256) in 551 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:43:00 INFO TaskSchedulerImpl: Removed TaskSet 257.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:43:00 INFO DAGScheduler: ResultStage 257 (start at NativeMethodAccessorImpl.java:0) finished in 0.557 s\n",
      "23/06/22 21:43:00 INFO DAGScheduler: Job 256 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:43:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 257: Stage finished\n",
      "23/06/22 21:43:00 INFO DAGScheduler: Job 256 finished: start at NativeMethodAccessorImpl.java:0, took 0.559554 s\n",
      "23/06/22 21:43:00 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@38316fae is committing.\n",
      "-------------------------------------------\n",
      "Batch: 125\n",
      "-------------------------------------------\n",
      "+--------------------+----------+--------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|          event_name|event_type|      event_id|           event_url|          venue_name|    venue_id|venue_zipcode|venues_timezone|venue_city|venue_state_full|venue_state_short|  venue_country_name|venue_country_short|       venue_address|venue_longitude|venue_latitude|     attraction_name|attraction_type|attraction_id|      attraction_url|attraction_segment_id|attraction_segment_name|attraction_genre_id|attraction_genre_name|attraction_subgenre_id|attraction_subgenre_name|event_start_date|ticket_status|event_start_time|currency|min_price|max_price|\n",
      "+--------------------+----------+--------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|Shania Twain: Que...|  standard|vvG1YZ94E4EgM4|https://concerts....|  Dos Equis Pavilion|KovZpZAEAFeA|        75210|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|     3839 S Fitzhugh|   -96.75646586|   32.77507215|        Shania Twain|     attraction|  K8vZ91719n0|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv6|              Country|   KZazBEonSMnZfZ7vAFa|                 Country|      2023-07-21|       onsale|        19:30:00|     USD|    55.95|   265.95|\n",
      "|Red River Showdow...|     \"NaN\"| Z7r9jZ1AdOE0x|https://www.ticke...|         Cotton Bowl|  Z6r9jZAeve|        75210|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|1300 Robert B Cul...|     -96.745499|     32.771099|University of Tex...|     attraction|  K8vZ9171MW7|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdE|             Football|   KZazBEonSMnZfZ7vFE6|                 College|      2023-10-07|       onsale|           \"NaN\"|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Stanley Cup Final...|  standard|vvG1YZ9JXIF4Ki|https://www.ticke...|American Airlines...|KovZpZAJ67eA|        75219|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US| 2500 Victory Avenue|   -96.81081803|   32.79067196|        Dallas Stars|     attraction|  K8vZ9171ozV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdI|               Hockey|   KZazBEonSMnZfZ7vFEE|                     NHL|      2023-07-20|    cancelled|        20:00:00|     USD|    160.0|   1540.0|\n",
      "|Third Round: TBD ...|  standard|vvG1YZ9JXI6PK_|https://www.ticke...|American Airlines...|KovZpZAJ67eA|        75219|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US| 2500 Victory Avenue|   -96.81081803|   32.79067196|        Dallas Stars|     attraction|  K8vZ9171ozV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdI|               Hockey|   KZazBEonSMnZfZ7vFEE|                     NHL|      2023-07-02|    cancelled|        20:00:00|     USD|     92.0|   1540.0|\n",
      "|Stanley Cup Final...|  standard|vvG1YZ9JXIFgKY|https://www.ticke...|American Airlines...|KovZpZAJ67eA|        75219|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US| 2500 Victory Avenue|   -96.81081803|   32.79067196|        Dallas Stars|     attraction|  K8vZ9171ozV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdI|               Hockey|   KZazBEonSMnZfZ7vFEE|                     NHL|      2023-07-21|    cancelled|        20:00:00|     USD|    160.0|   1540.0|\n",
      "|Stanley Cup Final...|  standard|vvG1YZ9JXIagKM|https://www.ticke...|American Airlines...|KovZpZAJ67eA|        75219|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US| 2500 Victory Avenue|   -96.81081803|   32.79067196|        Dallas Stars|     attraction|  K8vZ9171ozV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdI|               Hockey|   KZazBEonSMnZfZ7vFEE|                     NHL|      2023-07-22|    cancelled|        20:00:00|     USD|    160.0|   1540.0|\n",
      "|Stanley Cup Final...|  standard|vvG1YZ9JXI1PKW|https://www.ticke...|American Airlines...|KovZpZAJ67eA|        75219|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US| 2500 Victory Avenue|   -96.81081803|   32.79067196|        Dallas Stars|     attraction|  K8vZ9171ozV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdI|               Hockey|   KZazBEonSMnZfZ7vFEE|                     NHL|      2023-07-23|    cancelled|        20:00:00|     USD|    160.0|   1540.0|\n",
      "|Drake: It's All A...|  standard|vvG1YZ9JJpQoL3|https://www.ticke...|American Airlines...|KovZpZAJ67eA|        75219|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US| 2500 Victory Avenue|   -96.81081803|   32.79067196|               Drake|     attraction|  K8vZ917Gp47|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkdA|                   Urban|      2023-09-14|  rescheduled|        19:00:00|     USD|    144.5|    501.5|\n",
      "|Karol G: Mañana S...|  standard|vvG1YZ9tl_q75y|https://www.ticke...|         Cotton Bowl|KovZpZAdlEJA|        75226|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|3750 Midway Plaza...|   -96.75976624|   32.77946164|             Karol G|     attraction|  K8vZ917p3-V|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAJ6|                Latin|   KZazBEonSMnZfZ7va1a|                   Latin|      2023-09-02|       onsale|        19:00:00|     USD|     72.5|    432.5|\n",
      "|Fuerza Regida - O...|  standard|vvG1YZ9tZJRYR5|https://concerts....|  Dos Equis Pavilion|KovZpZAEAFeA|        75210|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|     3839 S Fitzhugh|   -96.75646586|   32.77507215|       Fuerza Regida|     attraction|  K8vZ9179vO0|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeF|                World|   KZazBEonSMnZfZ7vFdJ|                   Latin|      2023-07-07|       onsale|        20:00:00|     USD|     39.5|    419.5|\n",
      "| blink-182 Tour 2023|  standard|vvG1YZ9fQXQ3XS|https://www.ticke...|American Airlines...|KovZpZAJ67eA|        75219|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US| 2500 Victory Avenue|   -96.81081803|   32.79067196|           blink-182|     attraction|  K8vZ9171pNf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-07-05|       onsale|        19:30:00|     USD|     29.5|    249.5|\n",
      "|Drake: It's All A...|  standard|vvG1YZ9JJpY-Lt|https://www.ticke...|American Airlines...|KovZpZAJ67eA|        75219|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US| 2500 Victory Avenue|   -96.81081803|   32.79067196|               Drake|     attraction|  K8vZ917Gp47|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkdA|                   Urban|      2023-09-15|  rescheduled|        19:00:00|     USD|    144.5|    501.5|\n",
      "| Dave Chappelle Live|  standard|vvG1YZ9llk9N6s|https://www.ticke...|American Airlines...|KovZpZAJ67eA|        75219|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US| 2500 Victory Avenue|   -96.81081803|   32.79067196|      Dave Chappelle|     attraction|  K8vZ9171rcf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-06-29|       onsale|        19:30:00|     USD|     59.5|    299.5|\n",
      "|State Fair Classi...|  standard|vvG1YZ9t5-7SXg|https://www.ticke...|         Cotton Bowl|KovZpZAdlEJA|        75226|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|3750 Midway Plaza...|   -96.75976624|   32.77946164|Prairie View A&M ...|     attraction|  K8vZ9171gR7|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdE|             Football|   KZazBEonSMnZfZ7vFE6|                 College|      2023-09-30|      offsale|        18:00:00|     USD|     35.0|     35.0|\n",
      "|Post Malone: If Y...|  standard|vvG1YZ9nTf-dwP|https://concerts....|  Dos Equis Pavilion|KovZpZAEAFeA|        75210|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|     3839 S Fitzhugh|   -96.75646586|   32.77507215|         Post Malone|     attraction|  K8vZ917KjPf|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkdA|                   Urban|      2023-08-05|       onsale|        20:00:00|     USD|     59.5|    349.5|\n",
      "|Fall Out Boy - So...|  standard|vvG1YZ9NRVNJyt|https://concerts....|  Dos Equis Pavilion|KovZpZAEAFeA|        75210|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|     3839 S Fitzhugh|   -96.75646586|   32.77507215|        Fall Out Boy|     attraction|  K8vZ9175h30|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6dt|        Alternative Rock|      2023-06-28|       onsale|        18:30:00|     USD|     49.5|    169.5|\n",
      "|     Matchbox Twenty|  standard|vvG1YZpeEAIgFQ|https://concerts....|  Dos Equis Pavilion|KovZpZAEAFeA|        75210|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|     3839 S Fitzhugh|   -96.75646586|   32.77507215|     Matchbox Twenty|     attraction|  K8vZ91719p7|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-06-29|  rescheduled|        19:30:00|     USD|     40.5|    161.0|\n",
      "|Lil Baby - It's O...|  standard|vvG1YZ9ELuEN6d|https://www.ticke...|American Airlines...|KovZpZAJ67eA|        75219|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US| 2500 Victory Avenue|   -96.81081803|   32.79067196|            Lil Baby|     attraction|  K8vZ917pNq0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkvl|             Hip-Hop/Rap|      2023-07-29|       onsale|        19:00:00|     USD|     49.5|    279.5|\n",
      "|Jelly Roll: Backr...|  standard|vvG1YZ9Pk0re3V|https://concerts....|  Dos Equis Pavilion|KovZpZAEAFeA|        75210|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|     3839 S Fitzhugh|   -96.75646586|   32.77507215|          Jelly Roll|     attraction|  K8vZ9174y8V|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv6|              Country|   KZazBEonSMnZfZ7vAFa|                 Country|      2023-09-23|       onsale|        19:00:00|     USD|    50.75|   110.75|\n",
      "|MVP: Jake Paul v ...|  standard|vvG1YZ9npvi34a|https://www.ticke...|American Airlines...|KovZpZAJ67eA|        75219|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US| 2500 Victory Avenue|   -96.81081803|   32.79067196|               \"NaN\"|          \"NaN\"|        \"NaN\"|               \"NaN\"|                \"NaN\"|                  \"NaN\"|              \"NaN\"|                \"NaN\"|                 \"NaN\"|                   \"NaN\"|      2023-08-05|       onsale|        17:00:00|     USD|     61.5|   1006.5|\n",
      "+--------------------+----------+--------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "23/06/22 21:43:00 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@38316fae committed.\n",
      "23/06/22 21:43:00 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/125 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.125.eef6d8de-2836-4d54-b77b-f64955d9e863.tmp\n",
      "23/06/22 21:43:00 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.125.eef6d8de-2836-4d54-b77b-f64955d9e863.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/125\n",
      "23/06/22 21:43:00 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:43:00.003Z\",\n",
      "  \"batchId\" : 125,\n",
      "  \"numInputRows\" : 508,\n",
      "  \"inputRowsPerSecond\" : 50.79492050794921,\n",
      "  \"processedRowsPerSecond\" : 634.2072409488139,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 601,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 15,\n",
      "    \"queryPlanning\" : 34,\n",
      "    \"triggerExecution\" : 801,\n",
      "    \"walCommit\" : 90\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2455\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2963\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 508,\n",
      "    \"inputRowsPerSecond\" : 50.79492050794921,\n",
      "    \"processedRowsPerSecond\" : 634.2072409488139\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 508\n",
      "  }\n",
      "}\n",
      "23/06/22 21:43:01 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.197.93dffd86-8092-499f-93b5-68200cad55c0.tmp to gs://kafka-spark-data/spark-metadata/offsets/197\n",
      "23/06/22 21:43:01 INFO MicroBatchExecution: Committed offsets for batch 197. Metadata OffsetSeqMetadata(0,1687488180018,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:43:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:43:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:43:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:43:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:43:01 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:43:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:43:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:43:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:43:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:43:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:43:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:43:02 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:43:02 INFO DAGScheduler: Got job 257 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:43:02 INFO DAGScheduler: Final stage: ResultStage 258 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:43:02 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:43:02 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:43:02 INFO DAGScheduler: Submitting ResultStage 258 (MapPartitionsRDD[1340] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:43:02 INFO MemoryStore: Block broadcast_257 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/22 21:43:02 INFO MemoryStore: Block broadcast_257_piece0 stored as bytes in memory (estimated size 94.8 KiB, free 434.0 MiB)\n",
      "23/06/22 21:43:02 INFO BlockManagerInfo: Added broadcast_257_piece0 in memory on 192.168.4.24:51040 (size: 94.8 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:43:02 INFO SparkContext: Created broadcast 257 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:43:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 258 (MapPartitionsRDD[1340] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:43:02 INFO TaskSchedulerImpl: Adding task set 258.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:43:02 INFO TaskSetManager: Starting task 0.0 in stage 258.0 (TID 257) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:43:02 INFO Executor: Running task 0.0 in stage 258.0 (TID 257)\n",
      "23/06/22 21:43:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:43:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:43:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:43:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:43:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:43:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:43:02 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:43:02 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:43:02 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/22 21:43:02 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/22 21:43:02 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/22 21:43:02 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/22 21:43:02 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/22 21:43:02 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 2455 for partition ticketmaster-0\n",
      "23/06/22 21:43:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:43:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:43:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:43:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:43:02 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 2955 for partition ticketmaster-0\n",
      "23/06/22 21:43:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:43:02 INFO BlockManagerInfo: Removed broadcast_256_piece0 on 192.168.4.24:51040 in memory (size: 9.9 KiB, free: 434.3 MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 258:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:43:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:43:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:43:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:43:03 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-efc909ec-ec69-4ce7-ad29-0b43f328f95f/_temporary/0/_temporary/' directory.\n",
      "23/06/22 21:43:03 INFO FileOutputCommitter: Saved output of task 'attempt_202306222143028581242081243932956_0258_m_000000_257' to gs://kafka-spark-data/.spark-bigquery-local-1687482506437-efc909ec-ec69-4ce7-ad29-0b43f328f95f/_temporary/0/task_202306222143028581242081243932956_0258_m_000000\n",
      "23/06/22 21:43:03 INFO SparkHadoopMapRedUtil: attempt_202306222143028581242081243932956_0258_m_000000_257: Committed. Elapsed time: 599 ms.\n",
      "23/06/22 21:43:03 INFO Executor: Finished task 0.0 in stage 258.0 (TID 257). 2579 bytes result sent to driver\n",
      "23/06/22 21:43:03 INFO TaskSetManager: Finished task 0.0 in stage 258.0 (TID 257) in 1623 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:43:03 INFO TaskSchedulerImpl: Removed TaskSet 258.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:43:03 INFO DAGScheduler: ResultStage 258 (start at NativeMethodAccessorImpl.java:0) finished in 1.642 s\n",
      "23/06/22 21:43:03 INFO DAGScheduler: Job 257 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:43:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 258: Stage finished\n",
      "23/06/22 21:43:03 INFO DAGScheduler: Job 257 finished: start at NativeMethodAccessorImpl.java:0, took 1.642135 s\n",
      "23/06/22 21:43:03 INFO FileFormatWriter: Start to commit write Job 72e9c0d0-f1e0-4b32-a818-d99c585049b2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:43:04 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-efc909ec-ec69-4ce7-ad29-0b43f328f95f/_temporary/0/task_202306222143028581242081243932956_0258_m_000000/' directory.\n",
      "23/06/22 21:43:04 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-efc909ec-ec69-4ce7-ad29-0b43f328f95f/' directory.\n",
      "23/06/22 21:43:04 INFO BlockManagerInfo: Removed broadcast_257_piece0 on 192.168.4.24:51040 in memory (size: 94.8 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:43:05 INFO FileFormatWriter: Write Job 72e9c0d0-f1e0-4b32-a818-d99c585049b2 committed. Elapsed time: 1435 ms.\n",
      "23/06/22 21:43:05 INFO FileFormatWriter: Finished processing stats for write job 72e9c0d0-f1e0-4b32-a818-d99c585049b2.\n",
      "23/06/22 21:43:05 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687482506437-efc909ec-ec69-4ce7-ad29-0b43f328f95f/part-00000-9c2d8861-847c-47d6-a7a1-3e5e894e07b1-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=b5dfcf15-58eb-4e25-8623-36fc9c8877ae, location=US}\n",
      "23/06/22 21:43:07 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=b5dfcf15-58eb-4e25-8623-36fc9c8877ae, location=US}\n",
      "23/06/22 21:43:08 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/197 using temp file gs://kafka-spark-data/spark-metadata/commits/.197.8d722ba9-57c2-4d98-a170-51717b3dbc45.tmp\n",
      "23/06/22 21:43:09 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.197.8d722ba9-57c2-4d98-a170-51717b3dbc45.tmp to gs://kafka-spark-data/spark-metadata/commits/197\n",
      "23/06/22 21:43:09 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:43:00.002Z\",\n",
      "  \"batchId\" : 197,\n",
      "  \"numInputRows\" : 508,\n",
      "  \"inputRowsPerSecond\" : 50.8050805080508,\n",
      "  \"processedRowsPerSecond\" : 53.7395535808738,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6707,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 16,\n",
      "    \"queryPlanning\" : 8,\n",
      "    \"triggerExecution\" : 9453,\n",
      "    \"walCommit\" : 1510\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2455\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2963\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 508,\n",
      "    \"inputRowsPerSecond\" : 50.8050805080508,\n",
      "    \"processedRowsPerSecond\" : 53.7395535808738\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:43:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:43:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:43:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:43:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:43:10 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/126 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.126.40df63e1-403b-4e2a-bc47-90e0c90dc4a0.tmp\n",
      "23/06/22 21:43:10 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.126.40df63e1-403b-4e2a-bc47-90e0c90dc4a0.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/126\n",
      "23/06/22 21:43:10 INFO MicroBatchExecution: Committed offsets for batch 126. Metadata OffsetSeqMetadata(0,1687488190013,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:43:10 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:43:10 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:43:10 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:43:10 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:43:10 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:43:10 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:43:10 INFO WriteToDataSourceV2Exec: Start processing data source write support: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@6028cec0. The input RDD has 1 partitions.\n",
      "23/06/22 21:43:10 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:43:10 INFO DAGScheduler: Got job 258 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:43:10 INFO DAGScheduler: Final stage: ResultStage 259 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:43:10 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:43:10 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:43:10 INFO DAGScheduler: Submitting ResultStage 259 (MapPartitionsRDD[1343] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:43:10 INFO MemoryStore: Block broadcast_258 stored as values in memory (estimated size 23.0 KiB, free 434.4 MiB)\n",
      "23/06/22 21:43:10 INFO MemoryStore: Block broadcast_258_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 434.4 MiB)\n",
      "23/06/22 21:43:10 INFO BlockManagerInfo: Added broadcast_258_piece0 in memory on 192.168.4.24:51040 (size: 9.9 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:43:10 INFO SparkContext: Created broadcast 258 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:43:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 259 (MapPartitionsRDD[1343] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:43:10 INFO TaskSchedulerImpl: Adding task set 259.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:43:10 INFO TaskSetManager: Starting task 0.0 in stage 259.0 (TID 258) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:43:10 INFO Executor: Running task 0.0 in stage 259.0 (TID 258)\n",
      "23/06/22 21:43:10 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 258, attempt 0, stage 259.0)\n",
      "23/06/22 21:43:10 INFO DataWritingSparkTask: Committed partition 0 (task 258, attempt 0, stage 259.0)\n",
      "23/06/22 21:43:10 INFO Executor: Finished task 0.0 in stage 259.0 (TID 258). 5752 bytes result sent to driver\n",
      "23/06/22 21:43:10 INFO TaskSetManager: Finished task 0.0 in stage 259.0 (TID 258) in 6 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:43:10 INFO TaskSchedulerImpl: Removed TaskSet 259.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:43:10 INFO DAGScheduler: ResultStage 259 (start at NativeMethodAccessorImpl.java:0) finished in 0.009 s\n",
      "23/06/22 21:43:10 INFO DAGScheduler: Job 258 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:43:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 259: Stage finished\n",
      "23/06/22 21:43:10 INFO DAGScheduler: Job 258 finished: start at NativeMethodAccessorImpl.java:0, took 0.009810 s\n",
      "23/06/22 21:43:10 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@6028cec0 is committing.\n",
      "-------------------------------------------\n",
      "Batch: 126\n",
      "-------------------------------------------\n",
      "+--------------------+----------+--------------+--------------------+--------------------+-------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+-------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|          event_name|event_type|      event_id|           event_url|          venue_name|     venue_id|venue_zipcode|venues_timezone|venue_city|venue_state_full|venue_state_short|  venue_country_name|venue_country_short|      venue_address|venue_longitude|venue_latitude|     attraction_name|attraction_type|attraction_id|      attraction_url|attraction_segment_id|attraction_segment_name|attraction_genre_id|attraction_genre_name|attraction_subgenre_id|attraction_subgenre_name|event_start_date|ticket_status|event_start_time|currency|min_price|max_price|\n",
      "+--------------------+----------+--------------+--------------------+--------------------+-------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+-------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|     BashfortheWorld|     \"NaN\"| Z7r9jZ1AdxFa3|https://www.ticke...|South Side Music ...|   ZFr9jZa7FF|        75215|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|   1135 South Lamar|     -96.760803|     32.751598|     BashfortheWorld|     attraction|   Z7r9jZafXT|               \"NaN\"|   KZFzniwnSyZfZ7v7nl|              Undefined|              \"NaN\"|                \"NaN\"|                 \"NaN\"|                   \"NaN\"|      2023-07-08|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|    Louie The Singer|     \"NaN\"| Z7r9jZ1Adxd_a|https://www.ticke...|               Trees|   ZFr9jZeF76|        75226|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|       2707 Elm St.|     -96.775803|       32.7827|    Louie The Singer|     attraction|   Z7r9jZa4d2|               \"NaN\"|   KZFzniwnSyZfZ7v7nl|              Undefined|              \"NaN\"|                \"NaN\"|                 \"NaN\"|                   \"NaN\"|      2023-08-12|       onsale|        21:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Cheryl Porter Mas...|  standard|rZ7HnEZ1A3jN_4|https://www.ticke...|     Gilley's Dallas|rZ7HnEZ178EGA|        75215|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|    1135 S Lamar St|      -96.79757|     32.768867|               \"NaN\"|          \"NaN\"|        \"NaN\"|               \"NaN\"|                \"NaN\"|                  \"NaN\"|              \"NaN\"|                \"NaN\"|                 \"NaN\"|                   \"NaN\"|      2023-07-22|    cancelled|        10:00:00|     USD|     49.0|    249.0|\n",
      "|BBQ Buffet Upgrad...|  standard|vvG1YZ9lnj-sDu|https://concerts....|House of Blues Da...| KovZpZAEAF7A|        75202|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|    2200 N Lamar St|   -96.80851279|   32.78521325|LN Other-Non Mani...|     attraction|  K8vZ917bJT7|https://www.liven...|   KZFzniwnSyZfZ7v7n1|          Miscellaneous|        KnvZfZ7v7ll|            Undefined|   KZazBEonSMnZfZ7vAv1|               Undefined|      2023-06-30|       onsale|        19:00:00|     USD|     30.0|     30.0|\n",
      "|Carin Leon EXPERI...|  standard|vvG1YZ9nKlmk6S|https://www.ticke...|American Airlines...| KovZpZAJ67eA|        75219|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|2500 Victory Avenue|   -96.81081803|   32.79067196|          Carin Leon|     attraction|  K8vZ917_m_f|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAJ6|                Latin|   KZazBEonSMnZfZ7va1a|                   Latin|      2023-08-24|       onsale|        20:00:00|     USD|    749.0|    749.0|\n",
      "+--------------------+----------+--------------+--------------------+--------------------+-------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+-------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "\n",
      "23/06/22 21:43:10 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@6028cec0 committed.\n",
      "23/06/22 21:43:10 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/126 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.126.67635e84-90d4-48d1-a12a-fea6aabd2c8f.tmp\n",
      "23/06/22 21:43:10 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.126.67635e84-90d4-48d1-a12a-fea6aabd2c8f.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/126\n",
      "23/06/22 21:43:10 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:43:10.002Z\",\n",
      "  \"batchId\" : 126,\n",
      "  \"numInputRows\" : 5,\n",
      "  \"inputRowsPerSecond\" : 0.5000500050005,\n",
      "  \"processedRowsPerSecond\" : 28.24858757062147,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 25,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 11,\n",
      "    \"queryPlanning\" : 5,\n",
      "    \"triggerExecution\" : 177,\n",
      "    \"walCommit\" : 71\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2963\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 5,\n",
      "    \"inputRowsPerSecond\" : 0.5000500050005,\n",
      "    \"processedRowsPerSecond\" : 28.24858757062147\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 5\n",
      "  }\n",
      "}\n",
      "23/06/22 21:43:10 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/198 using temp file gs://kafka-spark-data/spark-metadata/offsets/.198.da758da6-3ba7-4eb0-8cf6-ece17eda81af.tmp\n",
      "23/06/22 21:43:11 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.198.da758da6-3ba7-4eb0-8cf6-ece17eda81af.tmp to gs://kafka-spark-data/spark-metadata/offsets/198\n",
      "23/06/22 21:43:11 INFO MicroBatchExecution: Committed offsets for batch 198. Metadata OffsetSeqMetadata(0,1687488190013,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:43:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:43:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:43:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:43:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:43:11 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:43:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:43:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:43:11 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:43:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:43:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:43:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:43:12 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:43:12 INFO DAGScheduler: Got job 259 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:43:12 INFO DAGScheduler: Final stage: ResultStage 260 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:43:12 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:43:12 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:43:12 INFO DAGScheduler: Submitting ResultStage 260 (MapPartitionsRDD[1350] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:43:12 INFO MemoryStore: Block broadcast_259 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/22 21:43:12 INFO MemoryStore: Block broadcast_259_piece0 stored as bytes in memory (estimated size 94.8 KiB, free 434.0 MiB)\n",
      "23/06/22 21:43:12 INFO BlockManagerInfo: Added broadcast_259_piece0 in memory on 192.168.4.24:51040 (size: 94.8 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:43:12 INFO SparkContext: Created broadcast 259 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:43:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 260 (MapPartitionsRDD[1350] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:43:12 INFO TaskSchedulerImpl: Adding task set 260.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:43:12 INFO TaskSetManager: Starting task 0.0 in stage 260.0 (TID 259) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:43:12 INFO Executor: Running task 0.0 in stage 260.0 (TID 259)\n",
      "23/06/22 21:43:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:43:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:43:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:43:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:43:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:43:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:43:12 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:43:12 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:43:12 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/22 21:43:12 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/22 21:43:12 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/22 21:43:12 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/22 21:43:12 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/22 21:43:12 INFO BlockManagerInfo: Removed broadcast_258_piece0 on 192.168.4.24:51040 in memory (size: 9.9 KiB, free: 434.3 MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 260:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:43:13 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-385fd38a-7b32-464a-b2b5-7accdb7ce9b3/_temporary/0/_temporary/' directory.\n",
      "23/06/22 21:43:13 INFO FileOutputCommitter: Saved output of task 'attempt_202306222143123711510372762876117_0260_m_000000_259' to gs://kafka-spark-data/.spark-bigquery-local-1687482506437-385fd38a-7b32-464a-b2b5-7accdb7ce9b3/_temporary/0/task_202306222143123711510372762876117_0260_m_000000\n",
      "23/06/22 21:43:13 INFO SparkHadoopMapRedUtil: attempt_202306222143123711510372762876117_0260_m_000000_259: Committed. Elapsed time: 607 ms.\n",
      "23/06/22 21:43:13 INFO Executor: Finished task 0.0 in stage 260.0 (TID 259). 2579 bytes result sent to driver\n",
      "23/06/22 21:43:13 INFO TaskSetManager: Finished task 0.0 in stage 260.0 (TID 259) in 1157 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:43:13 INFO TaskSchedulerImpl: Removed TaskSet 260.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:43:13 INFO DAGScheduler: ResultStage 260 (start at NativeMethodAccessorImpl.java:0) finished in 1.177 s\n",
      "23/06/22 21:43:13 INFO DAGScheduler: Job 259 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:43:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 260: Stage finished\n",
      "23/06/22 21:43:13 INFO DAGScheduler: Job 259 finished: start at NativeMethodAccessorImpl.java:0, took 1.177614 s\n",
      "23/06/22 21:43:13 INFO FileFormatWriter: Start to commit write Job e79a19ec-cc51-4410-ac0c-d17c87496ffe.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:43:13 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-385fd38a-7b32-464a-b2b5-7accdb7ce9b3/_temporary/0/task_202306222143123711510372762876117_0260_m_000000/' directory.\n",
      "23/06/22 21:43:14 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-385fd38a-7b32-464a-b2b5-7accdb7ce9b3/' directory.\n",
      "23/06/22 21:43:14 INFO FileFormatWriter: Write Job e79a19ec-cc51-4410-ac0c-d17c87496ffe committed. Elapsed time: 1444 ms.\n",
      "23/06/22 21:43:14 INFO FileFormatWriter: Finished processing stats for write job e79a19ec-cc51-4410-ac0c-d17c87496ffe.\n",
      "23/06/22 21:43:15 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687482506437-385fd38a-7b32-464a-b2b5-7accdb7ce9b3/part-00000-4e97f270-42f1-48cb-8c5b-ddac6724fc3f-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=7e1d761d-7ea8-4080-b2e7-e354a2f3a457, location=US}\n",
      "23/06/22 21:43:17 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=7e1d761d-7ea8-4080-b2e7-e354a2f3a457, location=US}\n",
      "23/06/22 21:43:17 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/198 using temp file gs://kafka-spark-data/spark-metadata/commits/.198.7f61d022-1d23-45b1-a138-dfd958aa8027.tmp\n",
      "23/06/22 21:43:17 INFO BlockManagerInfo: Removed broadcast_259_piece0 on 192.168.4.24:51040 in memory (size: 94.8 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:43:18 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.198.7f61d022-1d23-45b1-a138-dfd958aa8027.tmp to gs://kafka-spark-data/spark-metadata/commits/198\n",
      "23/06/22 21:43:18 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:43:10.006Z\",\n",
      "  \"batchId\" : 198,\n",
      "  \"numInputRows\" : 5,\n",
      "  \"inputRowsPerSecond\" : 0.4998000799680128,\n",
      "  \"processedRowsPerSecond\" : 0.5793071486502144,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 5948,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 7,\n",
      "    \"queryPlanning\" : 9,\n",
      "    \"triggerExecution\" : 8631,\n",
      "    \"walCommit\" : 1574\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2963\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 5,\n",
      "    \"inputRowsPerSecond\" : 0.4998000799680128,\n",
      "    \"processedRowsPerSecond\" : 0.5793071486502144\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:43:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:43:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:43:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:43:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:43:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:43:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:43:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:43:30 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:43:30.003Z\",\n",
      "  \"batchId\" : 199,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 11,\n",
      "    \"triggerExecution\" : 11\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:43:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:43:30 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:43:30.003Z\",\n",
      "  \"batchId\" : 127,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 16,\n",
      "    \"triggerExecution\" : 17\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 0\n",
      "  }\n",
      "}\n",
      "23/06/22 21:43:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:43:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:43:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:43:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:43:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:43:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:43:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:43:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:43:50 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:43:50.004Z\",\n",
      "  \"batchId\" : 199,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 14,\n",
      "    \"triggerExecution\" : 15\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:43:50 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:43:50.003Z\",\n",
      "  \"batchId\" : 127,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 14,\n",
      "    \"triggerExecution\" : 16\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 0\n",
      "  }\n",
      "}\n",
      "23/06/22 21:44:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:44:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:44:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:44:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:44:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:44:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:44:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:44:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:44:10 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:44:10.005Z\",\n",
      "  \"batchId\" : 127,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 9,\n",
      "    \"triggerExecution\" : 9\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 0\n",
      "  }\n",
      "}\n",
      "23/06/22 21:44:10 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:44:10.007Z\",\n",
      "  \"batchId\" : 199,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 7,\n",
      "    \"triggerExecution\" : 7\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:44:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:44:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:44:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:44:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:44:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:44:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:44:30 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:44:30.001Z\",\n",
      "  \"batchId\" : 127,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 3,\n",
      "    \"triggerExecution\" : 3\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 0\n",
      "  }\n",
      "}\n",
      "23/06/22 21:44:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:44:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:44:30 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:44:30.005Z\",\n",
      "  \"batchId\" : 199,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 1,\n",
      "    \"triggerExecution\" : 1\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:44:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:44:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:44:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:44:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:44:40 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:44:40.002Z\",\n",
      "  \"batchId\" : 127,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 13,\n",
      "    \"triggerExecution\" : 13\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 0\n",
      "  }\n",
      "}\n",
      "23/06/22 21:44:40 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:44:40.005Z\",\n",
      "  \"batchId\" : 199,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 9,\n",
      "    \"triggerExecution\" : 10\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:44:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:44:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:44:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:44:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:45:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:45:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:45:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:45:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:45:00 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:45:00.004Z\",\n",
      "  \"batchId\" : 127,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 18,\n",
      "    \"triggerExecution\" : 18\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 0\n",
      "  }\n",
      "}\n",
      "23/06/22 21:45:00 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:45:00.004Z\",\n",
      "  \"batchId\" : 199,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 18,\n",
      "    \"triggerExecution\" : 18\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:45:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:45:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:45:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:45:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:45:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:45:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:45:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:45:20 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:45:20.001Z\",\n",
      "  \"batchId\" : 199,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 3,\n",
      "    \"triggerExecution\" : 3\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:45:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:45:20 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:45:20.001Z\",\n",
      "  \"batchId\" : 127,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 4,\n",
      "    \"triggerExecution\" : 4\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 0\n",
      "  }\n",
      "}\n",
      "23/06/22 21:45:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:45:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:45:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:45:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 2968.\n",
      "23/06/22 21:45:30 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:45:30.006Z\",\n",
      "  \"batchId\" : 127,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 11,\n",
      "    \"triggerExecution\" : 11\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 0\n",
      "  }\n",
      "}\n",
      "23/06/22 21:45:30 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:45:30.002Z\",\n",
      "  \"batchId\" : 199,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 15,\n",
      "    \"triggerExecution\" : 15\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:45:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:45:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:45:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 3413.\n",
      "23/06/22 21:45:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 3413.\n",
      "23/06/22 21:45:40 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/127 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.127.de5af7ac-d5dd-4da8-8754-e062534b98a1.tmp\n",
      "23/06/22 21:45:40 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.127.de5af7ac-d5dd-4da8-8754-e062534b98a1.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/127\n",
      "23/06/22 21:45:40 INFO MicroBatchExecution: Committed offsets for batch 127. Metadata OffsetSeqMetadata(0,1687488340004,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:45:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:45:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:45:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:45:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:45:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:45:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:45:40 INFO WriteToDataSourceV2Exec: Start processing data source write support: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@e347320. The input RDD has 1 partitions.\n",
      "23/06/22 21:45:40 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:45:40 INFO DAGScheduler: Got job 260 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:45:40 INFO DAGScheduler: Final stage: ResultStage 261 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:45:40 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:45:40 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:45:40 INFO DAGScheduler: Submitting ResultStage 261 (MapPartitionsRDD[1353] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:45:40 INFO MemoryStore: Block broadcast_260 stored as values in memory (estimated size 23.0 KiB, free 434.4 MiB)\n",
      "23/06/22 21:45:40 INFO MemoryStore: Block broadcast_260_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 434.4 MiB)\n",
      "23/06/22 21:45:40 INFO BlockManagerInfo: Added broadcast_260_piece0 in memory on 192.168.4.24:51040 (size: 9.9 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:45:40 INFO SparkContext: Created broadcast 260 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:45:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 261 (MapPartitionsRDD[1353] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:45:40 INFO TaskSchedulerImpl: Adding task set 261.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:45:40 INFO TaskSetManager: Starting task 0.0 in stage 261.0 (TID 260) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:45:40 INFO Executor: Running task 0.0 in stage 261.0 (TID 260)\n",
      "23/06/22 21:45:40 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 2968 for partition ticketmaster-0\n",
      "23/06/22 21:45:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:45:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:45:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:45:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 3430.\n",
      "23/06/22 21:45:40 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 260, attempt 0, stage 261.0)\n",
      "23/06/22 21:45:40 INFO DataWritingSparkTask: Committed partition 0 (task 260, attempt 0, stage 261.0)\n",
      "23/06/22 21:45:40 INFO Executor: Finished task 0.0 in stage 261.0 (TID 260). 384608 bytes result sent to driver\n",
      "23/06/22 21:45:40 INFO TaskSetManager: Finished task 0.0 in stage 261.0 (TID 260) in 60 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:45:40 INFO TaskSchedulerImpl: Removed TaskSet 261.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:45:40 INFO DAGScheduler: ResultStage 261 (start at NativeMethodAccessorImpl.java:0) finished in 0.068 s\n",
      "23/06/22 21:45:40 INFO DAGScheduler: Job 260 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:45:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 261: Stage finished\n",
      "23/06/22 21:45:40 INFO DAGScheduler: Job 260 finished: start at NativeMethodAccessorImpl.java:0, took 0.070616 s\n",
      "23/06/22 21:45:40 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@e347320 is committing.\n",
      "-------------------------------------------\n",
      "Batch: 127\n",
      "-------------------------------------------\n",
      "23/06/22 21:45:40 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/199 using temp file gs://kafka-spark-data/spark-metadata/offsets/.199.21364072-a906-4ed9-9a45-6f8b13138d83.tmp\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|          event_name|event_type|     event_id|           event_url|          venue_name|    venue_id|venue_zipcode|venues_timezone|venue_city|venue_state_full|venue_state_short|  venue_country_name|venue_country_short|       venue_address|venue_longitude|venue_latitude|     attraction_name|attraction_type|attraction_id|      attraction_url|attraction_segment_id|attraction_segment_name|attraction_genre_id|attraction_genre_name|attraction_subgenre_id|attraction_subgenre_name|event_start_date|ticket_status|event_start_time|currency|min_price|max_price|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|Texas Longhorns F...|     \"NaN\"|Z7r9jZ1Adqs47|https://www.ticke...|Darrell K Royal -...|  ZFr9jZe6Fa|        78712|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US| University of Texas|     -97.744202|       30.2843|University of Tex...|     attraction|  K8vZ9171MW7|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdE|             Football|   KZazBEonSMnZfZ7vFE6|                 College|      2023-09-16|       onsale|           \"NaN\"|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Texas Longhorns F...|     \"NaN\"|Z7r9jZ1Adqwjk|https://www.ticke...|Darrell K Royal -...|  ZFr9jZe6Fa|        78712|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US| University of Texas|     -97.744202|       30.2843|University of Tex...|     attraction|  K8vZ9171MW7|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdE|             Football|   KZazBEonSMnZfZ7vFE6|                 College|      2023-09-30|       onsale|           \"NaN\"|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Texas Longhorns F...|     \"NaN\"|Z7r9jZ1AdjFuA|https://www.ticke...|Darrell K Royal -...|  ZFr9jZe6Fa|        78712|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US| University of Texas|     -97.744202|       30.2843|University of Tex...|     attraction|  K8vZ9171MW7|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdE|             Football|   KZazBEonSMnZfZ7vFE6|                 College|      2023-09-02|       onsale|           \"NaN\"|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Texas Longhorns F...|     \"NaN\"|Z7r9jZ1AdqwjA|https://www.ticke...|Darrell K Royal -...|  ZFr9jZe6Fa|        78712|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US| University of Texas|     -97.744202|       30.2843|University of Tex...|     attraction|  K8vZ9171MW7|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdE|             Football|   KZazBEonSMnZfZ7vFE6|                 College|      2023-10-28|       onsale|           \"NaN\"|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Texas Longhorns F...|     \"NaN\"|Z7r9jZ1Adqw8p|https://www.ticke...|Darrell K Royal -...|  ZFr9jZe6Fa|        78712|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US| University of Texas|     -97.744202|       30.2843|University of Tex...|     attraction|  K8vZ9171MW7|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdE|             Football|   KZazBEonSMnZfZ7vFE6|                 College|      2023-11-24|       onsale|           \"NaN\"|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Texas Longhorns F...|     \"NaN\"|Z7r9jZ1Adqwj7|https://www.ticke...|Darrell K Royal -...|  ZFr9jZe6Fa|        78712|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US| University of Texas|     -97.744202|       30.2843|University of Tex...|     attraction|  K8vZ9171MW7|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdE|             Football|   KZazBEonSMnZfZ7vFE6|                 College|      2023-11-04|       onsale|           \"NaN\"|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Texas Longhorns F...|     \"NaN\"|Z7r9jZ1Adjgpb|https://www.ticke...|Darrell K Royal -...|  ZFr9jZe6Fa|        78712|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US| University of Texas|     -97.744202|       30.2843|University of Tex...|     attraction|  K8vZ9171MW7|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdE|             Football|   KZazBEonSMnZfZ7vFE6|                 College|      2023-09-01|       onsale|           \"NaN\"|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Austin City Limit...|     \"NaN\"|G5dIZ99QiqeMv|https://on.fgtix....|         Zilker Park|KovZpZAEkItA|        78704|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US|2100 Barton Sprin...|    -97.7688358|    30.2456728|Austin City Limit...|     attraction|  K8vZ917KRmV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAe6|            Undefined|   KZazBEonSMnZfZ7v6JI|               Undefined|      2023-10-06|       onsale|           \"NaN\"|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|2023 F1 USGP - Si...|  standard|G5dIZ9bECfVdW|https://www.ticke...|Circuit of The Am...|KovZpZAJEF1A|        78617|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US|9201 Circuit of T...|   -97.63566001|   30.13526827|FORMULA 1 UNITED ...|     attraction|  K8vZ9172zW0|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vA7k|   Motorsports/Racing|   KZazBEonSMnZfZ7vFt7|      Motorsports/Racing|      2023-10-22|       onsale|        08:10:00|     USD|    280.0|    998.0|\n",
      "|Morgan Wallen: On...|  standard|G5dIZ9pLBP0HY|https://www.ticke...|    Moody Center ATX| KovZ917ANwG|        78712|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US|2001 Robert Dedma...|     -97.730837|     30.280735|       Morgan Wallen|     attraction|  K8vZ9174qlV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv6|              Country|   KZazBEonSMnZfZ7vAFa|                 Country|      2023-11-16|  rescheduled|        19:00:00|     USD|    79.75|    365.0|\n",
      "| blink-182 Tour 2023|  standard|G5dIZ9fKwWPE1|https://www.ticke...|    Moody Center ATX| KovZ917ANwG|        78712|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US|2001 Robert Dedma...|     -97.730837|     30.280735|           blink-182|     attraction|  K8vZ9171pNf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-07-07|       onsale|        19:30:00|     USD|     29.5|   264.75|\n",
      "|Luis Miguel Tour ...|  standard|G5dIZ9t3EwA3n|https://www.ticke...|    Moody Center ATX| KovZ917ANwG|        78712|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US|2001 Robert Dedma...|     -97.730837|     30.280735|         Luis Miguel|     attraction|  K8vZ9171ajV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeF|                World|   KZazBEonSMnZfZ7vFdJ|                   Latin|      2023-11-05|       onsale|        19:00:00|     USD|     65.0|    220.0|\n",
      "|Drake: It's All A...|  standard|G5dIZ9tCevsxW|https://www.ticke...|    Moody Center ATX| KovZ917ANwG|        78712|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US|2001 Robert Dedma...|     -97.730837|     30.280735|               Drake|     attraction|  K8vZ917Gp47|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkdA|                   Urban|      2023-09-11|       onsale|        19:00:00|     USD|     69.5|   484.75|\n",
      "|RBD - Soy Rebelde...|  standard|G5dIZ9N11Je9g|https://www.ticke...|    Moody Center ATX| KovZ917ANwG|        78712|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US|2001 Robert Dedma...|     -97.730837|     30.280735|                 RBD|     attraction|  K8vZ9175M80|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeF|                World|   KZazBEonSMnZfZ7vFdJ|                   Latin|      2023-10-01|       onsale|        20:00:00|     USD|     63.5|    754.0|\n",
      "|      Arctic Monkeys|  standard|G5dIZ9KwHc4-2|https://www.ticke...|    Moody Center ATX| KovZ917ANwG|        78712|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US|2001 Robert Dedma...|     -97.730837|     30.280735|      Arctic Monkeys|     attraction|  K8vZ9175wT0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6dt|        Alternative Rock|      2023-09-15|       onsale|        20:00:00|     USD|     39.5|    130.0|\n",
      "|            Paramore|  standard|G5dIZ9pCfOeCt|https://www.ticke...|    Moody Center ATX| KovZ917ANwG|        78712|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US|2001 Robert Dedma...|     -97.730837|     30.280735|            Paramore|     attraction|  K8vZ9175DY0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6dt|        Alternative Rock|      2023-07-09|       onsale|        19:00:00|     USD|     60.5|   191.25|\n",
      "|Peso Pluma - Dobl...|  standard|G5dIZ9nXkHwfv|https://www.ticke...|Germania Insuranc...|KovZpZAJEFJA|        78617|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US|9201 Circuit of t...|      -97.63801|      30.13538|          Peso Pluma|     attraction|  K8vZ917h54V|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAJ6|                Latin|   KZazBEonSMnZfZ7va1a|                   Latin|      2023-07-12|       onsale|        20:00:00|     USD|     39.5|    299.5|\n",
      "|           Pearl Jam|  standard|G5dIZ9IyCd1dr|https://www.ticke...|    Moody Center ATX| KovZ917ANwG|        78712|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US|2001 Robert Dedma...|     -97.730837|     30.280735|           Pearl Jam|     attraction|  K8vZ9171FdV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6dt|        Alternative Rock|      2023-09-18|       onsale|        19:30:00|     USD|    133.0|    133.0|\n",
      "| Dave Chappelle Live|  standard|G5dIZ9lJaix2s|https://www.ticke...|    Moody Center ATX| KovZ917ANwG|        78712|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US|2001 Robert Dedma...|     -97.730837|     30.280735|      Dave Chappelle|     attraction|  K8vZ9171rcf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-07-14|       onsale|        19:30:00|     USD|     89.5|    329.5|\n",
      "|           Pearl Jam|  standard|G5dIZ9t1M07_x|https://www.ticke...|    Moody Center ATX| KovZ917ANwG|        78712|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US|2001 Robert Dedma...|     -97.730837|     30.280735|           Pearl Jam|     attraction|  K8vZ9171FdV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6dt|        Alternative Rock|      2023-09-19|       onsale|        19:30:00|     USD|    133.0|    133.0|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "23/06/22 21:45:40 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@e347320 committed.\n",
      "23/06/22 21:45:40 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/127 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.127.4a0d8032-1a61-4e4a-9528-59ae9ef4eaad.tmp\n",
      "23/06/22 21:45:40 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.127.4a0d8032-1a61-4e4a-9528-59ae9ef4eaad.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/127\n",
      "23/06/22 21:45:40 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:45:40.001Z\",\n",
      "  \"batchId\" : 127,\n",
      "  \"numInputRows\" : 445,\n",
      "  \"inputRowsPerSecond\" : 44.52226113056528,\n",
      "  \"processedRowsPerSecond\" : 1196.236559139785,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 126,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 3,\n",
      "    \"queryPlanning\" : 35,\n",
      "    \"triggerExecution\" : 371,\n",
      "    \"walCommit\" : 97\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 3413\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 445,\n",
      "    \"inputRowsPerSecond\" : 44.52226113056528,\n",
      "    \"processedRowsPerSecond\" : 1196.236559139785\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 445\n",
      "  }\n",
      "}\n",
      "23/06/22 21:45:41 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.199.21364072-a906-4ed9-9a45-6f8b13138d83.tmp to gs://kafka-spark-data/spark-metadata/offsets/199\n",
      "23/06/22 21:45:41 INFO MicroBatchExecution: Committed offsets for batch 199. Metadata OffsetSeqMetadata(0,1687488340004,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:45:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:45:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:45:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:45:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:45:41 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:45:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:45:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:45:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:45:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:45:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:45:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:45:42 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:45:42 INFO DAGScheduler: Got job 261 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:45:42 INFO DAGScheduler: Final stage: ResultStage 262 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:45:42 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:45:42 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:45:42 INFO DAGScheduler: Submitting ResultStage 262 (MapPartitionsRDD[1360] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:45:42 INFO MemoryStore: Block broadcast_261 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/22 21:45:42 INFO BlockManagerInfo: Removed broadcast_260_piece0 on 192.168.4.24:51040 in memory (size: 9.9 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:45:42 INFO MemoryStore: Block broadcast_261_piece0 stored as bytes in memory (estimated size 94.8 KiB, free 434.0 MiB)\n",
      "23/06/22 21:45:42 INFO BlockManagerInfo: Added broadcast_261_piece0 in memory on 192.168.4.24:51040 (size: 94.8 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:45:42 INFO SparkContext: Created broadcast 261 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:45:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 262 (MapPartitionsRDD[1360] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:45:42 INFO TaskSchedulerImpl: Adding task set 262.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:45:42 INFO TaskSetManager: Starting task 0.0 in stage 262.0 (TID 261) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:45:42 INFO Executor: Running task 0.0 in stage 262.0 (TID 261)\n",
      "23/06/22 21:45:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:45:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:45:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:45:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:45:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:45:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:45:42 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:45:42 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:45:42 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/22 21:45:42 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/22 21:45:42 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/22 21:45:42 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/22 21:45:42 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/22 21:45:42 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 2968 for partition ticketmaster-0\n",
      "23/06/22 21:45:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:45:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:45:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:45:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 3596.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 262:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:45:43 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-9d485933-6a71-41a2-b6e9-0fc6bdc4e8fa/_temporary/0/_temporary/' directory.\n",
      "23/06/22 21:45:43 INFO FileOutputCommitter: Saved output of task 'attempt_20230622214542703586939479935313_0262_m_000000_261' to gs://kafka-spark-data/.spark-bigquery-local-1687482506437-9d485933-6a71-41a2-b6e9-0fc6bdc4e8fa/_temporary/0/task_20230622214542703586939479935313_0262_m_000000\n",
      "23/06/22 21:45:43 INFO SparkHadoopMapRedUtil: attempt_20230622214542703586939479935313_0262_m_000000_261: Committed. Elapsed time: 608 ms.\n",
      "23/06/22 21:45:43 INFO Executor: Finished task 0.0 in stage 262.0 (TID 261). 2579 bytes result sent to driver\n",
      "23/06/22 21:45:43 INFO TaskSetManager: Finished task 0.0 in stage 262.0 (TID 261) in 1126 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:45:43 INFO TaskSchedulerImpl: Removed TaskSet 262.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:45:43 INFO DAGScheduler: ResultStage 262 (start at NativeMethodAccessorImpl.java:0) finished in 1.168 s\n",
      "23/06/22 21:45:43 INFO DAGScheduler: Job 261 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:45:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 262: Stage finished\n",
      "23/06/22 21:45:43 INFO DAGScheduler: Job 261 finished: start at NativeMethodAccessorImpl.java:0, took 1.169262 s\n",
      "23/06/22 21:45:43 INFO FileFormatWriter: Start to commit write Job e360ea84-ad58-4f27-93b5-16566dcd3fb2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:45:44 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-9d485933-6a71-41a2-b6e9-0fc6bdc4e8fa/_temporary/0/task_20230622214542703586939479935313_0262_m_000000/' directory.\n",
      "23/06/22 21:45:44 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-9d485933-6a71-41a2-b6e9-0fc6bdc4e8fa/' directory.\n",
      "23/06/22 21:45:44 INFO FileFormatWriter: Write Job e360ea84-ad58-4f27-93b5-16566dcd3fb2 committed. Elapsed time: 1490 ms.\n",
      "23/06/22 21:45:44 INFO FileFormatWriter: Finished processing stats for write job e360ea84-ad58-4f27-93b5-16566dcd3fb2.\n",
      "23/06/22 21:45:45 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687482506437-9d485933-6a71-41a2-b6e9-0fc6bdc4e8fa/part-00000-db8eb9e6-6f1b-45ca-828c-54d3bcd4f407-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=c9982125-627b-4e83-bfe5-caff9134a3a3, location=US}\n",
      "23/06/22 21:45:47 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=c9982125-627b-4e83-bfe5-caff9134a3a3, location=US}\n",
      "23/06/22 21:45:47 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/199 using temp file gs://kafka-spark-data/spark-metadata/commits/.199.8dd1c489-b867-4161-bb51-e942a1fbad47.tmp\n",
      "23/06/22 21:45:48 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.199.8dd1c489-b867-4161-bb51-e942a1fbad47.tmp to gs://kafka-spark-data/spark-metadata/commits/199\n",
      "23/06/22 21:45:48 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:45:40.001Z\",\n",
      "  \"batchId\" : 199,\n",
      "  \"numInputRows\" : 445,\n",
      "  \"inputRowsPerSecond\" : 44.504450445044505,\n",
      "  \"processedRowsPerSecond\" : 52.17493258295228,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 5932,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 3,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 8529,\n",
      "    \"walCommit\" : 1523\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 2968\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 3413\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 445,\n",
      "    \"inputRowsPerSecond\" : 44.504450445044505,\n",
      "    \"processedRowsPerSecond\" : 52.17493258295228\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:45:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:45:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:45:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 3596.\n",
      "23/06/22 21:45:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 3596.\n",
      "23/06/22 21:45:50 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/128 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.128.21963a55-08db-4c3d-bbf3-412fd965d54a.tmp\n",
      "23/06/22 21:45:50 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.128.21963a55-08db-4c3d-bbf3-412fd965d54a.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/128\n",
      "23/06/22 21:45:50 INFO MicroBatchExecution: Committed offsets for batch 128. Metadata OffsetSeqMetadata(0,1687488350015,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:45:50 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:45:50 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:45:50 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:45:50 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:45:50 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:45:50 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:45:50 INFO WriteToDataSourceV2Exec: Start processing data source write support: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1d495b06. The input RDD has 1 partitions.\n",
      "23/06/22 21:45:50 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:45:50 INFO DAGScheduler: Got job 262 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:45:50 INFO DAGScheduler: Final stage: ResultStage 263 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:45:50 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:45:50 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:45:50 INFO DAGScheduler: Submitting ResultStage 263 (MapPartitionsRDD[1363] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:45:50 INFO MemoryStore: Block broadcast_262 stored as values in memory (estimated size 23.0 KiB, free 434.0 MiB)\n",
      "23/06/22 21:45:50 INFO MemoryStore: Block broadcast_262_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 434.0 MiB)\n",
      "23/06/22 21:45:50 INFO BlockManagerInfo: Added broadcast_262_piece0 in memory on 192.168.4.24:51040 (size: 9.9 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:45:50 INFO SparkContext: Created broadcast 262 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:45:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 263 (MapPartitionsRDD[1363] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:45:50 INFO TaskSchedulerImpl: Adding task set 263.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:45:50 INFO TaskSetManager: Starting task 0.0 in stage 263.0 (TID 262) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:45:50 INFO Executor: Running task 0.0 in stage 263.0 (TID 262)\n",
      "23/06/22 21:45:50 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 3429 for partition ticketmaster-0\n",
      "23/06/22 21:45:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:45:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:45:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:45:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 3596.\n",
      "23/06/22 21:45:50 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 3430 for partition ticketmaster-0\n",
      "23/06/22 21:45:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:45:50 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/200 using temp file gs://kafka-spark-data/spark-metadata/offsets/.200.a8b60ad3-cffe-43f3-bb41-c6fe5ede3f86.tmp\n",
      "23/06/22 21:45:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:45:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:45:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 3596.\n",
      "23/06/22 21:45:50 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 262, attempt 0, stage 263.0)\n",
      "23/06/22 21:45:50 INFO DataWritingSparkTask: Committed partition 0 (task 262, attempt 0, stage 263.0)\n",
      "23/06/22 21:45:50 INFO Executor: Finished task 0.0 in stage 263.0 (TID 262). 150398 bytes result sent to driver\n",
      "23/06/22 21:45:50 INFO TaskSetManager: Finished task 0.0 in stage 263.0 (TID 262) in 539 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:45:50 INFO TaskSchedulerImpl: Removed TaskSet 263.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:45:50 INFO DAGScheduler: ResultStage 263 (start at NativeMethodAccessorImpl.java:0) finished in 0.542 s\n",
      "23/06/22 21:45:50 INFO DAGScheduler: Job 262 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:45:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 263: Stage finished\n",
      "23/06/22 21:45:50 INFO DAGScheduler: Job 262 finished: start at NativeMethodAccessorImpl.java:0, took 0.543252 s\n",
      "23/06/22 21:45:50 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1d495b06 is committing.\n",
      "-------------------------------------------\n",
      "Batch: 128\n",
      "-------------------------------------------\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|          event_name|event_type|     event_id|           event_url|          venue_name|    venue_id|venue_zipcode|venues_timezone|venue_city|venue_state_full|venue_state_short|  venue_country_name|venue_country_short|       venue_address|venue_longitude|venue_latitude|     attraction_name|attraction_type|attraction_id|      attraction_url|attraction_segment_id|attraction_segment_name|attraction_genre_id|attraction_genre_name|attraction_subgenre_id|attraction_subgenre_name|event_start_date|ticket_status|event_start_time|currency|min_price|max_price|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|  The Book of Mormon|     \"NaN\"|Z7r9jZ1AdOU-6|https://www.ticke...|   Bass Concert Hall|  Z6r9jZek7e|        78712|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US|2350 Robert Dedma...|     -97.744202|       30.2843|The Book of Mormo...|     attraction|  K8vZ9172Sl7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-11-17|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|St. Paul and the ...|     \"NaN\"|Z7r9jZ1Adx7bY|https://www.ticke...|Paramount Theatre...|  ZFr9jZdFdF|        78701|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US|   713 Congress Ave.|     -97.742401|       30.2721|St. Paul and the ...|     attraction|  K8vZ917okm7|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAee|                  R&B|   KZazBEonSMnZfZ7vknE|                    Soul|      2023-11-04|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|         Death Grips|  standard|G5dIZ9t1OE3Hn|https://concerts....|        Emo's Austin|KovZpZAEAEeA|        78741|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US|2015 E Riverside Dr.|     -97.728048|     30.239574|         Death Grips|     attraction|  K8vZ9172tvf|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkdA|                   Urban|      2023-10-07|       onsale|        19:00:00|     USD|     39.5|     39.5|\n",
      "|  LSDREAM w/ Zingara|     \"NaN\"|Z7r9jZ1Ad0PF6|https://www.ticke...|The Concourse Pro...|  Z7r9jZa7Qf|        78719|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US|    8509 Burleson Rd|     -97.672501|       30.1003|             LSDREAM|     attraction|  K8vZ917b4y7|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvF|     Dance/Electronic|   KZazBEonSMnZfZ7vA1E|        Dance/Electronic|      2023-11-04|       onsale|        21:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|  The Book of Mormon|     \"NaN\"|Z7r9jZ1AdOze7|https://www.ticke...|   Bass Concert Hall|  Z6r9jZek7e|        78712|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US|2350 Robert Dedma...|     -97.744202|       30.2843|The Book of Mormo...|     attraction|  K8vZ9172Sl7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-11-18|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|          Jimmy Carr|     \"NaN\"|Z7r9jZ1Ad-ZpZ|https://www.ticke...|Paramount Theatre...|  ZFr9jZdFdF|        78701|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US|   713 Congress Ave.|     -97.742401|       30.2721|          Jimmy Carr|     attraction|  K8vZ9175lZV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-10-08|       onsale|        19:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|          Jimmy Carr|     \"NaN\"|Z7r9jZ1Ad-b0_|https://www.ticke...|Paramount Theatre...|  ZFr9jZdFdF|        78701|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US|   713 Congress Ave.|     -97.742401|       30.2721|          Jimmy Carr|     attraction|  K8vZ9175lZV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-10-08|       onsale|        21:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|  The Book of Mormon|     \"NaN\"|Z7r9jZ1AdOz7S|https://www.ticke...|   Bass Concert Hall|  Z6r9jZek7e|        78712|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US|2350 Robert Dedma...|     -97.744202|       30.2843|The Book of Mormo...|     attraction|  K8vZ9172Sl7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-11-19|       onsale|        18:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Tina Fey & Amy Po...|     \"NaN\"|G5dIZ9cdriAnt|https://texasperf...|   Bass Concert Hall|KovZpZAJJ7AA|        78701|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US|23rd Street & Rob...|     -97.730701|    30.2850972|Tina Fey & Amy Po...|     attraction|  K8vZ917hdm0|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-10-12|      offsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|            Tina Fey|     \"NaN\"|Z7r9jZ1Ad0YZ9|https://www.ticke...|   Bass Concert Hall|  Z6r9jZek7e|        78712|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US|2350 Robert Dedma...|     -97.744202|       30.2843|            Tina Fey|     attraction|  K8vZ917C1T0|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-10-12|      offsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Austin City Limit...|     \"NaN\"|G5dIZ99QiTxMP|https://on.fgtix....|         Zilker Park|KovZpZAEkItA|        78704|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US|2100 Barton Sprin...|    -97.7688358|    30.2456728|Austin City Limit...|     attraction|  K8vZ917KRmV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAe6|            Undefined|   KZazBEonSMnZfZ7v6JI|               Undefined|      2023-10-13|       onsale|           \"NaN\"|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Tina Fey & Amy Po...|     \"NaN\"|G5dIZ9chsek_J|https://texasperf...|   Bass Concert Hall|KovZpZAJJ7AA|        78701|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US|23rd Street & Rob...|     -97.730701|    30.2850972|Tina Fey & Amy Po...|     attraction|  K8vZ917hdm0|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-10-13|      offsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|            Tina Fey|     \"NaN\"|Z7r9jZ1Ad0VAs|https://www.ticke...|   Bass Concert Hall|  Z6r9jZek7e|        78712|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US|2350 Robert Dedma...|     -97.744202|       30.2843|            Tina Fey|     attraction|  K8vZ917C1T0|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-10-13|      offsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Trout Fishing in ...|     \"NaN\"|Z7r9jZ1AdxvFg|https://www.ticke...|           04 Center|  Z7r9jZadBZ|        78704|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US|2701 South Lamar ...|       -97.7658|     30.243299|Trout Fishing In ...|     attraction|  K8vZ9171fcV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-10-27|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|2023 F1 USGP - We...|     \"NaN\"|G5dIZ9E9gdAzO|https://am.ticket...|Circuit of The Am...|KovZpZAJEF1A|        78617|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US|9201 Circuit of T...|   -97.63566001|   30.13526827|FORMULA 1 UNITED ...|     attraction|  K8vZ9172zW0|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vA7k|   Motorsports/Racing|   KZazBEonSMnZfZ7vFt7|      Motorsports/Racing|      2023-10-20|       onsale|           \"NaN\"|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|2023 F1 USGP - We...|     \"NaN\"|G5dIZ9bwRieVD|https://thecircui...|Circuit of The Am...|KovZpZAJEF1A|        78617|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US|9201 Circuit of T...|   -97.63566001|   30.13526827|FORMULA 1 UNITED ...|     attraction|  K8vZ9172zW0|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vA7k|   Motorsports/Racing|   KZazBEonSMnZfZ7vFt7|      Motorsports/Racing|      2023-10-20|       onsale|           \"NaN\"|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|           Two Lanes|  standard|G5dIZ9iLa8Aif|https://www.ticke...|  Antone's Nightclub|KovZpZAtv1nA|        78701|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US|    305 E 5th Street|     -97.740401|      30.26605|           Two Lanes|     attraction|  K8vZ917_YU7|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvF|     Dance/Electronic|   KZazBEonSMnZfZ7vA1E|        Dance/Electronic|      2023-10-21|      offsale|        20:00:00|     USD|     15.0|     15.0|\n",
      "|The War and Treat...|  standard|G5dIZ9iNDx6ff|https://www.ticke...|  Antone's Nightclub|KovZpZAtv1nA|        78701|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US|    305 E 5th Street|     -97.740401|      30.26605|  The War and Treaty|     attraction|  K8vZ917phs0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAva|                 Folk|   KZazBEonSMnZfZ7vAna|               Americana|      2023-10-22|      offsale|        20:00:00|     USD|     26.0|     26.0|\n",
      "|6LACK - Since I H...|     \"NaN\"|G5dIZ9tJKKx0u|https://stubbs.fr...|Stubb's Waller Cr...| KovZ917AxzU|        78701|America/Chicago|   Austin |           Texas|               TX|United States Of ...|                 US|       801 Red River|     -97.736192|     30.268487|               6LACK|     attraction|  K8vZ9174IH0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkvl|             Hip-Hop/Rap|      2023-10-22|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|               6LACK|     \"NaN\"|Z7r9jZ1Ad-S37|https://www.ticke...|    Stubb's Barbeque|  ZFr9jZde1d|        78701|America/Chicago|    Austin|           Texas|               TX|United States Of ...|                 US|    801 Red River St|     -97.742401|       30.2721|               6LACK|     attraction|  K8vZ9174IH0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkvl|             Hip-Hop/Rap|      2023-10-22|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "23/06/22 21:45:50 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@1d495b06 committed.\n",
      "23/06/22 21:45:50 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/128 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.128.107b68a7-b819-4c25-aefc-0106ba84c0a1.tmp\n",
      "23/06/22 21:45:50 INFO BlockManagerInfo: Removed broadcast_262_piece0 on 192.168.4.24:51040 in memory (size: 9.9 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:45:50 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.128.107b68a7-b819-4c25-aefc-0106ba84c0a1.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/128\n",
      "23/06/22 21:45:50 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:45:50.004Z\",\n",
      "  \"batchId\" : 128,\n",
      "  \"numInputRows\" : 183,\n",
      "  \"inputRowsPerSecond\" : 18.29451164650605,\n",
      "  \"processedRowsPerSecond\" : 243.35106382978722,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 569,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 11,\n",
      "    \"queryPlanning\" : 5,\n",
      "    \"triggerExecution\" : 752,\n",
      "    \"walCommit\" : 76\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 3413\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 3596\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 183,\n",
      "    \"inputRowsPerSecond\" : 18.29451164650605,\n",
      "    \"processedRowsPerSecond\" : 243.35106382978722\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 183\n",
      "  }\n",
      "}\n",
      "23/06/22 21:45:51 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.200.a8b60ad3-cffe-43f3-bb41-c6fe5ede3f86.tmp to gs://kafka-spark-data/spark-metadata/offsets/200\n",
      "23/06/22 21:45:51 INFO MicroBatchExecution: Committed offsets for batch 200. Metadata OffsetSeqMetadata(0,1687488350015,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:45:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:45:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:45:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:45:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:45:51 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:45:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:45:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:45:51 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:45:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:45:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:45:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:45:52 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:45:52 INFO DAGScheduler: Got job 263 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:45:52 INFO DAGScheduler: Final stage: ResultStage 264 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:45:52 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:45:52 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:45:52 INFO DAGScheduler: Submitting ResultStage 264 (MapPartitionsRDD[1370] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:45:52 INFO MemoryStore: Block broadcast_263 stored as values in memory (estimated size 295.4 KiB, free 433.7 MiB)\n",
      "23/06/22 21:45:52 INFO MemoryStore: Block broadcast_263_piece0 stored as bytes in memory (estimated size 94.8 KiB, free 433.6 MiB)\n",
      "23/06/22 21:45:52 INFO BlockManagerInfo: Added broadcast_263_piece0 in memory on 192.168.4.24:51040 (size: 94.8 KiB, free: 434.2 MiB)\n",
      "23/06/22 21:45:52 INFO SparkContext: Created broadcast 263 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:45:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 264 (MapPartitionsRDD[1370] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:45:52 INFO TaskSchedulerImpl: Adding task set 264.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:45:52 INFO TaskSetManager: Starting task 0.0 in stage 264.0 (TID 263) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:45:52 INFO Executor: Running task 0.0 in stage 264.0 (TID 263)\n",
      "23/06/22 21:45:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:45:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:45:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:45:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:45:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:45:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:45:52 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:45:52 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:45:52 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/22 21:45:52 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/22 21:45:52 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/22 21:45:52 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/22 21:45:52 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/22 21:45:52 INFO BlockManagerInfo: Removed broadcast_261_piece0 on 192.168.4.24:51040 in memory (size: 94.8 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:45:52 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 3468 for partition ticketmaster-0\n",
      "23/06/22 21:45:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 264:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:45:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:45:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:45:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 3596.\n",
      "23/06/22 21:45:53 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-e2ae1f49-7b64-4f33-989e-3be8f2aa1a75/_temporary/0/_temporary/' directory.\n",
      "23/06/22 21:45:53 INFO FileOutputCommitter: Saved output of task 'attempt_202306222145529081300596962446217_0264_m_000000_263' to gs://kafka-spark-data/.spark-bigquery-local-1687482506437-e2ae1f49-7b64-4f33-989e-3be8f2aa1a75/_temporary/0/task_202306222145529081300596962446217_0264_m_000000\n",
      "23/06/22 21:45:53 INFO SparkHadoopMapRedUtil: attempt_202306222145529081300596962446217_0264_m_000000_263: Committed. Elapsed time: 622 ms.\n",
      "23/06/22 21:45:53 INFO Executor: Finished task 0.0 in stage 264.0 (TID 263). 2536 bytes result sent to driver\n",
      "23/06/22 21:45:53 INFO TaskSetManager: Finished task 0.0 in stage 264.0 (TID 263) in 1615 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:45:53 INFO TaskSchedulerImpl: Removed TaskSet 264.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:45:53 INFO DAGScheduler: ResultStage 264 (start at NativeMethodAccessorImpl.java:0) finished in 1.633 s\n",
      "23/06/22 21:45:53 INFO DAGScheduler: Job 263 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:45:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 264: Stage finished\n",
      "23/06/22 21:45:53 INFO DAGScheduler: Job 263 finished: start at NativeMethodAccessorImpl.java:0, took 1.633949 s\n",
      "23/06/22 21:45:53 INFO FileFormatWriter: Start to commit write Job 3adec513-8929-4338-bfb7-5590f3f76c0b.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:45:54 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-e2ae1f49-7b64-4f33-989e-3be8f2aa1a75/_temporary/0/task_202306222145529081300596962446217_0264_m_000000/' directory.\n",
      "23/06/22 21:45:54 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-e2ae1f49-7b64-4f33-989e-3be8f2aa1a75/' directory.\n",
      "23/06/22 21:45:55 INFO FileFormatWriter: Write Job 3adec513-8929-4338-bfb7-5590f3f76c0b committed. Elapsed time: 1493 ms.\n",
      "23/06/22 21:45:55 INFO FileFormatWriter: Finished processing stats for write job 3adec513-8929-4338-bfb7-5590f3f76c0b.\n",
      "23/06/22 21:45:55 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687482506437-e2ae1f49-7b64-4f33-989e-3be8f2aa1a75/part-00000-14642ba7-05db-44fa-920c-3b4705051da4-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=b329d66d-0bf4-4246-9dcb-4ee5154e29f7, location=US}\n",
      "23/06/22 21:45:57 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=b329d66d-0bf4-4246-9dcb-4ee5154e29f7, location=US}\n",
      "23/06/22 21:45:58 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/200 using temp file gs://kafka-spark-data/spark-metadata/commits/.200.e9956c19-f86c-460d-8379-927fa2ec90b4.tmp\n",
      "23/06/22 21:45:59 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.200.e9956c19-f86c-460d-8379-927fa2ec90b4.tmp to gs://kafka-spark-data/spark-metadata/commits/200\n",
      "23/06/22 21:45:59 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:45:50.004Z\",\n",
      "  \"batchId\" : 200,\n",
      "  \"numInputRows\" : 183,\n",
      "  \"inputRowsPerSecond\" : 18.29451164650605,\n",
      "  \"processedRowsPerSecond\" : 19.762419006479483,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6519,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 11,\n",
      "    \"queryPlanning\" : 9,\n",
      "    \"triggerExecution\" : 9260,\n",
      "    \"walCommit\" : 1602\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 3413\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 3596\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 183,\n",
      "    \"inputRowsPerSecond\" : 18.29451164650605,\n",
      "    \"processedRowsPerSecond\" : 19.762419006479483\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:46:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:46:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:46:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 3596.\n",
      "23/06/22 21:46:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 3596.\n",
      "23/06/22 21:46:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:46:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:46:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 3596.\n",
      "23/06/22 21:46:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 3596.\n",
      "23/06/22 21:46:10 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:46:10.002Z\",\n",
      "  \"batchId\" : 129,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 18,\n",
      "    \"triggerExecution\" : 20\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 3596\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 3596\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 0\n",
      "  }\n",
      "}\n",
      "23/06/22 21:46:10 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:46:10.002Z\",\n",
      "  \"batchId\" : 201,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 18,\n",
      "    \"triggerExecution\" : 20\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 3596\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 3596\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:46:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:46:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:46:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 3596.\n",
      "23/06/22 21:46:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 3596.\n",
      "23/06/22 21:46:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:46:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:46:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 3596.\n",
      "23/06/22 21:46:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 3596.\n",
      "23/06/22 21:46:30 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:46:30.005Z\",\n",
      "  \"batchId\" : 201,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 10,\n",
      "    \"triggerExecution\" : 11\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 3596\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 3596\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:46:30 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:46:30.005Z\",\n",
      "  \"batchId\" : 129,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 10,\n",
      "    \"triggerExecution\" : 11\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 3596\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 3596\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 0\n",
      "  }\n",
      "}\n",
      "23/06/22 21:46:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:46:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 3693.\n",
      "23/06/22 21:46:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:46:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 3693.\n",
      "23/06/22 21:46:40 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/129 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.129.f2666749-f1dc-4f15-a9de-74b14223a296.tmp\n",
      "23/06/22 21:46:40 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.129.f2666749-f1dc-4f15-a9de-74b14223a296.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/129\n",
      "23/06/22 21:46:40 INFO MicroBatchExecution: Committed offsets for batch 129. Metadata OffsetSeqMetadata(0,1687488400005,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:46:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:46:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:46:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:46:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:46:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:46:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:46:40 INFO WriteToDataSourceV2Exec: Start processing data source write support: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@33417e70. The input RDD has 1 partitions.\n",
      "23/06/22 21:46:40 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:46:40 INFO DAGScheduler: Got job 264 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:46:40 INFO DAGScheduler: Final stage: ResultStage 265 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:46:40 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:46:40 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:46:40 INFO DAGScheduler: Submitting ResultStage 265 (MapPartitionsRDD[1373] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:46:40 INFO MemoryStore: Block broadcast_264 stored as values in memory (estimated size 23.0 KiB, free 434.0 MiB)\n",
      "23/06/22 21:46:40 INFO MemoryStore: Block broadcast_264_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 434.0 MiB)\n",
      "23/06/22 21:46:40 INFO BlockManagerInfo: Added broadcast_264_piece0 in memory on 192.168.4.24:51040 (size: 9.9 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:46:40 INFO SparkContext: Created broadcast 264 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:46:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 265 (MapPartitionsRDD[1373] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:46:40 INFO TaskSchedulerImpl: Adding task set 265.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:46:40 INFO TaskSetManager: Starting task 0.0 in stage 265.0 (TID 264) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:46:40 INFO Executor: Running task 0.0 in stage 265.0 (TID 264)\n",
      "23/06/22 21:46:40 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 3596 for partition ticketmaster-0\n",
      "23/06/22 21:46:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:46:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:46:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:46:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 3710.\n",
      "23/06/22 21:46:40 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 264, attempt 0, stage 265.0)\n",
      "23/06/22 21:46:40 INFO DataWritingSparkTask: Committed partition 0 (task 264, attempt 0, stage 265.0)\n",
      "23/06/22 21:46:40 INFO Executor: Finished task 0.0 in stage 265.0 (TID 264). 88240 bytes result sent to driver\n",
      "23/06/22 21:46:40 INFO TaskSetManager: Finished task 0.0 in stage 265.0 (TID 264) in 51 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:46:40 INFO TaskSchedulerImpl: Removed TaskSet 265.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:46:40 INFO DAGScheduler: ResultStage 265 (start at NativeMethodAccessorImpl.java:0) finished in 0.057 s\n",
      "23/06/22 21:46:40 INFO DAGScheduler: Job 264 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:46:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 265: Stage finished\n",
      "23/06/22 21:46:40 INFO DAGScheduler: Job 264 finished: start at NativeMethodAccessorImpl.java:0, took 0.059660 s\n",
      "23/06/22 21:46:40 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@33417e70 is committing.\n",
      "-------------------------------------------\n",
      "Batch: 129\n",
      "-------------------------------------------\n",
      "+--------------------+----------+--------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|          event_name|event_type|      event_id|           event_url|          venue_name|    venue_id|venue_zipcode|venues_timezone|venue_city|venue_state_full|venue_state_short|  venue_country_name|venue_country_short|       venue_address|venue_longitude|venue_latitude|     attraction_name|attraction_type|attraction_id|      attraction_url|attraction_segment_id|attraction_segment_name|attraction_genre_id|attraction_genre_name|attraction_subgenre_id|attraction_subgenre_name|event_start_date|ticket_status|event_start_time|currency|min_price|max_price|\n",
      "+--------------------+----------+--------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|Shania Twain: Que...|  standard|vvG1YZ94E4EgM4|https://concerts....|  Dos Equis Pavilion|KovZpZAEAFeA|        75210|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|     3839 S Fitzhugh|   -96.75646586|   32.77507215|        Shania Twain|     attraction|  K8vZ91719n0|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv6|              Country|   KZazBEonSMnZfZ7vAFa|                 Country|      2023-07-21|       onsale|        19:30:00|     USD|    55.95|   265.95|\n",
      "|Red River Showdow...|     \"NaN\"| Z7r9jZ1AdOE0x|https://www.ticke...|         Cotton Bowl|  Z6r9jZAeve|        75210|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|1300 Robert B Cul...|     -96.745499|     32.771099|University of Tex...|     attraction|  K8vZ9171MW7|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdE|             Football|   KZazBEonSMnZfZ7vFE6|                 College|      2023-10-07|       onsale|           \"NaN\"|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Stanley Cup Final...|  standard|vvG1YZ9JXIF4Ki|https://www.ticke...|American Airlines...|KovZpZAJ67eA|        75219|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US| 2500 Victory Avenue|   -96.81081803|   32.79067196|        Dallas Stars|     attraction|  K8vZ9171ozV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdI|               Hockey|   KZazBEonSMnZfZ7vFEE|                     NHL|      2023-07-20|    cancelled|        20:00:00|     USD|    160.0|   1540.0|\n",
      "|Third Round: TBD ...|  standard|vvG1YZ9JXI6PK_|https://www.ticke...|American Airlines...|KovZpZAJ67eA|        75219|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US| 2500 Victory Avenue|   -96.81081803|   32.79067196|        Dallas Stars|     attraction|  K8vZ9171ozV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdI|               Hockey|   KZazBEonSMnZfZ7vFEE|                     NHL|      2023-07-02|    cancelled|        20:00:00|     USD|     92.0|   1540.0|\n",
      "|Stanley Cup Final...|  standard|vvG1YZ9JXIFgKY|https://www.ticke...|American Airlines...|KovZpZAJ67eA|        75219|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US| 2500 Victory Avenue|   -96.81081803|   32.79067196|        Dallas Stars|     attraction|  K8vZ9171ozV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdI|               Hockey|   KZazBEonSMnZfZ7vFEE|                     NHL|      2023-07-21|    cancelled|        20:00:00|     USD|    160.0|   1540.0|\n",
      "|Stanley Cup Final...|  standard|vvG1YZ9JXIagKM|https://www.ticke...|American Airlines...|KovZpZAJ67eA|        75219|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US| 2500 Victory Avenue|   -96.81081803|   32.79067196|        Dallas Stars|     attraction|  K8vZ9171ozV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdI|               Hockey|   KZazBEonSMnZfZ7vFEE|                     NHL|      2023-07-22|    cancelled|        20:00:00|     USD|    160.0|   1540.0|\n",
      "|Stanley Cup Final...|  standard|vvG1YZ9JXI1PKW|https://www.ticke...|American Airlines...|KovZpZAJ67eA|        75219|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US| 2500 Victory Avenue|   -96.81081803|   32.79067196|        Dallas Stars|     attraction|  K8vZ9171ozV|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdI|               Hockey|   KZazBEonSMnZfZ7vFEE|                     NHL|      2023-07-23|    cancelled|        20:00:00|     USD|    160.0|   1540.0|\n",
      "|Drake: It's All A...|  standard|vvG1YZ9JJpQoL3|https://www.ticke...|American Airlines...|KovZpZAJ67eA|        75219|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US| 2500 Victory Avenue|   -96.81081803|   32.79067196|               Drake|     attraction|  K8vZ917Gp47|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkdA|                   Urban|      2023-09-14|  rescheduled|        19:00:00|     USD|    144.5|    501.5|\n",
      "|Karol G: Mañana S...|  standard|vvG1YZ9tl_q75y|https://www.ticke...|         Cotton Bowl|KovZpZAdlEJA|        75226|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|3750 Midway Plaza...|   -96.75976624|   32.77946164|             Karol G|     attraction|  K8vZ917p3-V|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAJ6|                Latin|   KZazBEonSMnZfZ7va1a|                   Latin|      2023-09-02|       onsale|        19:00:00|     USD|     72.5|    432.5|\n",
      "|Fuerza Regida - O...|  standard|vvG1YZ9tZJRYR5|https://concerts....|  Dos Equis Pavilion|KovZpZAEAFeA|        75210|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|     3839 S Fitzhugh|   -96.75646586|   32.77507215|       Fuerza Regida|     attraction|  K8vZ9179vO0|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeF|                World|   KZazBEonSMnZfZ7vFdJ|                   Latin|      2023-07-07|       onsale|        20:00:00|     USD|     39.5|    419.5|\n",
      "| blink-182 Tour 2023|  standard|vvG1YZ9fQXQ3XS|https://www.ticke...|American Airlines...|KovZpZAJ67eA|        75219|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US| 2500 Victory Avenue|   -96.81081803|   32.79067196|           blink-182|     attraction|  K8vZ9171pNf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-07-05|       onsale|        19:30:00|     USD|     29.5|    249.5|\n",
      "|Drake: It's All A...|  standard|vvG1YZ9JJpY-Lt|https://www.ticke...|American Airlines...|KovZpZAJ67eA|        75219|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US| 2500 Victory Avenue|   -96.81081803|   32.79067196|               Drake|     attraction|  K8vZ917Gp47|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkdA|                   Urban|      2023-09-15|  rescheduled|        19:00:00|     USD|    144.5|    501.5|\n",
      "| Dave Chappelle Live|  standard|vvG1YZ9llk9N6s|https://www.ticke...|American Airlines...|KovZpZAJ67eA|        75219|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US| 2500 Victory Avenue|   -96.81081803|   32.79067196|      Dave Chappelle|     attraction|  K8vZ9171rcf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-06-29|       onsale|        19:30:00|     USD|     59.5|    299.5|\n",
      "|State Fair Classi...|  standard|vvG1YZ9t5-7SXg|https://www.ticke...|         Cotton Bowl|KovZpZAdlEJA|        75226|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|3750 Midway Plaza...|   -96.75976624|   32.77946164|Prairie View A&M ...|     attraction|  K8vZ9171gR7|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdE|             Football|   KZazBEonSMnZfZ7vFE6|                 College|      2023-09-30|      offsale|        18:00:00|     USD|     35.0|     35.0|\n",
      "|Post Malone: If Y...|  standard|vvG1YZ9nTf-dwP|https://concerts....|  Dos Equis Pavilion|KovZpZAEAFeA|        75210|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|     3839 S Fitzhugh|   -96.75646586|   32.77507215|         Post Malone|     attraction|  K8vZ917KjPf|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkdA|                   Urban|      2023-08-05|       onsale|        20:00:00|     USD|     59.5|    349.5|\n",
      "|Fall Out Boy - So...|  standard|vvG1YZ9NRVNJyt|https://concerts....|  Dos Equis Pavilion|KovZpZAEAFeA|        75210|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|     3839 S Fitzhugh|   -96.75646586|   32.77507215|        Fall Out Boy|     attraction|  K8vZ9175h30|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6dt|        Alternative Rock|      2023-06-28|       onsale|        18:30:00|     USD|     49.5|    169.5|\n",
      "|     Matchbox Twenty|  standard|vvG1YZpeEAIgFQ|https://concerts....|  Dos Equis Pavilion|KovZpZAEAFeA|        75210|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|     3839 S Fitzhugh|   -96.75646586|   32.77507215|     Matchbox Twenty|     attraction|  K8vZ91719p7|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-06-29|  rescheduled|        19:30:00|     USD|     40.5|    161.0|\n",
      "|Lil Baby - It's O...|  standard|vvG1YZ9ELuEN6d|https://www.ticke...|American Airlines...|KovZpZAJ67eA|        75219|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US| 2500 Victory Avenue|   -96.81081803|   32.79067196|            Lil Baby|     attraction|  K8vZ917pNq0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkvl|             Hip-Hop/Rap|      2023-07-29|       onsale|        19:00:00|     USD|     49.5|    279.5|\n",
      "|Jelly Roll: Backr...|  standard|vvG1YZ9Pk0re3V|https://concerts....|  Dos Equis Pavilion|KovZpZAEAFeA|        75210|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|     3839 S Fitzhugh|   -96.75646586|   32.77507215|          Jelly Roll|     attraction|  K8vZ9174y8V|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv6|              Country|   KZazBEonSMnZfZ7vAFa|                 Country|      2023-09-23|       onsale|        19:00:00|     USD|    50.75|   110.75|\n",
      "|MVP: Jake Paul v ...|  standard|vvG1YZ9npvi34a|https://www.ticke...|American Airlines...|KovZpZAJ67eA|        75219|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US| 2500 Victory Avenue|   -96.81081803|   32.79067196|               \"NaN\"|          \"NaN\"|        \"NaN\"|               \"NaN\"|                \"NaN\"|                  \"NaN\"|              \"NaN\"|                \"NaN\"|                 \"NaN\"|                   \"NaN\"|      2023-08-05|       onsale|        17:00:00|     USD|     61.5|   1006.5|\n",
      "+--------------------+----------+--------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "23/06/22 21:46:40 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@33417e70 committed.\n",
      "23/06/22 21:46:40 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/129 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.129.d40188f1-0bdc-4ccf-85dd-0d605066a7dd.tmp\n",
      "23/06/22 21:46:40 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/201 using temp file gs://kafka-spark-data/spark-metadata/offsets/.201.1bcc4fc8-f3a4-44cd-9a07-4523ba2c33ba.tmp\n",
      "23/06/22 21:46:40 INFO BlockManagerInfo: Removed broadcast_264_piece0 on 192.168.4.24:51040 in memory (size: 9.9 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:46:40 INFO BlockManagerInfo: Removed broadcast_263_piece0 on 192.168.4.24:51040 in memory (size: 94.8 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:46:40 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.129.d40188f1-0bdc-4ccf-85dd-0d605066a7dd.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/129\n",
      "23/06/22 21:46:40 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:46:40.002Z\",\n",
      "  \"batchId\" : 129,\n",
      "  \"numInputRows\" : 97,\n",
      "  \"inputRowsPerSecond\" : 9.70291087326198,\n",
      "  \"processedRowsPerSecond\" : 291.29129129129126,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 92,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 3,\n",
      "    \"queryPlanning\" : 15,\n",
      "    \"triggerExecution\" : 333,\n",
      "    \"walCommit\" : 117\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 3596\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 3693\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 97,\n",
      "    \"inputRowsPerSecond\" : 9.70291087326198,\n",
      "    \"processedRowsPerSecond\" : 291.29129129129126\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 97\n",
      "  }\n",
      "}\n",
      "23/06/22 21:46:41 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.201.1bcc4fc8-f3a4-44cd-9a07-4523ba2c33ba.tmp to gs://kafka-spark-data/spark-metadata/offsets/201\n",
      "23/06/22 21:46:41 INFO MicroBatchExecution: Committed offsets for batch 201. Metadata OffsetSeqMetadata(0,1687488400008,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:46:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:46:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:46:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:46:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:46:41 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:46:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:46:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:46:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:46:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:46:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:46:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:46:42 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:46:42 INFO DAGScheduler: Got job 265 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:46:42 INFO DAGScheduler: Final stage: ResultStage 266 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:46:42 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:46:42 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:46:42 INFO DAGScheduler: Submitting ResultStage 266 (MapPartitionsRDD[1380] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:46:42 INFO MemoryStore: Block broadcast_265 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/22 21:46:42 INFO MemoryStore: Block broadcast_265_piece0 stored as bytes in memory (estimated size 94.8 KiB, free 434.0 MiB)\n",
      "23/06/22 21:46:42 INFO BlockManagerInfo: Added broadcast_265_piece0 in memory on 192.168.4.24:51040 (size: 94.8 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:46:42 INFO SparkContext: Created broadcast 265 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:46:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 266 (MapPartitionsRDD[1380] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:46:42 INFO TaskSchedulerImpl: Adding task set 266.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:46:42 INFO TaskSetManager: Starting task 0.0 in stage 266.0 (TID 265) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:46:42 INFO Executor: Running task 0.0 in stage 266.0 (TID 265)\n",
      "23/06/22 21:46:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:46:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:46:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:46:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:46:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:46:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:46:42 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:46:42 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:46:42 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/22 21:46:42 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/22 21:46:42 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/22 21:46:42 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/22 21:46:42 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/22 21:46:42 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 3596 for partition ticketmaster-0\n",
      "23/06/22 21:46:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:46:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:46:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:46:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 3881.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 266:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:46:43 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-33882c02-0d4b-4a29-ad28-92b56b455130/_temporary/0/_temporary/' directory.\n",
      "23/06/22 21:46:43 INFO FileOutputCommitter: Saved output of task 'attempt_202306222146428944103055144102137_0266_m_000000_265' to gs://kafka-spark-data/.spark-bigquery-local-1687482506437-33882c02-0d4b-4a29-ad28-92b56b455130/_temporary/0/task_202306222146428944103055144102137_0266_m_000000\n",
      "23/06/22 21:46:43 INFO SparkHadoopMapRedUtil: attempt_202306222146428944103055144102137_0266_m_000000_265: Committed. Elapsed time: 582 ms.\n",
      "23/06/22 21:46:43 INFO Executor: Finished task 0.0 in stage 266.0 (TID 265). 2536 bytes result sent to driver\n",
      "23/06/22 21:46:43 INFO TaskSetManager: Finished task 0.0 in stage 266.0 (TID 265) in 1112 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:46:43 INFO TaskSchedulerImpl: Removed TaskSet 266.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:46:43 INFO DAGScheduler: ResultStage 266 (start at NativeMethodAccessorImpl.java:0) finished in 1.131 s\n",
      "23/06/22 21:46:43 INFO DAGScheduler: Job 265 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:46:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 266: Stage finished\n",
      "23/06/22 21:46:43 INFO DAGScheduler: Job 265 finished: start at NativeMethodAccessorImpl.java:0, took 1.131555 s\n",
      "23/06/22 21:46:43 INFO FileFormatWriter: Start to commit write Job dfe7f4ce-51d2-41ab-869a-b54e6a834135.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:46:43 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-33882c02-0d4b-4a29-ad28-92b56b455130/_temporary/0/task_202306222146428944103055144102137_0266_m_000000/' directory.\n",
      "23/06/22 21:46:44 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-33882c02-0d4b-4a29-ad28-92b56b455130/' directory.\n",
      "23/06/22 21:46:44 INFO FileFormatWriter: Write Job dfe7f4ce-51d2-41ab-869a-b54e6a834135 committed. Elapsed time: 1518 ms.\n",
      "23/06/22 21:46:44 INFO FileFormatWriter: Finished processing stats for write job dfe7f4ce-51d2-41ab-869a-b54e6a834135.\n",
      "23/06/22 21:46:45 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687482506437-33882c02-0d4b-4a29-ad28-92b56b455130/part-00000-ba7ceadc-9189-4e41-9c4a-e12d7fda2ed7-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=72e46557-e129-44a9-a957-97015938b64a, location=US}\n",
      "23/06/22 21:46:47 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=72e46557-e129-44a9-a957-97015938b64a, location=US}\n",
      "23/06/22 21:46:48 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/201 using temp file gs://kafka-spark-data/spark-metadata/commits/.201.bced63ab-ae75-4028-9989-853ae02835bb.tmp\n",
      "23/06/22 21:46:49 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.201.bced63ab-ae75-4028-9989-853ae02835bb.tmp to gs://kafka-spark-data/spark-metadata/commits/201\n",
      "23/06/22 21:46:49 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:46:40.005Z\",\n",
      "  \"batchId\" : 201,\n",
      "  \"numInputRows\" : 97,\n",
      "  \"inputRowsPerSecond\" : 9.7,\n",
      "  \"processedRowsPerSecond\" : 10.48082117774176,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6622,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 3,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 9255,\n",
      "    \"walCommit\" : 1521\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 3596\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 3693\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 97,\n",
      "    \"inputRowsPerSecond\" : 9.7,\n",
      "    \"processedRowsPerSecond\" : 10.48082117774176\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:46:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:46:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:46:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 4109.\n",
      "23/06/22 21:46:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4109.\n",
      "23/06/22 21:46:50 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/130 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.130.8f51810e-ec35-4583-af2e-ff9f30117af0.tmp\n",
      "23/06/22 21:46:50 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.130.8f51810e-ec35-4583-af2e-ff9f30117af0.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/130\n",
      "23/06/22 21:46:50 INFO MicroBatchExecution: Committed offsets for batch 130. Metadata OffsetSeqMetadata(0,1687488410015,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:46:50 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:46:50 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:46:50 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:46:50 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:46:50 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:46:50 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:46:50 INFO WriteToDataSourceV2Exec: Start processing data source write support: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@56835a71. The input RDD has 1 partitions.\n",
      "23/06/22 21:46:50 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:46:50 INFO DAGScheduler: Got job 266 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:46:50 INFO DAGScheduler: Final stage: ResultStage 267 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:46:50 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:46:50 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:46:50 INFO DAGScheduler: Submitting ResultStage 267 (MapPartitionsRDD[1383] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:46:50 INFO MemoryStore: Block broadcast_266 stored as values in memory (estimated size 23.0 KiB, free 434.0 MiB)\n",
      "23/06/22 21:46:50 INFO MemoryStore: Block broadcast_266_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 434.0 MiB)\n",
      "23/06/22 21:46:50 INFO BlockManagerInfo: Added broadcast_266_piece0 in memory on 192.168.4.24:51040 (size: 9.9 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:46:50 INFO SparkContext: Created broadcast 266 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:46:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 267 (MapPartitionsRDD[1383] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:46:50 INFO TaskSchedulerImpl: Adding task set 267.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:46:50 INFO TaskSetManager: Starting task 0.0 in stage 267.0 (TID 266) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:46:50 INFO Executor: Running task 0.0 in stage 267.0 (TID 266)\n",
      "23/06/22 21:46:50 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 3708 for partition ticketmaster-0\n",
      "23/06/22 21:46:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:46:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:46:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:46:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 4109.\n",
      "23/06/22 21:46:50 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 3709 for partition ticketmaster-0\n",
      "23/06/22 21:46:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:46:50 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/202 using temp file gs://kafka-spark-data/spark-metadata/offsets/.202.b8836a89-074f-47a1-bb98-38628d916256.tmp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:46:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:46:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:46:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 4109.\n",
      "23/06/22 21:46:50 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 266, attempt 0, stage 267.0)\n",
      "23/06/22 21:46:50 INFO DataWritingSparkTask: Committed partition 0 (task 266, attempt 0, stage 267.0)\n",
      "23/06/22 21:46:50 INFO Executor: Finished task 0.0 in stage 267.0 (TID 266). 352942 bytes result sent to driver\n",
      "23/06/22 21:46:50 INFO TaskSetManager: Finished task 0.0 in stage 267.0 (TID 266) in 572 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:46:50 INFO TaskSchedulerImpl: Removed TaskSet 267.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:46:50 INFO DAGScheduler: ResultStage 267 (start at NativeMethodAccessorImpl.java:0) finished in 0.573 s\n",
      "23/06/22 21:46:50 INFO DAGScheduler: Job 266 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:46:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 267: Stage finished\n",
      "23/06/22 21:46:50 INFO DAGScheduler: Job 266 finished: start at NativeMethodAccessorImpl.java:0, took 0.573378 s\n",
      "23/06/22 21:46:50 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@56835a71 is committing.\n",
      "-------------------------------------------\n",
      "Batch: 130\n",
      "-------------------------------------------\n",
      "23/06/22 21:46:50 INFO BlockManagerInfo: Removed broadcast_266_piece0 on 192.168.4.24:51040 in memory (size: 9.9 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:46:50 INFO BlockManagerInfo: Removed broadcast_265_piece0 on 192.168.4.24:51040 in memory (size: 94.8 KiB, free: 434.4 MiB)\n",
      "+--------------------+----------+--------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|          event_name|event_type|      event_id|           event_url|          venue_name|    venue_id|venue_zipcode|venues_timezone|venue_city|venue_state_full|venue_state_short|  venue_country_name|venue_country_short|       venue_address|venue_longitude|venue_latitude|     attraction_name|attraction_type|attraction_id|      attraction_url|attraction_segment_id|attraction_segment_name|attraction_genre_id|attraction_genre_name|attraction_subgenre_id|attraction_subgenre_name|event_start_date|ticket_status|event_start_time|currency|min_price|max_price|\n",
      "+--------------------+----------+--------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|Gov't Mule's Dark...|  standard|vvG1YZ9JGaipK8|https://concerts....|  Dos Equis Pavilion|KovZpZAEAFeA|        75210|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|     3839 S Fitzhugh|   -96.75646586|   32.77507215|          Gov't Mule|     attraction|  K8vZ9175Sn0|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-08-09|       onsale|        19:00:00|     USD|     25.0|     89.5|\n",
      "|Jurassic World Li...|  standard|vvG1YZ9InKyoha|https://www.ticke...|American Airlines...|KovZpZAJ67eA|        75219|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US| 2500 Victory Avenue|   -96.81081803|   32.79067196|Jurassic World Li...|     attraction|  K8vZ9179ScV|https://www.ticke...|   KZFzniwnSyZfZ7v7n1|          Miscellaneous|        KnvZfZ7vA1n|               Family|   KZazBEonSMnZfZ7vaav|                   Other|      2023-08-12|       onsale|        11:00:00|     USD|     20.0|    100.0|\n",
      "|Thundercat - In Y...|  standard|vvG1YZ9t0_5UCl|https://www.ticke...| South Side Ballroom|KovZpZAEAFdA|        75215|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|1135 Botham Jean ...|   -96.79808128|   32.76931197|          Thundercat|     attraction|  K8vZ917CBTV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAee|                  R&B|   KZazBEonSMnZfZ7vkIt|                     R&B|      2023-10-27|       onsale|        20:00:00|     USD|     35.0|    79.95|\n",
      "|Boywithuke with s...|  standard|vvG1YZ9tOCJ0gQ|https://concerts....|House of Blues Da...|KovZpZAEAF7A|        75202|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|     2200 N Lamar St|   -96.80851279|   32.78521325|          BoyWithUke|     attraction|  K8vZ917_TEV|https://www.liven...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAev|                  Pop|   KZazBEonSMnZfZ7vk1t|                     Pop|      2023-09-07|       onsale|        19:00:00|     USD|     20.0|     20.0|\n",
      "|The Book of Mormo...|  standard|vvG1YZ9NKfZ0si|https://www.ticke...|Music Hall At Fai...|KovZpZAFFvnA|        75210|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|         909 1st Ave|   -96.76590197|   32.78037016|The Book of Mormo...|     attraction|  K8vZ9172Sl7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-08-05|       onsale|        13:30:00|     USD|     30.0|    155.0|\n",
      "|An Evening With K...|  standard|vvG1YZ9tEjVVQ4|https://www.ticke...|Majestic Theatre ...|KovZpZAFl6vA|        75201|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|     1925 Elm Street|   -96.79557625|   32.78232551|     Kevin Von Erich|     attraction|  K8vZ917h9u7|https://www.ticke...|   KZFzniwnSyZfZ7v7n1|          Miscellaneous|        KnvZfZ7vAJe|      Lecture/Seminar|   KZazBEonSMnZfZ7vaat|         Lecture/Seminar|      2023-09-01|       onsale|        19:30:00|     USD|     17.0|     97.0|\n",
      "|Wilco: Tour To In...|  standard|vvG1YZ9nmYBdOW|https://www.ticke...| South Side Ballroom|KovZpZAEAFdA|        75215|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|1135 Botham Jean ...|   -96.79808128|   32.76931197|               Wilco|     attraction|  K8vZ9171Qw7|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-09-28|       onsale|        19:30:00|     USD|    59.95|   129.95|\n",
      "|The Book of Mormo...|  standard|vvG1YZ9NKfvfwv|https://www.ticke...|Music Hall At Fai...|KovZpZAFFvnA|        75210|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|         909 1st Ave|   -96.76590197|   32.78037016|The Book of Mormo...|     attraction|  K8vZ9172Sl7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-08-05|       onsale|        19:30:00|     USD|     30.0|    155.0|\n",
      "|       Mughal-e-Azam|  standard|vvG1YZ9E990SJS|https://www.ticke...|Music Hall At Fai...|KovZpZAFFvnA|        75210|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|         909 1st Ave|   -96.76590197|   32.78037016|       Mughal-e-Azam|     attraction|  K8vZ917hp1V|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-07-21|       onsale|        19:00:00|     USD|     69.0|    399.0|\n",
      "|The Book of Mormo...|  standard|vvG1YZ9NKKWVsf|https://www.ticke...|Music Hall At Fai...|KovZpZAFFvnA|        75210|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|         909 1st Ave|   -96.76590197|   32.78037016|The Book of Mormo...|     attraction|  K8vZ9172Sl7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-08-01|       onsale|        19:30:00|     USD|     30.0|    155.0|\n",
      "|Rema - RAVE & ROS...|  standard|vvG1YZ9t3XIVbC|https://www.ticke...| South Side Ballroom|KovZpZAEAFdA|        75215|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|1135 Botham Jean ...|   -96.79808128|   32.76931197|                Rema|     attraction|  K8vZ917Q6K0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAev|                  Pop|   KZazBEonSMnZfZ7vkJv|             African Pop|      2023-07-29|       onsale|        20:00:00|     USD|     41.0|     66.0|\n",
      "|Mark Normand: Ya ...|  standard|vvG1YZ9n2r0PnS|https://www.ticke...|Majestic Theatre ...|KovZpZAFl6vA|        75201|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|     1925 Elm Street|   -96.79557625|   32.78232551|        Mark Normand|     attraction|  K8vZ9178hUf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-10-14|       onsale|        19:00:00|     USD|     32.5|    57.25|\n",
      "|Ms. Pat: Ya Girl ...|  standard|vvG1YZ9JQqxvEx|https://www.ticke...|Majestic Theatre ...|KovZpZAFl6vA|        75201|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|     1925 Elm Street|   -96.79557625|   32.78232551|             Ms. Pat|     attraction|  K8vZ9173rGV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-11-04|       onsale|        19:00:00|     USD|     27.5|     37.5|\n",
      "|The Bald Brothers...|  standard|vvG1YZ9IHGe0Li|https://www.ticke...|Majestic Theatre ...|KovZpZAFl6vA|        75201|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|     1925 Elm Street|   -96.79557625|   32.78232551|Tony Baker & KevO...|     attraction|  K8vZ917hf3f|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-09-03|       onsale|        19:30:00|     USD|    39.75|     75.5|\n",
      "|The Book of Mormo...|  standard|vvG1YZ9NKKTVsE|https://www.ticke...|Music Hall At Fai...|KovZpZAFFvnA|        75210|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|         909 1st Ave|   -96.76590197|   32.78037016|The Book of Mormo...|     attraction|  K8vZ9172Sl7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-08-04|       onsale|        19:30:00|     USD|     30.0|    155.0|\n",
      "|Jurassic World Li...|  standard|vvG1YZ9InKzsh6|https://www.ticke...|American Airlines...|KovZpZAJ67eA|        75219|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US| 2500 Victory Avenue|   -96.81081803|   32.79067196|Jurassic World Li...|     attraction|  K8vZ9179ScV|https://www.ticke...|   KZFzniwnSyZfZ7v7n1|          Miscellaneous|        KnvZfZ7vA1n|               Family|   KZazBEonSMnZfZ7vaav|                   Other|      2023-08-11|       onsale|        19:00:00|     USD|     20.0|    100.0|\n",
      "|Jim Jefferies: Gi...|  standard|vvG1YZ9Eeoosso|https://www.ticke...|Majestic Theatre ...|KovZpZAFl6vA|        75201|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|     1925 Elm Street|   -96.79557625|   32.78232551|       Jim Jefferies|     attraction|  K8vZ917G1Cf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-11-17|       onsale|        19:00:00|     USD|    47.25|    87.25|\n",
      "|The Book of Mormo...|  standard|vvG1YZ9NKfefwk|https://www.ticke...|Music Hall At Fai...|KovZpZAFFvnA|        75210|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|         909 1st Ave|   -96.76590197|   32.78037016|The Book of Mormo...|     attraction|  K8vZ9172Sl7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-08-06|       onsale|        13:30:00|     USD|     30.0|    155.0|\n",
      "|Stevie, The Music...|  standard|vvG1YZ9i5IiMZB|https://www.ticke...|      Bruton Theatre|KovZpZAE7d6A|        75201|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|      1309 Canton St|    -96.8019332|    32.7812614|The Black Academy...|     attraction|  K8vZ917Cg7V|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7ld| Miscellaneous The...|   KZazBEonSMnZfZ7v7lk|    Miscellaneous The...|      2023-06-23|       onsale|        20:00:00|     USD|      5.0|      5.0|\n",
      "|The Book of Mormo...|  standard|vvG1YZ9NKKX0s_|https://www.ticke...|Music Hall At Fai...|KovZpZAFFvnA|        75210|America/Chicago|    Dallas|           Texas|               TX|United States Of ...|                 US|         909 1st Ave|   -96.76590197|   32.78037016|The Book of Mormo...|     attraction|  K8vZ9172Sl7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-08-02|       onsale|        19:30:00|     USD|     30.0|    155.0|\n",
      "+--------------------+----------+--------------+--------------------+--------------------+------------+-------------+---------------+----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "23/06/22 21:46:50 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@56835a71 committed.\n",
      "23/06/22 21:46:50 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/130 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.130.9af0a5ed-3e25-4f8b-ad1a-4518bb94bf2f.tmp\n",
      "23/06/22 21:46:50 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.130.9af0a5ed-3e25-4f8b-ad1a-4518bb94bf2f.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/130\n",
      "23/06/22 21:46:50 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:46:50.006Z\",\n",
      "  \"batchId\" : 130,\n",
      "  \"numInputRows\" : 416,\n",
      "  \"inputRowsPerSecond\" : 41.583366653338665,\n",
      "  \"processedRowsPerSecond\" : 544.5026178010471,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 597,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 9,\n",
      "    \"queryPlanning\" : 4,\n",
      "    \"triggerExecution\" : 764,\n",
      "    \"walCommit\" : 79\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 3693\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4109\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 416,\n",
      "    \"inputRowsPerSecond\" : 41.583366653338665,\n",
      "    \"processedRowsPerSecond\" : 544.5026178010471\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 416\n",
      "  }\n",
      "}\n",
      "23/06/22 21:46:51 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.202.b8836a89-074f-47a1-bb98-38628d916256.tmp to gs://kafka-spark-data/spark-metadata/offsets/202\n",
      "23/06/22 21:46:51 INFO MicroBatchExecution: Committed offsets for batch 202. Metadata OffsetSeqMetadata(0,1687488410015,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:46:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:46:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:46:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:46:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:46:51 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:46:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:46:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:46:51 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:46:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:46:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:46:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:46:52 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:46:52 INFO DAGScheduler: Got job 267 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:46:52 INFO DAGScheduler: Final stage: ResultStage 268 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:46:52 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:46:52 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:46:52 INFO DAGScheduler: Submitting ResultStage 268 (MapPartitionsRDD[1390] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:46:52 INFO MemoryStore: Block broadcast_267 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/22 21:46:52 INFO MemoryStore: Block broadcast_267_piece0 stored as bytes in memory (estimated size 94.8 KiB, free 434.0 MiB)\n",
      "23/06/22 21:46:52 INFO BlockManagerInfo: Added broadcast_267_piece0 in memory on 192.168.4.24:51040 (size: 94.8 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:46:52 INFO SparkContext: Created broadcast 267 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:46:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 268 (MapPartitionsRDD[1390] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:46:52 INFO TaskSchedulerImpl: Adding task set 268.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:46:52 INFO TaskSetManager: Starting task 0.0 in stage 268.0 (TID 267) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:46:52 INFO Executor: Running task 0.0 in stage 268.0 (TID 267)\n",
      "23/06/22 21:46:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:46:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:46:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:46:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:46:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:46:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:46:52 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:46:52 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:46:52 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/22 21:46:52 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/22 21:46:52 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/22 21:46:52 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/22 21:46:52 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/22 21:46:52 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 3880 for partition ticketmaster-0\n",
      "23/06/22 21:46:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:46:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:46:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:46:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4109.\n",
      "23/06/22 21:46:52 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 3881 for partition ticketmaster-0\n",
      "23/06/22 21:46:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 268:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:46:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:46:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:46:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4109.\n",
      "23/06/22 21:46:53 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-d70e64af-9a57-4fa2-9f73-576e33f0912d/_temporary/0/_temporary/' directory.\n",
      "23/06/22 21:46:53 INFO FileOutputCommitter: Saved output of task 'attempt_20230622214651487763760138690469_0268_m_000000_267' to gs://kafka-spark-data/.spark-bigquery-local-1687482506437-d70e64af-9a57-4fa2-9f73-576e33f0912d/_temporary/0/task_20230622214651487763760138690469_0268_m_000000\n",
      "23/06/22 21:46:53 INFO SparkHadoopMapRedUtil: attempt_20230622214651487763760138690469_0268_m_000000_267: Committed. Elapsed time: 592 ms.\n",
      "23/06/22 21:46:53 INFO Executor: Finished task 0.0 in stage 268.0 (TID 267). 2579 bytes result sent to driver\n",
      "23/06/22 21:46:53 INFO TaskSetManager: Finished task 0.0 in stage 268.0 (TID 267) in 1637 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:46:53 INFO TaskSchedulerImpl: Removed TaskSet 268.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:46:53 INFO DAGScheduler: ResultStage 268 (start at NativeMethodAccessorImpl.java:0) finished in 1.663 s\n",
      "23/06/22 21:46:53 INFO DAGScheduler: Job 267 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:46:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 268: Stage finished\n",
      "23/06/22 21:46:53 INFO DAGScheduler: Job 267 finished: start at NativeMethodAccessorImpl.java:0, took 1.664324 s\n",
      "23/06/22 21:46:53 INFO FileFormatWriter: Start to commit write Job bbc7cf89-e2da-4ff7-8243-a94abda66880.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:46:54 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-d70e64af-9a57-4fa2-9f73-576e33f0912d/_temporary/0/task_20230622214651487763760138690469_0268_m_000000/' directory.\n",
      "23/06/22 21:46:54 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-d70e64af-9a57-4fa2-9f73-576e33f0912d/' directory.\n",
      "23/06/22 21:46:54 INFO BlockManagerInfo: Removed broadcast_267_piece0 on 192.168.4.24:51040 in memory (size: 94.8 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:46:55 INFO FileFormatWriter: Write Job bbc7cf89-e2da-4ff7-8243-a94abda66880 committed. Elapsed time: 1430 ms.\n",
      "23/06/22 21:46:55 INFO FileFormatWriter: Finished processing stats for write job bbc7cf89-e2da-4ff7-8243-a94abda66880.\n",
      "23/06/22 21:46:55 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687482506437-d70e64af-9a57-4fa2-9f73-576e33f0912d/part-00000-1260b094-8add-4643-8651-faf5cf65cc24-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=e2707f62-dccf-4d59-a604-29de6c5aefc8, location=US}\n",
      "23/06/22 21:46:58 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=e2707f62-dccf-4d59-a604-29de6c5aefc8, location=US}\n",
      "23/06/22 21:46:59 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/202 using temp file gs://kafka-spark-data/spark-metadata/commits/.202.777e671d-d5e2-4ffd-a85b-7c0fbf53ea65.tmp\n",
      "23/06/22 21:47:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:47:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 4109.\n",
      "23/06/22 21:47:00 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.202.777e671d-d5e2-4ffd-a85b-7c0fbf53ea65.tmp to gs://kafka-spark-data/spark-metadata/commits/202\n",
      "23/06/22 21:47:00 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:46:50.003Z\",\n",
      "  \"batchId\" : 202,\n",
      "  \"numInputRows\" : 416,\n",
      "  \"inputRowsPerSecond\" : 41.60832166433287,\n",
      "  \"processedRowsPerSecond\" : 39.31947069943289,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7789,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 11,\n",
      "    \"queryPlanning\" : 9,\n",
      "    \"triggerExecution\" : 10580,\n",
      "    \"walCommit\" : 1454\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 3693\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4109\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 416,\n",
      "    \"inputRowsPerSecond\" : 41.60832166433287,\n",
      "    \"processedRowsPerSecond\" : 39.31947069943289\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:47:00 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 10587 milliseconds\n",
      "23/06/22 21:47:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:47:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4109.\n",
      "23/06/22 21:47:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:47:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:47:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 4109.\n",
      "23/06/22 21:47:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4109.\n",
      "23/06/22 21:47:10 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:47:10.004Z\",\n",
      "  \"batchId\" : 131,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 11,\n",
      "    \"triggerExecution\" : 13\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4109\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4109\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 0\n",
      "  }\n",
      "}\n",
      "23/06/22 21:47:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:47:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:47:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 4461.\n",
      "23/06/22 21:47:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4461.\n",
      "23/06/22 21:47:20 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/131 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.131.d41a9ee4-e623-4212-949a-3f6389ef08c7.tmp\n",
      "23/06/22 21:47:20 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.131.d41a9ee4-e623-4212-949a-3f6389ef08c7.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/131\n",
      "23/06/22 21:47:20 INFO MicroBatchExecution: Committed offsets for batch 131. Metadata OffsetSeqMetadata(0,1687488440008,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:47:20 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:47:20 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:47:20 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:47:20 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:47:20 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:47:20 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:47:20 INFO WriteToDataSourceV2Exec: Start processing data source write support: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@74d13fa3. The input RDD has 1 partitions.\n",
      "23/06/22 21:47:20 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:47:20 INFO DAGScheduler: Got job 268 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:47:20 INFO DAGScheduler: Final stage: ResultStage 269 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:47:20 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:47:20 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:47:20 INFO DAGScheduler: Submitting ResultStage 269 (MapPartitionsRDD[1393] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:47:20 INFO MemoryStore: Block broadcast_268 stored as values in memory (estimated size 23.0 KiB, free 434.4 MiB)\n",
      "23/06/22 21:47:20 INFO MemoryStore: Block broadcast_268_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 434.4 MiB)\n",
      "23/06/22 21:47:20 INFO BlockManagerInfo: Added broadcast_268_piece0 in memory on 192.168.4.24:51040 (size: 9.9 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:47:20 INFO SparkContext: Created broadcast 268 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:47:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 269 (MapPartitionsRDD[1393] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:47:20 INFO TaskSchedulerImpl: Adding task set 269.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:47:20 INFO TaskSetManager: Starting task 0.0 in stage 269.0 (TID 268) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:47:20 INFO Executor: Running task 0.0 in stage 269.0 (TID 268)\n",
      "23/06/22 21:47:20 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 4109 for partition ticketmaster-0\n",
      "23/06/22 21:47:20 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/203 using temp file gs://kafka-spark-data/spark-metadata/offsets/.203.eb8bc7b5-83e8-43e6-9911-fa7300748a83.tmp\n",
      "23/06/22 21:47:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:47:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:47:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:47:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 4483.\n",
      "23/06/22 21:47:20 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 268, attempt 0, stage 269.0)\n",
      "23/06/22 21:47:20 INFO DataWritingSparkTask: Committed partition 0 (task 268, attempt 0, stage 269.0)\n",
      "23/06/22 21:47:20 INFO Executor: Finished task 0.0 in stage 269.0 (TID 268). 307959 bytes result sent to driver\n",
      "23/06/22 21:47:20 INFO TaskSetManager: Finished task 0.0 in stage 269.0 (TID 268) in 78 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:47:20 INFO TaskSchedulerImpl: Removed TaskSet 269.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:47:20 INFO DAGScheduler: ResultStage 269 (start at NativeMethodAccessorImpl.java:0) finished in 0.085 s\n",
      "23/06/22 21:47:20 INFO DAGScheduler: Job 268 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:47:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 269: Stage finished\n",
      "23/06/22 21:47:20 INFO DAGScheduler: Job 268 finished: start at NativeMethodAccessorImpl.java:0, took 0.087602 s\n",
      "23/06/22 21:47:20 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@74d13fa3 is committing.\n",
      "-------------------------------------------\n",
      "Batch: 131\n",
      "-------------------------------------------\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+-----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|          event_name|event_type|     event_id|           event_url|          venue_name|    venue_id|venue_zipcode|venues_timezone| venue_city|venue_state_full|venue_state_short|  venue_country_name|venue_country_short|       venue_address|venue_longitude|venue_latitude|   attraction_name|attraction_type|attraction_id|      attraction_url|attraction_segment_id|attraction_segment_name|attraction_genre_id|attraction_genre_name|attraction_subgenre_id|attraction_subgenre_name|event_start_date|ticket_status|event_start_time|currency|min_price|max_price|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+-----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|P!NK: Summer Carn...|  standard|G5dIZ9prByxD1|https://www.ticke...|           Alamodome|KovZpZAEkIEA|        78203|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|      100 Montana St|    -98.4791514|   29.41705466|              P!NK|     attraction|  K8vZ9171Jo7|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-09-25|       onsale|        18:30:00|     USD|    39.95|   299.95|\n",
      "|Shania Twain: Que...|  standard|G5dIZ9bpISx4C|https://www.ticke...|         AT&T Center|KovZpZAJJEdA|        78219|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|       1 AT&T Center|    -98.4337987|    29.4330386|      Shania Twain|     attraction|  K8vZ91719n0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv6|              Country|   KZazBEonSMnZfZ7vAFa|                 Country|      2023-10-12|       onsale|        19:30:00|     USD|    40.95|   225.95|\n",
      "|  Hamilton (Touring)|  standard|G5dIZpcrllN1v|https://www.ticke...|Majestic Theatre ...|KovZpZA77alA|        78205|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|226 East Houston ...|    -98.4903863|    29.4264514|Hamilton (Touring)|     attraction|  K8vZ9174wRf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-06-24|  rescheduled|        14:00:00|     USD|     49.0|    229.0|\n",
      "|  Hamilton (Touring)|  standard|G5dIZpcrlONaA|https://www.ticke...|Majestic Theatre ...|KovZpZA77alA|        78205|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|226 East Houston ...|    -98.4903863|    29.4264514|Hamilton (Touring)|     attraction|  K8vZ9174wRf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-06-22|  rescheduled|        19:30:00|     USD|     49.0|    199.0|\n",
      "|  Hamilton (Touring)|  standard|G5dIZpcrlmK1m|https://www.ticke...|Majestic Theatre ...|KovZpZA77alA|        78205|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|226 East Houston ...|    -98.4903863|    29.4264514|Hamilton (Touring)|     attraction|  K8vZ9174wRf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-06-23|  rescheduled|        20:00:00|     USD|     49.0|    199.0|\n",
      "|  Hamilton (Touring)|  standard|G5dIZpcrliK1k|https://www.ticke...|Majestic Theatre ...|KovZpZA77alA|        78205|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|226 East Houston ...|    -98.4903863|    29.4264514|Hamilton (Touring)|     attraction|  K8vZ9174wRf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-06-25|  rescheduled|        14:00:00|     USD|     49.0|    229.0|\n",
      "|  Hamilton (Touring)|  standard|G5dIZpcrlmS1s|https://www.ticke...|Majestic Theatre ...|KovZpZA77alA|        78205|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|226 East Houston ...|    -98.4903863|    29.4264514|Hamilton (Touring)|     attraction|  K8vZ9174wRf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-06-24|  rescheduled|        20:00:00|     USD|     49.0|    229.0|\n",
      "|  Hamilton (Touring)|  standard|G5dIZpcrlNNaY|https://www.ticke...|Majestic Theatre ...|KovZpZA77alA|        78205|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|226 East Houston ...|    -98.4903863|    29.4264514|Hamilton (Touring)|     attraction|  K8vZ9174wRf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-07-02|  rescheduled|        14:00:00|     USD|     49.0|    229.0|\n",
      "|  Hamilton (Touring)|  standard|G5dIZpcrlxKaN|https://www.ticke...|Majestic Theatre ...|KovZpZA77alA|        78205|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|226 East Houston ...|    -98.4903863|    29.4264514|Hamilton (Touring)|     attraction|  K8vZ9174wRf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-07-01|  rescheduled|        14:00:00|     USD|     49.0|    229.0|\n",
      "|  Hamilton (Touring)|  standard|G5dIZ9uQzpJQP|https://www.ticke...|Majestic Theatre ...|KovZpZA77alA|        78205|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|226 East Houston ...|    -98.4903863|    29.4264514|Hamilton (Touring)|     attraction|  K8vZ9174wRf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-06-27|       onsale|        19:30:00|     USD|     49.0|    199.0|\n",
      "|  Hamilton (Touring)|  standard|G5dIZpcrl-da4|https://www.ticke...|Majestic Theatre ...|KovZpZA77alA|        78205|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|226 East Houston ...|    -98.4903863|    29.4264514|Hamilton (Touring)|     attraction|  K8vZ9174wRf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-06-30|  rescheduled|        20:00:00|     USD|     49.0|    199.0|\n",
      "|  Hamilton (Touring)|  standard|G5dIZpcrlNdaP|https://www.ticke...|Majestic Theatre ...|KovZpZA77alA|        78205|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|226 East Houston ...|    -98.4903863|    29.4264514|Hamilton (Touring)|     attraction|  K8vZ9174wRf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-07-02|  rescheduled|        20:00:00|     USD|     49.0|    199.0|\n",
      "|  Hamilton (Touring)|  standard|G5dIZpcrl-Naq|https://www.ticke...|Majestic Theatre ...|KovZpZA77alA|        78205|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|226 East Houston ...|    -98.4903863|    29.4264514|Hamilton (Touring)|     attraction|  K8vZ9174wRf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-07-01|  rescheduled|        20:00:00|     USD|     49.0|    229.0|\n",
      "|  Hamilton (Touring)|  standard|G5dIZ9uQz9JQI|https://www.ticke...|Majestic Theatre ...|KovZpZA77alA|        78205|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|226 East Houston ...|    -98.4903863|    29.4264514|Hamilton (Touring)|     attraction|  K8vZ9174wRf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-06-28|       onsale|        19:30:00|     USD|     49.0|    199.0|\n",
      "|  Hamilton (Touring)|  standard|G5dIZpcrlRK1S|https://www.ticke...|Majestic Theatre ...|KovZpZA77alA|        78205|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|226 East Houston ...|    -98.4903863|    29.4264514|Hamilton (Touring)|     attraction|  K8vZ9174wRf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-06-25|  rescheduled|        20:00:00|     USD|     49.0|    199.0|\n",
      "|  Hamilton (Touring)|  standard|G5dIZ9uQzbJhZ|https://www.ticke...|Majestic Theatre ...|KovZpZA77alA|        78205|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|226 East Houston ...|    -98.4903863|    29.4264514|Hamilton (Touring)|     attraction|  K8vZ9174wRf|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7v7l1|              Theatre|   KZazBEonSMnZfZ7vAve|                 Musical|      2023-06-29|       onsale|        19:30:00|     USD|     49.0|    199.0|\n",
      "|San Antonio Spurs...|     \"NaN\"|G5dIZ9i6mQkxE|https://www.ticke...|         AT&T Center|KovZpZAJJEdA|        78219|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|       1 AT&T Center|    -98.4337987|    29.4330386| San Antonio Spurs|     attraction|  K8vZ9171ov0|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAde|           Basketball|   KZazBEonSMnZfZ7vFJA|                     NBA|      2023-06-22|      offsale|        18:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|      SZA - SOS Tour|  standard|G5dIZ9IGkBgh1|https://www.ticke...|         AT&T Center|KovZpZAJJEdA|        78219|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|       1 AT&T Center|    -98.4337987|    29.4330386|               SZA|     attraction|  K8vZ917o6G0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAee|                  R&B|   KZazBEonSMnZfZ7vkIt|                     R&B|      2023-10-15|       onsale|        20:00:00|     USD|     39.5|    229.5|\n",
      "|       Guns N' Roses|  standard|G5dIZ9PFkxb_o|https://www.ticke...|           Alamodome|KovZpZAEkIEA|        78203|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|      100 Montana St|    -98.4791514|   29.41705466|     Guns N' Roses|     attraction|  K8vZ9171C80|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeA|                 Rock|   KZazBEonSMnZfZ7v6F1|                     Pop|      2023-09-26|       onsale|        18:00:00|     USD|     34.0|    369.5|\n",
      "|Luis Miguel Tour ...|  standard|G5dIZ9t2xA4Dn|https://www.ticke...|         AT&T Center|KovZpZAJJEdA|        78219|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|       1 AT&T Center|    -98.4337987|    29.4330386|       Luis Miguel|     attraction|  K8vZ9171ajV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAeF|                World|   KZazBEonSMnZfZ7vFdJ|                   Latin|      2023-11-04|       onsale|        20:00:00|     USD|     75.0|    211.0|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+-----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "23/06/22 21:47:20 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@74d13fa3 committed.\n",
      "23/06/22 21:47:20 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/131 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.131.47af32d0-988c-430d-ad96-2b3246f91649.tmp\n",
      "23/06/22 21:47:20 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.131.47af32d0-988c-430d-ad96-2b3246f91649.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/131\n",
      "23/06/22 21:47:20 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:47:20.001Z\",\n",
      "  \"batchId\" : 131,\n",
      "  \"numInputRows\" : 352,\n",
      "  \"inputRowsPerSecond\" : 35.210563168950685,\n",
      "  \"processedRowsPerSecond\" : 771.9298245614035,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 123,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 6,\n",
      "    \"queryPlanning\" : 14,\n",
      "    \"triggerExecution\" : 456,\n",
      "    \"walCommit\" : 168\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4109\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4461\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 352,\n",
      "    \"inputRowsPerSecond\" : 35.210563168950685,\n",
      "    \"processedRowsPerSecond\" : 771.9298245614035\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 352\n",
      "  }\n",
      "}\n",
      "23/06/22 21:47:21 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.203.eb8bc7b5-83e8-43e6-9911-fa7300748a83.tmp to gs://kafka-spark-data/spark-metadata/offsets/203\n",
      "23/06/22 21:47:21 INFO MicroBatchExecution: Committed offsets for batch 203. Metadata OffsetSeqMetadata(0,1687488440009,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:47:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:47:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:47:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:47:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:47:21 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:47:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:47:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:47:21 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:47:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:47:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:47:21 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:47:22 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:47:22 INFO DAGScheduler: Got job 269 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:47:22 INFO DAGScheduler: Final stage: ResultStage 270 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:47:22 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:47:22 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:47:22 INFO DAGScheduler: Submitting ResultStage 270 (MapPartitionsRDD[1400] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:47:22 INFO MemoryStore: Block broadcast_269 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/22 21:47:22 INFO MemoryStore: Block broadcast_269_piece0 stored as bytes in memory (estimated size 94.8 KiB, free 434.0 MiB)\n",
      "23/06/22 21:47:22 INFO BlockManagerInfo: Added broadcast_269_piece0 in memory on 192.168.4.24:51040 (size: 94.8 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:47:22 INFO SparkContext: Created broadcast 269 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:47:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 270 (MapPartitionsRDD[1400] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:47:22 INFO TaskSchedulerImpl: Adding task set 270.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:47:22 INFO TaskSetManager: Starting task 0.0 in stage 270.0 (TID 269) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:47:22 INFO Executor: Running task 0.0 in stage 270.0 (TID 269)\n",
      "23/06/22 21:47:22 INFO BlockManagerInfo: Removed broadcast_268_piece0 on 192.168.4.24:51040 in memory (size: 9.9 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:47:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:47:22 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:47:22 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:47:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:47:22 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:47:22 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:47:22 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:47:22 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:47:22 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/22 21:47:22 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/22 21:47:22 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/22 21:47:22 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/22 21:47:22 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/22 21:47:22 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 4109 for partition ticketmaster-0\n",
      "23/06/22 21:47:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:47:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:47:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:47:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4662.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 270:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:47:23 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-fe25737a-4a57-44ae-863e-9007d772755a/_temporary/0/_temporary/' directory.\n",
      "23/06/22 21:47:23 INFO FileOutputCommitter: Saved output of task 'attempt_202306222147226860459943412770208_0270_m_000000_269' to gs://kafka-spark-data/.spark-bigquery-local-1687482506437-fe25737a-4a57-44ae-863e-9007d772755a/_temporary/0/task_202306222147226860459943412770208_0270_m_000000\n",
      "23/06/22 21:47:23 INFO SparkHadoopMapRedUtil: attempt_202306222147226860459943412770208_0270_m_000000_269: Committed. Elapsed time: 591 ms.\n",
      "23/06/22 21:47:23 INFO Executor: Finished task 0.0 in stage 270.0 (TID 269). 2579 bytes result sent to driver\n",
      "23/06/22 21:47:23 INFO TaskSetManager: Finished task 0.0 in stage 270.0 (TID 269) in 1172 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:47:23 INFO TaskSchedulerImpl: Removed TaskSet 270.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:47:23 INFO DAGScheduler: ResultStage 270 (start at NativeMethodAccessorImpl.java:0) finished in 1.271 s\n",
      "23/06/22 21:47:23 INFO DAGScheduler: Job 269 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:47:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 270: Stage finished\n",
      "23/06/22 21:47:23 INFO DAGScheduler: Job 269 finished: start at NativeMethodAccessorImpl.java:0, took 1.272500 s\n",
      "23/06/22 21:47:23 INFO FileFormatWriter: Start to commit write Job 3f63af61-7d54-4767-b719-8472881c6d8a.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:47:24 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-fe25737a-4a57-44ae-863e-9007d772755a/_temporary/0/task_202306222147226860459943412770208_0270_m_000000/' directory.\n",
      "23/06/22 21:47:24 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-fe25737a-4a57-44ae-863e-9007d772755a/' directory.\n",
      "23/06/22 21:47:24 INFO FileFormatWriter: Write Job 3f63af61-7d54-4767-b719-8472881c6d8a committed. Elapsed time: 1471 ms.\n",
      "23/06/22 21:47:24 INFO FileFormatWriter: Finished processing stats for write job 3f63af61-7d54-4767-b719-8472881c6d8a.\n",
      "23/06/22 21:47:25 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687482506437-fe25737a-4a57-44ae-863e-9007d772755a/part-00000-144c302a-5bb5-42e0-b429-88a250f5ff8c-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=27db6f8a-322e-49a3-bbba-669fc4f8fa6c, location=US}\n",
      "23/06/22 21:47:29 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=27db6f8a-322e-49a3-bbba-669fc4f8fa6c, location=US}\n",
      "23/06/22 21:47:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:47:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 4831.\n",
      "23/06/22 21:47:30 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/132 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.132.eac6e234-5645-4376-a615-87d67ef3ca3d.tmp\n",
      "23/06/22 21:47:30 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.132.eac6e234-5645-4376-a615-87d67ef3ca3d.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/132\n",
      "23/06/22 21:47:30 INFO MicroBatchExecution: Committed offsets for batch 132. Metadata OffsetSeqMetadata(0,1687488450013,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:47:30 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:47:30 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:47:30 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:47:30 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:47:30 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:47:30 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:47:30 INFO WriteToDataSourceV2Exec: Start processing data source write support: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@77260779. The input RDD has 1 partitions.\n",
      "23/06/22 21:47:30 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:47:30 INFO DAGScheduler: Got job 270 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:47:30 INFO DAGScheduler: Final stage: ResultStage 271 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:47:30 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:47:30 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:47:30 INFO DAGScheduler: Submitting ResultStage 271 (MapPartitionsRDD[1403] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:47:30 INFO MemoryStore: Block broadcast_270 stored as values in memory (estimated size 23.0 KiB, free 434.0 MiB)\n",
      "23/06/22 21:47:30 INFO MemoryStore: Block broadcast_270_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 434.0 MiB)\n",
      "23/06/22 21:47:30 INFO BlockManagerInfo: Added broadcast_270_piece0 in memory on 192.168.4.24:51040 (size: 9.9 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:47:30 INFO SparkContext: Created broadcast 270 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:47:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 271 (MapPartitionsRDD[1403] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:47:30 INFO TaskSchedulerImpl: Adding task set 271.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:47:30 INFO TaskSetManager: Starting task 0.0 in stage 271.0 (TID 270) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:47:30 INFO Executor: Running task 0.0 in stage 271.0 (TID 270)\n",
      "23/06/22 21:47:30 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 4481 for partition ticketmaster-0\n",
      "23/06/22 21:47:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:47:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:47:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:47:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 4831.\n",
      "23/06/22 21:47:30 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to offset 4483 for partition ticketmaster-0\n",
      "23/06/22 21:47:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:47:30 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/203 using temp file gs://kafka-spark-data/spark-metadata/commits/.203.69c20f58-8187-4acd-9f92-8f291e6d3d1a.tmp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:47:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:47:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:47:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor-54, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-executor] Resetting offset for partition ticketmaster-0 to offset 4831.\n",
      "23/06/22 21:47:30 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 270, attempt 0, stage 271.0)\n",
      "23/06/22 21:47:30 INFO DataWritingSparkTask: Committed partition 0 (task 270, attempt 0, stage 271.0)\n",
      "23/06/22 21:47:30 INFO Executor: Finished task 0.0 in stage 271.0 (TID 270). 349770 bytes result sent to driver\n",
      "23/06/22 21:47:30 INFO TaskSetManager: Finished task 0.0 in stage 271.0 (TID 270) in 566 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:47:30 INFO TaskSchedulerImpl: Removed TaskSet 271.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:47:30 INFO DAGScheduler: ResultStage 271 (start at NativeMethodAccessorImpl.java:0) finished in 0.572 s\n",
      "23/06/22 21:47:30 INFO DAGScheduler: Job 270 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:47:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 271: Stage finished\n",
      "23/06/22 21:47:30 INFO DAGScheduler: Job 270 finished: start at NativeMethodAccessorImpl.java:0, took 0.573777 s\n",
      "23/06/22 21:47:30 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@77260779 is committing.\n",
      "-------------------------------------------\n",
      "Batch: 132\n",
      "-------------------------------------------\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+-----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|          event_name|event_type|     event_id|           event_url|          venue_name|    venue_id|venue_zipcode|venues_timezone| venue_city|venue_state_full|venue_state_short|  venue_country_name|venue_country_short|       venue_address|venue_longitude|venue_latitude|     attraction_name|attraction_type|attraction_id|      attraction_url|attraction_segment_id|attraction_segment_name|attraction_genre_id|attraction_genre_name|attraction_subgenre_id|attraction_subgenre_name|event_start_date|ticket_status|event_start_time|currency|min_price|max_price|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+-----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|San Antonio Missi...|     \"NaN\"|Z7r9jZ1AdbMZt|https://www.ticke...|Nelson Wolff Stadium|  ZFr9jZeeaA|        78227|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|    5757 Hwy 90 West|     -98.638496|       29.4051|San Antonio Missions|     attraction|  K8vZ9171mHf|https://www.ticke...|   KZFzniwnSyZfZ7v7nE|                 Sports|        KnvZfZ7vAdv|             Baseball|   KZazBEonSMnZfZ7vF1t|            Minor League|      2023-09-17|       onsale|        13:05:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|     Cristela Alonzo|     \"NaN\"|Z7r9jZ1Ad0eeF|https://www.ticke...|H-E-B Performance...|  Z7r9jZadBO|        78205|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|100 Auditorium Ci...|     -98.488503|     29.424801|     Cristela Alonzo|     attraction|  K8vZ917GcT0|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-09-20|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|         Bruce Bruce|     \"NaN\"|G5e0Z9nInUvPz|https://www.ticke...|Laugh Out Loud Co...|KovZpZAFIAaA|        78216|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|     618 NW Loop 410|     -98.502544|     29.518441|         Bruce Bruce|     attraction|  K8vZ9171HaV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-09-22|       onsale|        21:45:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|         Bruce Bruce|     \"NaN\"|G5e0Z9nIngsOY|https://www.ticke...|Laugh Out Loud Co...|KovZpZAFIAaA|        78216|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|     618 NW Loop 410|     -98.502544|     29.518441|         Bruce Bruce|     attraction|  K8vZ9171HaV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-09-22|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|         Bruce Bruce|     \"NaN\"|G5e0Z9nInUv-4|https://www.ticke...|Laugh Out Loud Co...|KovZpZAFIAaA|        78216|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|     618 NW Loop 410|     -98.502544|     29.518441|         Bruce Bruce|     attraction|  K8vZ9171HaV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-09-23|       onsale|        21:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|         Bruce Bruce|     \"NaN\"|G5e0Z9nInUvx2|https://www.ticke...|Laugh Out Loud Co...|KovZpZAFIAaA|        78216|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|     618 NW Loop 410|     -98.502544|     29.518441|         Bruce Bruce|     attraction|  K8vZ9171HaV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-09-23|       onsale|        19:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "| Escape the Fate Vip|     \"NaN\"|G5e0Z9l8FDSl8|https://www.ticke...|  Vibes Event Center| KovZ917A3M0|        78205|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|1211 East Houston...|     -98.478755|     29.425185|               \"NaN\"|          \"NaN\"|        \"NaN\"|               \"NaN\"|                \"NaN\"|                  \"NaN\"|              \"NaN\"|                \"NaN\"|                 \"NaN\"|                   \"NaN\"|      2023-09-24|       onsale|        16:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|         Bruce Bruce|     \"NaN\"|G5e0Z9nInUoEC|https://www.ticke...|Laugh Out Loud Co...|KovZpZAFIAaA|        78216|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|     618 NW Loop 410|     -98.502544|     29.518441|         Bruce Bruce|     attraction|  K8vZ9171HaV|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-09-24|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|     Ne Obliviscaris|     \"NaN\"|Z7r9jZ1Adjp0a|https://www.ticke...|  Vibes Event Center|  Z7r9jZadCS|        78205|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|1211 E. Houston S...|     -98.488503|     29.424801|     Ne Obliviscaris|     attraction|  K8vZ917fZ-0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvt|                Metal|   KZazBEonSMnZfZ7vk6E|                   Metal|      2023-10-15|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|          Chico Bean|     \"NaN\"|G5e0Z9nO9IKNO|https://www.ticke...|Laugh Out Loud Co...|KovZpZAFIAaA|        78216|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|     618 NW Loop 410|     -98.502544|     29.518441|               \"NaN\"|          \"NaN\"|        \"NaN\"|               \"NaN\"|                \"NaN\"|                  \"NaN\"|              \"NaN\"|                \"NaN\"|                 \"NaN\"|                   \"NaN\"|      2023-09-30|       onsale|        19:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|          Chico Bean|     \"NaN\"|G5e0Z9nO9IKNj|https://www.ticke...|Laugh Out Loud Co...|KovZpZAFIAaA|        78216|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|     618 NW Loop 410|     -98.502544|     29.518441|               \"NaN\"|          \"NaN\"|        \"NaN\"|               \"NaN\"|                \"NaN\"|                  \"NaN\"|              \"NaN\"|                \"NaN\"|                 \"NaN\"|                   \"NaN\"|      2023-09-30|       onsale|        21:45:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|Spyro Gyra 49th Y...|  standard|G5dIZ9iUXlAHH|https://www.ticke...|     Jo Long Theatre|KovZpZAJ1eaA|        78202|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|     226 N Hackberry|     -98.471752|     29.421806|          Spyro Gyra|     attraction|  K8vZ9171aD0|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvE|                 Jazz|   KZazBEonSMnZfZ7vkda|                    Jazz|      2023-10-01|      offsale|        19:00:00|     USD|     60.0|     60.0|\n",
      "|          Andrea Jin|     \"NaN\"|G5e0Z9nFw68Ts|https://www.ticke...|Laugh Out Loud Co...|KovZpZAFIAaA|        78216|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|     618 NW Loop 410|     -98.502544|     29.518441|               \"NaN\"|          \"NaN\"|        \"NaN\"|               \"NaN\"|                \"NaN\"|                  \"NaN\"|              \"NaN\"|                \"NaN\"|                 \"NaN\"|                   \"NaN\"|      2023-10-04|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|SABIFF 2023 - HBC...|  standard|G5dIZ9ilEukJd|https://www.ticke...|     Jo Long Theatre|KovZpZAJ1eaA|        78202|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|     226 N Hackberry|     -98.471752|     29.421806|               \"NaN\"|          \"NaN\"|        \"NaN\"|               \"NaN\"|                \"NaN\"|                  \"NaN\"|              \"NaN\"|                \"NaN\"|                 \"NaN\"|                   \"NaN\"|      2023-10-05|       onsale|        18:00:00|     USD|     43.0|     43.0|\n",
      "|Scott Bradlee's P...|     \"NaN\"|Z7r9jZ1Adxkef|https://www.ticke...|H-E-B Performance...|  Z7r9jZadBO|        78205|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|100 Auditorium Ci...|     -98.488503|     29.424801|Scott Bradlee's P...|     attraction|  K8vZ917KQQV|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvE|                 Jazz|   KZazBEonSMnZfZ7vkda|                    Jazz|      2023-11-04|       onsale|        20:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|          Morgan Jay|     \"NaN\"|G5e0Z9E41vZch|https://www.ticke...|Laugh Out Loud Co...|KovZpZAFIAaA|        78216|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|     618 NW Loop 410|     -98.502544|     29.518441|               \"NaN\"|          \"NaN\"|        \"NaN\"|               \"NaN\"|                \"NaN\"|                  \"NaN\"|              \"NaN\"|                \"NaN\"|                 \"NaN\"|                   \"NaN\"|      2023-10-10|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|          Morgan Jay|     \"NaN\"|Z7r9jZ1AdOz4a|https://www.ticke...|Laugh Out Loud Co...|  Z7r9jZadUY|        78216|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|     618 NW Loop 410|     -98.488197|       29.5371|          Morgan Jay|     attraction|   Z7r9jZa2iG|               \"NaN\"|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvl|                Other|   KZazBEonSMnZfZ7vk1I|                   Other|      2023-10-10|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|           Matt Rife|     \"NaN\"|Z7r9jZ1AdQkOx|https://www.ticke...|Laugh Out Loud Co...|  Z7r9jZadUY|        78216|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|     618 NW Loop 410|     -98.488197|       29.5371|           Matt Rife|     attraction|  K8vZ9179SV7|https://www.ticke...|   KZFzniwnSyZfZ7v7na|         Arts & Theatre|        KnvZfZ7vAe1|               Comedy|   KZazBEonSMnZfZ7vF17|                  Comedy|      2023-12-01|       onsale|        21:45:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "| Polaris w/ Currents|     \"NaN\"|Z7r9jZ1Ad0P_f|https://www.ticke...|         Paper Tiger|  ZFr9jZeaFA|        78212|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|2410 N. St. Mary'...|       -98.4916|     29.464199|             Polaris|     attraction|  K8vZ9173mmf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAvt|                Metal|   KZazBEonSMnZfZ7vaJk|               Metalcore|      2023-11-01|       onsale|        19:00:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "|        Chingo Bling|     \"NaN\"|G5e0Z90z35ZMA|https://www.ticke...|Laugh Out Loud Co...|KovZpZAFIAaA|        78216|America/Chicago|San Antonio|           Texas|               TX|United States Of ...|                 US|     618 NW Loop 410|     -98.502544|     29.518441|        Chingo Bling|     attraction|  K8vZ917C5Tf|https://www.ticke...|   KZFzniwnSyZfZ7v7nJ|                  Music|        KnvZfZ7vAv1|          Hip-Hop/Rap|   KZazBEonSMnZfZ7vkdA|                   Urban|      2023-10-12|       onsale|        19:30:00|   \"NaN\"|    \"NaN\"|    \"NaN\"|\n",
      "+--------------------+----------+-------------+--------------------+--------------------+------------+-------------+---------------+-----------+----------------+-----------------+--------------------+-------------------+--------------------+---------------+--------------+--------------------+---------------+-------------+--------------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "23/06/22 21:47:30 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@77260779 committed.\n",
      "23/06/22 21:47:30 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/132 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.132.38149372-d584-4ecb-afba-d97a8ab79912.tmp\n",
      "23/06/22 21:47:30 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.132.38149372-d584-4ecb-afba-d97a8ab79912.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/132\n",
      "23/06/22 21:47:30 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:47:30.001Z\",\n",
      "  \"batchId\" : 132,\n",
      "  \"numInputRows\" : 370,\n",
      "  \"inputRowsPerSecond\" : 37.0,\n",
      "  \"processedRowsPerSecond\" : 455.66502463054184,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 607,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 10,\n",
      "    \"queryPlanning\" : 30,\n",
      "    \"triggerExecution\" : 812,\n",
      "    \"walCommit\" : 99\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4461\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4831\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 370,\n",
      "    \"inputRowsPerSecond\" : 37.0,\n",
      "    \"processedRowsPerSecond\" : 455.66502463054184\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 370\n",
      "  }\n",
      "}\n",
      "23/06/22 21:47:31 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.203.69c20f58-8187-4acd-9f92-8f291e6d3d1a.tmp to gs://kafka-spark-data/spark-metadata/commits/203\n",
      "23/06/22 21:47:31 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:47:20.003Z\",\n",
      "  \"batchId\" : 203,\n",
      "  \"numInputRows\" : 352,\n",
      "  \"inputRowsPerSecond\" : 35.2035203520352,\n",
      "  \"processedRowsPerSecond\" : 30.96410978184377,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 8645,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 6,\n",
      "    \"queryPlanning\" : 4,\n",
      "    \"triggerExecution\" : 11368,\n",
      "    \"walCommit\" : 1589\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4109\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4461\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 352,\n",
      "    \"inputRowsPerSecond\" : 35.2035203520352,\n",
      "    \"processedRowsPerSecond\" : 30.96410978184377\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:47:31 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 11368 milliseconds\n",
      "23/06/22 21:47:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:47:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4831.\n",
      "23/06/22 21:47:31 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/204 using temp file gs://kafka-spark-data/spark-metadata/offsets/.204.05b6dcaf-0a8d-446e-b27b-f5dbd45f0b31.tmp\n",
      "23/06/22 21:47:32 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.204.05b6dcaf-0a8d-446e-b27b-f5dbd45f0b31.tmp to gs://kafka-spark-data/spark-metadata/offsets/204\n",
      "23/06/22 21:47:32 INFO MicroBatchExecution: Committed offsets for batch 204. Metadata OffsetSeqMetadata(0,1687488451375,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 21:47:32 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:47:32 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:47:32 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:47:32 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 21:47:33 INFO BlockManagerInfo: Removed broadcast_270_piece0 on 192.168.4.24:51040 in memory (size: 9.9 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:47:33 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:47:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:47:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:47:33 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:47:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:47:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:47:33 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:47:33 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 21:47:33 INFO DAGScheduler: Got job 271 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 21:47:33 INFO DAGScheduler: Final stage: ResultStage 272 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 21:47:33 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 21:47:33 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 21:47:33 INFO DAGScheduler: Submitting ResultStage 272 (MapPartitionsRDD[1410] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 21:47:33 INFO MemoryStore: Block broadcast_271 stored as values in memory (estimated size 295.4 KiB, free 433.7 MiB)\n",
      "23/06/22 21:47:33 INFO MemoryStore: Block broadcast_271_piece0 stored as bytes in memory (estimated size 94.8 KiB, free 433.6 MiB)\n",
      "23/06/22 21:47:33 INFO BlockManagerInfo: Added broadcast_271_piece0 in memory on 192.168.4.24:51040 (size: 94.8 KiB, free: 434.2 MiB)\n",
      "23/06/22 21:47:33 INFO SparkContext: Created broadcast 271 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 21:47:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 272 (MapPartitionsRDD[1410] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 21:47:33 INFO TaskSchedulerImpl: Adding task set 272.0 with 1 tasks resource profile 0\n",
      "23/06/22 21:47:33 INFO TaskSetManager: Starting task 0.0 in stage 272.0 (TID 271) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/22 21:47:33 INFO Executor: Running task 0.0 in stage 272.0 (TID 271)\n",
      "23/06/22 21:47:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:47:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:47:33 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:47:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/22 21:47:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/22 21:47:33 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/22 21:47:33 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:47:33 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/22 21:47:33 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/22 21:47:33 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/22 21:47:33 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/22 21:47:33 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/22 21:47:33 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/22 21:47:33 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 4609 for partition ticketmaster-0\n",
      "23/06/22 21:47:33 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/22 21:47:33 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:47:33 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:47:33 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4831.\n",
      "23/06/22 21:47:33 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to offset 4661 for partition ticketmaster-0\n",
      "23/06/22 21:47:33 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 272:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:47:34 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 21:47:34 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:47:34 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor-55, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4831.\n",
      "23/06/22 21:47:35 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-ae47c2fd-4ef5-4748-9901-719a536cd12b/_temporary/0/_temporary/' directory.\n",
      "23/06/22 21:47:35 INFO FileOutputCommitter: Saved output of task 'attempt_20230622214733973222591584667979_0272_m_000000_271' to gs://kafka-spark-data/.spark-bigquery-local-1687482506437-ae47c2fd-4ef5-4748-9901-719a536cd12b/_temporary/0/task_20230622214733973222591584667979_0272_m_000000\n",
      "23/06/22 21:47:35 INFO SparkHadoopMapRedUtil: attempt_20230622214733973222591584667979_0272_m_000000_271: Committed. Elapsed time: 618 ms.\n",
      "23/06/22 21:47:35 INFO Executor: Finished task 0.0 in stage 272.0 (TID 271). 2579 bytes result sent to driver\n",
      "23/06/22 21:47:35 INFO TaskSetManager: Finished task 0.0 in stage 272.0 (TID 271) in 1632 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 21:47:35 INFO TaskSchedulerImpl: Removed TaskSet 272.0, whose tasks have all completed, from pool \n",
      "23/06/22 21:47:35 INFO DAGScheduler: ResultStage 272 (start at NativeMethodAccessorImpl.java:0) finished in 1.658 s\n",
      "23/06/22 21:47:35 INFO DAGScheduler: Job 271 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 21:47:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 272: Stage finished\n",
      "23/06/22 21:47:35 INFO DAGScheduler: Job 271 finished: start at NativeMethodAccessorImpl.java:0, took 1.660893 s\n",
      "23/06/22 21:47:35 INFO FileFormatWriter: Start to commit write Job a215e29f-2cd2-45af-95ba-3b780434ecf6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 21:47:35 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-ae47c2fd-4ef5-4748-9901-719a536cd12b/_temporary/0/task_20230622214733973222591584667979_0272_m_000000/' directory.\n",
      "23/06/22 21:47:36 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687482506437-ae47c2fd-4ef5-4748-9901-719a536cd12b/' directory.\n",
      "23/06/22 21:47:36 INFO BlockManagerInfo: Removed broadcast_271_piece0 on 192.168.4.24:51040 in memory (size: 94.8 KiB, free: 434.3 MiB)\n",
      "23/06/22 21:47:36 INFO BlockManagerInfo: Removed broadcast_269_piece0 on 192.168.4.24:51040 in memory (size: 94.8 KiB, free: 434.4 MiB)\n",
      "23/06/22 21:47:36 INFO FileFormatWriter: Write Job a215e29f-2cd2-45af-95ba-3b780434ecf6 committed. Elapsed time: 1423 ms.\n",
      "23/06/22 21:47:36 INFO FileFormatWriter: Finished processing stats for write job a215e29f-2cd2-45af-95ba-3b780434ecf6.\n",
      "23/06/22 21:47:36 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687482506437-ae47c2fd-4ef5-4748-9901-719a536cd12b/part-00000-e4b5b367-cd5c-496b-ab07-4660a6f87d4b-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=9938e456-6b24-4511-9830-d17827d86ba5, location=US}\n",
      "23/06/22 21:47:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:47:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 4831.\n",
      "23/06/22 21:47:40 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=9938e456-6b24-4511-9830-d17827d86ba5, location=US}\n",
      "23/06/22 21:47:40 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/204 using temp file gs://kafka-spark-data/spark-metadata/commits/.204.62040151-8de2-4f4f-94a9-1548b869754e.tmp\n",
      "23/06/22 21:47:41 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.204.62040151-8de2-4f4f-94a9-1548b869754e.tmp to gs://kafka-spark-data/spark-metadata/commits/204\n",
      "23/06/22 21:47:41 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:47:31.372Z\",\n",
      "  \"batchId\" : 204,\n",
      "  \"numInputRows\" : 370,\n",
      "  \"inputRowsPerSecond\" : 32.54463893042484,\n",
      "  \"processedRowsPerSecond\" : 35.638605278366406,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7773,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 2,\n",
      "    \"queryPlanning\" : 13,\n",
      "    \"triggerExecution\" : 10382,\n",
      "    \"walCommit\" : 1500\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4461\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4831\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 370,\n",
      "    \"inputRowsPerSecond\" : 32.54463893042484,\n",
      "    \"processedRowsPerSecond\" : 35.638605278366406\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:47:41 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 10383 milliseconds\n",
      "23/06/22 21:47:41 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:47:41 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4831.\n",
      "23/06/22 21:47:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:47:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:47:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 4831.\n",
      "23/06/22 21:47:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4831.\n",
      "23/06/22 21:47:50 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:47:50.005Z\",\n",
      "  \"batchId\" : 133,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 17,\n",
      "    \"triggerExecution\" : 18\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4831\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4831\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 0\n",
      "  }\n",
      "}\n",
      "23/06/22 21:48:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:48:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:48:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 4831.\n",
      "23/06/22 21:48:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4831.\n",
      "23/06/22 21:48:00 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:48:00.001Z\",\n",
      "  \"batchId\" : 205,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 19,\n",
      "    \"triggerExecution\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4831\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4831\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:48:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:48:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:48:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 4831.\n",
      "23/06/22 21:48:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4831.\n",
      "23/06/22 21:48:10 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:48:10.003Z\",\n",
      "  \"batchId\" : 133,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 10,\n",
      "    \"triggerExecution\" : 10\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4831\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4831\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 0\n",
      "  }\n",
      "}\n",
      "23/06/22 21:48:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:48:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:48:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 4831.\n",
      "23/06/22 21:48:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4831.\n",
      "23/06/22 21:48:20 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:48:20.006Z\",\n",
      "  \"batchId\" : 133,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 16,\n",
      "    \"triggerExecution\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4831\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4831\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 0\n",
      "  }\n",
      "}\n",
      "23/06/22 21:48:20 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:48:20.005Z\",\n",
      "  \"batchId\" : 205,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 14,\n",
      "    \"triggerExecution\" : 20\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4831\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4831\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:48:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:48:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:48:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4831.\n",
      "23/06/22 21:48:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 4831.\n",
      "23/06/22 21:48:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:48:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:48:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 4831.\n",
      "23/06/22 21:48:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4831.\n",
      "23/06/22 21:48:40 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:48:40.001Z\",\n",
      "  \"batchId\" : 133,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 7,\n",
      "    \"triggerExecution\" : 8\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4831\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4831\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 0\n",
      "  }\n",
      "}\n",
      "23/06/22 21:48:40 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:48:40.004Z\",\n",
      "  \"batchId\" : 205,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 3,\n",
      "    \"triggerExecution\" : 5\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4831\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4831\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:48:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:48:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:48:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4831.\n",
      "23/06/22 21:48:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 4831.\n",
      "23/06/22 21:48:58 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Group coordinator 127.0.0.1:9092 (id: 2147483646 rack: null) is unavailable or invalid, will attempt rediscovery\n",
      "23/06/22 21:48:58 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Group coordinator 127.0.0.1:9092 (id: 2147483646 rack: null) is unavailable or invalid, will attempt rediscovery\n",
      "23/06/22 21:49:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Error while fetching metadata with correlation id 1815 : {ticketmaster=UNKNOWN_TOPIC_OR_PARTITION}\n",
      "23/06/22 21:49:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Error while fetching metadata with correlation id 277 : {ticketmaster=LEADER_NOT_AVAILABLE}\n",
      "23/06/22 21:49:09 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Discovered group coordinator 127.0.0.1:9092 (id: 2147483646 rack: null)\n",
      "23/06/22 21:49:09 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:49:09 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Discovered group coordinator 127.0.0.1:9092 (id: 2147483646 rack: null)\n",
      "23/06/22 21:49:09 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:49:09 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Attempt to heartbeat failed since coordinator 127.0.0.1:9092 (id: 2147483646 rack: null) is either not started or not valid\n",
      "23/06/22 21:49:09 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Group coordinator 127.0.0.1:9092 (id: 2147483646 rack: null) is unavailable or invalid, will attempt rediscovery\n",
      "23/06/22 21:49:09 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 4831.\n",
      "23/06/22 21:49:09 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4831.\n",
      "23/06/22 21:49:09 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"74802c4c-e991-4c01-8644-e6c0d1d872fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:49:00.011Z\",\n",
      "  \"batchId\" : 205,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 9298,\n",
      "    \"triggerExecution\" : 9302\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4831\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4831\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@12cc7cbd,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@74f3981c,com.google.cloud.bigquery.connector.common.BigQueryClient@2b76da2b)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/22 21:49:09 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T02:49:00.011Z\",\n",
      "  \"batchId\" : 133,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 9296,\n",
      "    \"triggerExecution\" : 9301\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4831\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4831\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 0\n",
      "  }\n",
      "}\n",
      "23/06/22 21:49:09 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Discovered group coordinator 127.0.0.1:9092 (id: 2147483646 rack: null)\n",
      "23/06/22 21:49:09 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Attempt to heartbeat failed since coordinator 127.0.0.1:9092 (id: 2147483646 rack: null) is either not started or not valid\n",
      "23/06/22 21:49:09 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Group coordinator 127.0.0.1:9092 (id: 2147483646 rack: null) is unavailable or invalid, will attempt rediscovery\n",
      "23/06/22 21:49:09 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Discovered group coordinator 127.0.0.1:9092 (id: 2147483646 rack: null)\n",
      "23/06/22 21:49:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:49:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 21:49:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4831.\n",
      "23/06/22 21:49:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 4831.\n",
      "23/06/22 21:49:11 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Group coordinator 127.0.0.1:9092 (id: 2147483646 rack: null) is unavailable or invalid, will attempt rediscovery\n",
      "23/06/22 21:49:11 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Group coordinator 127.0.0.1:9092 (id: 2147483646 rack: null) is unavailable or invalid, will attempt rediscovery\n",
      "23/06/22 21:49:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:49:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:50:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:51:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:52:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:53:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:54:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:55:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:56:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 21:57:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:00:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:00:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:00:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:00:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:00:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:00:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:00:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:00:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:00:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:00:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:00:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:00:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:00:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:00:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:00:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:00:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:00:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:00:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:00:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:00:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:00:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:00:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:00:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:00:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:00:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:00:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:00:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:01:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:01:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:01:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:01:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:01:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:01:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:01:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:01:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:01:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:01:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:01:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:01:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:01:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:01:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:01:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:01:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:01:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:01:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:01:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:02:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:02:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:02:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:02:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:02:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:02:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:02:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:02:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:02:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:02:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:02:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:02:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:02:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:02:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:02:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:10:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:11:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:12:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:14:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:14:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:14:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:14:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:14:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:14:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:14:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:14:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:14:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:14:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:14:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:14:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:14:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:15:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:15:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:16:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:16:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:16:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:16:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:16:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:16:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:16:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:16:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:16:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:16:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:16:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:16:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:16:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:16:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:16:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:16:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:16:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:16:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:16:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:16:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:16:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:16:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:17:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:18:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:21:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:21:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:21:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:21:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:21:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:21:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:21:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:21:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:21:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:21:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:21:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:21:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:21:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:21:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:21:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:21:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:21:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:21:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:21:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:21:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:21:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:21:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:21:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:25:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:25:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:25:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:25:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:25:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:25:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:25:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:25:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:25:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:25:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:25:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:25:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:25:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:25:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:25:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:25:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:27:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:27:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:27:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:27:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:27:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:27:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:27:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:27:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:27:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:27:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:27:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:27:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:27:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:27:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:27:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:27:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:27:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:27:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:29:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:29:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:29:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:29:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:29:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:29:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:29:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:29:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:29:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:29:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:29:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:29:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:29:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:29:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:29:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:31:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:31:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:31:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:31:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:31:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:31:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:31:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:31:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:31:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:31:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:31:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:31:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:31:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:31:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:31:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:31:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:34:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:34:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:34:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:34:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:34:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:34:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:34:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:34:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:34:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:34:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:34:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:34:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:34:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:34:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:34:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:34:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:42:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:42:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:42:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:42:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:42:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:42:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:42:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:42:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:42:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:42:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:42:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:42:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:42:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:42:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:42:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:42:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:50:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:50:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:50:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:50:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:50:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:50:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:50:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:50:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:50:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:50:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:50:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:50:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:50:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:50:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:50:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:50:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:50:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:50:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:50:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:50:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:50:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:50:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:50:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:50:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:50:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:50:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:50:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:50:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:52:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:52:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:52:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:52:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:52:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:52:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:52:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:52:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:52:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:52:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:52:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:52:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:52:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:52:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:52:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:52:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:52:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:52:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:52:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:52:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:53:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:58:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:58:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:58:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:58:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:58:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:58:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:58:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:58:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:58:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:58:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:58:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:58:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:58:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:58:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:58:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:58:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 22:58:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:14:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:14:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:14:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:14:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:14:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:14:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:14:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:14:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:14:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:14:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:14:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:14:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:17:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:17:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:18:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:18:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:18:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:18:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:18:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:18:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:18:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:18:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:18:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:18:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:18:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:18:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:18:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:18:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:25:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:25:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:25:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:25:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:25:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:25:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:25:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:25:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:25:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:25:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:25:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:25:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:25:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:25:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:25:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:25:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:25:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:41:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:41:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:41:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:41:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:41:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:41:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:41:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:41:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:41:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:41:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:41:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:41:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:41:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:41:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:41:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:41:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:41:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:41:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:45:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:45:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:45:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:45:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:45:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:45:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:45:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:45:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:45:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:45:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:45:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:45:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:45:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:45:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:45:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/22 23:45:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:01:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:01:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:01:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:01:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:01:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:01:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:01:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:01:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:01:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:01:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:01:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:01:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:01:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:09:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:09:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:09:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:09:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:09:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:09:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:09:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:09:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:09:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:09:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:09:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:09:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:09:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:09:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:09:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:09:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:09:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:19:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:19:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:19:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:19:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:20:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:20:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:20:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:20:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:20:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:20:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:20:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:20:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:20:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:20:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:20:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:20:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:20:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:20:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:20:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:20:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:20:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:20:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:20:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:20:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:20:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:20:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:20:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:20:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:20:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:20:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:24:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:24:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:24:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:24:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:24:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:24:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:24:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:24:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:24:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:24:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:24:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:24:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:24:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:24:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:24:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:24:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:39:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:39:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:40:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:40:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:40:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:40:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:40:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:40:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:40:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:40:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:40:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:40:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:42:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:44:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:44:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:44:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:44:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:44:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:44:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:44:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:44:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:44:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:44:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:44:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:44:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:44:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:44:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:44:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:44:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:58:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:58:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:58:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:58:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:58:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:58:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:58:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:58:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:58:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:58:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:58:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:58:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:58:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:58:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:58:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:58:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 00:58:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:04:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:05:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:06:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:06:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:06:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:06:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:06:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:06:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:06:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:06:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:06:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:06:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:06:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:06:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:06:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:06:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:06:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:06:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:23:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:23:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:23:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:23:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:23:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:23:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:23:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:23:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:23:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:23:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:23:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:23:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:23:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:23:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:23:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:23:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:23:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:23:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:23:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:23:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:23:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:23:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:23:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:23:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:23:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:23:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:23:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:23:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:38:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:49:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:49:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:49:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:49:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:49:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:49:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:49:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:49:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:49:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:49:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:49:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:49:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:49:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:49:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:49:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:49:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:49:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:49:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:49:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:55:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:55:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:55:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:55:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:55:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:55:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:55:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:55:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:55:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:55:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:55:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:55:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:55:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:55:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:56:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 01:56:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:00:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:00:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:00:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:00:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:00:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:00:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:00:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:00:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:00:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:00:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:00:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:00:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:00:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:00:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:00:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:17:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:17:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:17:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:17:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:17:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:17:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:17:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:17:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:17:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:17:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:17:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:17:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:18:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:18:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:18:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:18:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:18:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:18:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:18:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:18:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:18:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:18:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:19:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:19:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:19:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:19:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:19:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:19:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:24:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:24:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:24:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:24:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:24:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:24:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:24:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:24:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:24:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:24:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:24:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:24:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:24:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:24:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:24:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:24:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:25:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:41:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:41:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:41:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:41:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:41:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:41:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:41:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:41:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:41:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:41:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:41:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:41:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:56:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:56:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:56:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:56:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:56:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:56:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:56:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:56:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:56:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:56:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:56:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:56:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:56:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:56:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:56:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:56:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:56:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:56:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:56:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:56:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:56:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:56:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:56:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:56:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:56:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:56:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:56:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:56:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:56:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:57:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:57:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:57:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:57:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:57:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:57:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:57:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:57:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 02:57:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:04:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:04:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:04:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:04:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:04:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:04:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:05:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:19:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:37:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:37:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:37:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:37:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:37:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:37:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:37:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:37:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:37:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:37:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:37:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:37:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:46:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:46:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:46:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:46:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:46:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:46:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:46:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:46:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:46:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:46:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:46:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:46:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:46:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:46:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:46:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:46:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 03:46:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:02:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:02:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:02:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:02:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:02:31 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 941207 ms exceeds timeout 120000 ms\n",
      "23/06/23 04:02:31 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "23/06/23 04:02:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:02:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:02:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:02:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:02:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:02:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:02:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:02:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:18:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:18:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:18:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:18:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:18:25 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 04:18:25 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 04:18:25 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 04:18:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 04:18:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 04:18:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:18:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:18:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:18:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:18:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:18:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:18:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:18:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:24:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:24:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:24:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:24:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:24:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:24:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:24:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:24:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:24:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:24:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:24:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:24:58 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 04:24:58 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 04:24:58 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 04:24:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 04:24:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 04:24:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:24:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:25:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:25:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:25:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:25:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:40:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:40:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:40:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:40:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:40:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:40:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:40:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:40:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:40:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:40:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:40:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:40:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:46:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:46:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:46:20 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 04:46:20 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 04:46:20 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 04:46:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 04:46:20 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 04:46:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:46:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:46:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:46:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:46:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:46:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:46:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:46:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:46:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:46:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:46:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:46:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:46:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:46:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:46:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 04:46:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:01:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:01:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:01:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:01:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:01:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:01:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:01:32 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 05:01:32 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 05:01:32 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 05:01:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 05:01:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 05:01:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:01:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:01:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:01:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:01:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:01:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:01:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:01:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:19:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:19:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:19:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:19:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:19:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:19:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:19:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:19:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:19:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:19:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:19:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:19:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:25:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:25:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:25:39 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 05:25:39 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 05:25:39 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 05:25:39 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 05:25:39 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 05:25:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:25:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:25:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:25:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:25:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:25:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:25:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:25:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:25:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:25:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:25:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:25:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:25:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:25:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:25:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:13 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 05:38:13 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 05:38:13 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 05:38:13 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 05:38:13 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 05:38:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:23 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 05:38:23 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 05:38:23 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 05:38:23 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 05:38:23 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 05:38:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:38:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:53:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:53:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:53:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:53:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:53:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:53:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:53:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:53:56 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 05:53:56 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 05:53:56 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 05:53:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/23 05:53:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/23 05:53:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:53:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:53:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:53:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:53:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:53:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:53:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:53:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:54:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 05:54:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:08:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:08:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:08:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:08:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:08:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:08:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:08:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:08:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:08:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:08:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:08:20 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 06:08:20 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 06:08:20 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 06:08:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 06:08:20 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 06:08:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:08:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:08:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:08:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:08:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:08:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:08:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:17:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:17:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:17:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:17:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:17:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:17:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:17:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:17:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:17:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:17:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:17:33 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 06:17:33 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 06:17:33 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 06:17:33 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 06:17:33 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 06:17:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:17:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:17:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:17:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:17:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:17:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:18:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:18:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:18:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:18:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:18:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:18:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:18:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:18:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:18:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:18:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:18:09 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 06:18:09 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 06:18:09 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 06:18:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/23 06:18:09 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/23 06:18:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:18:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:18:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:18:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:18:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:21:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:21:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:21:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:21:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:21:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:21:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:21:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:21:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:21:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:21:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:21:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:21:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:21:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:21:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:21:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:21:12 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 06:21:12 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 06:21:12 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 06:21:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 06:21:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 06:21:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:23:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:23:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:23:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:23:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:23:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:23:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:23:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:23:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:23:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:23:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:23:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:23:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:23:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:23:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:23:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:23:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:40:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:40:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:40:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:40:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:40:58 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 06:40:58 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 06:40:58 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 06:40:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 06:40:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 06:40:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:40:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:41:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:41:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:41:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:41:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:41:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:41:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:44:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:44:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:44:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:44:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:44:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:44:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:44:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:44:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:44:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:44:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:44:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:44:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:44:44 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 06:44:44 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 06:44:44 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 06:44:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 06:44:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 06:44:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:44:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:44:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:44:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:44:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:44:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:45:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:45:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:45:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:45:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:45:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:45:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:45:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:45:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:45:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:45:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:45:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:45:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:45:13 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 06:45:13 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 06:45:13 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 06:45:13 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 06:45:13 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 06:45:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:45:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:53:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:53:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:53:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:53:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:53:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:53:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:53:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:53:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:53:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:53:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:53:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:53:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:53:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:53:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:53:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:53:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:53:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:56:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:56:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:56:34 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 06:56:34 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 06:56:34 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 06:56:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 06:56:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 06:56:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:56:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:56:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:56:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:56:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:56:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:56:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:56:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:56:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:56:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:56:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:56:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 06:56:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:00:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:00:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:00:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:00:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:00:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:00:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:00:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:00:03 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 07:00:03 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 07:00:03 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 07:00:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:00:03 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:00:03 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:00:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:00:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:00:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:00:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:00:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:00:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:00:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:00:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:00:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:00:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:00:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:00:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:00:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:00:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:00:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:00:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:00:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:00:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:00:56 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 07:00:56 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 07:00:56 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 07:00:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:00:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:00:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:00:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:00:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:00:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:08 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 07:03:08 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 07:03:08 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 07:03:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:03:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:03:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:03:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:05:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:05:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:05:23 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 07:05:23 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 07:05:23 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 07:05:23 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:05:23 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:05:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:05:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:05:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:05:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:05:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:05:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:05:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:05:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:05:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:05:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:05:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:05:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:05:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:23:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:23:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:23:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:23:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:23:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:23:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:23:06 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 07:23:06 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 07:23:06 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 07:23:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:23:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:23:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:23:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:23:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:23:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:23:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:23:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:24:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:24:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:24:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:24:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:24:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:24:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:24:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:24:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:24:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:24:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:24:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:24:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:24:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:24:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:24:36 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 07:24:36 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 07:24:36 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 07:24:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:24:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:24:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:24:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:24:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:24:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:24:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:24:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:24:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:24:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:24:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:24:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:25:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:25:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:25:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:25:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:25:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:25:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:25:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:25:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:25:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:25:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:25:57 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 07:25:57 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 07:25:57 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 07:25:57 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:25:57 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:25:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:25:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:25:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:25:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:25:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:25:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:26:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:26:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:26:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:26:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:26:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:26:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:26:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:26:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:26:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:26:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:26:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:26:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:26:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:26:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:26:07 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 07:26:07 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 07:26:07 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 07:26:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:26:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:26:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:26:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:26:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:26:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:26:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:26:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:26:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:26:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:30:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:30:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:30:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:30:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:30:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:30:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:30:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:30:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:30:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:30:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:30:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:30:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:30:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:30:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:30:40 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 07:30:40 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 07:30:40 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 07:30:40 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:30:40 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:30:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:30:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:30:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:51 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 07:33:51 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 07:33:51 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 07:33:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:33:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:33:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:33:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:34:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:34:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:34:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:34:01 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 07:34:01 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 07:34:01 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 07:34:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:34:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:34:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:34:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:34:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:34:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:34:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:34:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:35:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:35:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:35:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:35:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:35:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:35:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:35:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:35:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:35:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:35:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:35:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:35:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:35:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:35:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:35:43 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 07:35:43 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 07:35:43 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 07:35:43 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:35:43 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:35:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:35:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:35:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:35:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:35:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:35:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:35:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:35:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:35:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:35:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:35:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:35:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:24 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 07:36:24 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 07:36:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 07:36:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/23 07:36:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 19 more\n",
      "23/06/23 07:36:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:46 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 07:36:46 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 07:36:46 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 07:36:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:36:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:36:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:36:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:38:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:38:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:38:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:38:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:38:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:38:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:38:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:38:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:38:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:38:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:38:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:38:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:38:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:38:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:38:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:38:42 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 07:38:42 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 07:38:42 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 07:38:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:38:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:38:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:43:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:43:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:43:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:43:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:43:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:43:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:43:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:43:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:43:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:43:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:43:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:43:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:43:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:43:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:43:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:43:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:14 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 07:45:14 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 07:45:14 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 07:45:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:45:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:45:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:24 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 07:45:24 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 07:45:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 07:45:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:45:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:45:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:36 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 07:45:36 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 07:45:36 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 07:45:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:45:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:45:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:45:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:47:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:47:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:47:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:47:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:47:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:47:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:47:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:47:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:47:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:47:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:47:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:47:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:47:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:47:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:47:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:02 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 07:53:02 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 07:53:02 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 07:53:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:53:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:53:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:12 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 07:53:12 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 07:53:12 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 07:53:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:53:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:53:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:30 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 07:53:30 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 07:53:30 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 07:53:30 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:53:30 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:53:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:53:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:56:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:56:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:56:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:56:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:56:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:56:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:56:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:56:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:56:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:56:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:56:30 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 07:56:30 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 07:56:30 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 07:56:30 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:56:30 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 07:56:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:56:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:56:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:56:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:56:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 07:56:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:02:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:02:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:02:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:02:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:02:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:02:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:02:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:02:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:02:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:02:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:02:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:02:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:02:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:02:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:02:54 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 08:02:54 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 08:02:54 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 08:02:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 08:02:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 08:02:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:02:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:11:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:11:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:11:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:11:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:11:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:11:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:11:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:11:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:11:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:11:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:11:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:11:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:11:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:11:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:11:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:11:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:21:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:21:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:21:15 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 08:21:15 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 08:21:15 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 08:21:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 08:21:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 08:21:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:21:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:21:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:21:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:21:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:21:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:21:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:21:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:21:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:21:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:21:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:21:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:21:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:21:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:25:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:25:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:25:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:25:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:25:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:25:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:25:57 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 08:25:57 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 08:25:57 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 08:25:57 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 08:25:57 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 08:25:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:25:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:25:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:25:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:26:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:26:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:26:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:26:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:26:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:26:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:26:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:26:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:26:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:26:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:26:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:26:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:26:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:26:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:26:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:26:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:26:07 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 08:26:07 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 08:26:07 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 08:26:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 08:26:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 08:26:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:26:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:26:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:26:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:26:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:26:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:26:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:26:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:26:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:26:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:32 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 08:28:32 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 08:28:32 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 08:28:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 08:28:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 08:28:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:42 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 08:28:42 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 08:28:42 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 08:28:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 08:28:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 08:28:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:52 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 08:28:52 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 08:28:52 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 08:28:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 08:28:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 08:28:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:28:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:02 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 08:29:02 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 08:29:02 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 08:29:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 08:29:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 08:29:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:12 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 08:29:12 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 08:29:12 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 08:29:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 08:29:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 08:29:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:22 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 08:29:22 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 08:29:22 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 08:29:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 08:29:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 08:29:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:32 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 08:29:32 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 08:29:32 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 08:29:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 08:29:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 08:29:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:29:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:45:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:45:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:45:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:45:27 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 08:45:27 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 08:45:27 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 08:45:27 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 08:45:27 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 08:45:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:45:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:45:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:45:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:45:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:45:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:45:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:45:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 08:45:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:02:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:02:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:02:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:02:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:02:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:02:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:02:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:02:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:02:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:02:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:02:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:17:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:17:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:17:41 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 09:17:41 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 09:17:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 09:17:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 09:17:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 09:17:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:17:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:17:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:17:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:17:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:17:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:17:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:17:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:17:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:33:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:33:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:33:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:33:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:33:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:33:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:33:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:33:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:33:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:33:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:33:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:33:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:50:07 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 09:50:07 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 09:50:07 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 09:50:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 09:50:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 09:50:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:50:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:50:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:50:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:50:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:50:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:50:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:50:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:50:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:50:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 09:50:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:07:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:07:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:07:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:07:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:07:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:07:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:07:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:07:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:07:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:07:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:07:12 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 10:07:12 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 10:07:12 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 10:07:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 10:07:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 10:07:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:24:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:24:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:24:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:24:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:24:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:24:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:25:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:25:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:25:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:25:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:25:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:40:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:40:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:40:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:40:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:40:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:40:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:41:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:41:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:41:00 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 10:41:00 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 10:41:00 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 10:41:00 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 10:41:00 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 10:41:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:41:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:41:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:41:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:41:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:41:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:58:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:58:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:58:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:58:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:58:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:58:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:58:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:58:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:58:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:58:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:58:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 10:58:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:13:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:13:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:13:44 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 11:13:44 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 11:13:44 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 11:13:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 11:13:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 11:13:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:13:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:13:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:13:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:13:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:13:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:13:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:13:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:13:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:13:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:30:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:30:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:30:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:30:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:30:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:30:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:30:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:30:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:30:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:30:59 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 11:30:59 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 11:30:59 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 11:30:59 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 11:30:59 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 11:30:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:31:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:48:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:48:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:48:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:48:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:48:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:48:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:48:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:48:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:48:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:48:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:48:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:48:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:48:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 11:48:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:04:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:04:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:04:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:04:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:04:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:04:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:04:14 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 12:04:14 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 12:04:14 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 12:04:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 12:04:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 12:04:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:04:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:04:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:04:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:04:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:04:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:04:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:04:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:20:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:20:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:20:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:20:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:20:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:20:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:20:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:20:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:20:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:20:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:20:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:20:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:20:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:20:47 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 12:20:47 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 12:20:47 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 12:20:47 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 12:20:47 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 12:38:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:38:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:38:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:38:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:38:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:38:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:38:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:38:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:38:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:38:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:38:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:38:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:38:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:38:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:55:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:55:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:55:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:55:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:55:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:55:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:55:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:55:16 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 12:55:16 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 12:55:16 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 12:55:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 12:55:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 12:55:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:55:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:55:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:55:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 12:55:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:12:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:12:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:12:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:12:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:12:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:12:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:12:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:12:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:12:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:12:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:12:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:12:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:12:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:35 INFO Executor: Told to re-register on heartbeat\n",
      "23/06/23 13:28:35 INFO BlockManager: BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None) re-registering with master\n",
      "23/06/23 13:28:35 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.4.24, 51040, None)\n",
      "23/06/23 13:28:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 13:28:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:643)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1057)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:238)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:593)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:592)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:630)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.4.24:51039\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/06/23 13:28:35 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n",
      "23/06/23 13:28:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:45 INFO SparkContext: Invoking stop() from shutdown hook\n",
      "23/06/23 13:28:45 INFO SparkUI: Stopped Spark web UI at http://192.168.4.24:4040\n",
      "23/06/23 13:28:45 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\n",
      "23/06/23 13:28:45 INFO MemoryStore: MemoryStore cleared\n",
      "23/06/23 13:28:45 INFO BlockManager: BlockManager stopped\n",
      "23/06/23 13:28:45 INFO BlockManagerMaster: BlockManagerMaster stopped\n",
      "23/06/23 13:28:45 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\n",
      "23/06/23 13:28:45 INFO SparkContext: Successfully stopped SparkContext\n",
      "23/06/23 13:28:45 INFO ShutdownHookManager: Shutdown hook called\n",
      "23/06/23 13:28:45 INFO ShutdownHookManager: Deleting directory /private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/spark-0d03f05a-75fd-4cab-af23-ba9a0c97b7c7/pyspark-043b407a-c1cd-4624-afa5-1d1c29e81944\n",
      "23/06/23 13:28:45 INFO ShutdownHookManager: Deleting directory /private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c\n",
      "23/06/23 13:28:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:45 INFO ShutdownHookManager: Deleting directory /private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/spark-0d03f05a-75fd-4cab-af23-ba9a0c97b7c7/pyspark-92fb3c49-a7dd-4c46-aafb-c15f81dd1ca5\n",
      "23/06/23 13:28:45 INFO ShutdownHookManager: Deleting directory /private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/spark-3fbf98c1-aa02-4765-9b77-2b8396503d1e\n",
      "23/06/23 13:28:45 INFO ShutdownHookManager: Deleting directory /private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-87a9e2b6-9538-43b0-9519-48c3dc8834df\n",
      "23/06/23 13:28:45 INFO ShutdownHookManager: Deleting directory /private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/spark-0d03f05a-75fd-4cab-af23-ba9a0c97b7c7\n",
      "23/06/23 13:28:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:28:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:29:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:46:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:46:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:46:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:46:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:46:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:46:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:46:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:46:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:46:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:46:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:46:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:46:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:46:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 13:46:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:40 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:41 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:43 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:03:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:34 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:04:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:06:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:06:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:06:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:06:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:06:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:06:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:06:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:06:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:06:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:06:56 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:06:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:06:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:06:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:06:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:06:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:06:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:07:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:23:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:23:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:23:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:23:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:23:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:23:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:23:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:23:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:23:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:23:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:23:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:23:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:40:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:40:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:40:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:40:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:40:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:40:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:40:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:40:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:40:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:40:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:40:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:55:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:55:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:55:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:55:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:55:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:55:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:55:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:55:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:55:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:55:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 14:55:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:10:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:10:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:10:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:10:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:10:59 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:11:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:11:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:11:01 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:11:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:11:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:11:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:11:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:26:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:26:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:26:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:26:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:26:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:26:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:26:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:26:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:26:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:26:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:26:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:41:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:41:35 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:41:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:41:36 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:41:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:41:37 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:41:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:41:38 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:41:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:41:39 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:57:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:57:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:57:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:57:09 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:57:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:57:10 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:57:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:57:11 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:57:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:57:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 15:57:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 16:15:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 16:15:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 16:15:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 16:15:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 16:15:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 16:15:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 16:15:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 16:15:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 16:15:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 16:15:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 16:31:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 16:31:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 16:31:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 16:31:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 16:31:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 16:31:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 16:31:50 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 16:31:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 16:31:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 16:31:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 16:31:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 16:49:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 16:49:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 16:49:02 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 16:49:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 16:49:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 16:49:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 16:49:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 16:49:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 16:49:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 16:49:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 16:49:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:04:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:04:44 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:04:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:04:45 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:04:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:04:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:04:46 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:04:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:04:47 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:04:48 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:04:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:04:49 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:21:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:21:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:21:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:21:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:21:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:21:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:21:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:21:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:21:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:21:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:21:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:21:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:39:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:39:03 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:39:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:39:04 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:39:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:39:05 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:39:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:39:06 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:39:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:39:07 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:39:08 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:55:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:55:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:55:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:55:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:55:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:55:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:55:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:55:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:55:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:55:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:55:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 17:55:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:13:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:13:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:13:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:13:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:13:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:13:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:13:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:13:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:13:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:13:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:13:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:29:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:29:51 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:29:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:29:52 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:29:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:29:53 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:29:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:29:54 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:29:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:29:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:29:55 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:46:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:46:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:46:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:46:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:46:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:46:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:46:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:46:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:46:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:46:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 18:46:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:03:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:03:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:03:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:03:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:03:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:03:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:03:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:03:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:03:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:03:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:03:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:03:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:14:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:14:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:14:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:14:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:14:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:14:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:14:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:14:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:14:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:14:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:14:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:14:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:14:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:14:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:14:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:14:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:14:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:14:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:14:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:14:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:14:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:14:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:14:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:14:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:12 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:13 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:14 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:15 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:16 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:17 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:18 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:19 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:20 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:21 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:22 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:23 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:24 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:25 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:26 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:27 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:28 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:29 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:30 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:31 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:32 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0-53, groupId=spark-kafka-source-2dddb316-bacd-4c13-8f6c-9f3fb9aad032--2001384727-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n",
      "23/06/23 19:30:33 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Connection to node 1 (/127.0.0.1:9092) could not be established. Broker may not be available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicburkett/opt/anaconda3/envs/spark/lib/python3.11/site-packages/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicburkett/opt/anaconda3/envs/spark/lib/python3.11/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nicburkett/opt/anaconda3/envs/spark/lib/python3.11/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o1447.awaitTermination",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 75\u001b[0m\n\u001b[1;32m     64\u001b[0m gcs_bigquery_stream \u001b[39m=\u001b[39m df2\u001b[39m.\u001b[39mwriteStream \\\n\u001b[1;32m     65\u001b[0m     \u001b[39m.\u001b[39mformat(\u001b[39m\"\u001b[39m\u001b[39mbigquery\u001b[39m\u001b[39m\"\u001b[39m) \\\n\u001b[1;32m     66\u001b[0m     \u001b[39m.\u001b[39mtrigger(processingTime\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m10 seconds\u001b[39m\u001b[39m\"\u001b[39m) \\\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[39m.\u001b[39moption(\u001b[39m\"\u001b[39m\u001b[39mmode\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFAILFAST\u001b[39m\u001b[39m\"\u001b[39m) \\\n\u001b[1;32m     71\u001b[0m     \u001b[39m.\u001b[39mstart()\n\u001b[1;32m     73\u001b[0m     \u001b[39m# .option(\"failOnDataLoss\",'false') \\\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m gcs_bigquery_stream\u001b[39m.\u001b[39;49mawaitTermination()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/spark/lib/python3.11/site-packages/pyspark/sql/streaming/query.py:201\u001b[0m, in \u001b[0;36mStreamingQuery.awaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jsq\u001b[39m.\u001b[39mawaitTermination(\u001b[39mint\u001b[39m(timeout \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m))\n\u001b[1;32m    200\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jsq\u001b[39m.\u001b[39;49mawaitTermination()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/spark/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/spark/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:169\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdeco\u001b[39m(\u001b[39m*\u001b[39ma: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    168\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49ma, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    170\u001b[0m     \u001b[39mexcept\u001b[39;00m Py4JJavaError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    171\u001b[0m         converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/spark/lib/python3.11/site-packages/py4j/protocol.py:334\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[39mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m. Trace:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{3}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[1;32m    332\u001b[0m                 \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name, value))\n\u001b[1;32m    333\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m         \u001b[39mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    335\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[1;32m    336\u001b[0m             \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name))\n\u001b[1;32m    337\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[39mtype\u001b[39m \u001b[39m=\u001b[39m answer[\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o1447.awaitTermination"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicburkett/opt/anaconda3/envs/spark/lib/python3.11/site-packages/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicburkett/opt/anaconda3/envs/spark/lib/python3.11/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nicburkett/opt/anaconda3/envs/spark/lib/python3.11/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    }
   ],
   "source": [
    "##### STREAMING DATA PROCESSING #####\n",
    "\n",
    "# Read the data from kafka\n",
    "df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "    .option(\"subscribe\", topic_name) \\\n",
    "    .option(\"startingOffsets\", \"latest\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .load() \\\n",
    "    .selectExpr(\"CAST(value AS STRING)\")\n",
    "    \n",
    "# Apply deserialization or further processing if needed\n",
    "df1 = df.withColumn(\"parsed_data\", from_json(\"value\", schema))\n",
    "\n",
    "### DATA TYPE CONVERSIONS ####\n",
    "# Extract and convert the \"venue_zipcode\" as Integer\n",
    "# df1 = df1.withColumn(\"venue_zipcode\", col(\"parsed_data.venue_zipcode\").cast(IntegerType()))\n",
    "# # Extract and convert the coordinates as Double\n",
    "# df1 = df1.withColumn(\"venue_longitude\", col(\"parsed_data.venue_longitude\").cast(DoubleType()))\n",
    "# df1 = df1.withColumn(\"venue_latitude\", col(\"parsed_data.venue_latitude\").cast(DoubleType()))\n",
    "# # Extract and Convert the event_start_date as Date \n",
    "# df1 = df1.withColumn(\"event_start_date\", col(\"parsed_data.event_start_date\").cast(DateType()))\n",
    "\n",
    "df2 = df1.select(\"parsed_data.*\")\n",
    "\n",
    "\n",
    "df2.printSchema()\n",
    "\n",
    "path = '/Users/nicburkett/Desktop/spark_output'\n",
    "\n",
    "\n",
    "# # # Write to a local file\n",
    "# # file_query = df2.writeStream \\\n",
    "# #     .format(\"csv\") \\\n",
    "# #     .outputMode(\"append\") \\\n",
    "# #     .option(\"header\", \"true\") \\\n",
    "# #     .option(\"checkpointLocation\", path) \\\n",
    "# #     .trigger(processingTime=\"10 seconds\") \\\n",
    "# #     .start(path)\n",
    "\n",
    "# # # WRITE TO GCS BUCKET \n",
    "# gcs_write = df2.writeStream \\\n",
    "#     .format(\"csv\") \\\n",
    "#     .outputMode(\"append\") \\\n",
    "#     .option(\"path\",\"gs://kafka-spark-data/raw-spark-data\") \\\n",
    "#     .option(\"checkpointLocation\", \"gs://kafka-spark-data/spark-metadata\") \\\n",
    "#     .trigger(processingTime=\"10 seconds\") \\\n",
    "#     .start() \n",
    "\n",
    "# gcs_write.awaitTermination()\n",
    "\n",
    "# WRITE TO CONSOLE TO LOG \n",
    "# console_query = df2.writeStream \\\n",
    "#     .format(\"console\") \\\n",
    "#     .outputMode(\"append\") \\\n",
    "#     .trigger(processingTime=\"10 seconds\") \\\n",
    "#     .start() \\\n",
    "#     .awaitTermination()\n",
    "\n",
    "    # .foreachBatch(write_batch) \\\n",
    "\n",
    "gcs_bigquery_stream = df2.writeStream \\\n",
    "    .format(\"bigquery\") \\\n",
    "    .trigger(processingTime=\"10 seconds\") \\\n",
    "    .option(\"checkpointLocation\", gcs_metadata_folder) \\\n",
    "    .option(\"temporaryGcsBucket\", 'kafka-spark-data') \\\n",
    "    .option(\"table\",'global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark') \\\n",
    "    .option(\"mode\", \"FAILFAST\") \\\n",
    "    .start()\n",
    "\n",
    "    # .option(\"failOnDataLoss\",'false') \\\n",
    "\n",
    "gcs_bigquery_stream.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 20:39:55 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "23/06/22 20:39:55 INFO ResolveWriteToStream: Checkpoint root /private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c resolved to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c.\n",
      "23/06/22 20:39:55 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "23/06/22 20:39:55 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/metadata using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/.metadata.db73f13d-0540-4f6f-bd8a-73b3b535ef60.tmp\n",
      "23/06/22 20:39:55 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/.metadata.db73f13d-0540-4f6f-bd8a-73b3b535ef60.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/metadata\n",
      "23/06/22 20:39:55 INFO MicroBatchExecution: Starting [id = 5ff3f0d9-8649-4084-a0de-9c984d47f474, runId = 061d6392-20e9-47dc-a164-da2a57f51557]. Use file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c to store the query checkpoint.\n",
      "23/06/22 20:39:55 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3ffa2c25] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@313dc472]\n",
      "23/06/22 20:39:55 INFO MicroBatchExecution: Starting new streaming query.\n",
      "23/06/22 20:39:55 INFO MicroBatchExecution: Stream started from {}\n",
      "23/06/22 20:39:55 INFO ConsumerConfig: ConsumerConfig values: \n",
      "\tallow.auto.create.topics = true\n",
      "\tauto.commit.interval.ms = 5000\n",
      "\tauto.offset.reset = earliest\n",
      "\tbootstrap.servers = [localhost:9092]\n",
      "\tcheck.crcs = true\n",
      "\tclient.dns.lookup = use_all_dns_ips\n",
      "\tclient.id = consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33\n",
      "\tclient.rack = \n",
      "\tconnections.max.idle.ms = 540000\n",
      "\tdefault.api.timeout.ms = 60000\n",
      "\tenable.auto.commit = false\n",
      "\texclude.internal.topics = true\n",
      "\tfetch.max.bytes = 52428800\n",
      "\tfetch.max.wait.ms = 500\n",
      "\tfetch.min.bytes = 1\n",
      "\tgroup.id = spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0\n",
      "\tgroup.instance.id = null\n",
      "\theartbeat.interval.ms = 3000\n",
      "\tinterceptor.classes = []\n",
      "\tinternal.leave.group.on.close = true\n",
      "\tinternal.throw.on.fetch.stable.offset.unsupported = false\n",
      "\tisolation.level = read_uncommitted\n",
      "\tkey.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer\n",
      "\tmax.partition.fetch.bytes = 1048576\n",
      "\tmax.poll.interval.ms = 300000\n",
      "\tmax.poll.records = 1\n",
      "\tmetadata.max.age.ms = 300000\n",
      "\tmetric.reporters = []\n",
      "\tmetrics.num.samples = 2\n",
      "\tmetrics.recording.level = INFO\n",
      "\tmetrics.sample.window.ms = 30000\n",
      "\tpartition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]\n",
      "\treceive.buffer.bytes = 65536\n",
      "\treconnect.backoff.max.ms = 1000\n",
      "\treconnect.backoff.ms = 50\n",
      "\trequest.timeout.ms = 30000\n",
      "\tretry.backoff.ms = 100\n",
      "\tsasl.client.callback.handler.class = null\n",
      "\tsasl.jaas.config = null\n",
      "\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n",
      "\tsasl.kerberos.min.time.before.relogin = 60000\n",
      "\tsasl.kerberos.service.name = null\n",
      "\tsasl.kerberos.ticket.renew.jitter = 0.05\n",
      "\tsasl.kerberos.ticket.renew.window.factor = 0.8\n",
      "\tsasl.login.callback.handler.class = null\n",
      "\tsasl.login.class = null\n",
      "\tsasl.login.refresh.buffer.seconds = 300\n",
      "\tsasl.login.refresh.min.period.seconds = 60\n",
      "\tsasl.login.refresh.window.factor = 0.8\n",
      "\tsasl.login.refresh.window.jitter = 0.05\n",
      "\tsasl.mechanism = GSSAPI\n",
      "\tsecurity.protocol = PLAINTEXT\n",
      "\tsecurity.providers = null\n",
      "\tsend.buffer.bytes = 131072\n",
      "\tsession.timeout.ms = 10000\n",
      "\tssl.cipher.suites = null\n",
      "\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n",
      "\tssl.endpoint.identification.algorithm = https\n",
      "\tssl.engine.factory.class = null\n",
      "\tssl.key.password = null\n",
      "\tssl.keymanager.algorithm = SunX509\n",
      "\tssl.keystore.location = null\n",
      "\tssl.keystore.password = null\n",
      "\tssl.keystore.type = JKS\n",
      "\tssl.protocol = TLSv1.3\n",
      "\tssl.provider = null\n",
      "\tssl.secure.random.implementation = null\n",
      "\tssl.trustmanager.algorithm = PKIX\n",
      "\tssl.truststore.location = null\n",
      "\tssl.truststore.password = null\n",
      "\tssl.truststore.type = JKS\n",
      "\tvalue.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer\n",
      "\n",
      "23/06/22 20:39:55 INFO AppInfoParser: Kafka version: 2.6.0\n",
      "23/06/22 20:39:55 INFO AppInfoParser: Kafka commitId: 62abe01bee039651\n",
      "23/06/22 20:39:55 INFO AppInfoParser: Kafka startTimeMs: 1687484395268\n",
      "23/06/22 20:39:55 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Subscribed to topic(s): ticketmaster\n",
      "23/06/22 20:39:55 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Cluster ID: kJYfpPSDQYKOEac6knVYNg\n",
      "23/06/22 20:39:55 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Discovered group coordinator 127.0.0.1:9092 (id: 2147483646 rack: null)\n",
      "23/06/22 20:39:55 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] (Re-)joining group\n",
      "23/06/22 20:39:55 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group.\n",
      "23/06/22 20:39:55 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] (Re-)joining group\n",
      "23/06/22 20:39:58 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Finished assignment for group at generation 1: {consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33-d918989d-4970-4a0d-ba8b-2562fc284fa0=Assignment(partitions=[ticketmaster-0])}\n",
      "23/06/22 20:39:58 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Successfully joined group with generation 1\n",
      "23/06/22 20:39:58 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Notifying assignor about the new Assignment(partitions=[ticketmaster-0])\n",
      "23/06/22 20:39:58 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Adding newly assigned partitions: ticketmaster-0\n",
      "23/06/22 20:39:58 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Found no committed offset for partition ticketmaster-0\n",
      "23/06/22 20:39:58 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 20:39:58 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 20:39:58 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 1393.\n",
      "23/06/22 20:39:58 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/sources/0/0 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/sources/0/.0.b96c1db1-6d54-4d9e-97a6-2e84101f2c29.tmp\n",
      "23/06/22 20:39:58 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/sources/0/.0.b96c1db1-6d54-4d9e-97a6-2e84101f2c29.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/sources/0/0\n",
      "23/06/22 20:39:58 INFO KafkaMicroBatchStream: Initial offsets: {\"ticketmaster\":{\"0\":1393}}\n",
      "23/06/22 20:39:58 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 20:39:58 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 1393.\n",
      "23/06/22 20:39:58 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/0 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.0.904f4124-92b7-4b34-8879-a7b63ce929a5.tmp\n",
      "23/06/22 20:39:58 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.0.904f4124-92b7-4b34-8879-a7b63ce929a5.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/0\n",
      "23/06/22 20:39:58 INFO MicroBatchExecution: Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1687484398424,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 20:39:58 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 20:39:58 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 20:39:58 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 20:39:58 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 20:39:58 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 20:39:58 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 20:39:58 INFO WriteToDataSourceV2Exec: Start processing data source write support: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@7349b08. The input RDD has 1 partitions.\n",
      "23/06/22 20:39:58 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 20:39:58 INFO DAGScheduler: Got job 12 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 20:39:58 INFO DAGScheduler: Final stage: ResultStage 13 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 20:39:58 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 20:39:58 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 20:39:58 INFO DAGScheduler: Submitting ResultStage 13 (ParallelCollectionRDD[113] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 20:39:58 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 3.2 KiB, free 434.0 MiB)\n",
      "23/06/22 20:39:58 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 1987.0 B, free 434.0 MiB)\n",
      "23/06/22 20:39:58 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 192.168.4.24:51040 (size: 1987.0 B, free: 434.3 MiB)\n",
      "23/06/22 20:39:58 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 20:39:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (ParallelCollectionRDD[113] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 20:39:58 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0\n",
      "23/06/22 20:39:58 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 12) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 4474 bytes) taskResourceAssignments Map()\n",
      "23/06/22 20:39:58 INFO Executor: Running task 0.0 in stage 13.0 (TID 12)\n",
      "23/06/22 20:39:58 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 12, attempt 0, stage 13.0)\n",
      "23/06/22 20:39:58 INFO DataWritingSparkTask: Committed partition 0 (task 12, attempt 0, stage 13.0)\n",
      "23/06/22 20:39:58 INFO Executor: Finished task 0.0 in stage 13.0 (TID 12). 1119 bytes result sent to driver\n",
      "23/06/22 20:39:58 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 12) in 3 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 20:39:58 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool \n",
      "23/06/22 20:39:58 INFO DAGScheduler: ResultStage 13 (start at NativeMethodAccessorImpl.java:0) finished in 0.008 s\n",
      "23/06/22 20:39:58 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 20:39:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished\n",
      "23/06/22 20:39:58 INFO DAGScheduler: Job 12 finished: start at NativeMethodAccessorImpl.java:0, took 0.008294 s\n",
      "23/06/22 20:39:58 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@7349b08 is committing.\n",
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+----------+----------+--------+---------+----------+--------+-------------+---------------+----------+----------------+-----------------+------------------+-------------------+-------------+---------------+--------------+---------------+---------------+-------------+--------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|event_name|event_type|event_id|event_url|venue_name|venue_id|venue_zipcode|venues_timezone|venue_city|venue_state_full|venue_state_short|venue_country_name|venue_country_short|venue_address|venue_longitude|venue_latitude|attraction_name|attraction_type|attraction_id|attraction_url|attraction_segment_id|attraction_segment_name|attraction_genre_id|attraction_genre_name|attraction_subgenre_id|attraction_subgenre_name|event_start_date|ticket_status|event_start_time|currency|min_price|max_price|\n",
      "+----------+----------+--------+---------+----------+--------+-------------+---------------+----------+----------------+-----------------+------------------+-------------------+-------------+---------------+--------------+---------------+---------------+-------------+--------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "+----------+----------+--------+---------+----------+--------+-------------+---------------+----------+----------------+-----------------+------------------+-------------------+-------------+---------------+--------------+---------------+---------------+-------------+--------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "\n",
      "23/06/22 20:39:58 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@7349b08 committed.\n",
      "23/06/22 20:39:58 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/0 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.0.22f41be0-96af-4b58-8140-35d6003cf105.tmp\n",
      "23/06/22 20:39:58 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.0.22f41be0-96af-4b58-8140-35d6003cf105.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/0\n",
      "23/06/22 20:39:58 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T01:39:55.254Z\",\n",
      "  \"batchId\" : 0,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 27,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 3170,\n",
      "    \"queryPlanning\" : 5,\n",
      "    \"triggerExecution\" : 3318,\n",
      "    \"walCommit\" : 57\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : null,\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1393\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 0\n",
      "  }\n",
      "}\n",
      "23/06/22 20:40:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 20:40:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 1393.\n",
      "23/06/22 20:40:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 20:40:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 1393.\n",
      "23/06/22 20:40:10 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T01:40:10.005Z\",\n",
      "  \"batchId\" : 1,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 3,\n",
      "    \"triggerExecution\" : 3\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1393\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1393\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 0\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicburkett/opt/anaconda3/envs/spark/lib/python3.11/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nicburkett/opt/anaconda3/envs/spark/lib/python3.11/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nicburkett/opt/anaconda3/envs/spark/lib/python3.11/socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# WRITE TO CONSOLE TO LOG \u001b[39;00m\n\u001b[1;32m      2\u001b[0m console_query \u001b[39m=\u001b[39m df2\u001b[39m.\u001b[39;49mwriteStream \\\n\u001b[1;32m      3\u001b[0m     \u001b[39m.\u001b[39;49mformat(\u001b[39m\"\u001b[39;49m\u001b[39mconsole\u001b[39;49m\u001b[39m\"\u001b[39;49m) \\\n\u001b[1;32m      4\u001b[0m     \u001b[39m.\u001b[39;49moutputMode(\u001b[39m\"\u001b[39;49m\u001b[39mappend\u001b[39;49m\u001b[39m\"\u001b[39;49m) \\\n\u001b[1;32m      5\u001b[0m     \u001b[39m.\u001b[39;49mtrigger(processingTime\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m10 seconds\u001b[39;49m\u001b[39m\"\u001b[39;49m) \\\n\u001b[1;32m      6\u001b[0m     \u001b[39m.\u001b[39;49mstart() \\\n\u001b[0;32m----> 7\u001b[0m     \u001b[39m.\u001b[39;49mawaitTermination()\n\u001b[1;32m      9\u001b[0m     \u001b[39m# .foreachBatch(write_batch) \\\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/spark/lib/python3.11/site-packages/pyspark/sql/streaming/query.py:201\u001b[0m, in \u001b[0;36mStreamingQuery.awaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jsq\u001b[39m.\u001b[39mawaitTermination(\u001b[39mint\u001b[39m(timeout \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m))\n\u001b[1;32m    200\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jsq\u001b[39m.\u001b[39;49mawaitTermination()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/spark/lib/python3.11/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_args(\u001b[39m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/spark/lib/python3.11/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1039\u001b[0m     \u001b[39mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[39mreturn\u001b[39;00m response, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/spark/lib/python3.11/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[39m=\u001b[39m smart_decode(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream\u001b[39m.\u001b[39mreadline()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mAnswer received: \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[39m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[39m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/spark/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 20:40:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 20:40:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 1393.\n",
      "23/06/22 20:40:20 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T01:40:20.005Z\",\n",
      "  \"batchId\" : 1,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 10,\n",
      "    \"triggerExecution\" : 12\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1393\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1393\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 0\n",
      "  }\n",
      "}\n",
      "23/06/22 20:40:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 20:40:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 1393.\n",
      "23/06/22 20:40:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 20:40:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 1393.\n",
      "23/06/22 20:40:40 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T01:40:40.003Z\",\n",
      "  \"batchId\" : 1,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 4,\n",
      "    \"triggerExecution\" : 4\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1393\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1393\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 0\n",
      "  }\n",
      "}\n",
      "23/06/22 20:40:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 20:40:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 1393.\n",
      "23/06/22 20:41:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 20:41:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 1393.\n",
      "23/06/22 20:41:00 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T01:41:00.004Z\",\n",
      "  \"batchId\" : 1,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 11,\n",
      "    \"triggerExecution\" : 11\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1393\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1393\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 0\n",
      "  }\n",
      "}\n",
      "23/06/22 20:41:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 20:41:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 1393.\n",
      "23/06/22 20:41:10 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T01:41:10.006Z\",\n",
      "  \"batchId\" : 1,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 13,\n",
      "    \"triggerExecution\" : 13\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1393\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1393\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 0\n",
      "  }\n",
      "}\n",
      "23/06/22 20:41:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 20:41:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 1393.\n"
     ]
    }
   ],
   "source": [
    "# WRITE TO CONSOLE TO LOG \n",
    "console_query = df2.writeStream \\\n",
    "    .format(\"console\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .trigger(processingTime=\"10 seconds\") \\\n",
    "    .start() \\\n",
    "    .awaitTermination()\n",
    "\n",
    "    # .foreachBatch(write_batch) \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/19 19:50:27 INFO FetchSessionHandler: [Consumer clientId=consumer-spark-kafka-source-d2941ca6-4ad1-48ba-bda3-65af4267d63f--2001384727-executor-9, groupId=spark-kafka-source-d2941ca6-4ad1-48ba-bda3-65af4267d63f--2001384727-executor] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1001:\n",
      "org.apache.kafka.common.errors.TimeoutException: Failed to send request after 30000 ms.\n",
      "23/06/19 19:50:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-d2941ca6-4ad1-48ba-bda3-65af4267d63f--2001384727-executor-9, groupId=spark-kafka-source-d2941ca6-4ad1-48ba-bda3-65af4267d63f--2001384727-executor] Connection to node 1001 (host.docker.internal/143.244.220.150:9092) could not be established. Broker may not be available.\n",
      "23/06/19 19:50:42 INFO FetchSessionHandler: [Consumer clientId=consumer-spark-kafka-source-d2941ca6-4ad1-48ba-bda3-65af4267d63f--2001384727-executor-9, groupId=spark-kafka-source-d2941ca6-4ad1-48ba-bda3-65af4267d63f--2001384727-executor] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1001:\n",
      "org.apache.kafka.common.errors.DisconnectException\n",
      "23/06/19 19:51:12 INFO FetchSessionHandler: [Consumer clientId=consumer-spark-kafka-source-d2941ca6-4ad1-48ba-bda3-65af4267d63f--2001384727-executor-9, groupId=spark-kafka-source-d2941ca6-4ad1-48ba-bda3-65af4267d63f--2001384727-executor] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1001:\n",
      "org.apache.kafka.common.errors.TimeoutException: Failed to send request after 30000 ms.\n",
      "23/06/19 19:51:27 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-d2941ca6-4ad1-48ba-bda3-65af4267d63f--2001384727-executor-9, groupId=spark-kafka-source-d2941ca6-4ad1-48ba-bda3-65af4267d63f--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/19 19:51:42 INFO FetchSessionHandler: [Consumer clientId=consumer-spark-kafka-source-d2941ca6-4ad1-48ba-bda3-65af4267d63f--2001384727-executor-9, groupId=spark-kafka-source-d2941ca6-4ad1-48ba-bda3-65af4267d63f--2001384727-executor] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1001:\n",
      "org.apache.kafka.common.errors.TimeoutException: Failed to send request after 30000 ms.\n",
      "23/06/19 19:51:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-d2941ca6-4ad1-48ba-bda3-65af4267d63f--2001384727-executor-9, groupId=spark-kafka-source-d2941ca6-4ad1-48ba-bda3-65af4267d63f--2001384727-executor] Connection to node 1001 (host.docker.internal/143.244.220.150:9092) could not be established. Broker may not be available.\n"
     ]
    }
   ],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## BATCH DATA PROCESSING \n",
    "\n",
    "df = spark \\\n",
    "  .read \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "  .option(\"subscribe\", topic_name) \\\n",
    "  .load()\\\n",
    "  .selectExpr(\"CAST(value AS STRING)\")\n",
    "\n",
    "# Apply deserialization or further processing if needed\n",
    "df1 = df.withColumn(\"parsed_data\", from_json(\"value\", schema))\n",
    "## Select the data from the parsed_data column\n",
    "df2 = df1.select(\"parsed_data.*\")\n",
    "\n",
    "gcs_metadata_folder = \"gs://kafka-spark-data/spark-metadata\"\n",
    "gcs_data_folder = \"gs://kafka-spark-data/raw-spark-data\"\n",
    "\n",
    "print(df2.schema)\n",
    "\n",
    "## WRITE TO LOCAL STORAGE\n",
    "# gcs_write = df2.write \\\n",
    "#   .format(\"csv\") \\\n",
    "#   .option(\"checkpointLocation\", \"/Users/nicburkett/Desktop/spark_output\") \\\n",
    "#   .option(\"path\",\"/Users/nicburkett/Desktop/spark_output\") \\\n",
    "#   .mode(\"overwrite\")\\\n",
    "#   .save()\n",
    "\n",
    "##WRITE TO GCS BUCKET\n",
    "# gcs_write_newfolder = df2.write \\\n",
    "#   .format(\"parquet\") \\\n",
    "#   .option(\"checkpointLocation\", gcs_metadata_folder) \\\n",
    "#   .option(\"path\",gcs_data_folder) \\\n",
    "#   .mode(\"overwrite\")\\\n",
    "#   .save()\n",
    "\n",
    "\n",
    "dataset = 'global-maxim-338114.twitter_kafka_pyspark_test'\n",
    "table = 'twitter_kafka_pyspark_test'\n",
    "\n",
    "# Write the DataFrame to BigQuery\n",
    " ## this is the bucket where the data is stored temporarily\n",
    "df2.write \\\n",
    "    .format(\"bigquery\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"checkpointLocation\", gcs_metadata_folder) \\\n",
    "    .option(\"temporaryGcsBucket\", 'kafka-spark-data') \\\n",
    "    .option(\"table\",'global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark') \\\n",
    "    .option(\"mode\", \"FAILFAST\") \\\n",
    "    .save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Function to save the data to GCS with a custom filename\n",
    "def save_to_gcs(batch_df, batch_id):\n",
    "    # Convert the batch dataframe to a pandas dataframe\n",
    "    pandas_df = batch_df.toPandas()\n",
    "\n",
    "    # Get the values of the desired columns from the first row\n",
    "    column1_value = pandas_df.loc[0, \"column1\"]\n",
    "    column2_value = pandas_df.loc[0, \"column2\"]\n",
    "\n",
    "    # Get the current time\n",
    "    current_time = pd.Timestamp.now()\n",
    "\n",
    "    # Generate the custom filename\n",
    "    filename = f\"file_{column1_value}_{column2_value}_{current_time}.parquet\"\n",
    "\n",
    "    # Save the dataframe to GCS with the custom filename\n",
    "    pandas_df.to_parquet(f\"gs://{bucket_name}/{path}/{filename}\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA TYPES THOUGHOUT KAFKA SERVER\n",
    "import json\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, udf\n",
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "topic_name = 'twitter'\n",
    "# Config\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"TwitterSentimentAnalysis\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "prod = {'user_id': 19, 'recipient_id': 57, 'message': 'YbfyRHyWgjuGlzOiudEcVMLJNzqUPDvV'}\n",
    "print(type(prod))\n",
    "##convert dictionary to json string (BYTES)\n",
    "serialized_prod = json.dumps(prod).encode('utf-8')\n",
    "\n",
    "print(f'The producer dtype is {type(serialized_prod)} and output is {(serialized_prod)}')\n",
    "\n",
    "## turn from string/bytes into a dictionary again\n",
    "deserializer_function = lambda x: json.loads(x.decode('utf-8'))\n",
    "deserialized_cons = deserializer_function(serialized_prod)\n",
    "\n",
    "print(f'The producer dtype is {type(deserialized_cons)} and output is {(deserialized_cons)}')\n",
    "\n",
    "### PARSING THE JSON COMING OUT \n",
    "user_id = deserialized_cons.get('user_id')\n",
    "recipient_id = deserialized_cons.get('recipient_id')\n",
    "message = deserialized_cons.get('message')\n",
    "output_parsed = print(f'UserID: {user_id}, RecipientID: {recipient_id}, Message:{message}')\n",
    "\n",
    "\n",
    "df_pandas = pd.DataFrame([deserialized_cons])\n",
    "df_pandas\n",
    "\n",
    "\n",
    "# df_spark = spark.createDataFrame(df_pandas)\n",
    "# df_spark.show()\n",
    "\n",
    "# Create a spark schema/column headers\n",
    "schema = StructType([\n",
    "    StructField(\"user_id\", IntegerType(), True),\n",
    "    StructField(\"recipient_id\", IntegerType(), True),\n",
    "    StructField(\"message\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Create DataFrame from a single row\n",
    "# data = [(user_id, recipient_id, message)]\n",
    "df_spark = spark.createDataFrame(df_pandas,schema)\n",
    "df_spark.show()\n",
    "# df.write.csv('/path/to/output.csv', header=True, mode='overwrite')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
