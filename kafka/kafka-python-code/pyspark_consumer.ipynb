{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import findspark\n",
    "from datetime import datetime\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, udf, col, when\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType, DoubleType\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ticketmaster\n"
     ]
    }
   ],
   "source": [
    "findspark.init()\n",
    "topic_name = os.getenv('kafka_topic_name')\n",
    "\n",
    "# spark_path = findspark.find()\n",
    "# print(spark_path)\n",
    "print(topic_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials_location = os.getenv('gcp_credentials_path')\n",
    "\n",
    "# Spark Config\n",
    "conf = SparkConf() \\\n",
    "    .setMaster('local[*]') \\\n",
    "    .setAppName('TwitterSentimentAnalysis') \\\n",
    "    .set(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.2\") \\\n",
    "    .set(\"spark.jars\", \"gs://path/to/spark-bigquery-latest.jar,gs://path/to/google-cloud-bigquery-latest.jar,/path/to/local-jar-file.jar\") \\\n",
    "    .set(\"spark.hadoop.fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\") \\\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\") \\\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", credentials_location)\\\n",
    "    .set(\"spark.jars\", \"gcs-connector-hadoop3-2.2.5.jar\") \n",
    "\n",
    "\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "hadoop_conf = sc._jsc.hadoopConfiguration()\n",
    "\n",
    "hadoop_conf.set(\"fs.AbstractFileSystem.gs.impl\",  \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "hadoop_conf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "hadoop_conf.set(\"fs.gs.auth.service.account.json.keyfile\", credentials_location)\n",
    "hadoop_conf.set(\"fs.gs.auth.service.account.enable\", \"true\")\n",
    "\n",
    "# Spark Context\n",
    "# sc = spark.sparkContext\n",
    "# sc.setLogLevel('ERROR')\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .config(conf=sc.getConf()) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:00:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-driver-0-1, groupId=spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:00:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-driver-0-1, groupId=spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4833.\n",
      "23/06/24 15:00:20 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/205 using temp file gs://kafka-spark-data/spark-metadata/offsets/.205.6d021bce-9f83-4973-bbdc-70b32df0eb66.tmp\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"event_name\", StringType()),\n",
    "    StructField(\"event_type\", StringType()),\n",
    "    StructField(\"event_id\", StringType()),\n",
    "    StructField(\"event_url\", StringType()),\n",
    "    StructField(\"venue_name\", StringType()),\n",
    "    StructField(\"venue_id\", StringType()),\n",
    "    StructField(\"venue_zipcode\", StringType()),\n",
    "    StructField(\"venues_timezone\", StringType()),\n",
    "    StructField(\"venue_city\", StringType()),\n",
    "    StructField(\"venue_state_full\", StringType()),\n",
    "    StructField(\"venue_state_short\", StringType()),\n",
    "    StructField(\"venue_country_name\", StringType()),\n",
    "    StructField(\"venue_country_short\", StringType()),\n",
    "    StructField(\"venue_address\", StringType()),\n",
    "    StructField(\"venue_longitude\", StringType()),\n",
    "    StructField(\"venue_latitude\", StringType()),\n",
    "    StructField(\"attraction_name\", StringType()),\n",
    "    StructField(\"attraction_type\", StringType()),\n",
    "    StructField(\"attraction_id\", StringType()),\n",
    "    StructField(\"attraction_url\", StringType()),\n",
    "    StructField(\"attraction_segment_id\", StringType()),\n",
    "    StructField(\"attraction_segment_name\", StringType()),\n",
    "    StructField(\"attraction_genre_id\", StringType()),\n",
    "    StructField(\"attraction_genre_name\", StringType()),\n",
    "    StructField(\"attraction_subgenre_id\", StringType()),\n",
    "    StructField(\"attraction_subgenre_name\", StringType()),\n",
    "    StructField(\"event_start_date\", StringType()),\n",
    "    StructField(\"ticket_status\", StringType()),\n",
    "    StructField(\"event_start_time\", StringType()),\n",
    "    StructField(\"currency\", StringType()),\n",
    "    StructField(\"min_price\", StringType()),\n",
    "    StructField(\"max_price\", StringType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:00:21 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.205.6d021bce-9f83-4973-bbdc-70b32df0eb66.tmp to gs://kafka-spark-data/spark-metadata/offsets/205\n",
      "23/06/24 15:00:21 INFO MicroBatchExecution: Committed offsets for batch 205. Metadata OffsetSeqMetadata(0,1687636820009,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "global-maxim-338114\n",
      "kafka-spark-data\n",
      "global-maxim-338114.twitter_kafka_pyspark_test\n",
      "gs://kafka-spark-data/raw-spark-data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:00:22 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:00:22 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:00:22 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:00:22 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:00:23 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:00:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:00:23 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:00:23 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:00:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:00:23 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:00:23 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:00:23 INFO CodeGenerator: Code generated in 33.559042 ms\n",
      "23/06/24 15:00:23 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:00:23 INFO DAGScheduler: Got job 0 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:00:23 INFO DAGScheduler: Final stage: ResultStage 0 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:00:23 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:00:23 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:00:23 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:00:23 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:00:23 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:00:23 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:00:23 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:00:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:00:23 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:00:23 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:00:23 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)\n",
      "23/06/24 15:00:23 INFO CodeGenerator: Code generated in 21.670958 ms\n",
      "23/06/24 15:00:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:00:23 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:00:23 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:00:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:00:23 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:00:23 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:00:23 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:00:23 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:00:23 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:00:23 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:00:23 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:00:23 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:00:23 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:00:24 INFO CodecPool: Got brand-new compressor [.snappy]\n",
      "23/06/24 15:00:24 INFO ConsumerConfig: ConsumerConfig values: \n",
      "\tallow.auto.create.topics = true\n",
      "\tauto.commit.interval.ms = 5000\n",
      "\tauto.offset.reset = none\n",
      "\tbootstrap.servers = [localhost:9092]\n",
      "\tcheck.crcs = true\n",
      "\tclient.dns.lookup = use_all_dns_ips\n",
      "\tclient.id = consumer-spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-executor-2\n",
      "\tclient.rack = \n",
      "\tconnections.max.idle.ms = 540000\n",
      "\tdefault.api.timeout.ms = 60000\n",
      "\tenable.auto.commit = false\n",
      "\texclude.internal.topics = true\n",
      "\tfetch.max.bytes = 52428800\n",
      "\tfetch.max.wait.ms = 500\n",
      "\tfetch.min.bytes = 1\n",
      "\tgroup.id = spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-executor\n",
      "\tgroup.instance.id = null\n",
      "\theartbeat.interval.ms = 3000\n",
      "\tinterceptor.classes = []\n",
      "\tinternal.leave.group.on.close = true\n",
      "\tinternal.throw.on.fetch.stable.offset.unsupported = false\n",
      "\tisolation.level = read_uncommitted\n",
      "\tkey.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer\n",
      "\tmax.partition.fetch.bytes = 1048576\n",
      "\tmax.poll.interval.ms = 300000\n",
      "\tmax.poll.records = 500\n",
      "\tmetadata.max.age.ms = 300000\n",
      "\tmetric.reporters = []\n",
      "\tmetrics.num.samples = 2\n",
      "\tmetrics.recording.level = INFO\n",
      "\tmetrics.sample.window.ms = 30000\n",
      "\tpartition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]\n",
      "\treceive.buffer.bytes = 65536\n",
      "\treconnect.backoff.max.ms = 1000\n",
      "\treconnect.backoff.ms = 50\n",
      "\trequest.timeout.ms = 30000\n",
      "\tretry.backoff.ms = 100\n",
      "\tsasl.client.callback.handler.class = null\n",
      "\tsasl.jaas.config = null\n",
      "\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n",
      "\tsasl.kerberos.min.time.before.relogin = 60000\n",
      "\tsasl.kerberos.service.name = null\n",
      "\tsasl.kerberos.ticket.renew.jitter = 0.05\n",
      "\tsasl.kerberos.ticket.renew.window.factor = 0.8\n",
      "\tsasl.login.callback.handler.class = null\n",
      "\tsasl.login.class = null\n",
      "\tsasl.login.refresh.buffer.seconds = 300\n",
      "\tsasl.login.refresh.min.period.seconds = 60\n",
      "\tsasl.login.refresh.window.factor = 0.8\n",
      "\tsasl.login.refresh.window.jitter = 0.05\n",
      "\tsasl.mechanism = GSSAPI\n",
      "\tsecurity.protocol = PLAINTEXT\n",
      "\tsecurity.providers = null\n",
      "\tsend.buffer.bytes = 131072\n",
      "\tsession.timeout.ms = 10000\n",
      "\tssl.cipher.suites = null\n",
      "\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n",
      "\tssl.endpoint.identification.algorithm = https\n",
      "\tssl.engine.factory.class = null\n",
      "\tssl.key.password = null\n",
      "\tssl.keymanager.algorithm = SunX509\n",
      "\tssl.keystore.location = null\n",
      "\tssl.keystore.password = null\n",
      "\tssl.keystore.type = JKS\n",
      "\tssl.protocol = TLSv1.3\n",
      "\tssl.provider = null\n",
      "\tssl.secure.random.implementation = null\n",
      "\tssl.trustmanager.algorithm = PKIX\n",
      "\tssl.truststore.location = null\n",
      "\tssl.truststore.password = null\n",
      "\tssl.truststore.type = JKS\n",
      "\tvalue.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer\n",
      "\n",
      "23/06/24 15:00:24 INFO AppInfoParser: Kafka version: 2.6.0\n",
      "23/06/24 15:00:24 INFO AppInfoParser: Kafka commitId: 62abe01bee039651\n",
      "23/06/24 15:00:24 INFO AppInfoParser: Kafka startTimeMs: 1687636824171\n",
      "23/06/24 15:00:24 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-executor-2, groupId=spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-executor] Subscribed to partition(s): ticketmaster-0\n",
      "23/06/24 15:00:24 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-executor-2, groupId=spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-executor] Seeking to offset 4831 for partition ticketmaster-0\n",
      "23/06/24 15:00:24 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-executor-2, groupId=spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-executor] Cluster ID: kJYfpPSDQYKOEac6knVYNg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:00:24 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-executor-2, groupId=spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:00:24 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-executor-2, groupId=spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:00:24 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-executor-2, groupId=spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:00:24 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-executor-2, groupId=spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4834.\n",
      "23/06/24 15:00:24 INFO CodeGenerator: Code generated in 15.785584 ms\n",
      "23/06/24 15:00:25 INFO CodeGenerator: Code generated in 55.847083 ms\n",
      "23/06/24 15:00:26 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-1c839cdd-4a30-4906-99cf-fccc5e0b8cb4/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:00:26 INFO FileOutputCommitter: Saved output of task 'attempt_202306241500238432565655569741210_0000_m_000000_0' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-1c839cdd-4a30-4906-99cf-fccc5e0b8cb4/_temporary/0/task_202306241500238432565655569741210_0000_m_000000\n",
      "23/06/24 15:00:26 INFO SparkHadoopMapRedUtil: attempt_202306241500238432565655569741210_0000_m_000000_0: Committed. Elapsed time: 623 ms.\n",
      "23/06/24 15:00:26 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2622 bytes result sent to driver\n",
      "23/06/24 15:00:26 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2382 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:00:26 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:00:26 INFO DAGScheduler: ResultStage 0 (start at NativeMethodAccessorImpl.java:0) finished in 2.624 s\n",
      "23/06/24 15:00:26 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:00:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished\n",
      "23/06/24 15:00:26 INFO DAGScheduler: Job 0 finished: start at NativeMethodAccessorImpl.java:0, took 2.648230 s\n",
      "23/06/24 15:00:26 INFO FileFormatWriter: Start to commit write Job 24df0e55-195e-42f2-9160-ef4b6316ac03.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:00:26 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-1c839cdd-4a30-4906-99cf-fccc5e0b8cb4/_temporary/0/task_202306241500238432565655569741210_0000_m_000000/' directory.\n",
      "23/06/24 15:00:27 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-1c839cdd-4a30-4906-99cf-fccc5e0b8cb4/' directory.\n",
      "23/06/24 15:00:27 INFO BlockManagerInfo: Removed broadcast_0_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:00:27 INFO FileFormatWriter: Write Job 24df0e55-195e-42f2-9160-ef4b6316ac03 committed. Elapsed time: 1514 ms.\n",
      "23/06/24 15:00:27 INFO FileFormatWriter: Finished processing stats for write job 24df0e55-195e-42f2-9160-ef4b6316ac03.\n",
      "23/06/24 15:00:28 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-1c839cdd-4a30-4906-99cf-fccc5e0b8cb4/part-00000-a317a4b1-582c-40f1-9b73-cfd0b37a5500-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=cba2d540-c863-45ec-b6e1-411e97fd808d, location=US}\n",
      "23/06/24 15:00:30 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=cba2d540-c863-45ec-b6e1-411e97fd808d, location=US}\n",
      "23/06/24 15:00:30 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/205 using temp file gs://kafka-spark-data/spark-metadata/commits/.205.6d38103b-3030-4b21-8d09-18bf3abedfd5.tmp\n",
      "23/06/24 15:00:31 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.205.6d38103b-3030-4b21-8d09-18bf3abedfd5.tmp to gs://kafka-spark-data/spark-metadata/commits/205\n",
      "23/06/24 15:00:31 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"33222548-a064-4a2f-a619-cedca234e6fd\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:00:20.005Z\",\n",
      "  \"batchId\" : 205,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.19994001799460162,\n",
      "  \"processedRowsPerSecond\" : 0.17165908505707664,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 8234,\n",
      "    \"getBatch\" : 2,\n",
      "    \"latestOffset\" : 4,\n",
      "    \"queryPlanning\" : 279,\n",
      "    \"triggerExecution\" : 11651,\n",
      "    \"walCommit\" : 1966\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4831\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4833\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.19994001799460162,\n",
      "    \"processedRowsPerSecond\" : 0.17165908505707664\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@6b8a2ce4,com.google.cloud.bigquery.connector.common.BigQueryClient@5558e442)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:00:31 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 11659 milliseconds\n",
      "23/06/24 15:00:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-driver-0-1, groupId=spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:00:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-driver-0-1, groupId=spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4836.\n",
      "23/06/24 15:00:31 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/206 using temp file gs://kafka-spark-data/spark-metadata/offsets/.206.a44840bc-f5b3-415f-bc60-b42c7cf0f792.tmp\n"
     ]
    }
   ],
   "source": [
    "\n",
    "PROJECT_ID = os.getenv('GCP_PROJECT_ID')\n",
    "BUCKET = os.getenv('GCP_BUCKET')\n",
    "\n",
    "dataset = os.getenv('GCP_dataset')\n",
    "table = os.getenv('GCP_table')\n",
    "\n",
    "gcs_metadata_folder = os.getenv('GCP_metadata_bucket')\n",
    "gcs_data_folder = os.getenv('GCP_data_bucket')\n",
    "\n",
    "print(PROJECT_ID)\n",
    "print(BUCKET)\n",
    "print(dataset)\n",
    "print(gcs_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- event_name: string (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- event_id: string (nullable = true)\n",
      " |-- event_url: string (nullable = true)\n",
      " |-- venue_name: string (nullable = true)\n",
      " |-- venue_id: string (nullable = true)\n",
      " |-- venue_zipcode: string (nullable = true)\n",
      " |-- venues_timezone: string (nullable = true)\n",
      " |-- venue_city: string (nullable = true)\n",
      " |-- venue_state_full: string (nullable = true)\n",
      " |-- venue_state_short: string (nullable = true)\n",
      " |-- venue_country_name: string (nullable = true)\n",
      " |-- venue_country_short: string (nullable = true)\n",
      " |-- venue_address: string (nullable = true)\n",
      " |-- venue_longitude: string (nullable = true)\n",
      " |-- venue_latitude: string (nullable = true)\n",
      " |-- attraction_name: string (nullable = true)\n",
      " |-- attraction_type: string (nullable = true)\n",
      " |-- attraction_id: string (nullable = true)\n",
      " |-- attraction_url: string (nullable = true)\n",
      " |-- attraction_segment_id: string (nullable = true)\n",
      " |-- attraction_segment_name: string (nullable = true)\n",
      " |-- attraction_genre_id: string (nullable = true)\n",
      " |-- attraction_genre_name: string (nullable = true)\n",
      " |-- attraction_subgenre_id: string (nullable = true)\n",
      " |-- attraction_subgenre_name: string (nullable = true)\n",
      " |-- event_start_date: string (nullable = true)\n",
      " |-- ticket_status: string (nullable = true)\n",
      " |-- event_start_time: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- min_price: string (nullable = true)\n",
      " |-- max_price: string (nullable = true)\n",
      "\n",
      "23/06/24 15:00:32 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.206.a44840bc-f5b3-415f-bc60-b42c7cf0f792.tmp to gs://kafka-spark-data/spark-metadata/offsets/206\n",
      "23/06/24 15:00:32 INFO MicroBatchExecution: Committed offsets for batch 206. Metadata OffsetSeqMetadata(0,1687636831672,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:00:33 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:00:33 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:00:33 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:00:33 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:00:33 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:00:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:00:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:00:33 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:00:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:00:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:00:33 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:00:33 INFO GoogleCloudStorageImpl: Ignoring exception of type GoogleJsonResponseException; verified object already exists with desired state.\n",
      "23/06/24 15:00:33 INFO ResolveWriteToStream: Checkpoint root gs://kafka-spark-data/spark-metadata resolved to gs://kafka-spark-data/spark-metadata.\n",
      "23/06/24 15:00:33 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "23/06/24 15:00:33 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:00:33 INFO DAGScheduler: Got job 1 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:00:33 INFO DAGScheduler: Final stage: ResultStage 1 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:00:33 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:00:33 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:00:33 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[13] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:00:33 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:00:33 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:00:33 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:00:33 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:00:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[13] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:00:33 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:00:33 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:00:33 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)\n",
      "23/06/24 15:00:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:00:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:00:33 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:00:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:00:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:00:33 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:00:33 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:00:33 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:00:33 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:00:33 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:00:33 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:00:33 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:00:33 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:00:33 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-executor-2, groupId=spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-executor] Seeking to offset 4834 for partition ticketmaster-0\n",
      "23/06/24 15:00:33 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-executor-2, groupId=spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:00:33 WARN StreamingQueryManager: Stopping existing streaming query [id=f2bc1daa-c744-4e59-9ab7-7162c43fc781, runId=33222548-a064-4a2f-a619-cedca234e6fd], as a new run is being started.\n",
      "23/06/24 15:00:33 INFO DAGScheduler: Asked to cancel job group 33222548-a064-4a2f-a619-cedca234e6fd\n",
      "23/06/24 15:00:33 ERROR FileFormatWriter: Aborting job 61a69240-c3cd-4044-9b24-08980dae81fb.\n",
      "java.lang.InterruptedException\n",
      "\tat java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1048)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:242)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:258)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:187)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitReady(ThreadUtils.scala:334)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:943)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2238)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:255)\n",
      "\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:186)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:584)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:176)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:584)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:560)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:116)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:860)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:390)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:363)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239)\n",
      "\tat com.google.cloud.spark.bigquery.write.BigQueryWriteHelper.writeDataFrameToBigQuery(BigQueryWriteHelper.java:105)\n",
      "\tat com.google.cloud.spark.bigquery.BigQueryStreamWriter$.writeBatch(BigQueryStreamWriter.scala:58)\n",
      "\tat com.google.cloud.spark.bigquery.BigQueryStreamingSink.addBatch(BigQueryStreamingSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:665)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:663)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:375)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:373)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:663)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:256)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:375)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:373)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:213)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:285)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:208)\n",
      "23/06/24 15:00:33 INFO TaskSchedulerImpl: Cancelling stage 1\n",
      "23/06/24 15:00:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage cancelled\n",
      "23/06/24 15:00:33 INFO Executor: Executor is trying to kill task 0.0 in stage 1.0 (TID 1), reason: Stage cancelled\n",
      "23/06/24 15:00:33 INFO TaskSchedulerImpl: Stage 1 was cancelled\n",
      "23/06/24 15:00:33 INFO DAGScheduler: ResultStage 1 (start at NativeMethodAccessorImpl.java:0) failed in 0.354 s due to Job 1 cancelled part of cancelled job group 33222548-a064-4a2f-a619-cedca234e6fd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:00:34 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-9756b57f-78f1-47e4-9eaa-8e6b0ed5aa94/' directory.\n",
      "23/06/24 15:00:34 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-executor-2, groupId=spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:00:34 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-executor-2, groupId=spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:00:34 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-executor-2, groupId=spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4836.\n",
      "23/06/24 15:00:34 ERROR Utils: Aborting task\n",
      "org.apache.spark.TaskKilledException\n",
      "\tat org.apache.spark.TaskContextImpl.killTaskIfInterrupted(TaskContextImpl.scala:217)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:36)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.writeWithIterator(FileFormatDataWriter.scala:91)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:341)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1538)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:348)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$22(FileFormatWriter.scala:266)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "23/06/24 15:00:34 WARN FileOutputCommitter: Could not delete gs://kafka-spark-data/.spark-bigquery-local-1687636163344-9756b57f-78f1-47e4-9eaa-8e6b0ed5aa94/_temporary/0/_temporary/attempt_202306241500334269243882207176228_0001_m_000000_1\n",
      "23/06/24 15:00:34 WARN Utils: Suppressing exception in catch: Failed to write 2642 bytes in 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-9756b57f-78f1-47e4-9eaa-8e6b0ed5aa94/_temporary/0/_temporary/attempt_202306241500334269243882207176228_0001_m_000000_1/part-00000-603aa5f2-1d4c-4be0-a919-5ff0818b3ca1-c000.snappy.parquet'\n",
      "java.io.IOException: Failed to write 2642 bytes in 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-9756b57f-78f1-47e4-9eaa-8e6b0ed5aa94/_temporary/0/_temporary/attempt_202306241500334269243882207176228_0001_m_000000_1/part-00000-603aa5f2-1d4c-4be0-a919-5ff0818b3ca1-c000.snappy.parquet'\n",
      "\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.BaseAbstractGoogleAsyncWriteChannel.write(BaseAbstractGoogleAsyncWriteChannel.java:136)\n",
      "\tat java.base/java.nio.channels.Channels.writeFullyImpl(Channels.java:74)\n",
      "\tat java.base/java.nio.channels.Channels.writeFully(Channels.java:96)\n",
      "\tat java.base/java.nio.channels.Channels$1.write(Channels.java:171)\n",
      "\tat java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81)\n",
      "\tat java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142)\n",
      "\tat java.base/java.io.FilterOutputStream.close(FilterOutputStream.java:182)\n",
      "\tat com.google.cloud.hadoop.fs.gcs.GoogleHadoopOutputStream.close(GoogleHadoopOutputStream.java:119)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:77)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)\n",
      "\tat org.apache.parquet.hadoop.util.HadoopPositionOutputStream.close(HadoopPositionOutputStream.java:64)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileWriter.end(ParquetFileWriter.java:1106)\n",
      "\tat org.apache.parquet.hadoop.InternalParquetRecordWriter.close(InternalParquetRecordWriter.java:132)\n",
      "\tat org.apache.parquet.hadoop.ParquetRecordWriter.close(ParquetRecordWriter.java:164)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetOutputWriter.close(ParquetOutputWriter.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.releaseCurrentWriter(FileFormatDataWriter.scala:64)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.releaseResources(FileFormatDataWriter.scala:75)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.abort(FileFormatDataWriter.scala:117)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$2(FileFormatWriter.scala:345)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1549)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:348)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$22(FileFormatWriter.scala:266)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "Caused by: java.nio.channels.ClosedByInterruptException\n",
      "\tat java.base/java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:199)\n",
      "\tat java.base/java.nio.channels.Channels$WritableByteChannelImpl.write(Channels.java:465)\n",
      "\tat com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.BaseAbstractGoogleAsyncWriteChannel.write(BaseAbstractGoogleAsyncWriteChannel.java:133)\n",
      "\t... 29 more\n",
      "23/06/24 15:00:34 INFO Executor: Executor interrupted and killed task 0.0 in stage 1.0 (TID 1), reason: Stage cancelled\n",
      "23/06/24 15:00:34 WARN TaskSetManager: Lost task 0.0 in stage 1.0 (TID 1) (nics-mbp.attlocal.net executor driver): TaskKilled (Stage cancelled)\n",
      "23/06/24 15:00:34 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:00:34 ERROR MicroBatchExecution: Query [id = f2bc1daa-c744-4e59-9ab7-7162c43fc781, runId = 33222548-a064-4a2f-a619-cedca234e6fd] terminated with error\n",
      "com.google.cloud.bigquery.connector.common.BigQueryConnectorException: Failed to write to BigQuery\n",
      "\tat com.google.cloud.spark.bigquery.write.BigQueryWriteHelper.writeDataFrameToBigQuery(BigQueryWriteHelper.java:110)\n",
      "\tat com.google.cloud.spark.bigquery.BigQueryStreamWriter$.writeBatch(BigQueryStreamWriter.scala:58)\n",
      "\tat com.google.cloud.spark.bigquery.BigQueryStreamingSink.addBatch(BigQueryStreamingSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:665)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:663)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:375)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:373)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:663)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:256)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:375)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:373)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:219)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:213)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:285)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:208)\n",
      "Caused by: org.apache.spark.SparkException: Job aborted.\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.jobAbortedError(QueryExecutionErrors.scala:651)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:288)\n",
      "\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:186)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:584)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:176)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:584)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:560)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:116)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:860)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:390)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:363)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239)\n",
      "\tat com.google.cloud.spark.bigquery.write.BigQueryWriteHelper.writeDataFrameToBigQuery(BigQueryWriteHelper.java:105)\n",
      "\t... 26 more\n",
      "Caused by: java.lang.InterruptedException\n",
      "\tat java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1048)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:242)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:258)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:187)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitReady(ThreadUtils.scala:334)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:943)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2238)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:255)\n",
      "\t... 56 more\n",
      "23/06/24 15:00:34 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-driver-0-1, groupId=spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-driver-0] Revoke previously assigned partitions ticketmaster-0\n",
      "23/06/24 15:00:34 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-driver-0-1, groupId=spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-driver-0] Member consumer-spark-kafka-source-71d3a546-2d9e-4f76-a6b9-bc85d9902881--2001384727-driver-0-1-6dae00fb-73e4-48db-aef1-e624f6eb4c53 sending LeaveGroup request to coordinator 127.0.0.1:9092 (id: 2147483646 rack: null) due to the consumer is being closed\n",
      "23/06/24 15:00:34 INFO DAGScheduler: Asked to cancel job group 33222548-a064-4a2f-a619-cedca234e6fd\n",
      "23/06/24 15:00:34 INFO MicroBatchExecution: Query [id = f2bc1daa-c744-4e59-9ab7-7162c43fc781, runId = 33222548-a064-4a2f-a619-cedca234e6fd] was stopped\n",
      "23/06/24 15:00:34 INFO MicroBatchExecution: Starting [id = f2bc1daa-c744-4e59-9ab7-7162c43fc781, runId = ee32ed25-701b-49a6-888b-d137ee1cde4f]. Use gs://kafka-spark-data/spark-metadata to store the query checkpoint.\n",
      "23/06/24 15:00:34 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3e742516] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@30b3dd70]\n",
      "23/06/24 15:00:35 INFO MicroBatchExecution: Resuming at batch 206 with committed offsets {KafkaV2[Subscribe[ticketmaster]]: {\"ticketmaster\":{\"0\":4833}}} and available offsets {KafkaV2[Subscribe[ticketmaster]]: {\"ticketmaster\":{\"0\":4836}}}\n",
      "23/06/24 15:00:35 INFO MicroBatchExecution: Stream started from {KafkaV2[Subscribe[ticketmaster]]: {\"ticketmaster\":{\"0\":4833}}}\n",
      "23/06/24 15:00:35 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:00:35 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:00:35 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:00:35 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:00:35 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:00:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:00:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:00:35 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:00:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:00:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:00:35 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:00:35 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:00:35 INFO DAGScheduler: Got job 2 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:00:35 INFO DAGScheduler: Final stage: ResultStage 2 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:00:35 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:00:35 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:00:35 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[20] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:00:36 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 295.4 KiB, free 433.7 MiB)\n",
      "23/06/24 15:00:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 433.6 MiB)\n",
      "23/06/24 15:00:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.2 MiB)\n",
      "23/06/24 15:00:36 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:00:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[20] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:00:36 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:00:36 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:00:36 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)\n",
      "23/06/24 15:00:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:00:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:00:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:00:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:00:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:00:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:00:36 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:00:36 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:00:36 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:00:36 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:00:36 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:00:36 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:00:36 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:00:36 INFO ConsumerConfig: ConsumerConfig values: \n",
      "\tallow.auto.create.topics = true\n",
      "\tauto.commit.interval.ms = 5000\n",
      "\tauto.offset.reset = none\n",
      "\tbootstrap.servers = [localhost:9092]\n",
      "\tcheck.crcs = true\n",
      "\tclient.dns.lookup = use_all_dns_ips\n",
      "\tclient.id = consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3\n",
      "\tclient.rack = \n",
      "\tconnections.max.idle.ms = 540000\n",
      "\tdefault.api.timeout.ms = 60000\n",
      "\tenable.auto.commit = false\n",
      "\texclude.internal.topics = true\n",
      "\tfetch.max.bytes = 52428800\n",
      "\tfetch.max.wait.ms = 500\n",
      "\tfetch.min.bytes = 1\n",
      "\tgroup.id = spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor\n",
      "\tgroup.instance.id = null\n",
      "\theartbeat.interval.ms = 3000\n",
      "\tinterceptor.classes = []\n",
      "\tinternal.leave.group.on.close = true\n",
      "\tinternal.throw.on.fetch.stable.offset.unsupported = false\n",
      "\tisolation.level = read_uncommitted\n",
      "\tkey.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer\n",
      "\tmax.partition.fetch.bytes = 1048576\n",
      "\tmax.poll.interval.ms = 300000\n",
      "\tmax.poll.records = 500\n",
      "\tmetadata.max.age.ms = 300000\n",
      "\tmetric.reporters = []\n",
      "\tmetrics.num.samples = 2\n",
      "\tmetrics.recording.level = INFO\n",
      "\tmetrics.sample.window.ms = 30000\n",
      "\tpartition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]\n",
      "\treceive.buffer.bytes = 65536\n",
      "\treconnect.backoff.max.ms = 1000\n",
      "\treconnect.backoff.ms = 50\n",
      "\trequest.timeout.ms = 30000\n",
      "\tretry.backoff.ms = 100\n",
      "\tsasl.client.callback.handler.class = null\n",
      "\tsasl.jaas.config = null\n",
      "\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n",
      "\tsasl.kerberos.min.time.before.relogin = 60000\n",
      "\tsasl.kerberos.service.name = null\n",
      "\tsasl.kerberos.ticket.renew.jitter = 0.05\n",
      "\tsasl.kerberos.ticket.renew.window.factor = 0.8\n",
      "\tsasl.login.callback.handler.class = null\n",
      "\tsasl.login.class = null\n",
      "\tsasl.login.refresh.buffer.seconds = 300\n",
      "\tsasl.login.refresh.min.period.seconds = 60\n",
      "\tsasl.login.refresh.window.factor = 0.8\n",
      "\tsasl.login.refresh.window.jitter = 0.05\n",
      "\tsasl.mechanism = GSSAPI\n",
      "\tsecurity.protocol = PLAINTEXT\n",
      "\tsecurity.providers = null\n",
      "\tsend.buffer.bytes = 131072\n",
      "\tsession.timeout.ms = 10000\n",
      "\tssl.cipher.suites = null\n",
      "\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n",
      "\tssl.endpoint.identification.algorithm = https\n",
      "\tssl.engine.factory.class = null\n",
      "\tssl.key.password = null\n",
      "\tssl.keymanager.algorithm = SunX509\n",
      "\tssl.keystore.location = null\n",
      "\tssl.keystore.password = null\n",
      "\tssl.keystore.type = JKS\n",
      "\tssl.protocol = TLSv1.3\n",
      "\tssl.provider = null\n",
      "\tssl.secure.random.implementation = null\n",
      "\tssl.trustmanager.algorithm = PKIX\n",
      "\tssl.truststore.location = null\n",
      "\tssl.truststore.password = null\n",
      "\tssl.truststore.type = JKS\n",
      "\tvalue.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer\n",
      "\n",
      "23/06/24 15:00:36 INFO AppInfoParser: Kafka version: 2.6.0\n",
      "23/06/24 15:00:36 INFO AppInfoParser: Kafka commitId: 62abe01bee039651\n",
      "23/06/24 15:00:36 INFO AppInfoParser: Kafka startTimeMs: 1687636836171\n",
      "23/06/24 15:00:36 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Subscribed to partition(s): ticketmaster-0\n",
      "23/06/24 15:00:36 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4833 for partition ticketmaster-0\n",
      "23/06/24 15:00:36 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Cluster ID: kJYfpPSDQYKOEac6knVYNg\n",
      "23/06/24 15:00:36 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:00:36 INFO BlockManagerInfo: Removed broadcast_1_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:00:36 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:00:36 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:00:36 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4837.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:00:37 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-5f01326b-0233-4789-a924-95976f02eb4e/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:00:37 INFO FileOutputCommitter: Saved output of task 'attempt_202306241500357702791542536645745_0002_m_000000_2' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-5f01326b-0233-4789-a924-95976f02eb4e/_temporary/0/task_202306241500357702791542536645745_0002_m_000000\n",
      "23/06/24 15:00:37 INFO SparkHadoopMapRedUtil: attempt_202306241500357702791542536645745_0002_m_000000_2: Committed. Elapsed time: 583 ms.\n",
      "23/06/24 15:00:37 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2579 bytes result sent to driver\n",
      "23/06/24 15:00:37 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1383 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:00:37 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:00:37 INFO DAGScheduler: ResultStage 2 (start at NativeMethodAccessorImpl.java:0) finished in 1.414 s\n",
      "23/06/24 15:00:37 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:00:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished\n",
      "23/06/24 15:00:37 INFO DAGScheduler: Job 2 finished: start at NativeMethodAccessorImpl.java:0, took 1.415681 s\n",
      "23/06/24 15:00:37 INFO FileFormatWriter: Start to commit write Job 52b6cfab-5929-44a5-b1d6-943b95e2b862.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:00:38 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-5f01326b-0233-4789-a924-95976f02eb4e/_temporary/0/task_202306241500357702791542536645745_0002_m_000000/' directory.\n",
      "23/06/24 15:00:38 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-5f01326b-0233-4789-a924-95976f02eb4e/' directory.\n",
      "23/06/24 15:00:38 INFO BlockManagerInfo: Removed broadcast_2_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:00:38 INFO FileFormatWriter: Write Job 52b6cfab-5929-44a5-b1d6-943b95e2b862 committed. Elapsed time: 1522 ms.\n",
      "23/06/24 15:00:38 INFO FileFormatWriter: Finished processing stats for write job 52b6cfab-5929-44a5-b1d6-943b95e2b862.\n",
      "23/06/24 15:00:39 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-5f01326b-0233-4789-a924-95976f02eb4e/part-00000-180b96ac-7935-488c-a366-b8f569efe718-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=e784d34c-5adc-4084-a2c7-a8eda08dddc4, location=US}\n",
      "23/06/24 15:00:43 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=e784d34c-5adc-4084-a2c7-a8eda08dddc4, location=US}\n",
      "23/06/24 15:00:43 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/206 using temp file gs://kafka-spark-data/spark-metadata/commits/.206.cbd2aa93-ff7d-430c-94cf-2c87b2f93f18.tmp\n",
      "23/06/24 15:00:44 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.206.cbd2aa93-ff7d-430c-94cf-2c87b2f93f18.tmp to gs://kafka-spark-data/spark-metadata/commits/206\n",
      "23/06/24 15:00:44 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:00:34.826Z\",\n",
      "  \"batchId\" : 206,\n",
      "  \"numInputRows\" : 3,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.3012048192771084,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 8315,\n",
      "    \"getBatch\" : 0,\n",
      "    \"queryPlanning\" : 11,\n",
      "    \"triggerExecution\" : 9960\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4833\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4836\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 3,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.3012048192771084\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:00:44 INFO ConsumerConfig: ConsumerConfig values: \n",
      "\tallow.auto.create.topics = true\n",
      "\tauto.commit.interval.ms = 5000\n",
      "\tauto.offset.reset = earliest\n",
      "\tbootstrap.servers = [localhost:9092]\n",
      "\tcheck.crcs = true\n",
      "\tclient.dns.lookup = use_all_dns_ips\n",
      "\tclient.id = consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4\n",
      "\tclient.rack = \n",
      "\tconnections.max.idle.ms = 540000\n",
      "\tdefault.api.timeout.ms = 60000\n",
      "\tenable.auto.commit = false\n",
      "\texclude.internal.topics = true\n",
      "\tfetch.max.bytes = 52428800\n",
      "\tfetch.max.wait.ms = 500\n",
      "\tfetch.min.bytes = 1\n",
      "\tgroup.id = spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0\n",
      "\tgroup.instance.id = null\n",
      "\theartbeat.interval.ms = 3000\n",
      "\tinterceptor.classes = []\n",
      "\tinternal.leave.group.on.close = true\n",
      "\tinternal.throw.on.fetch.stable.offset.unsupported = false\n",
      "\tisolation.level = read_uncommitted\n",
      "\tkey.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer\n",
      "\tmax.partition.fetch.bytes = 1048576\n",
      "\tmax.poll.interval.ms = 300000\n",
      "\tmax.poll.records = 1\n",
      "\tmetadata.max.age.ms = 300000\n",
      "\tmetric.reporters = []\n",
      "\tmetrics.num.samples = 2\n",
      "\tmetrics.recording.level = INFO\n",
      "\tmetrics.sample.window.ms = 30000\n",
      "\tpartition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]\n",
      "\treceive.buffer.bytes = 65536\n",
      "\treconnect.backoff.max.ms = 1000\n",
      "\treconnect.backoff.ms = 50\n",
      "\trequest.timeout.ms = 30000\n",
      "\tretry.backoff.ms = 100\n",
      "\tsasl.client.callback.handler.class = null\n",
      "\tsasl.jaas.config = null\n",
      "\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n",
      "\tsasl.kerberos.min.time.before.relogin = 60000\n",
      "\tsasl.kerberos.service.name = null\n",
      "\tsasl.kerberos.ticket.renew.jitter = 0.05\n",
      "\tsasl.kerberos.ticket.renew.window.factor = 0.8\n",
      "\tsasl.login.callback.handler.class = null\n",
      "\tsasl.login.class = null\n",
      "\tsasl.login.refresh.buffer.seconds = 300\n",
      "\tsasl.login.refresh.min.period.seconds = 60\n",
      "\tsasl.login.refresh.window.factor = 0.8\n",
      "\tsasl.login.refresh.window.jitter = 0.05\n",
      "\tsasl.mechanism = GSSAPI\n",
      "\tsecurity.protocol = PLAINTEXT\n",
      "\tsecurity.providers = null\n",
      "\tsend.buffer.bytes = 131072\n",
      "\tsession.timeout.ms = 10000\n",
      "\tssl.cipher.suites = null\n",
      "\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n",
      "\tssl.endpoint.identification.algorithm = https\n",
      "\tssl.engine.factory.class = null\n",
      "\tssl.key.password = null\n",
      "\tssl.keymanager.algorithm = SunX509\n",
      "\tssl.keystore.location = null\n",
      "\tssl.keystore.password = null\n",
      "\tssl.keystore.type = JKS\n",
      "\tssl.protocol = TLSv1.3\n",
      "\tssl.provider = null\n",
      "\tssl.secure.random.implementation = null\n",
      "\tssl.trustmanager.algorithm = PKIX\n",
      "\tssl.truststore.location = null\n",
      "\tssl.truststore.password = null\n",
      "\tssl.truststore.type = JKS\n",
      "\tvalue.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer\n",
      "\n",
      "23/06/24 15:00:44 INFO AppInfoParser: Kafka version: 2.6.0\n",
      "23/06/24 15:00:44 INFO AppInfoParser: Kafka commitId: 62abe01bee039651\n",
      "23/06/24 15:00:44 INFO AppInfoParser: Kafka startTimeMs: 1687636844792\n",
      "23/06/24 15:00:44 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Subscribed to topic(s): ticketmaster\n",
      "23/06/24 15:00:44 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Cluster ID: kJYfpPSDQYKOEac6knVYNg\n",
      "23/06/24 15:00:44 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Discovered group coordinator 127.0.0.1:9092 (id: 2147483646 rack: null)\n",
      "23/06/24 15:00:44 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] (Re-)joining group\n",
      "23/06/24 15:00:44 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group.\n",
      "23/06/24 15:00:44 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] (Re-)joining group\n",
      "23/06/24 15:00:47 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Finished assignment for group at generation 1: {consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4-c15ef13a-8fb7-4b73-a2d6-6b90efa63449=Assignment(partitions=[ticketmaster-0])}\n",
      "23/06/24 15:00:47 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Successfully joined group with generation 1\n",
      "23/06/24 15:00:47 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Notifying assignor about the new Assignment(partitions=[ticketmaster-0])\n",
      "23/06/24 15:00:47 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Adding newly assigned partitions: ticketmaster-0\n",
      "23/06/24 15:00:47 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Found no committed offset for partition ticketmaster-0\n",
      "23/06/24 15:00:47 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:00:47 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:00:47 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4839.\n",
      "23/06/24 15:00:48 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/207 using temp file gs://kafka-spark-data/spark-metadata/offsets/.207.6edf252a-845e-49ba-adea-62007d1a8b8d.tmp\n",
      "23/06/24 15:00:48 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.207.6edf252a-845e-49ba-adea-62007d1a8b8d.tmp to gs://kafka-spark-data/spark-metadata/offsets/207\n",
      "23/06/24 15:00:48 INFO MicroBatchExecution: Committed offsets for batch 207. Metadata OffsetSeqMetadata(0,1687636847846,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:00:49 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:00:49 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:00:49 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:00:49 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:00:49 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:00:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:00:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:00:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:00:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:00:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:00:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:00:50 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:00:50 INFO DAGScheduler: Got job 3 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:00:50 INFO DAGScheduler: Final stage: ResultStage 3 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:00:50 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:00:50 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:00:50 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[27] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:00:50 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:00:50 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:00:50 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:00:50 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:00:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[27] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:00:50 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:00:50 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:00:50 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)\n",
      "23/06/24 15:00:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:00:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:00:50 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:00:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:00:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:00:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:00:50 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:00:50 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:00:50 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:00:50 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:00:50 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:00:50 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:00:50 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:00:50 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4836 for partition ticketmaster-0\n",
      "23/06/24 15:00:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:00:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:00:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:00:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4839.\n",
      "23/06/24 15:00:50 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4837 for partition ticketmaster-0\n",
      "23/06/24 15:00:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:00:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:00:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:00:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4839.\n",
      "23/06/24 15:00:51 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-0f4ee3f6-9614-44ab-81ca-c289fc92dd40/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:00:51 INFO FileOutputCommitter: Saved output of task 'attempt_202306241500503141862791064854583_0003_m_000000_3' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-0f4ee3f6-9614-44ab-81ca-c289fc92dd40/_temporary/0/task_202306241500503141862791064854583_0003_m_000000\n",
      "23/06/24 15:00:51 INFO SparkHadoopMapRedUtil: attempt_202306241500503141862791064854583_0003_m_000000_3: Committed. Elapsed time: 620 ms.\n",
      "23/06/24 15:00:51 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2579 bytes result sent to driver\n",
      "23/06/24 15:00:51 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 1579 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:00:51 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:00:51 INFO DAGScheduler: ResultStage 3 (start at NativeMethodAccessorImpl.java:0) finished in 1.619 s\n",
      "23/06/24 15:00:51 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:00:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished\n",
      "23/06/24 15:00:51 INFO DAGScheduler: Job 3 finished: start at NativeMethodAccessorImpl.java:0, took 1.621121 s\n",
      "23/06/24 15:00:51 INFO FileFormatWriter: Start to commit write Job 74059735-6cde-41c3-9535-0dcce0a65a6d.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:00:52 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-0f4ee3f6-9614-44ab-81ca-c289fc92dd40/_temporary/0/task_202306241500503141862791064854583_0003_m_000000/' directory.\n",
      "23/06/24 15:00:52 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-0f4ee3f6-9614-44ab-81ca-c289fc92dd40/' directory.\n",
      "23/06/24 15:00:53 INFO BlockManagerInfo: Removed broadcast_3_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:00:53 INFO FileFormatWriter: Write Job 74059735-6cde-41c3-9535-0dcce0a65a6d committed. Elapsed time: 1536 ms.\n",
      "23/06/24 15:00:53 INFO FileFormatWriter: Finished processing stats for write job 74059735-6cde-41c3-9535-0dcce0a65a6d.\n",
      "23/06/24 15:00:53 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-0f4ee3f6-9614-44ab-81ca-c289fc92dd40/part-00000-846c5302-b1ed-4151-99fc-72ebc9da5e31-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=a14d7559-2937-4d83-b3f3-01c3d4762307, location=US}\n",
      "23/06/24 15:00:56 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=a14d7559-2937-4d83-b3f3-01c3d4762307, location=US}\n",
      "23/06/24 15:00:56 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/207 using temp file gs://kafka-spark-data/spark-metadata/commits/.207.9a60bdb6-d6c5-4f5f-a18c-9039877358ae.tmp\n",
      "23/06/24 15:00:57 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.207.9a60bdb6-d6c5-4f5f-a18c-9039877358ae.tmp to gs://kafka-spark-data/spark-metadata/commits/207\n",
      "23/06/24 15:00:57 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:00:44.789Z\",\n",
      "  \"batchId\" : 207,\n",
      "  \"numInputRows\" : 3,\n",
      "  \"inputRowsPerSecond\" : 0.30111412225233364,\n",
      "  \"processedRowsPerSecond\" : 0.23881547524279576,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6897,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 3057,\n",
      "    \"queryPlanning\" : 13,\n",
      "    \"triggerExecution\" : 12562,\n",
      "    \"walCommit\" : 1612\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4836\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4839\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 3,\n",
      "    \"inputRowsPerSecond\" : 0.30111412225233364,\n",
      "    \"processedRowsPerSecond\" : 0.23881547524279576\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:00:57 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 12565 milliseconds\n",
      "23/06/24 15:00:57 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:00:57 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4841.\n",
      "23/06/24 15:00:57 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/208 using temp file gs://kafka-spark-data/spark-metadata/offsets/.208.ef8af6e0-b3c5-4bd2-8318-8d853e947394.tmp\n",
      "23/06/24 15:00:58 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.208.ef8af6e0-b3c5-4bd2-8318-8d853e947394.tmp to gs://kafka-spark-data/spark-metadata/offsets/208\n",
      "23/06/24 15:00:58 INFO MicroBatchExecution: Committed offsets for batch 208. Metadata OffsetSeqMetadata(0,1687636857362,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:00:58 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:00:58 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:00:58 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:00:58 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:00:59 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:00:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:00:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:00:59 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:00:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:00:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:00:59 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:00:59 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:00:59 INFO DAGScheduler: Got job 4 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:00:59 INFO DAGScheduler: Final stage: ResultStage 4 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:00:59 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:00:59 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:00:59 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[34] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:00:59 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:00:59 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:00:59 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:00:59 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:00:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[34] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:00:59 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:00:59 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:00:59 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)\n",
      "23/06/24 15:00:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:00:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:00:59 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:00:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:00:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:00:59 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:00:59 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:00:59 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:00:59 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:00:59 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:00:59 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:00:59 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:00:59 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:00:59 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4839 for partition ticketmaster-0\n",
      "23/06/24 15:00:59 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:00:59 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:00:59 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:00:59 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4841.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:01:00 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-d2de2e12-a8f4-42dd-93bc-e810003e742d/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:01:00 INFO FileOutputCommitter: Saved output of task 'attempt_202306241500591977800507846998020_0004_m_000000_4' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-d2de2e12-a8f4-42dd-93bc-e810003e742d/_temporary/0/task_202306241500591977800507846998020_0004_m_000000\n",
      "23/06/24 15:01:00 INFO SparkHadoopMapRedUtil: attempt_202306241500591977800507846998020_0004_m_000000_4: Committed. Elapsed time: 566 ms.\n",
      "23/06/24 15:01:00 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2579 bytes result sent to driver\n",
      "23/06/24 15:01:00 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 1514 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:01:00 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:01:00 INFO DAGScheduler: ResultStage 4 (start at NativeMethodAccessorImpl.java:0) finished in 1.534 s\n",
      "23/06/24 15:01:00 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:01:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished\n",
      "23/06/24 15:01:00 INFO DAGScheduler: Job 4 finished: start at NativeMethodAccessorImpl.java:0, took 1.536099 s\n",
      "23/06/24 15:01:00 INFO FileFormatWriter: Start to commit write Job 14d076d1-4368-4d55-9643-c9eb4a6b1a60.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:01:01 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-d2de2e12-a8f4-42dd-93bc-e810003e742d/_temporary/0/task_202306241500591977800507846998020_0004_m_000000/' directory.\n",
      "23/06/24 15:01:01 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-d2de2e12-a8f4-42dd-93bc-e810003e742d/' directory.\n",
      "23/06/24 15:01:02 INFO FileFormatWriter: Write Job 14d076d1-4368-4d55-9643-c9eb4a6b1a60 committed. Elapsed time: 1374 ms.\n",
      "23/06/24 15:01:02 INFO FileFormatWriter: Finished processing stats for write job 14d076d1-4368-4d55-9643-c9eb4a6b1a60.\n",
      "23/06/24 15:01:02 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-d2de2e12-a8f4-42dd-93bc-e810003e742d/part-00000-62d6c14f-50d5-4718-b44e-ada3ee4fbd44-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=795080f0-5af0-45e9-862e-a3b0753313fa, location=US}\n",
      "23/06/24 15:01:05 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=795080f0-5af0-45e9-862e-a3b0753313fa, location=US}\n",
      "23/06/24 15:01:06 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/208 using temp file gs://kafka-spark-data/spark-metadata/commits/.208.f259dbca-f46b-4214-9762-c85309c09f18.tmp\n",
      "23/06/24 15:01:06 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.208.f259dbca-f46b-4214-9762-c85309c09f18.tmp to gs://kafka-spark-data/spark-metadata/commits/208\n",
      "23/06/24 15:01:06 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:00:57.354Z\",\n",
      "  \"batchId\" : 208,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.15917230401910068,\n",
      "  \"processedRowsPerSecond\" : 0.20792182139515542,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7136,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 8,\n",
      "    \"queryPlanning\" : 9,\n",
      "    \"triggerExecution\" : 9619,\n",
      "    \"walCommit\" : 1409\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4839\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4841\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.15917230401910068,\n",
      "    \"processedRowsPerSecond\" : 0.20792182139515542\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:01:06 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:01:06 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4843.\n",
      "23/06/24 15:01:07 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/209 using temp file gs://kafka-spark-data/spark-metadata/offsets/.209.bff0a56f-30b6-4bee-89bb-d154679b2070.tmp\n",
      "23/06/24 15:01:07 INFO BlockManagerInfo: Removed broadcast_4_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:01:07 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.209.bff0a56f-30b6-4bee-89bb-d154679b2070.tmp to gs://kafka-spark-data/spark-metadata/offsets/209\n",
      "23/06/24 15:01:07 INFO MicroBatchExecution: Committed offsets for batch 209. Metadata OffsetSeqMetadata(0,1687636866980,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:01:08 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:01:08 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:01:08 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:01:08 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:01:08 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:01:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:01:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:01:08 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:01:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:01:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:01:08 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:01:08 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:01:08 INFO DAGScheduler: Got job 5 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:01:08 INFO DAGScheduler: Final stage: ResultStage 5 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:01:08 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:01:08 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:01:08 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[41] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:01:08 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:01:08 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:01:08 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:01:08 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:01:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[41] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:01:08 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:01:08 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:01:08 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)\n",
      "23/06/24 15:01:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:01:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:01:08 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:01:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:01:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:01:08 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:01:08 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:01:08 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:01:08 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:01:08 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:01:08 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:01:08 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:01:08 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:01:09 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4841 for partition ticketmaster-0\n",
      "23/06/24 15:01:09 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:01:09 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:01:09 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:01:09 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4843.\n",
      "23/06/24 15:01:10 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-5a130a64-61ab-403d-87ab-991e889ede64/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:01:10 INFO FileOutputCommitter: Saved output of task 'attempt_202306241501088862672782781836120_0005_m_000000_5' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-5a130a64-61ab-403d-87ab-991e889ede64/_temporary/0/task_202306241501088862672782781836120_0005_m_000000\n",
      "23/06/24 15:01:10 INFO SparkHadoopMapRedUtil: attempt_202306241501088862672782781836120_0005_m_000000_5: Committed. Elapsed time: 652 ms.\n",
      "23/06/24 15:01:10 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 2536 bytes result sent to driver\n",
      "23/06/24 15:01:10 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 1566 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:01:10 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:01:10 INFO DAGScheduler: ResultStage 5 (start at NativeMethodAccessorImpl.java:0) finished in 1.607 s\n",
      "23/06/24 15:01:10 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:01:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished\n",
      "23/06/24 15:01:10 INFO DAGScheduler: Job 5 finished: start at NativeMethodAccessorImpl.java:0, took 1.608098 s\n",
      "23/06/24 15:01:10 INFO FileFormatWriter: Start to commit write Job c15ce5a2-af36-4d9a-b439-af16503d3f1d.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:01:11 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-5a130a64-61ab-403d-87ab-991e889ede64/_temporary/0/task_202306241501088862672782781836120_0005_m_000000/' directory.\n",
      "23/06/24 15:01:11 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-5a130a64-61ab-403d-87ab-991e889ede64/' directory.\n",
      "23/06/24 15:01:11 INFO BlockManagerInfo: Removed broadcast_5_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:01:11 INFO FileFormatWriter: Write Job c15ce5a2-af36-4d9a-b439-af16503d3f1d committed. Elapsed time: 1432 ms.\n",
      "23/06/24 15:01:11 INFO FileFormatWriter: Finished processing stats for write job c15ce5a2-af36-4d9a-b439-af16503d3f1d.\n",
      "23/06/24 15:01:12 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-5a130a64-61ab-403d-87ab-991e889ede64/part-00000-3f9c61c0-f54f-456f-8f8b-f7406ccb93c1-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=c2a2f191-9cc6-42a3-9059-726aad703135, location=US}\n",
      "23/06/24 15:01:14 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=c2a2f191-9cc6-42a3-9059-726aad703135, location=US}\n",
      "23/06/24 15:01:15 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/209 using temp file gs://kafka-spark-data/spark-metadata/commits/.209.9fdc565f-604f-4aab-90fe-70b11afc1b97.tmp\n",
      "23/06/24 15:01:15 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.209.9fdc565f-604f-4aab-90fe-70b11afc1b97.tmp to gs://kafka-spark-data/spark-metadata/commits/209\n",
      "23/06/24 15:01:15 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:01:06.974Z\",\n",
      "  \"batchId\" : 209,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.2079002079002079,\n",
      "  \"processedRowsPerSecond\" : 0.22885913720105272,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6276,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 6,\n",
      "    \"queryPlanning\" : 12,\n",
      "    \"triggerExecution\" : 8739,\n",
      "    \"walCommit\" : 1398\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4841\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4843\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.2079002079002079,\n",
      "    \"processedRowsPerSecond\" : 0.22885913720105272\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:01:15 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:01:15 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4844.\n",
      "23/06/24 15:01:15 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/210 using temp file gs://kafka-spark-data/spark-metadata/offsets/.210.ebce6bb1-4d3e-4326-937d-d6144ea552d7.tmp\n",
      "23/06/24 15:01:16 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.210.ebce6bb1-4d3e-4326-937d-d6144ea552d7.tmp to gs://kafka-spark-data/spark-metadata/offsets/210\n",
      "23/06/24 15:01:16 INFO MicroBatchExecution: Committed offsets for batch 210. Metadata OffsetSeqMetadata(0,1687636875736,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:01:17 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:01:17 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:01:17 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:01:17 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:01:17 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:01:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:01:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:01:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:01:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:01:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:01:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:01:17 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:01:17 INFO DAGScheduler: Got job 6 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:01:17 INFO DAGScheduler: Final stage: ResultStage 6 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:01:17 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:01:17 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:01:17 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[48] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:01:17 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:01:17 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:01:17 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:01:17 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:01:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[48] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:01:17 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:01:17 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:01:17 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)\n",
      "23/06/24 15:01:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:01:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:01:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:01:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:01:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:01:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:01:17 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:01:17 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:01:17 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:01:17 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:01:17 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:01:17 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:01:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:01:17 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4843 for partition ticketmaster-0\n",
      "23/06/24 15:01:17 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:01:18 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:01:18 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:01:18 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4845.\n",
      "23/06/24 15:01:19 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-9c94f029-4e06-42d6-b79b-a8b4e6ad5f53/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:01:19 INFO FileOutputCommitter: Saved output of task 'attempt_202306241501172172957430006984938_0006_m_000000_6' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-9c94f029-4e06-42d6-b79b-a8b4e6ad5f53/_temporary/0/task_202306241501172172957430006984938_0006_m_000000\n",
      "23/06/24 15:01:19 INFO SparkHadoopMapRedUtil: attempt_202306241501172172957430006984938_0006_m_000000_6: Committed. Elapsed time: 743 ms.\n",
      "23/06/24 15:01:19 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 2536 bytes result sent to driver\n",
      "23/06/24 15:01:19 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 1775 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:01:19 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:01:19 INFO DAGScheduler: ResultStage 6 (start at NativeMethodAccessorImpl.java:0) finished in 1.803 s\n",
      "23/06/24 15:01:19 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:01:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished\n",
      "23/06/24 15:01:19 INFO DAGScheduler: Job 6 finished: start at NativeMethodAccessorImpl.java:0, took 1.806685 s\n",
      "23/06/24 15:01:19 INFO FileFormatWriter: Start to commit write Job 7271c47d-0b6f-4e08-a6f8-480a61584d2b.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:01:20 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-9c94f029-4e06-42d6-b79b-a8b4e6ad5f53/_temporary/0/task_202306241501172172957430006984938_0006_m_000000/' directory.\n",
      "23/06/24 15:01:20 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-9c94f029-4e06-42d6-b79b-a8b4e6ad5f53/' directory.\n",
      "23/06/24 15:01:20 INFO BlockManagerInfo: Removed broadcast_6_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:01:20 INFO FileFormatWriter: Write Job 7271c47d-0b6f-4e08-a6f8-480a61584d2b committed. Elapsed time: 1367 ms.\n",
      "23/06/24 15:01:20 INFO FileFormatWriter: Finished processing stats for write job 7271c47d-0b6f-4e08-a6f8-480a61584d2b.\n",
      "23/06/24 15:01:21 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-9c94f029-4e06-42d6-b79b-a8b4e6ad5f53/part-00000-e69298ca-76ca-4822-87c6-9f9ef34d7da2-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=7fb3fb05-2da7-4191-9f71-d91183fbf15e, location=US}\n",
      "23/06/24 15:01:24 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=7fb3fb05-2da7-4191-9f71-d91183fbf15e, location=US}\n",
      "23/06/24 15:01:25 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/210 using temp file gs://kafka-spark-data/spark-metadata/commits/.210.3b752773-bd62-4778-9216-21766a636075.tmp\n",
      "23/06/24 15:01:25 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.210.3b752773-bd62-4778-9216-21766a636075.tmp to gs://kafka-spark-data/spark-metadata/commits/210\n",
      "23/06/24 15:01:25 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:01:15.722Z\",\n",
      "  \"batchId\" : 210,\n",
      "  \"numInputRows\" : 1,\n",
      "  \"inputRowsPerSecond\" : 0.11431184270690445,\n",
      "  \"processedRowsPerSecond\" : 0.09733307377846993,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7764,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 14,\n",
      "    \"queryPlanning\" : 13,\n",
      "    \"triggerExecution\" : 10274,\n",
      "    \"walCommit\" : 1448\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4843\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4844\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 1,\n",
      "    \"inputRowsPerSecond\" : 0.11431184270690445,\n",
      "    \"processedRowsPerSecond\" : 0.09733307377846993\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:01:25 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 10275 milliseconds\n",
      "23/06/24 15:01:25 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:01:26 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4846.\n",
      "23/06/24 15:01:26 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/211 using temp file gs://kafka-spark-data/spark-metadata/offsets/.211.d8580207-6532-478e-8ab1-986e4a6dbe00.tmp\n",
      "23/06/24 15:01:27 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.211.d8580207-6532-478e-8ab1-986e4a6dbe00.tmp to gs://kafka-spark-data/spark-metadata/offsets/211\n",
      "23/06/24 15:01:27 INFO MicroBatchExecution: Committed offsets for batch 211. Metadata OffsetSeqMetadata(0,1687636886002,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:01:27 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:01:27 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:01:27 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:01:27 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:01:27 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:01:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:01:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:01:27 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:01:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:01:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:01:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:01:27 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:01:27 INFO DAGScheduler: Got job 7 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:01:27 INFO DAGScheduler: Final stage: ResultStage 7 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:01:27 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:01:27 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:01:27 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[55] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:01:27 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:01:27 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:01:27 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:01:27 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:01:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[55] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:01:27 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:01:27 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:01:27 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)\n",
      "23/06/24 15:01:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:01:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:01:27 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:01:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:01:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:01:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:01:27 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:01:27 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:01:27 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:01:27 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:01:27 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:01:27 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:01:27 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:01:28 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4845 for partition ticketmaster-0\n",
      "23/06/24 15:01:28 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:01:28 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:01:28 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:01:28 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4847.\n",
      "23/06/24 15:01:29 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-6dcdb1a0-4adc-4e30-b110-26762d40e316/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:01:29 INFO FileOutputCommitter: Saved output of task 'attempt_202306241501271035405509442653421_0007_m_000000_7' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-6dcdb1a0-4adc-4e30-b110-26762d40e316/_temporary/0/task_202306241501271035405509442653421_0007_m_000000\n",
      "23/06/24 15:01:29 INFO SparkHadoopMapRedUtil: attempt_202306241501271035405509442653421_0007_m_000000_7: Committed. Elapsed time: 592 ms.\n",
      "23/06/24 15:01:29 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 2536 bytes result sent to driver\n",
      "23/06/24 15:01:29 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 1585 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:01:29 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:01:29 INFO DAGScheduler: ResultStage 7 (start at NativeMethodAccessorImpl.java:0) finished in 1.622 s\n",
      "23/06/24 15:01:29 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:01:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished\n",
      "23/06/24 15:01:29 INFO DAGScheduler: Job 7 finished: start at NativeMethodAccessorImpl.java:0, took 1.625362 s\n",
      "23/06/24 15:01:29 INFO FileFormatWriter: Start to commit write Job 70b49480-280f-458e-a8ca-3cc15e7b3a81.\n",
      "23/06/24 15:01:29 INFO BlockManagerInfo: Removed broadcast_7_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:01:30 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-6dcdb1a0-4adc-4e30-b110-26762d40e316/_temporary/0/task_202306241501271035405509442653421_0007_m_000000/' directory.\n",
      "23/06/24 15:01:30 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-6dcdb1a0-4adc-4e30-b110-26762d40e316/' directory.\n",
      "23/06/24 15:01:30 INFO FileFormatWriter: Write Job 70b49480-280f-458e-a8ca-3cc15e7b3a81 committed. Elapsed time: 1404 ms.\n",
      "23/06/24 15:01:30 INFO FileFormatWriter: Finished processing stats for write job 70b49480-280f-458e-a8ca-3cc15e7b3a81.\n",
      "23/06/24 15:01:31 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-6dcdb1a0-4adc-4e30-b110-26762d40e316/part-00000-16455385-01ce-4e96-b103-688a392c3110-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=638fedfd-2bef-42da-8b44-b5e8bb750326, location=US}\n",
      "23/06/24 15:01:34 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=638fedfd-2bef-42da-8b44-b5e8bb750326, location=US}\n",
      "23/06/24 15:01:35 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/211 using temp file gs://kafka-spark-data/spark-metadata/commits/.211.e2be8caa-35b3-49a9-a726-94a59a890670.tmp\n",
      "23/06/24 15:01:36 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.211.e2be8caa-35b3-49a9-a726-94a59a890670.tmp to gs://kafka-spark-data/spark-metadata/commits/211\n",
      "23/06/24 15:01:36 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:01:25.997Z\",\n",
      "  \"batchId\" : 211,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.194647201946472,\n",
      "  \"processedRowsPerSecond\" : 0.1947230065232207,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7763,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 5,\n",
      "    \"queryPlanning\" : 13,\n",
      "    \"triggerExecution\" : 10271,\n",
      "    \"walCommit\" : 1409\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4844\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4846\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.194647201946472,\n",
      "    \"processedRowsPerSecond\" : 0.1947230065232207\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:01:36 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 10274 milliseconds\n",
      "23/06/24 15:01:36 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:01:36 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4848.\n",
      "23/06/24 15:01:36 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/212 using temp file gs://kafka-spark-data/spark-metadata/offsets/.212.f7f201aa-97a9-444e-8c8a-04a7d9f66497.tmp\n",
      "23/06/24 15:01:37 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.212.f7f201aa-97a9-444e-8c8a-04a7d9f66497.tmp to gs://kafka-spark-data/spark-metadata/offsets/212\n",
      "23/06/24 15:01:37 INFO MicroBatchExecution: Committed offsets for batch 212. Metadata OffsetSeqMetadata(0,1687636896279,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:01:37 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:01:37 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:01:37 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:01:37 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:01:38 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:01:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:01:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:01:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:01:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:01:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:01:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:01:38 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:01:38 INFO DAGScheduler: Got job 8 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:01:38 INFO DAGScheduler: Final stage: ResultStage 8 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:01:38 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:01:38 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:01:38 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[62] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:01:38 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:01:38 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:01:38 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:01:38 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:01:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[62] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:01:38 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:01:38 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:01:38 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)\n",
      "23/06/24 15:01:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:01:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:01:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:01:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:01:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:01:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:01:38 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:01:38 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:01:38 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:01:38 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:01:38 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:01:38 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:01:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:01:38 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4847 for partition ticketmaster-0\n",
      "23/06/24 15:01:38 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:01:39 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:01:39 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:01:39 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4849.\n",
      "23/06/24 15:01:40 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8ae9bced-43fc-45fc-87ce-71256d7dcb37/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:01:40 INFO FileOutputCommitter: Saved output of task 'attempt_202306241501386854639227359393471_0008_m_000000_8' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8ae9bced-43fc-45fc-87ce-71256d7dcb37/_temporary/0/task_202306241501386854639227359393471_0008_m_000000\n",
      "23/06/24 15:01:40 INFO SparkHadoopMapRedUtil: attempt_202306241501386854639227359393471_0008_m_000000_8: Committed. Elapsed time: 693 ms.\n",
      "23/06/24 15:01:40 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 2579 bytes result sent to driver\n",
      "23/06/24 15:01:40 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 1634 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:01:40 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:01:40 INFO DAGScheduler: ResultStage 8 (start at NativeMethodAccessorImpl.java:0) finished in 1.673 s\n",
      "23/06/24 15:01:40 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:01:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished\n",
      "23/06/24 15:01:40 INFO DAGScheduler: Job 8 finished: start at NativeMethodAccessorImpl.java:0, took 1.675298 s\n",
      "23/06/24 15:01:40 INFO FileFormatWriter: Start to commit write Job 007a53c9-7263-429e-bb0a-73bd94b35039.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:01:40 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8ae9bced-43fc-45fc-87ce-71256d7dcb37/_temporary/0/task_202306241501386854639227359393471_0008_m_000000/' directory.\n",
      "23/06/24 15:01:41 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8ae9bced-43fc-45fc-87ce-71256d7dcb37/' directory.\n",
      "23/06/24 15:01:41 INFO BlockManagerInfo: Removed broadcast_8_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:01:41 INFO FileFormatWriter: Write Job 007a53c9-7263-429e-bb0a-73bd94b35039 committed. Elapsed time: 1537 ms.\n",
      "23/06/24 15:01:41 INFO FileFormatWriter: Finished processing stats for write job 007a53c9-7263-429e-bb0a-73bd94b35039.\n",
      "23/06/24 15:01:42 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8ae9bced-43fc-45fc-87ce-71256d7dcb37/part-00000-22a47244-db8f-47d8-b0ae-274abc441ccb-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=581b4f90-2728-4c98-8d0a-aa0aae57d455, location=US}\n",
      "23/06/24 15:01:44 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=581b4f90-2728-4c98-8d0a-aa0aae57d455, location=US}\n",
      "23/06/24 15:01:44 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/212 using temp file gs://kafka-spark-data/spark-metadata/commits/.212.60529657-fa1b-4826-8f53-d00412dcb772.tmp\n",
      "23/06/24 15:01:45 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.212.60529657-fa1b-4826-8f53-d00412dcb772.tmp to gs://kafka-spark-data/spark-metadata/commits/212\n",
      "23/06/24 15:01:45 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:01:36.271Z\",\n",
      "  \"batchId\" : 212,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.19466614755693987,\n",
      "  \"processedRowsPerSecond\" : 0.21265284423179162,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6958,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 8,\n",
      "    \"queryPlanning\" : 11,\n",
      "    \"triggerExecution\" : 9405,\n",
      "    \"walCommit\" : 1481\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4846\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4848\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.19466614755693987,\n",
      "    \"processedRowsPerSecond\" : 0.21265284423179162\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:01:45 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:01:45 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4850.\n",
      "23/06/24 15:01:45 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/213 using temp file gs://kafka-spark-data/spark-metadata/offsets/.213.b3f3f742-1872-4726-a596-c3faa6fca084.tmp\n",
      "23/06/24 15:01:46 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.213.b3f3f742-1872-4726-a596-c3faa6fca084.tmp to gs://kafka-spark-data/spark-metadata/offsets/213\n",
      "23/06/24 15:01:46 INFO MicroBatchExecution: Committed offsets for batch 213. Metadata OffsetSeqMetadata(0,1687636905704,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:01:47 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:01:47 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:01:47 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:01:47 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:01:47 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:01:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:01:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:01:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:01:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:01:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:01:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:01:47 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:01:47 INFO DAGScheduler: Got job 9 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:01:47 INFO DAGScheduler: Final stage: ResultStage 9 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:01:47 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:01:47 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:01:47 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[69] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:01:47 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:01:47 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:01:47 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:01:47 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:01:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[69] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:01:47 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:01:47 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:01:47 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)\n",
      "23/06/24 15:01:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:01:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:01:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:01:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:01:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:01:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:01:47 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:01:47 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:01:47 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:01:47 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:01:47 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:01:47 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:01:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:01:47 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4849 for partition ticketmaster-0\n",
      "23/06/24 15:01:47 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:01:48 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:01:48 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:01:48 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4851.\n",
      "23/06/24 15:01:49 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-67f3cd24-2063-47d3-a2bb-7caa86a87d07/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:01:49 INFO FileOutputCommitter: Saved output of task 'attempt_202306241501477964405640832713663_0009_m_000000_9' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-67f3cd24-2063-47d3-a2bb-7caa86a87d07/_temporary/0/task_202306241501477964405640832713663_0009_m_000000\n",
      "23/06/24 15:01:49 INFO SparkHadoopMapRedUtil: attempt_202306241501477964405640832713663_0009_m_000000_9: Committed. Elapsed time: 566 ms.\n",
      "23/06/24 15:01:49 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 2579 bytes result sent to driver\n",
      "23/06/24 15:01:49 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 1494 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:01:49 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:01:49 INFO DAGScheduler: ResultStage 9 (start at NativeMethodAccessorImpl.java:0) finished in 1.543 s\n",
      "23/06/24 15:01:49 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:01:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished\n",
      "23/06/24 15:01:49 INFO DAGScheduler: Job 9 finished: start at NativeMethodAccessorImpl.java:0, took 1.545542 s\n",
      "23/06/24 15:01:49 INFO FileFormatWriter: Start to commit write Job 1a4f737f-07dc-43be-a128-16a516a63bc0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:01:49 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-67f3cd24-2063-47d3-a2bb-7caa86a87d07/_temporary/0/task_202306241501477964405640832713663_0009_m_000000/' directory.\n",
      "23/06/24 15:01:50 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-67f3cd24-2063-47d3-a2bb-7caa86a87d07/' directory.\n",
      "23/06/24 15:01:50 INFO FileFormatWriter: Write Job 1a4f737f-07dc-43be-a128-16a516a63bc0 committed. Elapsed time: 1492 ms.\n",
      "23/06/24 15:01:50 INFO FileFormatWriter: Finished processing stats for write job 1a4f737f-07dc-43be-a128-16a516a63bc0.\n",
      "23/06/24 15:01:50 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-67f3cd24-2063-47d3-a2bb-7caa86a87d07/part-00000-63bf8a40-167d-422f-8fd0-389cfc43358c-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=b5837788-febe-456c-9046-d5164bc85d0c, location=US}\n",
      "23/06/24 15:01:52 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=b5837788-febe-456c-9046-d5164bc85d0c, location=US}\n",
      "23/06/24 15:01:53 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/213 using temp file gs://kafka-spark-data/spark-metadata/commits/.213.d66218b8-9a40-4625-8451-6b7f76d3d21e.tmp\n",
      "23/06/24 15:01:54 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.213.d66218b8-9a40-4625-8451-6b7f76d3d21e.tmp to gs://kafka-spark-data/spark-metadata/commits/213\n",
      "23/06/24 15:01:54 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:01:45.682Z\",\n",
      "  \"batchId\" : 213,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.21251726702794602,\n",
      "  \"processedRowsPerSecond\" : 0.23245002324500236,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6139,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 22,\n",
      "    \"queryPlanning\" : 9,\n",
      "    \"triggerExecution\" : 8604,\n",
      "    \"walCommit\" : 1419\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4848\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4850\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.21251726702794602,\n",
      "    \"processedRowsPerSecond\" : 0.23245002324500236\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:01:54 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:01:54 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4852.\n",
      "23/06/24 15:01:54 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/214 using temp file gs://kafka-spark-data/spark-metadata/offsets/.214.6fc78359-1cb1-4d2e-8ce3-af6db7c90620.tmp\n",
      "23/06/24 15:01:54 INFO BlockManagerInfo: Removed broadcast_9_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:01:55 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.214.6fc78359-1cb1-4d2e-8ce3-af6db7c90620.tmp to gs://kafka-spark-data/spark-metadata/offsets/214\n",
      "23/06/24 15:01:55 INFO MicroBatchExecution: Committed offsets for batch 214. Metadata OffsetSeqMetadata(0,1687636914297,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:01:55 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:01:55 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:01:55 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:01:55 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:01:56 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:01:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:01:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:01:56 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:01:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:01:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:01:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:01:56 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:01:56 INFO DAGScheduler: Got job 10 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:01:56 INFO DAGScheduler: Final stage: ResultStage 10 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:01:56 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:01:56 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:01:56 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[76] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:01:56 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:01:56 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:01:56 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:01:56 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:01:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[76] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:01:56 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:01:56 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:01:56 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)\n",
      "23/06/24 15:01:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:01:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:01:56 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:01:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:01:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:01:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:01:56 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:01:56 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:01:56 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:01:56 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:01:56 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:01:56 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:01:56 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:01:56 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4851 for partition ticketmaster-0\n",
      "23/06/24 15:01:56 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:01:57 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:01:57 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:01:57 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4853.\n",
      "23/06/24 15:01:58 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-7bf8cecd-8db8-4b09-9d8b-39d9f796addb/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:01:58 INFO FileOutputCommitter: Saved output of task 'attempt_202306241501568066687536157810260_0010_m_000000_10' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-7bf8cecd-8db8-4b09-9d8b-39d9f796addb/_temporary/0/task_202306241501568066687536157810260_0010_m_000000\n",
      "23/06/24 15:01:58 INFO SparkHadoopMapRedUtil: attempt_202306241501568066687536157810260_0010_m_000000_10: Committed. Elapsed time: 593 ms.\n",
      "23/06/24 15:01:58 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 2536 bytes result sent to driver\n",
      "23/06/24 15:01:58 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 1594 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:01:58 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:01:58 INFO DAGScheduler: ResultStage 10 (start at NativeMethodAccessorImpl.java:0) finished in 1.616 s\n",
      "23/06/24 15:01:58 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:01:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished\n",
      "23/06/24 15:01:58 INFO DAGScheduler: Job 10 finished: start at NativeMethodAccessorImpl.java:0, took 1.617871 s\n",
      "23/06/24 15:01:58 INFO FileFormatWriter: Start to commit write Job 8f32b3c2-819e-4fd3-9aca-8c54ff4a90a9.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:01:58 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-7bf8cecd-8db8-4b09-9d8b-39d9f796addb/_temporary/0/task_202306241501568066687536157810260_0010_m_000000/' directory.\n",
      "23/06/24 15:01:59 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-7bf8cecd-8db8-4b09-9d8b-39d9f796addb/' directory.\n",
      "23/06/24 15:01:59 INFO FileFormatWriter: Write Job 8f32b3c2-819e-4fd3-9aca-8c54ff4a90a9 committed. Elapsed time: 1443 ms.\n",
      "23/06/24 15:01:59 INFO FileFormatWriter: Finished processing stats for write job 8f32b3c2-819e-4fd3-9aca-8c54ff4a90a9.\n",
      "23/06/24 15:02:00 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-7bf8cecd-8db8-4b09-9d8b-39d9f796addb/part-00000-59f366fe-5f53-4efe-9467-fc09a9216444-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=4a6eefcb-4766-4461-91f6-d15d55911ef0, location=US}\n",
      "23/06/24 15:02:03 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=4a6eefcb-4766-4461-91f6-d15d55911ef0, location=US}\n",
      "23/06/24 15:02:03 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/214 using temp file gs://kafka-spark-data/spark-metadata/commits/.214.5aa95fb6-3da2-4f06-912f-751e74a044db.tmp\n",
      "23/06/24 15:02:04 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.214.5aa95fb6-3da2-4f06-912f-751e74a044db.tmp to gs://kafka-spark-data/spark-metadata/commits/214\n",
      "23/06/24 15:02:04 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:01:54.288Z\",\n",
      "  \"batchId\" : 214,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.23239600278875203,\n",
      "  \"processedRowsPerSecond\" : 0.18977132555270898,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7733,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 9,\n",
      "    \"queryPlanning\" : 17,\n",
      "    \"triggerExecution\" : 10539,\n",
      "    \"walCommit\" : 1569\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4850\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4852\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.23239600278875203,\n",
      "    \"processedRowsPerSecond\" : 0.18977132555270898\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:02:04 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 10542 milliseconds\n",
      "23/06/24 15:02:04 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:02:04 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4854.\n",
      "23/06/24 15:02:05 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/215 using temp file gs://kafka-spark-data/spark-metadata/offsets/.215.713a2699-a822-4892-ab98-c178f1e0d2e9.tmp\n",
      "23/06/24 15:02:05 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.215.713a2699-a822-4892-ab98-c178f1e0d2e9.tmp to gs://kafka-spark-data/spark-metadata/offsets/215\n",
      "23/06/24 15:02:05 INFO MicroBatchExecution: Committed offsets for batch 215. Metadata OffsetSeqMetadata(0,1687636924838,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:02:06 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:02:06 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:02:06 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:02:06 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:02:06 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:02:06 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:02:06 INFO DAGScheduler: Got job 11 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:02:06 INFO DAGScheduler: Final stage: ResultStage 11 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:02:06 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:02:06 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:02:06 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[83] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:02:06 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 295.4 KiB, free 433.7 MiB)\n",
      "23/06/24 15:02:06 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 433.6 MiB)\n",
      "23/06/24 15:02:06 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.2 MiB)\n",
      "23/06/24 15:02:06 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:02:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[83] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:02:06 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:02:06 INFO BlockManagerInfo: Removed broadcast_10_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:02:06 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:02:06 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)\n",
      "23/06/24 15:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:02:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:02:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:02:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:02:06 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:02:06 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:02:06 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:02:06 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:02:06 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:02:06 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:02:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:02:07 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4853 for partition ticketmaster-0\n",
      "23/06/24 15:02:07 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:02:07 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:02:07 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:02:07 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4855.\n",
      "23/06/24 15:02:08 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-58461425-12d7-4359-995f-56ecadab0f09/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:02:08 INFO FileOutputCommitter: Saved output of task 'attempt_202306241502068016195644599335974_0011_m_000000_11' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-58461425-12d7-4359-995f-56ecadab0f09/_temporary/0/task_202306241502068016195644599335974_0011_m_000000\n",
      "23/06/24 15:02:08 INFO SparkHadoopMapRedUtil: attempt_202306241502068016195644599335974_0011_m_000000_11: Committed. Elapsed time: 606 ms.\n",
      "23/06/24 15:02:08 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 2579 bytes result sent to driver\n",
      "23/06/24 15:02:08 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 1551 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:02:08 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:02:08 INFO DAGScheduler: ResultStage 11 (start at NativeMethodAccessorImpl.java:0) finished in 1.588 s\n",
      "23/06/24 15:02:08 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:02:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished\n",
      "23/06/24 15:02:08 INFO DAGScheduler: Job 11 finished: start at NativeMethodAccessorImpl.java:0, took 1.592236 s\n",
      "23/06/24 15:02:08 INFO FileFormatWriter: Start to commit write Job 2f2c2bd7-6b36-47a5-b2fb-f90c130a587c.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:02:09 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-58461425-12d7-4359-995f-56ecadab0f09/_temporary/0/task_202306241502068016195644599335974_0011_m_000000/' directory.\n",
      "23/06/24 15:02:09 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-58461425-12d7-4359-995f-56ecadab0f09/' directory.\n",
      "23/06/24 15:02:09 INFO FileFormatWriter: Write Job 2f2c2bd7-6b36-47a5-b2fb-f90c130a587c committed. Elapsed time: 1435 ms.\n",
      "23/06/24 15:02:09 INFO FileFormatWriter: Finished processing stats for write job 2f2c2bd7-6b36-47a5-b2fb-f90c130a587c.\n",
      "23/06/24 15:02:10 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-58461425-12d7-4359-995f-56ecadab0f09/part-00000-6186480f-d5cc-4a5d-966e-0ff47ea8cd46-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=3c40bed3-1c16-4801-87cd-8cbb6b9ecf1b, location=US}\n",
      "23/06/24 15:02:12 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=3c40bed3-1c16-4801-87cd-8cbb6b9ecf1b, location=US}\n",
      "23/06/24 15:02:12 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/215 using temp file gs://kafka-spark-data/spark-metadata/commits/.215.7c44ddaf-dab1-42e9-9623-18da6b49b209.tmp\n",
      "23/06/24 15:02:13 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.215.7c44ddaf-dab1-42e9-9623-18da6b49b209.tmp to gs://kafka-spark-data/spark-metadata/commits/215\n",
      "23/06/24 15:02:13 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:02:04.831Z\",\n",
      "  \"batchId\" : 215,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.1896993265673907,\n",
      "  \"processedRowsPerSecond\" : 0.23266635644485806,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 5977,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 7,\n",
      "    \"queryPlanning\" : 6,\n",
      "    \"triggerExecution\" : 8596,\n",
      "    \"walCommit\" : 1467\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4852\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4854\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.1896993265673907,\n",
      "    \"processedRowsPerSecond\" : 0.23266635644485806\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:02:13 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:02:13 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4856.\n",
      "23/06/24 15:02:13 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/216 using temp file gs://kafka-spark-data/spark-metadata/offsets/.216.ee646819-327d-4e93-8616-14d4dc88d93c.tmp\n",
      "23/06/24 15:02:14 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.216.ee646819-327d-4e93-8616-14d4dc88d93c.tmp to gs://kafka-spark-data/spark-metadata/offsets/216\n",
      "23/06/24 15:02:14 INFO MicroBatchExecution: Committed offsets for batch 216. Metadata OffsetSeqMetadata(0,1687636933449,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:02:14 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:02:14 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:02:14 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:02:14 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:02:15 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:02:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:02:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:02:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:02:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:02:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:02:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:02:15 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:02:15 INFO DAGScheduler: Got job 12 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:02:15 INFO DAGScheduler: Final stage: ResultStage 12 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:02:15 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:02:15 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:02:15 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[90] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:02:15 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 295.4 KiB, free 433.7 MiB)\n",
      "23/06/24 15:02:15 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 433.6 MiB)\n",
      "23/06/24 15:02:15 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.2 MiB)\n",
      "23/06/24 15:02:15 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:02:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[90] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:02:15 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:02:15 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:02:15 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)\n",
      "23/06/24 15:02:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:02:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:02:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:02:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:02:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:02:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:02:15 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:02:15 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:02:15 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:02:15 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:02:15 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:02:15 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:02:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:02:15 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4855 for partition ticketmaster-0\n",
      "23/06/24 15:02:15 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:02:16 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:02:16 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:02:16 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4856.\n",
      "23/06/24 15:02:17 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-6ee74ff3-ef5c-443a-ab9e-b669588be8df/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:02:17 INFO FileOutputCommitter: Saved output of task 'attempt_202306241502156071345516681221641_0012_m_000000_12' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-6ee74ff3-ef5c-443a-ab9e-b669588be8df/_temporary/0/task_202306241502156071345516681221641_0012_m_000000\n",
      "23/06/24 15:02:17 INFO SparkHadoopMapRedUtil: attempt_202306241502156071345516681221641_0012_m_000000_12: Committed. Elapsed time: 669 ms.\n",
      "23/06/24 15:02:17 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 2536 bytes result sent to driver\n",
      "23/06/24 15:02:17 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 1605 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:02:17 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:02:17 INFO DAGScheduler: ResultStage 12 (start at NativeMethodAccessorImpl.java:0) finished in 1.648 s\n",
      "23/06/24 15:02:17 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:02:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished\n",
      "23/06/24 15:02:17 INFO DAGScheduler: Job 12 finished: start at NativeMethodAccessorImpl.java:0, took 1.651521 s\n",
      "23/06/24 15:02:17 INFO FileFormatWriter: Start to commit write Job 1e02f996-554b-4d7c-963e-2772b6e8b98f.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:02:17 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-6ee74ff3-ef5c-443a-ab9e-b669588be8df/_temporary/0/task_202306241502156071345516681221641_0012_m_000000/' directory.\n",
      "23/06/24 15:02:17 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-6ee74ff3-ef5c-443a-ab9e-b669588be8df/' directory.\n",
      "23/06/24 15:02:18 INFO FileFormatWriter: Write Job 1e02f996-554b-4d7c-963e-2772b6e8b98f committed. Elapsed time: 1349 ms.\n",
      "23/06/24 15:02:18 INFO FileFormatWriter: Finished processing stats for write job 1e02f996-554b-4d7c-963e-2772b6e8b98f.\n",
      "23/06/24 15:02:18 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-6ee74ff3-ef5c-443a-ab9e-b669588be8df/part-00000-21842f4f-f758-4586-95f3-f49d1e9f3eb9-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=f1ef4363-b805-4c15-acd2-94ac0fa1ebe6, location=US}\n",
      "23/06/24 15:02:40 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=f1ef4363-b805-4c15-acd2-94ac0fa1ebe6, location=US}\n",
      "23/06/24 15:02:40 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/216 using temp file gs://kafka-spark-data/spark-metadata/commits/.216.d49edcc8-a379-44e5-89b9-38d366c0fba7.tmp\n",
      "23/06/24 15:02:41 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.216.d49edcc8-a379-44e5-89b9-38d366c0fba7.tmp to gs://kafka-spark-data/spark-metadata/commits/216\n",
      "23/06/24 15:02:41 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:02:13.433Z\",\n",
      "  \"batchId\" : 216,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.23250406882120436,\n",
      "  \"processedRowsPerSecond\" : 0.07093456286575633,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 25783,\n",
      "    \"getBatch\" : 3,\n",
      "    \"latestOffset\" : 16,\n",
      "    \"queryPlanning\" : 20,\n",
      "    \"triggerExecution\" : 28195,\n",
      "    \"walCommit\" : 1463\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4854\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4856\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.23250406882120436,\n",
      "    \"processedRowsPerSecond\" : 0.07093456286575633\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:02:41 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 28197 milliseconds\n",
      "23/06/24 15:02:41 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:02:41 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4862.\n",
      "23/06/24 15:02:41 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/217 using temp file gs://kafka-spark-data/spark-metadata/offsets/.217.22fbf444-5733-4a47-83c1-45f7326a2c09.tmp\n",
      "23/06/24 15:02:42 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.217.22fbf444-5733-4a47-83c1-45f7326a2c09.tmp to gs://kafka-spark-data/spark-metadata/offsets/217\n",
      "23/06/24 15:02:42 INFO MicroBatchExecution: Committed offsets for batch 217. Metadata OffsetSeqMetadata(0,1687636961639,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:02:42 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:02:42 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:02:42 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:02:42 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:02:43 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:02:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:02:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:02:43 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:02:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:02:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:02:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:02:43 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:02:43 INFO DAGScheduler: Got job 13 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:02:43 INFO DAGScheduler: Final stage: ResultStage 13 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:02:43 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:02:43 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:02:43 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[97] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:02:43 INFO BlockManagerInfo: Removed broadcast_12_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:02:43 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 295.4 KiB, free 433.7 MiB)\n",
      "23/06/24 15:02:43 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 433.6 MiB)\n",
      "23/06/24 15:02:43 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.2 MiB)\n",
      "23/06/24 15:02:43 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:02:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[97] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:02:43 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:02:43 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:02:43 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)\n",
      "23/06/24 15:02:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:02:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:02:43 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:02:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:02:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:02:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:02:43 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:02:43 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:02:43 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:02:43 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:02:43 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:02:43 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:02:43 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:02:43 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4856 for partition ticketmaster-0\n",
      "23/06/24 15:02:43 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:02:44 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:02:44 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:02:44 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4862.\n",
      "23/06/24 15:02:45 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-00ca2b24-5965-403b-97db-e06a98ea0fbc/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:02:45 INFO FileOutputCommitter: Saved output of task 'attempt_202306241502432805985332119756274_0013_m_000000_13' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-00ca2b24-5965-403b-97db-e06a98ea0fbc/_temporary/0/task_202306241502432805985332119756274_0013_m_000000\n",
      "23/06/24 15:02:45 INFO SparkHadoopMapRedUtil: attempt_202306241502432805985332119756274_0013_m_000000_13: Committed. Elapsed time: 617 ms.\n",
      "23/06/24 15:02:45 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 2579 bytes result sent to driver\n",
      "23/06/24 15:02:45 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 1557 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:02:45 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:02:45 INFO DAGScheduler: ResultStage 13 (start at NativeMethodAccessorImpl.java:0) finished in 1.605 s\n",
      "23/06/24 15:02:45 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:02:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished\n",
      "23/06/24 15:02:45 INFO DAGScheduler: Job 13 finished: start at NativeMethodAccessorImpl.java:0, took 1.608737 s\n",
      "23/06/24 15:02:45 INFO FileFormatWriter: Start to commit write Job d9c77843-b326-4b02-854f-d2038d315a33.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:02:45 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-00ca2b24-5965-403b-97db-e06a98ea0fbc/_temporary/0/task_202306241502432805985332119756274_0013_m_000000/' directory.\n",
      "23/06/24 15:02:46 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-00ca2b24-5965-403b-97db-e06a98ea0fbc/' directory.\n",
      "23/06/24 15:02:46 INFO BlockManagerInfo: Removed broadcast_13_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:02:46 INFO BlockManagerInfo: Removed broadcast_11_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:02:46 INFO FileFormatWriter: Write Job d9c77843-b326-4b02-854f-d2038d315a33 committed. Elapsed time: 1313 ms.\n",
      "23/06/24 15:02:46 INFO FileFormatWriter: Finished processing stats for write job d9c77843-b326-4b02-854f-d2038d315a33.\n",
      "23/06/24 15:02:46 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-00ca2b24-5965-403b-97db-e06a98ea0fbc/part-00000-12f57f20-469f-45d0-92a4-45f58eaea3c2-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=5a921112-7092-4495-8d5d-7090e6b4f2ae, location=US}\n",
      "23/06/24 15:02:48 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=5a921112-7092-4495-8d5d-7090e6b4f2ae, location=US}\n",
      "23/06/24 15:02:49 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/217 using temp file gs://kafka-spark-data/spark-metadata/commits/.217.b36ae568-b436-4c4e-945d-6a5b6e4a4c4f.tmp\n",
      "23/06/24 15:02:49 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.217.b36ae568-b436-4c4e-945d-6a5b6e4a4c4f.tmp to gs://kafka-spark-data/spark-metadata/commits/217\n",
      "23/06/24 15:02:49 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:02:41.630Z\",\n",
      "  \"batchId\" : 217,\n",
      "  \"numInputRows\" : 6,\n",
      "  \"inputRowsPerSecond\" : 0.21278859453133311,\n",
      "  \"processedRowsPerSecond\" : 0.7226303745634107,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 5947,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 9,\n",
      "    \"queryPlanning\" : 11,\n",
      "    \"triggerExecution\" : 8303,\n",
      "    \"walCommit\" : 1290\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4856\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4862\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 6,\n",
      "    \"inputRowsPerSecond\" : 0.21278859453133311,\n",
      "    \"processedRowsPerSecond\" : 0.7226303745634107\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:02:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:02:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4863.\n",
      "23/06/24 15:02:50 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/218 using temp file gs://kafka-spark-data/spark-metadata/offsets/.218.b6c8e196-1128-4508-9c7c-000614cdb93c.tmp\n",
      "23/06/24 15:02:51 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.218.b6c8e196-1128-4508-9c7c-000614cdb93c.tmp to gs://kafka-spark-data/spark-metadata/offsets/218\n",
      "23/06/24 15:02:51 INFO MicroBatchExecution: Committed offsets for batch 218. Metadata OffsetSeqMetadata(0,1687636970018,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:02:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:02:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:02:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:02:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:02:51 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:02:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:02:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:02:51 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:02:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:02:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:02:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:02:51 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:02:51 INFO DAGScheduler: Got job 14 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:02:51 INFO DAGScheduler: Final stage: ResultStage 14 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:02:51 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:02:51 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:02:51 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[104] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:02:51 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:02:51 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:02:51 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:02:51 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:02:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[104] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:02:51 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:02:52 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:02:52 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)\n",
      "23/06/24 15:02:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:02:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:02:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:02:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:02:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:02:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:02:52 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:02:52 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:02:52 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:02:52 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:02:52 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:02:52 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:02:52 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:02:52 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4862 for partition ticketmaster-0\n",
      "23/06/24 15:02:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:02:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:02:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:02:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4864.\n",
      "23/06/24 15:02:53 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8892f334-8a5c-4a6e-a759-68194c7c7312/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:02:53 INFO FileOutputCommitter: Saved output of task 'attempt_202306241502513578040999968829847_0014_m_000000_14' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8892f334-8a5c-4a6e-a759-68194c7c7312/_temporary/0/task_202306241502513578040999968829847_0014_m_000000\n",
      "23/06/24 15:02:53 INFO SparkHadoopMapRedUtil: attempt_202306241502513578040999968829847_0014_m_000000_14: Committed. Elapsed time: 575 ms.\n",
      "23/06/24 15:02:53 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 2536 bytes result sent to driver\n",
      "23/06/24 15:02:53 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 1502 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:02:53 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:02:53 INFO DAGScheduler: ResultStage 14 (start at NativeMethodAccessorImpl.java:0) finished in 1.543 s\n",
      "23/06/24 15:02:53 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:02:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished\n",
      "23/06/24 15:02:53 INFO DAGScheduler: Job 14 finished: start at NativeMethodAccessorImpl.java:0, took 1.545314 s\n",
      "23/06/24 15:02:53 INFO FileFormatWriter: Start to commit write Job 6742c57b-2b88-404c-a95a-b6637297ada1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:02:54 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8892f334-8a5c-4a6e-a759-68194c7c7312/_temporary/0/task_202306241502513578040999968829847_0014_m_000000/' directory.\n",
      "23/06/24 15:02:54 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8892f334-8a5c-4a6e-a759-68194c7c7312/' directory.\n",
      "23/06/24 15:02:54 INFO FileFormatWriter: Write Job 6742c57b-2b88-404c-a95a-b6637297ada1 committed. Elapsed time: 1484 ms.\n",
      "23/06/24 15:02:54 INFO FileFormatWriter: Finished processing stats for write job 6742c57b-2b88-404c-a95a-b6637297ada1.\n",
      "23/06/24 15:02:55 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8892f334-8a5c-4a6e-a759-68194c7c7312/part-00000-e4ff708c-38f1-49f4-913d-5d11bf36041c-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=50b4308e-0622-4064-9f41-5be8efb442e8, location=US}\n",
      "23/06/24 15:02:57 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=50b4308e-0622-4064-9f41-5be8efb442e8, location=US}\n",
      "23/06/24 15:02:57 INFO BlockManagerInfo: Removed broadcast_14_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:02:58 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/218 using temp file gs://kafka-spark-data/spark-metadata/commits/.218.74ea76b5-6400-4749-aae7-b26223e90264.tmp\n",
      "23/06/24 15:02:58 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.218.74ea76b5-6400-4749-aae7-b26223e90264.tmp to gs://kafka-spark-data/spark-metadata/commits/218\n",
      "23/06/24 15:02:58 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:02:50.001Z\",\n",
      "  \"batchId\" : 218,\n",
      "  \"numInputRows\" : 1,\n",
      "  \"inputRowsPerSecond\" : 0.1194600406164138,\n",
      "  \"processedRowsPerSecond\" : 0.11312217194570136,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6362,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 16,\n",
      "    \"queryPlanning\" : 10,\n",
      "    \"triggerExecution\" : 8840,\n",
      "    \"walCommit\" : 1457\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4862\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4863\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 1,\n",
      "    \"inputRowsPerSecond\" : 0.1194600406164138,\n",
      "    \"processedRowsPerSecond\" : 0.11312217194570136\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:03:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:03:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4865.\n",
      "23/06/24 15:03:00 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/219 using temp file gs://kafka-spark-data/spark-metadata/offsets/.219.a3d51cf9-31dd-43e5-a947-42e4b7f9e218.tmp\n",
      "23/06/24 15:03:01 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.219.a3d51cf9-31dd-43e5-a947-42e4b7f9e218.tmp to gs://kafka-spark-data/spark-metadata/offsets/219\n",
      "23/06/24 15:03:01 INFO MicroBatchExecution: Committed offsets for batch 219. Metadata OffsetSeqMetadata(0,1687636980017,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:03:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:03:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:03:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:03:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:03:01 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:03:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:03:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:03:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:03:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:03:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:03:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:03:02 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:03:02 INFO DAGScheduler: Got job 15 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:03:02 INFO DAGScheduler: Final stage: ResultStage 15 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:03:02 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:03:02 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:03:02 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[111] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:03:02 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:03:02 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:03:02 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:03:02 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:03:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[111] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:03:02 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:03:02 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:03:02 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)\n",
      "23/06/24 15:03:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:03:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:03:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:03:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:03:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:03:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:03:02 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:03:02 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:03:02 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:03:02 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:03:02 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:03:02 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:03:02 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:03:02 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4864 for partition ticketmaster-0\n",
      "23/06/24 15:03:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:03:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:03:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:03:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:03:03 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-61f7576d-48e1-4b95-92dc-8778ab81659f/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:03:03 INFO FileOutputCommitter: Saved output of task 'attempt_202306241503027160193761214221700_0015_m_000000_15' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-61f7576d-48e1-4b95-92dc-8778ab81659f/_temporary/0/task_202306241503027160193761214221700_0015_m_000000\n",
      "23/06/24 15:03:03 INFO SparkHadoopMapRedUtil: attempt_202306241503027160193761214221700_0015_m_000000_15: Committed. Elapsed time: 595 ms.\n",
      "23/06/24 15:03:03 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 2579 bytes result sent to driver\n",
      "23/06/24 15:03:03 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 1530 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:03:03 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:03:03 INFO DAGScheduler: ResultStage 15 (start at NativeMethodAccessorImpl.java:0) finished in 1.548 s\n",
      "23/06/24 15:03:03 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:03:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished\n",
      "23/06/24 15:03:03 INFO DAGScheduler: Job 15 finished: start at NativeMethodAccessorImpl.java:0, took 1.549561 s\n",
      "23/06/24 15:03:03 INFO FileFormatWriter: Start to commit write Job 4f1f1929-4b2e-413c-bfe3-8837c5e97ef7.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:03:04 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-61f7576d-48e1-4b95-92dc-8778ab81659f/_temporary/0/task_202306241503027160193761214221700_0015_m_000000/' directory.\n",
      "23/06/24 15:03:04 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-61f7576d-48e1-4b95-92dc-8778ab81659f/' directory.\n",
      "23/06/24 15:03:04 INFO BlockManagerInfo: Removed broadcast_15_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:03:05 INFO FileFormatWriter: Write Job 4f1f1929-4b2e-413c-bfe3-8837c5e97ef7 committed. Elapsed time: 1364 ms.\n",
      "23/06/24 15:03:05 INFO FileFormatWriter: Finished processing stats for write job 4f1f1929-4b2e-413c-bfe3-8837c5e97ef7.\n",
      "23/06/24 15:03:05 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-61f7576d-48e1-4b95-92dc-8778ab81659f/part-00000-c7ed8428-4451-45cb-b26b-d1da26ede313-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=bab22f9e-bc03-496f-8976-069590b086ff, location=US}\n",
      "23/06/24 15:03:07 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=bab22f9e-bc03-496f-8976-069590b086ff, location=US}\n",
      "23/06/24 15:03:08 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/219 using temp file gs://kafka-spark-data/spark-metadata/commits/.219.8a55b674-519d-47ca-ba45-91fa726491fd.tmp\n",
      "23/06/24 15:03:09 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.219.8a55b674-519d-47ca-ba45-91fa726491fd.tmp to gs://kafka-spark-data/spark-metadata/commits/219\n",
      "23/06/24 15:03:09 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:03:00.006Z\",\n",
      "  \"batchId\" : 219,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.19990004997501248,\n",
      "  \"processedRowsPerSecond\" : 0.21997360316761988,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6366,\n",
      "    \"getBatch\" : 2,\n",
      "    \"latestOffset\" : 11,\n",
      "    \"queryPlanning\" : 29,\n",
      "    \"triggerExecution\" : 9091,\n",
      "    \"walCommit\" : 1563\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4863\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4865\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.19990004997501248,\n",
      "    \"processedRowsPerSecond\" : 0.21997360316761988\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:03:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:03:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4867.\n",
      "23/06/24 15:03:10 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/220 using temp file gs://kafka-spark-data/spark-metadata/offsets/.220.0e09b940-a755-46b9-81f7-3371442ab6d7.tmp\n",
      "23/06/24 15:03:11 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.220.0e09b940-a755-46b9-81f7-3371442ab6d7.tmp to gs://kafka-spark-data/spark-metadata/offsets/220\n",
      "23/06/24 15:03:11 INFO MicroBatchExecution: Committed offsets for batch 220. Metadata OffsetSeqMetadata(0,1687636990035,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:03:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:03:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:03:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:03:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:03:11 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:03:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:03:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:03:11 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:03:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:03:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:03:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:03:11 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:03:11 INFO DAGScheduler: Got job 16 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:03:11 INFO DAGScheduler: Final stage: ResultStage 16 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:03:11 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:03:11 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:03:11 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[118] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:03:12 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:03:12 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:03:12 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:03:12 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:03:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[118] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:03:12 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:03:12 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:03:12 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)\n",
      "23/06/24 15:03:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:03:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:03:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:03:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:03:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:03:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:03:12 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:03:12 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:03:12 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:03:12 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:03:12 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:03:12 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:03:12 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:03:12 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4866 for partition ticketmaster-0\n",
      "23/06/24 15:03:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:03:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:03:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:03:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4868.\n",
      "23/06/24 15:03:13 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-e0b8863d-61fc-4cec-8f15-9ffcb5df0baf/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:03:13 INFO FileOutputCommitter: Saved output of task 'attempt_202306241503113096927068600842272_0016_m_000000_16' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-e0b8863d-61fc-4cec-8f15-9ffcb5df0baf/_temporary/0/task_202306241503113096927068600842272_0016_m_000000\n",
      "23/06/24 15:03:13 INFO SparkHadoopMapRedUtil: attempt_202306241503113096927068600842272_0016_m_000000_16: Committed. Elapsed time: 676 ms.\n",
      "23/06/24 15:03:13 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 2579 bytes result sent to driver\n",
      "23/06/24 15:03:13 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 1713 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:03:13 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:03:13 INFO DAGScheduler: ResultStage 16 (start at NativeMethodAccessorImpl.java:0) finished in 1.740 s\n",
      "23/06/24 15:03:13 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:03:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished\n",
      "23/06/24 15:03:13 INFO DAGScheduler: Job 16 finished: start at NativeMethodAccessorImpl.java:0, took 1.747482 s\n",
      "23/06/24 15:03:13 INFO FileFormatWriter: Start to commit write Job 10523add-8734-4217-93d1-ca0e55d36110.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:03:14 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-e0b8863d-61fc-4cec-8f15-9ffcb5df0baf/_temporary/0/task_202306241503113096927068600842272_0016_m_000000/' directory.\n",
      "23/06/24 15:03:14 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-e0b8863d-61fc-4cec-8f15-9ffcb5df0baf/' directory.\n",
      "23/06/24 15:03:14 INFO BlockManagerInfo: Removed broadcast_16_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:03:15 INFO FileFormatWriter: Write Job 10523add-8734-4217-93d1-ca0e55d36110 committed. Elapsed time: 1428 ms.\n",
      "23/06/24 15:03:15 INFO FileFormatWriter: Finished processing stats for write job 10523add-8734-4217-93d1-ca0e55d36110.\n",
      "23/06/24 15:03:15 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-e0b8863d-61fc-4cec-8f15-9ffcb5df0baf/part-00000-7bbcbc27-6a31-4a5e-8d2a-94a099b2edc2-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=0ba4fe76-921c-4ba4-985a-9abf9f6e80a0, location=US}\n",
      "23/06/24 15:03:17 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=0ba4fe76-921c-4ba4-985a-9abf9f6e80a0, location=US}\n",
      "23/06/24 15:03:18 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/220 using temp file gs://kafka-spark-data/spark-metadata/commits/.220.3bd0ef1a-b4c9-4e4f-9c17-aae2e563b97e.tmp\n",
      "23/06/24 15:03:19 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.220.3bd0ef1a-b4c9-4e4f-9c17-aae2e563b97e.tmp to gs://kafka-spark-data/spark-metadata/commits/220\n",
      "23/06/24 15:03:19 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:03:10.010Z\",\n",
      "  \"batchId\" : 220,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.19992003198720512,\n",
      "  \"processedRowsPerSecond\" : 0.21925016443762332,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6577,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 25,\n",
      "    \"queryPlanning\" : 15,\n",
      "    \"triggerExecution\" : 9122,\n",
      "    \"walCommit\" : 1438\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4865\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4867\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.19992003198720512,\n",
      "    \"processedRowsPerSecond\" : 0.21925016443762332\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:03:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:03:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4869.\n",
      "23/06/24 15:03:20 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/221 using temp file gs://kafka-spark-data/spark-metadata/offsets/.221.99a6263b-1eb3-4fcd-afe9-a3c4db444cd3.tmp\n",
      "23/06/24 15:03:20 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.221.99a6263b-1eb3-4fcd-afe9-a3c4db444cd3.tmp to gs://kafka-spark-data/spark-metadata/offsets/221\n",
      "23/06/24 15:03:20 INFO MicroBatchExecution: Committed offsets for batch 221. Metadata OffsetSeqMetadata(0,1687637000014,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:03:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:03:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:03:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:03:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:03:21 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:03:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:03:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:03:21 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:03:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:03:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:03:21 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:03:21 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:03:21 INFO DAGScheduler: Got job 17 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:03:21 INFO DAGScheduler: Final stage: ResultStage 17 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:03:21 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:03:21 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:03:21 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[125] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:03:21 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:03:21 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:03:21 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:03:21 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:03:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[125] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:03:21 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:03:21 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:03:21 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)\n",
      "23/06/24 15:03:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:03:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:03:21 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:03:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:03:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:03:21 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:03:21 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:03:21 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:03:21 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:03:21 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:03:21 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:03:21 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:03:21 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:03:22 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4868 for partition ticketmaster-0\n",
      "23/06/24 15:03:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:03:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:03:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:03:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4870.\n",
      "23/06/24 15:03:23 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8f99005a-1400-4ef0-af04-a37f38aeee78/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:03:23 INFO FileOutputCommitter: Saved output of task 'attempt_202306241503211557976161894272944_0017_m_000000_17' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8f99005a-1400-4ef0-af04-a37f38aeee78/_temporary/0/task_202306241503211557976161894272944_0017_m_000000\n",
      "23/06/24 15:03:23 INFO SparkHadoopMapRedUtil: attempt_202306241503211557976161894272944_0017_m_000000_17: Committed. Elapsed time: 631 ms.\n",
      "23/06/24 15:03:23 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 2536 bytes result sent to driver\n",
      "23/06/24 15:03:23 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 1541 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:03:23 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:03:23 INFO DAGScheduler: ResultStage 17 (start at NativeMethodAccessorImpl.java:0) finished in 1.580 s\n",
      "23/06/24 15:03:23 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:03:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished\n",
      "23/06/24 15:03:23 INFO DAGScheduler: Job 17 finished: start at NativeMethodAccessorImpl.java:0, took 1.581631 s\n",
      "23/06/24 15:03:23 INFO FileFormatWriter: Start to commit write Job ed5f8dba-fef7-4f75-b0b4-1d0795797d86.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:03:24 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8f99005a-1400-4ef0-af04-a37f38aeee78/_temporary/0/task_202306241503211557976161894272944_0017_m_000000/' directory.\n",
      "23/06/24 15:03:24 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8f99005a-1400-4ef0-af04-a37f38aeee78/' directory.\n",
      "23/06/24 15:03:24 INFO FileFormatWriter: Write Job ed5f8dba-fef7-4f75-b0b4-1d0795797d86 committed. Elapsed time: 1411 ms.\n",
      "23/06/24 15:03:24 INFO FileFormatWriter: Finished processing stats for write job ed5f8dba-fef7-4f75-b0b4-1d0795797d86.\n",
      "23/06/24 15:03:25 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8f99005a-1400-4ef0-af04-a37f38aeee78/part-00000-a85fc2e8-7768-47fb-9232-cfb5f990fc3a-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=70b65acc-ef0d-4dc3-9a44-acb4198ae335, location=US}\n",
      "23/06/24 15:03:28 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=70b65acc-ef0d-4dc3-9a44-acb4198ae335, location=US}\n",
      "23/06/24 15:03:29 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/221 using temp file gs://kafka-spark-data/spark-metadata/commits/.221.a611e877-c507-4d1e-943c-6f02590ff10d.tmp\n",
      "23/06/24 15:03:30 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.221.a611e877-c507-4d1e-943c-6f02590ff10d.tmp to gs://kafka-spark-data/spark-metadata/commits/221\n",
      "23/06/24 15:03:30 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:03:20.005Z\",\n",
      "  \"batchId\" : 221,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.20010005002501252,\n",
      "  \"processedRowsPerSecond\" : 0.19477989871445264,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7769,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 9,\n",
      "    \"queryPlanning\" : 19,\n",
      "    \"triggerExecution\" : 10268,\n",
      "    \"walCommit\" : 1302\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4867\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4869\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.20010005002501252,\n",
      "    \"processedRowsPerSecond\" : 0.19477989871445264\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:03:30 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 10271 milliseconds\n",
      "23/06/24 15:03:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:03:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4871.\n",
      "23/06/24 15:03:30 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/222 using temp file gs://kafka-spark-data/spark-metadata/offsets/.222.8cef5ef3-42d4-455a-82da-bc220d7e6bd7.tmp\n",
      "23/06/24 15:03:30 INFO BlockManagerInfo: Removed broadcast_17_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:03:31 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.222.8cef5ef3-42d4-455a-82da-bc220d7e6bd7.tmp to gs://kafka-spark-data/spark-metadata/offsets/222\n",
      "23/06/24 15:03:31 INFO MicroBatchExecution: Committed offsets for batch 222. Metadata OffsetSeqMetadata(0,1687637010283,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:03:31 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:03:31 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:03:31 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:03:31 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:03:32 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:03:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:03:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:03:32 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:03:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:03:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:03:32 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:03:32 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:03:32 INFO DAGScheduler: Got job 18 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:03:32 INFO DAGScheduler: Final stage: ResultStage 18 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:03:32 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:03:32 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:03:32 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[132] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:03:32 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:03:32 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:03:32 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:03:32 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:03:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[132] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:03:32 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:03:32 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:03:32 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)\n",
      "23/06/24 15:03:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:03:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:03:32 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:03:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:03:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:03:32 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:03:32 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:03:32 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:03:32 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:03:32 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:03:32 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:03:32 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:03:32 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:03:32 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4870 for partition ticketmaster-0\n",
      "23/06/24 15:03:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:03:33 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:03:33 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:03:33 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4872.\n",
      "23/06/24 15:03:34 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-9476b304-e34a-4f08-a6db-d11408046c3d/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:03:34 INFO FileOutputCommitter: Saved output of task 'attempt_202306241503326393298390469348812_0018_m_000000_18' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-9476b304-e34a-4f08-a6db-d11408046c3d/_temporary/0/task_202306241503326393298390469348812_0018_m_000000\n",
      "23/06/24 15:03:34 INFO SparkHadoopMapRedUtil: attempt_202306241503326393298390469348812_0018_m_000000_18: Committed. Elapsed time: 758 ms.\n",
      "23/06/24 15:03:34 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 2536 bytes result sent to driver\n",
      "23/06/24 15:03:34 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 1766 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:03:34 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:03:34 INFO DAGScheduler: ResultStage 18 (start at NativeMethodAccessorImpl.java:0) finished in 1.802 s\n",
      "23/06/24 15:03:34 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:03:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished\n",
      "23/06/24 15:03:34 INFO DAGScheduler: Job 18 finished: start at NativeMethodAccessorImpl.java:0, took 1.803078 s\n",
      "23/06/24 15:03:34 INFO FileFormatWriter: Start to commit write Job 89d7ec90-6f1c-4df4-ba74-dc5ae6ab1f0e.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:03:34 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-9476b304-e34a-4f08-a6db-d11408046c3d/_temporary/0/task_202306241503326393298390469348812_0018_m_000000/' directory.\n",
      "23/06/24 15:03:35 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-9476b304-e34a-4f08-a6db-d11408046c3d/' directory.\n",
      "23/06/24 15:03:35 INFO FileFormatWriter: Write Job 89d7ec90-6f1c-4df4-ba74-dc5ae6ab1f0e committed. Elapsed time: 1548 ms.\n",
      "23/06/24 15:03:35 INFO FileFormatWriter: Finished processing stats for write job 89d7ec90-6f1c-4df4-ba74-dc5ae6ab1f0e.\n",
      "23/06/24 15:03:36 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-9476b304-e34a-4f08-a6db-d11408046c3d/part-00000-006682bd-c8da-4ba3-b9c2-cb527d94c1b3-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=98f860e6-3389-4e24-99b0-a654a2c3df44, location=US}\n",
      "23/06/24 15:03:38 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=98f860e6-3389-4e24-99b0-a654a2c3df44, location=US}\n",
      "23/06/24 15:03:39 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/222 using temp file gs://kafka-spark-data/spark-metadata/commits/.222.2c307b59-cdb8-4f71-86c9-da11f9abc067.tmp\n",
      "23/06/24 15:03:40 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.222.2c307b59-cdb8-4f71-86c9-da11f9abc067.tmp to gs://kafka-spark-data/spark-metadata/commits/222\n",
      "23/06/24 15:03:40 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:03:30.276Z\",\n",
      "  \"batchId\" : 222,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.1947230065232207,\n",
      "  \"processedRowsPerSecond\" : 0.20506510817184456,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7038,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 7,\n",
      "    \"queryPlanning\" : 6,\n",
      "    \"triggerExecution\" : 9753,\n",
      "    \"walCommit\" : 1598\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4869\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4871\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.1947230065232207,\n",
      "    \"processedRowsPerSecond\" : 0.20506510817184456\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:03:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:03:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4873.\n",
      "23/06/24 15:03:40 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/223 using temp file gs://kafka-spark-data/spark-metadata/offsets/.223.3854ce70-3000-40d3-a71c-9a21e4d0a2bb.tmp\n",
      "23/06/24 15:03:41 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.223.3854ce70-3000-40d3-a71c-9a21e4d0a2bb.tmp to gs://kafka-spark-data/spark-metadata/offsets/223\n",
      "23/06/24 15:03:41 INFO MicroBatchExecution: Committed offsets for batch 223. Metadata OffsetSeqMetadata(0,1687637020052,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:03:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:03:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:03:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:03:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:03:41 INFO BlockManagerInfo: Removed broadcast_18_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:03:41 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:03:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:03:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:03:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:03:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:03:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:03:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:03:42 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:03:42 INFO DAGScheduler: Got job 19 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:03:42 INFO DAGScheduler: Final stage: ResultStage 19 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:03:42 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:03:42 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:03:42 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[139] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:03:42 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:03:42 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:03:42 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:03:42 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:03:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[139] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:03:42 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:03:42 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:03:42 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)\n",
      "23/06/24 15:03:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:03:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:03:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:03:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:03:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:03:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:03:42 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:03:42 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:03:42 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:03:42 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:03:42 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:03:42 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:03:42 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:03:42 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4872 for partition ticketmaster-0\n",
      "23/06/24 15:03:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:03:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:03:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:03:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4874.\n",
      "23/06/24 15:03:43 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-636d6b00-2029-4059-894a-7fea50b0cbb9/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:03:43 INFO FileOutputCommitter: Saved output of task 'attempt_202306241503418425197019464613163_0019_m_000000_19' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-636d6b00-2029-4059-894a-7fea50b0cbb9/_temporary/0/task_202306241503418425197019464613163_0019_m_000000\n",
      "23/06/24 15:03:43 INFO SparkHadoopMapRedUtil: attempt_202306241503418425197019464613163_0019_m_000000_19: Committed. Elapsed time: 639 ms.\n",
      "23/06/24 15:03:43 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 2579 bytes result sent to driver\n",
      "23/06/24 15:03:43 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 1652 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:03:43 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:03:43 INFO DAGScheduler: ResultStage 19 (start at NativeMethodAccessorImpl.java:0) finished in 1.672 s\n",
      "23/06/24 15:03:43 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:03:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished\n",
      "23/06/24 15:03:43 INFO DAGScheduler: Job 19 finished: start at NativeMethodAccessorImpl.java:0, took 1.672625 s\n",
      "23/06/24 15:03:43 INFO FileFormatWriter: Start to commit write Job faeb2362-d79b-40ba-b281-c4f635020f10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:03:44 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-636d6b00-2029-4059-894a-7fea50b0cbb9/_temporary/0/task_202306241503418425197019464613163_0019_m_000000/' directory.\n",
      "23/06/24 15:03:44 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-636d6b00-2029-4059-894a-7fea50b0cbb9/' directory.\n",
      "23/06/24 15:03:44 INFO BlockManagerInfo: Removed broadcast_19_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:03:45 INFO FileFormatWriter: Write Job faeb2362-d79b-40ba-b281-c4f635020f10 committed. Elapsed time: 1514 ms.\n",
      "23/06/24 15:03:45 INFO FileFormatWriter: Finished processing stats for write job faeb2362-d79b-40ba-b281-c4f635020f10.\n",
      "23/06/24 15:03:45 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-636d6b00-2029-4059-894a-7fea50b0cbb9/part-00000-2d83968c-fb18-4672-b63a-ddbb94986080-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=0c658f25-1ce2-4129-9c8f-390a46900075, location=US}\n",
      "23/06/24 15:03:48 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=0c658f25-1ce2-4129-9c8f-390a46900075, location=US}\n",
      "23/06/24 15:03:48 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/223 using temp file gs://kafka-spark-data/spark-metadata/commits/.223.7e56d86c-7b5c-45e3-bcc9-9d1eab974fbb.tmp\n",
      "23/06/24 15:03:49 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.223.7e56d86c-7b5c-45e3-bcc9-9d1eab974fbb.tmp to gs://kafka-spark-data/spark-metadata/commits/223\n",
      "23/06/24 15:03:49 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:03:40.032Z\",\n",
      "  \"batchId\" : 223,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.2050020500205002,\n",
      "  \"processedRowsPerSecond\" : 0.20887728459530028,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7055,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 20,\n",
      "    \"queryPlanning\" : 13,\n",
      "    \"triggerExecution\" : 9575,\n",
      "    \"walCommit\" : 1417\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4871\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4873\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.2050020500205002,\n",
      "    \"processedRowsPerSecond\" : 0.20887728459530028\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:03:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:03:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4875.\n",
      "23/06/24 15:03:50 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/224 using temp file gs://kafka-spark-data/spark-metadata/offsets/.224.e2eb5080-58fe-431b-aeb4-c460c69b7a23.tmp\n",
      "23/06/24 15:03:51 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.224.e2eb5080-58fe-431b-aeb4-c460c69b7a23.tmp to gs://kafka-spark-data/spark-metadata/offsets/224\n",
      "23/06/24 15:03:51 INFO MicroBatchExecution: Committed offsets for batch 224. Metadata OffsetSeqMetadata(0,1687637030005,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:03:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:03:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:03:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:03:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:03:51 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:03:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:03:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:03:51 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:03:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:03:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:03:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:03:52 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:03:52 INFO DAGScheduler: Got job 20 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:03:52 INFO DAGScheduler: Final stage: ResultStage 20 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:03:52 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:03:52 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:03:52 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[146] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:03:52 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:03:52 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:03:52 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:03:52 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:03:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[146] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:03:52 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:03:52 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:03:52 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)\n",
      "23/06/24 15:03:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:03:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:03:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:03:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:03:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:03:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:03:52 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:03:52 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:03:52 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:03:52 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:03:52 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:03:52 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:03:52 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:03:52 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4874 for partition ticketmaster-0\n",
      "23/06/24 15:03:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:03:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:03:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:03:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4876.\n",
      "23/06/24 15:03:53 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-778c6a30-05ae-44bb-a0e5-58af064b380d/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:03:53 INFO FileOutputCommitter: Saved output of task 'attempt_202306241503514935407973839387653_0020_m_000000_20' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-778c6a30-05ae-44bb-a0e5-58af064b380d/_temporary/0/task_202306241503514935407973839387653_0020_m_000000\n",
      "23/06/24 15:03:53 INFO SparkHadoopMapRedUtil: attempt_202306241503514935407973839387653_0020_m_000000_20: Committed. Elapsed time: 715 ms.\n",
      "23/06/24 15:03:53 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 2579 bytes result sent to driver\n",
      "23/06/24 15:03:53 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 1730 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:03:53 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:03:53 INFO DAGScheduler: ResultStage 20 (start at NativeMethodAccessorImpl.java:0) finished in 1.750 s\n",
      "23/06/24 15:03:53 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:03:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished\n",
      "23/06/24 15:03:53 INFO DAGScheduler: Job 20 finished: start at NativeMethodAccessorImpl.java:0, took 1.751260 s\n",
      "23/06/24 15:03:53 INFO FileFormatWriter: Start to commit write Job 7011baa2-b70d-4499-a3a8-181de8ffa9f3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:03:54 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-778c6a30-05ae-44bb-a0e5-58af064b380d/_temporary/0/task_202306241503514935407973839387653_0020_m_000000/' directory.\n",
      "23/06/24 15:03:54 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-778c6a30-05ae-44bb-a0e5-58af064b380d/' directory.\n",
      "23/06/24 15:03:54 INFO BlockManagerInfo: Removed broadcast_20_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:03:55 INFO FileFormatWriter: Write Job 7011baa2-b70d-4499-a3a8-181de8ffa9f3 committed. Elapsed time: 1496 ms.\n",
      "23/06/24 15:03:55 INFO FileFormatWriter: Finished processing stats for write job 7011baa2-b70d-4499-a3a8-181de8ffa9f3.\n",
      "23/06/24 15:03:55 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-778c6a30-05ae-44bb-a0e5-58af064b380d/part-00000-d4fa2200-ed0c-44eb-be39-f959bb838a4b-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=2603e6d1-0814-45c3-9afe-d1d72b52ec57, location=US}\n",
      "23/06/24 15:03:57 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=2603e6d1-0814-45c3-9afe-d1d72b52ec57, location=US}\n",
      "23/06/24 15:03:58 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/224 using temp file gs://kafka-spark-data/spark-metadata/commits/.224.b8a6d264-c489-447d-b212-73c36290e598.tmp\n",
      "23/06/24 15:03:59 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.224.b8a6d264-c489-447d-b212-73c36290e598.tmp to gs://kafka-spark-data/spark-metadata/commits/224\n",
      "23/06/24 15:03:59 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:03:50.001Z\",\n",
      "  \"batchId\" : 224,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.20062192797672787,\n",
      "  \"processedRowsPerSecond\" : 0.2109482122139015,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6850,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 4,\n",
      "    \"queryPlanning\" : 15,\n",
      "    \"triggerExecution\" : 9481,\n",
      "    \"walCommit\" : 1439\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4873\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4875\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.20062192797672787,\n",
      "    \"processedRowsPerSecond\" : 0.2109482122139015\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:04:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:04:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4877.\n",
      "23/06/24 15:04:00 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/225 using temp file gs://kafka-spark-data/spark-metadata/offsets/.225.a6cf1f72-4649-4c42-8d20-e1163ee1052b.tmp\n",
      "23/06/24 15:04:01 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.225.a6cf1f72-4649-4c42-8d20-e1163ee1052b.tmp to gs://kafka-spark-data/spark-metadata/offsets/225\n",
      "23/06/24 15:04:01 INFO MicroBatchExecution: Committed offsets for batch 225. Metadata OffsetSeqMetadata(0,1687637040026,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:04:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:04:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:04:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:04:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:04:01 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:04:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:04:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:04:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:04:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:04:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:04:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:04:01 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:04:01 INFO DAGScheduler: Got job 21 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:04:01 INFO DAGScheduler: Final stage: ResultStage 21 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:04:01 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:04:01 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:04:01 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[153] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:04:01 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:04:01 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:04:01 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:04:01 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:04:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[153] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:04:01 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:04:01 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:04:01 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)\n",
      "23/06/24 15:04:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:04:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:04:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:04:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:04:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:04:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:04:02 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:04:02 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:04:02 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:04:02 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:04:02 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:04:02 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:04:02 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:04:02 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4876 for partition ticketmaster-0\n",
      "23/06/24 15:04:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:04:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:04:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:04:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4878.\n",
      "23/06/24 15:04:03 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-bfe54065-12b0-49c5-a0da-3d38755be759/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:04:03 INFO FileOutputCommitter: Saved output of task 'attempt_202306241504019006718895649779243_0021_m_000000_21' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-bfe54065-12b0-49c5-a0da-3d38755be759/_temporary/0/task_202306241504019006718895649779243_0021_m_000000\n",
      "23/06/24 15:04:03 INFO SparkHadoopMapRedUtil: attempt_202306241504019006718895649779243_0021_m_000000_21: Committed. Elapsed time: 678 ms.\n",
      "23/06/24 15:04:03 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 2579 bytes result sent to driver\n",
      "23/06/24 15:04:03 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 1681 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:04:03 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:04:03 INFO DAGScheduler: ResultStage 21 (start at NativeMethodAccessorImpl.java:0) finished in 1.739 s\n",
      "23/06/24 15:04:03 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:04:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished\n",
      "23/06/24 15:04:03 INFO DAGScheduler: Job 21 finished: start at NativeMethodAccessorImpl.java:0, took 1.740789 s\n",
      "23/06/24 15:04:03 INFO FileFormatWriter: Start to commit write Job cfeeed6c-ba52-4131-bec6-6bbe2814465b.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:04:04 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-bfe54065-12b0-49c5-a0da-3d38755be759/_temporary/0/task_202306241504019006718895649779243_0021_m_000000/' directory.\n",
      "23/06/24 15:04:04 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-bfe54065-12b0-49c5-a0da-3d38755be759/' directory.\n",
      "23/06/24 15:04:04 INFO BlockManagerInfo: Removed broadcast_21_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:04:05 INFO FileFormatWriter: Write Job cfeeed6c-ba52-4131-bec6-6bbe2814465b committed. Elapsed time: 1348 ms.\n",
      "23/06/24 15:04:05 INFO FileFormatWriter: Finished processing stats for write job cfeeed6c-ba52-4131-bec6-6bbe2814465b.\n",
      "23/06/24 15:04:05 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-bfe54065-12b0-49c5-a0da-3d38755be759/part-00000-43d1add4-dce8-4a48-91aa-9f0bab3edcd4-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=60385af8-04c9-405a-8707-f88a5c77c4ae, location=US}\n",
      "23/06/24 15:04:07 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=60385af8-04c9-405a-8707-f88a5c77c4ae, location=US}\n",
      "23/06/24 15:04:07 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/225 using temp file gs://kafka-spark-data/spark-metadata/commits/.225.db7fb7ff-194d-4c68-8ec3-1f83570e4563.tmp\n",
      "23/06/24 15:04:08 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.225.db7fb7ff-194d-4c68-8ec3-1f83570e4563.tmp to gs://kafka-spark-data/spark-metadata/commits/225\n",
      "23/06/24 15:04:08 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:04:00.021Z\",\n",
      "  \"batchId\" : 225,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.1996007984031936,\n",
      "  \"processedRowsPerSecond\" : 0.2334267040149393,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6052,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 4,\n",
      "    \"queryPlanning\" : 11,\n",
      "    \"triggerExecution\" : 8568,\n",
      "    \"walCommit\" : 1455\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4875\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4877\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.1996007984031936,\n",
      "    \"processedRowsPerSecond\" : 0.2334267040149393\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:04:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:04:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4879.\n",
      "23/06/24 15:04:10 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/226 using temp file gs://kafka-spark-data/spark-metadata/offsets/.226.532e2031-c848-4d3e-862d-84454f30922e.tmp\n",
      "23/06/24 15:04:11 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.226.532e2031-c848-4d3e-862d-84454f30922e.tmp to gs://kafka-spark-data/spark-metadata/offsets/226\n",
      "23/06/24 15:04:11 INFO MicroBatchExecution: Committed offsets for batch 226. Metadata OffsetSeqMetadata(0,1687637050013,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:04:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:04:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:04:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:04:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:04:11 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:04:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:04:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:04:11 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:04:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:04:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:04:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:04:11 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:04:11 INFO DAGScheduler: Got job 22 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:04:11 INFO DAGScheduler: Final stage: ResultStage 22 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:04:11 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:04:11 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:04:11 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[160] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:04:11 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:04:11 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:04:11 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:04:11 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:04:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[160] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:04:11 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:04:11 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:04:11 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)\n",
      "23/06/24 15:04:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:04:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:04:11 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:04:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:04:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:04:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:04:11 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:04:11 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:04:11 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:04:11 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:04:11 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:04:11 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:04:11 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:04:12 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4878 for partition ticketmaster-0\n",
      "23/06/24 15:04:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:04:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:04:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:04:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4880.\n",
      "23/06/24 15:04:13 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-141e1ef1-3a9d-480f-89cd-68bbc2279cb4/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:04:13 INFO FileOutputCommitter: Saved output of task 'attempt_202306241504116418874411319169619_0022_m_000000_22' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-141e1ef1-3a9d-480f-89cd-68bbc2279cb4/_temporary/0/task_202306241504116418874411319169619_0022_m_000000\n",
      "23/06/24 15:04:13 INFO SparkHadoopMapRedUtil: attempt_202306241504116418874411319169619_0022_m_000000_22: Committed. Elapsed time: 551 ms.\n",
      "23/06/24 15:04:13 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 2579 bytes result sent to driver\n",
      "23/06/24 15:04:13 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 1493 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:04:13 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:04:13 INFO DAGScheduler: ResultStage 22 (start at NativeMethodAccessorImpl.java:0) finished in 1.532 s\n",
      "23/06/24 15:04:13 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:04:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished\n",
      "23/06/24 15:04:13 INFO DAGScheduler: Job 22 finished: start at NativeMethodAccessorImpl.java:0, took 1.534166 s\n",
      "23/06/24 15:04:13 INFO FileFormatWriter: Start to commit write Job 852c3b14-2fa5-41f8-bd21-4dcc45c635bb.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:04:14 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-141e1ef1-3a9d-480f-89cd-68bbc2279cb4/_temporary/0/task_202306241504116418874411319169619_0022_m_000000/' directory.\n",
      "23/06/24 15:04:14 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-141e1ef1-3a9d-480f-89cd-68bbc2279cb4/' directory.\n",
      "23/06/24 15:04:14 INFO BlockManagerInfo: Removed broadcast_22_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:04:15 INFO FileFormatWriter: Write Job 852c3b14-2fa5-41f8-bd21-4dcc45c635bb committed. Elapsed time: 1637 ms.\n",
      "23/06/24 15:04:15 INFO FileFormatWriter: Finished processing stats for write job 852c3b14-2fa5-41f8-bd21-4dcc45c635bb.\n",
      "23/06/24 15:04:15 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-141e1ef1-3a9d-480f-89cd-68bbc2279cb4/part-00000-5918c34f-5fec-4d41-9f47-b5f9c301e8cc-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=d0ea6133-b5b9-4bd1-814a-72daabbb8ee9, location=US}\n",
      "23/06/24 15:04:17 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=d0ea6133-b5b9-4bd1-814a-72daabbb8ee9, location=US}\n",
      "23/06/24 15:04:18 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/226 using temp file gs://kafka-spark-data/spark-metadata/commits/.226.fbba881e-2c4a-48fc-9e17-28a597c0dce2.tmp\n",
      "23/06/24 15:04:19 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.226.fbba881e-2c4a-48fc-9e17-28a597c0dce2.tmp to gs://kafka-spark-data/spark-metadata/commits/226\n",
      "23/06/24 15:04:19 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:04:10.005Z\",\n",
      "  \"batchId\" : 226,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.20032051282051283,\n",
      "  \"processedRowsPerSecond\" : 0.2215330084182543,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6471,\n",
      "    \"getBatch\" : 2,\n",
      "    \"latestOffset\" : 8,\n",
      "    \"queryPlanning\" : 16,\n",
      "    \"triggerExecution\" : 9028,\n",
      "    \"walCommit\" : 1395\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4877\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4879\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.20032051282051283,\n",
      "    \"processedRowsPerSecond\" : 0.2215330084182543\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:04:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:04:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4881.\n",
      "23/06/24 15:04:20 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/227 using temp file gs://kafka-spark-data/spark-metadata/offsets/.227.c8d63f3e-27dd-4920-ad41-e35095344f48.tmp\n",
      "23/06/24 15:04:21 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.227.c8d63f3e-27dd-4920-ad41-e35095344f48.tmp to gs://kafka-spark-data/spark-metadata/offsets/227\n",
      "23/06/24 15:04:21 INFO MicroBatchExecution: Committed offsets for batch 227. Metadata OffsetSeqMetadata(0,1687637060013,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:04:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:04:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:04:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:04:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:04:21 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:04:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:04:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:04:21 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:04:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:04:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:04:21 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:04:21 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:04:21 INFO DAGScheduler: Got job 23 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:04:21 INFO DAGScheduler: Final stage: ResultStage 23 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:04:21 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:04:21 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:04:21 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[167] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:04:21 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:04:21 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:04:21 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:04:21 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:04:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[167] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:04:21 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:04:21 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:04:21 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)\n",
      "23/06/24 15:04:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:04:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:04:21 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:04:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:04:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:04:21 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:04:21 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:04:21 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:04:21 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:04:21 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:04:21 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:04:21 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:04:21 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:04:22 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4880 for partition ticketmaster-0\n",
      "23/06/24 15:04:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:04:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:04:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:04:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4882.\n",
      "23/06/24 15:04:23 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-ace2cb22-b9b6-47e6-8274-42eb6677f48e/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:04:23 INFO FileOutputCommitter: Saved output of task 'attempt_202306241504216305260328436330409_0023_m_000000_23' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-ace2cb22-b9b6-47e6-8274-42eb6677f48e/_temporary/0/task_202306241504216305260328436330409_0023_m_000000\n",
      "23/06/24 15:04:23 INFO SparkHadoopMapRedUtil: attempt_202306241504216305260328436330409_0023_m_000000_23: Committed. Elapsed time: 615 ms.\n",
      "23/06/24 15:04:23 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 2579 bytes result sent to driver\n",
      "23/06/24 15:04:23 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 1507 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:04:23 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:04:23 INFO DAGScheduler: ResultStage 23 (start at NativeMethodAccessorImpl.java:0) finished in 1.540 s\n",
      "23/06/24 15:04:23 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:04:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished\n",
      "23/06/24 15:04:23 INFO DAGScheduler: Job 23 finished: start at NativeMethodAccessorImpl.java:0, took 1.542782 s\n",
      "23/06/24 15:04:23 INFO FileFormatWriter: Start to commit write Job e5b2a187-5fd3-4e9e-9ba1-88757d506998.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:04:24 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-ace2cb22-b9b6-47e6-8274-42eb6677f48e/_temporary/0/task_202306241504216305260328436330409_0023_m_000000/' directory.\n",
      "23/06/24 15:04:24 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-ace2cb22-b9b6-47e6-8274-42eb6677f48e/' directory.\n",
      "23/06/24 15:04:24 INFO BlockManagerInfo: Removed broadcast_23_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:04:24 INFO FileFormatWriter: Write Job e5b2a187-5fd3-4e9e-9ba1-88757d506998 committed. Elapsed time: 1319 ms.\n",
      "23/06/24 15:04:24 INFO FileFormatWriter: Finished processing stats for write job e5b2a187-5fd3-4e9e-9ba1-88757d506998.\n",
      "23/06/24 15:04:25 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-ace2cb22-b9b6-47e6-8274-42eb6677f48e/part-00000-dbf30703-74ee-4c48-bc8e-596926435a12-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=3cc89fd2-ff69-4ea8-be5b-d9785b7cc1da, location=US}\n",
      "23/06/24 15:04:28 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=3cc89fd2-ff69-4ea8-be5b-d9785b7cc1da, location=US}\n",
      "23/06/24 15:04:28 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/227 using temp file gs://kafka-spark-data/spark-metadata/commits/.227.c8cc56cd-e311-42f6-87e7-b590de7ea0e9.tmp\n",
      "23/06/24 15:04:29 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.227.c8cc56cd-e311-42f6-87e7-b590de7ea0e9.tmp to gs://kafka-spark-data/spark-metadata/commits/227\n",
      "23/06/24 15:04:29 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:04:20.004Z\",\n",
      "  \"batchId\" : 227,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.2000200020002,\n",
      "  \"processedRowsPerSecond\" : 0.201999798000202,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7188,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 8,\n",
      "    \"queryPlanning\" : 20,\n",
      "    \"triggerExecution\" : 9901,\n",
      "    \"walCommit\" : 1433\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4879\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4881\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.2000200020002,\n",
      "    \"processedRowsPerSecond\" : 0.201999798000202\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:04:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:04:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4883.\n",
      "23/06/24 15:04:30 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/228 using temp file gs://kafka-spark-data/spark-metadata/offsets/.228.81fc0816-fa4d-4bb8-a9ba-3faca9d0a4e9.tmp\n",
      "23/06/24 15:04:31 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.228.81fc0816-fa4d-4bb8-a9ba-3faca9d0a4e9.tmp to gs://kafka-spark-data/spark-metadata/offsets/228\n",
      "23/06/24 15:04:31 INFO MicroBatchExecution: Committed offsets for batch 228. Metadata OffsetSeqMetadata(0,1687637070026,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:04:31 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:04:31 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:04:31 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:04:31 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:04:31 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:04:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:04:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:04:31 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:04:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:04:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:04:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:04:31 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:04:31 INFO DAGScheduler: Got job 24 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:04:31 INFO DAGScheduler: Final stage: ResultStage 24 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:04:31 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:04:31 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:04:31 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[174] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:04:32 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:04:32 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:04:32 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:04:32 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:04:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[174] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:04:32 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:04:32 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:04:32 INFO Executor: Running task 0.0 in stage 24.0 (TID 24)\n",
      "23/06/24 15:04:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:04:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:04:32 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:04:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:04:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:04:32 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:04:32 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:04:32 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:04:32 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:04:32 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:04:32 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:04:32 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:04:32 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:04:32 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4882 for partition ticketmaster-0\n",
      "23/06/24 15:04:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:04:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:04:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:04:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4884.\n",
      "23/06/24 15:04:33 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-cf077984-1ea6-4429-a198-9b621ce44adb/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:04:33 INFO FileOutputCommitter: Saved output of task 'attempt_202306241504317777343633327452170_0024_m_000000_24' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-cf077984-1ea6-4429-a198-9b621ce44adb/_temporary/0/task_202306241504317777343633327452170_0024_m_000000\n",
      "23/06/24 15:04:33 INFO SparkHadoopMapRedUtil: attempt_202306241504317777343633327452170_0024_m_000000_24: Committed. Elapsed time: 589 ms.\n",
      "23/06/24 15:04:33 INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 2579 bytes result sent to driver\n",
      "23/06/24 15:04:33 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 1554 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:04:33 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:04:33 INFO DAGScheduler: ResultStage 24 (start at NativeMethodAccessorImpl.java:0) finished in 1.592 s\n",
      "23/06/24 15:04:33 INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:04:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished\n",
      "23/06/24 15:04:33 INFO DAGScheduler: Job 24 finished: start at NativeMethodAccessorImpl.java:0, took 1.593079 s\n",
      "23/06/24 15:04:33 INFO FileFormatWriter: Start to commit write Job 47a13ccf-af47-4a8e-b3d9-9ef73aa0d3ad.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:04:34 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-cf077984-1ea6-4429-a198-9b621ce44adb/_temporary/0/task_202306241504317777343633327452170_0024_m_000000/' directory.\n",
      "23/06/24 15:04:34 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-cf077984-1ea6-4429-a198-9b621ce44adb/' directory.\n",
      "23/06/24 15:04:34 INFO BlockManagerInfo: Removed broadcast_24_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:04:35 INFO FileFormatWriter: Write Job 47a13ccf-af47-4a8e-b3d9-9ef73aa0d3ad committed. Elapsed time: 1545 ms.\n",
      "23/06/24 15:04:35 INFO FileFormatWriter: Finished processing stats for write job 47a13ccf-af47-4a8e-b3d9-9ef73aa0d3ad.\n",
      "23/06/24 15:04:35 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-cf077984-1ea6-4429-a198-9b621ce44adb/part-00000-321b9f07-3225-4231-b5b4-e9aa3036a3dc-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=4bcae1be-6566-47dc-b8ff-ab14e016188c, location=US}\n",
      "23/06/24 15:04:38 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=4bcae1be-6566-47dc-b8ff-ab14e016188c, location=US}\n",
      "23/06/24 15:04:39 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/228 using temp file gs://kafka-spark-data/spark-metadata/commits/.228.fa3bdbd6-6632-44ac-8edd-948b9e038d0a.tmp\n",
      "23/06/24 15:04:40 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.228.fa3bdbd6-6632-44ac-8edd-948b9e038d0a.tmp to gs://kafka-spark-data/spark-metadata/commits/228\n",
      "23/06/24 15:04:40 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:04:30.001Z\",\n",
      "  \"batchId\" : 228,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.20006001800540163,\n",
      "  \"processedRowsPerSecond\" : 0.19538882375928096,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7699,\n",
      "    \"getBatch\" : 2,\n",
      "    \"latestOffset\" : 24,\n",
      "    \"queryPlanning\" : 27,\n",
      "    \"triggerExecution\" : 10236,\n",
      "    \"walCommit\" : 1416\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4881\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4883\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.20006001800540163,\n",
      "    \"processedRowsPerSecond\" : 0.19538882375928096\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:04:40 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 10240 milliseconds\n",
      "23/06/24 15:04:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:04:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4885.\n",
      "23/06/24 15:04:40 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/229 using temp file gs://kafka-spark-data/spark-metadata/offsets/.229.ecb771be-97b0-44d0-be86-cd9db956106f.tmp\n",
      "23/06/24 15:04:41 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.229.ecb771be-97b0-44d0-be86-cd9db956106f.tmp to gs://kafka-spark-data/spark-metadata/offsets/229\n",
      "23/06/24 15:04:41 INFO MicroBatchExecution: Committed offsets for batch 229. Metadata OffsetSeqMetadata(0,1687637080260,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:04:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:04:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:04:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:04:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:04:42 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:04:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:04:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:04:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:04:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:04:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:04:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:04:42 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:04:42 INFO DAGScheduler: Got job 25 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:04:42 INFO DAGScheduler: Final stage: ResultStage 25 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:04:42 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:04:42 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:04:42 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[181] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:04:42 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:04:42 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:04:42 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:04:42 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:04:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[181] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:04:42 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:04:42 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:04:42 INFO Executor: Running task 0.0 in stage 25.0 (TID 25)\n",
      "23/06/24 15:04:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:04:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:04:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:04:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:04:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:04:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:04:42 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:04:42 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:04:42 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:04:42 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:04:42 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:04:42 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:04:42 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:04:42 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4884 for partition ticketmaster-0\n",
      "23/06/24 15:04:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:04:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:04:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:04:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4886.\n",
      "23/06/24 15:04:43 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-498161db-03c1-4cfc-9933-cc6d050347f8/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:04:43 INFO FileOutputCommitter: Saved output of task 'attempt_202306241504424816590396130754283_0025_m_000000_25' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-498161db-03c1-4cfc-9933-cc6d050347f8/_temporary/0/task_202306241504424816590396130754283_0025_m_000000\n",
      "23/06/24 15:04:43 INFO SparkHadoopMapRedUtil: attempt_202306241504424816590396130754283_0025_m_000000_25: Committed. Elapsed time: 686 ms.\n",
      "23/06/24 15:04:43 INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 2579 bytes result sent to driver\n",
      "23/06/24 15:04:43 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 1672 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:04:43 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:04:43 INFO DAGScheduler: ResultStage 25 (start at NativeMethodAccessorImpl.java:0) finished in 1.707 s\n",
      "23/06/24 15:04:43 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:04:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished\n",
      "23/06/24 15:04:43 INFO DAGScheduler: Job 25 finished: start at NativeMethodAccessorImpl.java:0, took 1.709360 s\n",
      "23/06/24 15:04:43 INFO FileFormatWriter: Start to commit write Job 7c52ae8f-fbdf-4c3f-88d6-a0e3945ad15c.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:04:44 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-498161db-03c1-4cfc-9933-cc6d050347f8/_temporary/0/task_202306241504424816590396130754283_0025_m_000000/' directory.\n",
      "23/06/24 15:04:45 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-498161db-03c1-4cfc-9933-cc6d050347f8/' directory.\n",
      "23/06/24 15:04:45 INFO BlockManagerInfo: Removed broadcast_25_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:04:45 INFO FileFormatWriter: Write Job 7c52ae8f-fbdf-4c3f-88d6-a0e3945ad15c committed. Elapsed time: 1545 ms.\n",
      "23/06/24 15:04:45 INFO FileFormatWriter: Finished processing stats for write job 7c52ae8f-fbdf-4c3f-88d6-a0e3945ad15c.\n",
      "23/06/24 15:04:45 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-498161db-03c1-4cfc-9933-cc6d050347f8/part-00000-ba9b0e56-7a3f-4c7f-b8b4-a227fd088a81-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=469c4caa-1c88-4181-a76e-06b782a8471d, location=US}\n",
      "23/06/24 15:04:48 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=469c4caa-1c88-4181-a76e-06b782a8471d, location=US}\n",
      "23/06/24 15:04:49 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/229 using temp file gs://kafka-spark-data/spark-metadata/commits/.229.2a58785c-741e-4cf9-9e73-edd5597bf112.tmp\n",
      "23/06/24 15:04:50 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.229.2a58785c-741e-4cf9-9e73-edd5597bf112.tmp to gs://kafka-spark-data/spark-metadata/commits/229\n",
      "23/06/24 15:04:50 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:04:40.241Z\",\n",
      "  \"batchId\" : 229,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.1953125,\n",
      "  \"processedRowsPerSecond\" : 0.20244964065188786,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7283,\n",
      "    \"getBatch\" : 2,\n",
      "    \"latestOffset\" : 19,\n",
      "    \"queryPlanning\" : 14,\n",
      "    \"triggerExecution\" : 9879,\n",
      "    \"walCommit\" : 1489\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4883\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4885\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.1953125,\n",
      "    \"processedRowsPerSecond\" : 0.20244964065188786\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:04:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:04:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4887.\n",
      "23/06/24 15:04:50 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/230 using temp file gs://kafka-spark-data/spark-metadata/offsets/.230.56f8c6b4-4b4e-431c-acec-ecc6a6c4ec87.tmp\n",
      "23/06/24 15:04:51 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.230.56f8c6b4-4b4e-431c-acec-ecc6a6c4ec87.tmp to gs://kafka-spark-data/spark-metadata/offsets/230\n",
      "23/06/24 15:04:51 INFO MicroBatchExecution: Committed offsets for batch 230. Metadata OffsetSeqMetadata(0,1687637090128,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:04:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:04:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:04:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:04:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:04:51 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:04:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:04:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:04:51 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:04:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:04:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:04:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:04:51 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:04:51 INFO DAGScheduler: Got job 26 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:04:51 INFO DAGScheduler: Final stage: ResultStage 26 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:04:51 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:04:51 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:04:51 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[188] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:04:52 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:04:52 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:04:52 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:04:52 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:04:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[188] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:04:52 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:04:52 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 26) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:04:52 INFO Executor: Running task 0.0 in stage 26.0 (TID 26)\n",
      "23/06/24 15:04:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:04:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:04:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:04:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:04:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:04:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:04:52 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:04:52 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:04:52 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:04:52 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:04:52 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:04:52 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:04:52 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:04:52 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4886 for partition ticketmaster-0\n",
      "23/06/24 15:04:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:04:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:04:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:04:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4888.\n",
      "23/06/24 15:04:53 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-62a9c498-08ea-434b-9a8a-97bde6bfa6b5/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:04:53 INFO FileOutputCommitter: Saved output of task 'attempt_202306241504511660078928687357221_0026_m_000000_26' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-62a9c498-08ea-434b-9a8a-97bde6bfa6b5/_temporary/0/task_202306241504511660078928687357221_0026_m_000000\n",
      "23/06/24 15:04:53 INFO SparkHadoopMapRedUtil: attempt_202306241504511660078928687357221_0026_m_000000_26: Committed. Elapsed time: 560 ms.\n",
      "23/06/24 15:04:53 INFO Executor: Finished task 0.0 in stage 26.0 (TID 26). 2579 bytes result sent to driver\n",
      "23/06/24 15:04:53 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 26) in 1535 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:04:53 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:04:53 INFO DAGScheduler: ResultStage 26 (start at NativeMethodAccessorImpl.java:0) finished in 1.585 s\n",
      "23/06/24 15:04:53 INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:04:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 26: Stage finished\n",
      "23/06/24 15:04:53 INFO DAGScheduler: Job 26 finished: start at NativeMethodAccessorImpl.java:0, took 1.586801 s\n",
      "23/06/24 15:04:53 INFO FileFormatWriter: Start to commit write Job 19d19e05-eebc-40d7-90bd-cca9aa665865.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:04:54 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-62a9c498-08ea-434b-9a8a-97bde6bfa6b5/_temporary/0/task_202306241504511660078928687357221_0026_m_000000/' directory.\n",
      "23/06/24 15:04:54 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-62a9c498-08ea-434b-9a8a-97bde6bfa6b5/' directory.\n",
      "23/06/24 15:04:55 INFO FileFormatWriter: Write Job 19d19e05-eebc-40d7-90bd-cca9aa665865 committed. Elapsed time: 1617 ms.\n",
      "23/06/24 15:04:55 INFO FileFormatWriter: Finished processing stats for write job 19d19e05-eebc-40d7-90bd-cca9aa665865.\n",
      "23/06/24 15:04:55 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-62a9c498-08ea-434b-9a8a-97bde6bfa6b5/part-00000-43a56945-7cd2-40fc-89f3-661cc47d6bb3-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=2d63d59c-213e-4029-95e2-fc059d1a6c64, location=US}\n",
      "23/06/24 15:04:58 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=2d63d59c-213e-4029-95e2-fc059d1a6c64, location=US}\n",
      "23/06/24 15:04:59 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/230 using temp file gs://kafka-spark-data/spark-metadata/commits/.230.79cea004-a703-4811-a8a5-77def2b4df7f.tmp\n",
      "23/06/24 15:04:59 INFO BlockManagerInfo: Removed broadcast_26_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:04:59 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.230.79cea004-a703-4811-a8a5-77def2b4df7f.tmp to gs://kafka-spark-data/spark-metadata/commits/230\n",
      "23/06/24 15:04:59 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:04:50.122Z\",\n",
      "  \"batchId\" : 230,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.2024086630907803,\n",
      "  \"processedRowsPerSecond\" : 0.20659022828220228,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7355,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 6,\n",
      "    \"queryPlanning\" : 7,\n",
      "    \"triggerExecution\" : 9681,\n",
      "    \"walCommit\" : 1346\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4885\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4887\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.2024086630907803,\n",
      "    \"processedRowsPerSecond\" : 0.20659022828220228\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:05:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:05:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4889.\n",
      "23/06/24 15:05:00 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/231 using temp file gs://kafka-spark-data/spark-metadata/offsets/.231.9893fcfd-77e2-42be-b5c5-a8fc4f915dba.tmp\n",
      "23/06/24 15:05:01 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.231.9893fcfd-77e2-42be-b5c5-a8fc4f915dba.tmp to gs://kafka-spark-data/spark-metadata/offsets/231\n",
      "23/06/24 15:05:01 INFO MicroBatchExecution: Committed offsets for batch 231. Metadata OffsetSeqMetadata(0,1687637100015,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:05:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:05:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:05:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:05:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:05:01 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:05:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:05:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:05:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:05:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:05:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:05:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:05:01 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:05:01 INFO DAGScheduler: Got job 27 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:05:01 INFO DAGScheduler: Final stage: ResultStage 27 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:05:01 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:05:01 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:05:01 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[195] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:05:01 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:05:01 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:05:01 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:05:01 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:05:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[195] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:05:01 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:05:01 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 27) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:05:01 INFO Executor: Running task 0.0 in stage 27.0 (TID 27)\n",
      "23/06/24 15:05:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:05:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:05:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:05:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:05:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:05:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:05:02 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:05:02 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:05:02 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:05:02 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:05:02 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:05:02 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:05:02 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:05:02 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4888 for partition ticketmaster-0\n",
      "23/06/24 15:05:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 27:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:05:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:05:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:05:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4890.\n",
      "23/06/24 15:05:03 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-d3d67248-bf34-4698-a607-de73f587262e/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:05:03 INFO FileOutputCommitter: Saved output of task 'attempt_202306241505012603131395362253134_0027_m_000000_27' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-d3d67248-bf34-4698-a607-de73f587262e/_temporary/0/task_202306241505012603131395362253134_0027_m_000000\n",
      "23/06/24 15:05:03 INFO SparkHadoopMapRedUtil: attempt_202306241505012603131395362253134_0027_m_000000_27: Committed. Elapsed time: 611 ms.\n",
      "23/06/24 15:05:03 INFO Executor: Finished task 0.0 in stage 27.0 (TID 27). 2536 bytes result sent to driver\n",
      "23/06/24 15:05:03 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 27) in 1576 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:05:03 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:05:03 INFO DAGScheduler: ResultStage 27 (start at NativeMethodAccessorImpl.java:0) finished in 1.594 s\n",
      "23/06/24 15:05:03 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:05:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished\n",
      "23/06/24 15:05:03 INFO DAGScheduler: Job 27 finished: start at NativeMethodAccessorImpl.java:0, took 1.595303 s\n",
      "23/06/24 15:05:03 INFO FileFormatWriter: Start to commit write Job 18cdf833-fba6-4194-a14f-c27d4ac4f6f2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:05:04 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-d3d67248-bf34-4698-a607-de73f587262e/_temporary/0/task_202306241505012603131395362253134_0027_m_000000/' directory.\n",
      "23/06/24 15:05:04 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-d3d67248-bf34-4698-a607-de73f587262e/' directory.\n",
      "23/06/24 15:05:05 INFO FileFormatWriter: Write Job 18cdf833-fba6-4194-a14f-c27d4ac4f6f2 committed. Elapsed time: 1746 ms.\n",
      "23/06/24 15:05:05 INFO FileFormatWriter: Finished processing stats for write job 18cdf833-fba6-4194-a14f-c27d4ac4f6f2.\n",
      "23/06/24 15:05:05 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-d3d67248-bf34-4698-a607-de73f587262e/part-00000-57ae532f-cf84-44fd-8d3e-1094b46dcd63-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=93b05a00-4171-438b-90b6-29fe1393ac78, location=US}\n",
      "23/06/24 15:05:07 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=93b05a00-4171-438b-90b6-29fe1393ac78, location=US}\n",
      "23/06/24 15:05:08 INFO BlockManagerInfo: Removed broadcast_27_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:05:08 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/231 using temp file gs://kafka-spark-data/spark-metadata/commits/.231.7dd1f067-ca14-473f-951c-d8c9be3b05e0.tmp\n",
      "23/06/24 15:05:09 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.231.7dd1f067-ca14-473f-951c-d8c9be3b05e0.tmp to gs://kafka-spark-data/spark-metadata/commits/231\n",
      "23/06/24 15:05:09 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:05:00.004Z\",\n",
      "  \"batchId\" : 231,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.20238818053025703,\n",
      "  \"processedRowsPerSecond\" : 0.21659085986571366,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6774,\n",
      "    \"getBatch\" : 3,\n",
      "    \"latestOffset\" : 11,\n",
      "    \"queryPlanning\" : 17,\n",
      "    \"triggerExecution\" : 9234,\n",
      "    \"walCommit\" : 1408\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4887\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4889\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.20238818053025703,\n",
      "    \"processedRowsPerSecond\" : 0.21659085986571366\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:05:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:05:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4891.\n",
      "23/06/24 15:05:10 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/232 using temp file gs://kafka-spark-data/spark-metadata/offsets/.232.7faafa3e-432c-488f-9e79-d437fb9e25cf.tmp\n",
      "23/06/24 15:05:11 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.232.7faafa3e-432c-488f-9e79-d437fb9e25cf.tmp to gs://kafka-spark-data/spark-metadata/offsets/232\n",
      "23/06/24 15:05:11 INFO MicroBatchExecution: Committed offsets for batch 232. Metadata OffsetSeqMetadata(0,1687637110024,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:05:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:05:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:05:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:05:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:05:11 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:05:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:05:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:05:11 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:05:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:05:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:05:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:05:11 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:05:11 INFO DAGScheduler: Got job 28 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:05:11 INFO DAGScheduler: Final stage: ResultStage 28 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:05:11 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:05:11 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:05:11 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[202] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:05:11 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:05:11 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:05:11 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:05:11 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:05:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[202] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:05:11 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:05:11 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 28) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:05:11 INFO Executor: Running task 0.0 in stage 28.0 (TID 28)\n",
      "23/06/24 15:05:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:05:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:05:11 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:05:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:05:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:05:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:05:11 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:05:11 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:05:11 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:05:11 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:05:11 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:05:11 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:05:11 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:05:12 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4890 for partition ticketmaster-0\n",
      "23/06/24 15:05:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:05:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:05:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:05:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4892.\n",
      "23/06/24 15:05:13 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c57050b0-b817-4c88-a938-bb9da95fb4c8/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:05:13 INFO FileOutputCommitter: Saved output of task 'attempt_202306241505115077036066957393650_0028_m_000000_28' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c57050b0-b817-4c88-a938-bb9da95fb4c8/_temporary/0/task_202306241505115077036066957393650_0028_m_000000\n",
      "23/06/24 15:05:13 INFO SparkHadoopMapRedUtil: attempt_202306241505115077036066957393650_0028_m_000000_28: Committed. Elapsed time: 698 ms.\n",
      "23/06/24 15:05:13 INFO Executor: Finished task 0.0 in stage 28.0 (TID 28). 2579 bytes result sent to driver\n",
      "23/06/24 15:05:13 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 28) in 1691 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:05:13 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:05:13 INFO DAGScheduler: ResultStage 28 (start at NativeMethodAccessorImpl.java:0) finished in 1.730 s\n",
      "23/06/24 15:05:13 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:05:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 28: Stage finished\n",
      "23/06/24 15:05:13 INFO DAGScheduler: Job 28 finished: start at NativeMethodAccessorImpl.java:0, took 1.731231 s\n",
      "23/06/24 15:05:13 INFO FileFormatWriter: Start to commit write Job b2715436-43ab-4903-b0b8-30bed062d479.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:05:14 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c57050b0-b817-4c88-a938-bb9da95fb4c8/_temporary/0/task_202306241505115077036066957393650_0028_m_000000/' directory.\n",
      "23/06/24 15:05:14 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c57050b0-b817-4c88-a938-bb9da95fb4c8/' directory.\n",
      "23/06/24 15:05:14 INFO BlockManagerInfo: Removed broadcast_28_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:05:15 INFO FileFormatWriter: Write Job b2715436-43ab-4903-b0b8-30bed062d479 committed. Elapsed time: 1393 ms.\n",
      "23/06/24 15:05:15 INFO FileFormatWriter: Finished processing stats for write job b2715436-43ab-4903-b0b8-30bed062d479.\n",
      "23/06/24 15:05:15 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c57050b0-b817-4c88-a938-bb9da95fb4c8/part-00000-7550c5c6-8588-466b-99a2-c8b0ec227b7b-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=64163da5-f5bf-451d-b370-6566d5942643, location=US}\n",
      "23/06/24 15:05:17 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=64163da5-f5bf-451d-b370-6566d5942643, location=US}\n",
      "23/06/24 15:05:17 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/232 using temp file gs://kafka-spark-data/spark-metadata/commits/.232.a3bcf817-c253-47ca-9b87-ad2d634fb7d9.tmp\n",
      "23/06/24 15:05:18 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.232.a3bcf817-c253-47ca-9b87-ad2d634fb7d9.tmp to gs://kafka-spark-data/spark-metadata/commits/232\n",
      "23/06/24 15:05:18 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:05:10.006Z\",\n",
      "  \"batchId\" : 232,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.1999600079984003,\n",
      "  \"processedRowsPerSecond\" : 0.22650056625141562,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6275,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 17,\n",
      "    \"queryPlanning\" : 6,\n",
      "    \"triggerExecution\" : 8829,\n",
      "    \"walCommit\" : 1400\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4889\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4891\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.1999600079984003,\n",
      "    \"processedRowsPerSecond\" : 0.22650056625141562\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:05:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:05:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4893.\n",
      "23/06/24 15:05:20 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/233 using temp file gs://kafka-spark-data/spark-metadata/offsets/.233.6d9f7c29-ff1e-4a30-b673-fb983cb86175.tmp\n",
      "23/06/24 15:05:21 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.233.6d9f7c29-ff1e-4a30-b673-fb983cb86175.tmp to gs://kafka-spark-data/spark-metadata/offsets/233\n",
      "23/06/24 15:05:21 INFO MicroBatchExecution: Committed offsets for batch 233. Metadata OffsetSeqMetadata(0,1687637120006,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:05:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:05:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:05:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:05:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:05:21 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:05:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:05:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:05:21 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:05:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:05:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:05:21 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:05:22 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:05:22 INFO DAGScheduler: Got job 29 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:05:22 INFO DAGScheduler: Final stage: ResultStage 29 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:05:22 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:05:22 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:05:22 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[209] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:05:22 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:05:22 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:05:22 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:05:22 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:05:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[209] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:05:22 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:05:22 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 29) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:05:22 INFO Executor: Running task 0.0 in stage 29.0 (TID 29)\n",
      "23/06/24 15:05:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:05:22 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:05:22 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:05:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:05:22 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:05:22 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:05:22 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:05:22 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:05:22 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:05:22 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:05:22 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:05:22 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:05:22 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:05:22 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4892 for partition ticketmaster-0\n",
      "23/06/24 15:05:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:05:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:05:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:05:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4894.\n",
      "23/06/24 15:05:23 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8188731c-1fe7-460a-abf7-fec1fcbc2d89/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:05:23 INFO FileOutputCommitter: Saved output of task 'attempt_202306241505227736636273039595742_0029_m_000000_29' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8188731c-1fe7-460a-abf7-fec1fcbc2d89/_temporary/0/task_202306241505227736636273039595742_0029_m_000000\n",
      "23/06/24 15:05:23 INFO SparkHadoopMapRedUtil: attempt_202306241505227736636273039595742_0029_m_000000_29: Committed. Elapsed time: 542 ms.\n",
      "23/06/24 15:05:23 INFO Executor: Finished task 0.0 in stage 29.0 (TID 29). 2579 bytes result sent to driver\n",
      "23/06/24 15:05:23 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 29) in 1531 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:05:23 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:05:23 INFO DAGScheduler: ResultStage 29 (start at NativeMethodAccessorImpl.java:0) finished in 1.555 s\n",
      "23/06/24 15:05:23 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:05:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished\n",
      "23/06/24 15:05:23 INFO DAGScheduler: Job 29 finished: start at NativeMethodAccessorImpl.java:0, took 1.557790 s\n",
      "23/06/24 15:05:23 INFO FileFormatWriter: Start to commit write Job 05917492-afa4-4636-bbf5-942247cc0d93.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:05:24 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8188731c-1fe7-460a-abf7-fec1fcbc2d89/_temporary/0/task_202306241505227736636273039595742_0029_m_000000/' directory.\n",
      "23/06/24 15:05:24 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8188731c-1fe7-460a-abf7-fec1fcbc2d89/' directory.\n",
      "23/06/24 15:05:25 INFO FileFormatWriter: Write Job 05917492-afa4-4636-bbf5-942247cc0d93 committed. Elapsed time: 1470 ms.\n",
      "23/06/24 15:05:25 INFO FileFormatWriter: Finished processing stats for write job 05917492-afa4-4636-bbf5-942247cc0d93.\n",
      "23/06/24 15:05:25 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8188731c-1fe7-460a-abf7-fec1fcbc2d89/part-00000-83d7991b-5860-4988-ad21-78f2669a455d-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=809fd4ab-84da-4f67-b1f9-eb143baba40e, location=US}\n",
      "23/06/24 15:05:27 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=809fd4ab-84da-4f67-b1f9-eb143baba40e, location=US}\n",
      "23/06/24 15:05:28 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/233 using temp file gs://kafka-spark-data/spark-metadata/commits/.233.320e12fe-9e54-4f5f-96a9-6b691686aab0.tmp\n",
      "23/06/24 15:05:29 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.233.320e12fe-9e54-4f5f-96a9-6b691686aab0.tmp to gs://kafka-spark-data/spark-metadata/commits/233\n",
      "23/06/24 15:05:29 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:05:20.001Z\",\n",
      "  \"batchId\" : 233,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.20010005002501252,\n",
      "  \"processedRowsPerSecond\" : 0.22094564737074682,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6629,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 4,\n",
      "    \"queryPlanning\" : 20,\n",
      "    \"triggerExecution\" : 9052,\n",
      "    \"walCommit\" : 1434\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4891\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4893\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.20010005002501252,\n",
      "    \"processedRowsPerSecond\" : 0.22094564737074682\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:05:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:05:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4895.\n",
      "23/06/24 15:05:30 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/234 using temp file gs://kafka-spark-data/spark-metadata/offsets/.234.c9dc1776-a228-4e92-a4a1-55b6abd1e613.tmp\n",
      "23/06/24 15:05:31 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.234.c9dc1776-a228-4e92-a4a1-55b6abd1e613.tmp to gs://kafka-spark-data/spark-metadata/offsets/234\n",
      "23/06/24 15:05:31 INFO MicroBatchExecution: Committed offsets for batch 234. Metadata OffsetSeqMetadata(0,1687637130008,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:05:31 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:05:31 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:05:31 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:05:31 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:05:31 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:05:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:05:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:05:31 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:05:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:05:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:05:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:05:32 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:05:32 INFO DAGScheduler: Got job 30 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:05:32 INFO DAGScheduler: Final stage: ResultStage 30 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:05:32 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:05:32 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:05:32 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[216] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:05:32 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 295.4 KiB, free 433.7 MiB)\n",
      "23/06/24 15:05:32 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 433.6 MiB)\n",
      "23/06/24 15:05:32 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.2 MiB)\n",
      "23/06/24 15:05:32 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:05:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[216] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:05:32 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:05:32 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 30) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:05:32 INFO Executor: Running task 0.0 in stage 30.0 (TID 30)\n",
      "23/06/24 15:05:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:05:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:05:32 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:05:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:05:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:05:32 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:05:32 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:05:32 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:05:32 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:05:32 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:05:32 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:05:32 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:05:32 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:05:32 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4894 for partition ticketmaster-0\n",
      "23/06/24 15:05:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:05:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:05:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:05:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4896.\n",
      "23/06/24 15:05:33 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-b97456b7-2978-4a9b-9720-382aed38a069/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:05:33 INFO FileOutputCommitter: Saved output of task 'attempt_202306241505325962426841764456757_0030_m_000000_30' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-b97456b7-2978-4a9b-9720-382aed38a069/_temporary/0/task_202306241505325962426841764456757_0030_m_000000\n",
      "23/06/24 15:05:33 INFO SparkHadoopMapRedUtil: attempt_202306241505325962426841764456757_0030_m_000000_30: Committed. Elapsed time: 565 ms.\n",
      "23/06/24 15:05:33 INFO Executor: Finished task 0.0 in stage 30.0 (TID 30). 2579 bytes result sent to driver\n",
      "23/06/24 15:05:33 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 30) in 1514 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:05:33 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:05:33 INFO DAGScheduler: ResultStage 30 (start at NativeMethodAccessorImpl.java:0) finished in 1.535 s\n",
      "23/06/24 15:05:33 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:05:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished\n",
      "23/06/24 15:05:33 INFO DAGScheduler: Job 30 finished: start at NativeMethodAccessorImpl.java:0, took 1.536283 s\n",
      "23/06/24 15:05:33 INFO FileFormatWriter: Start to commit write Job 965c0f4a-ad2d-44dd-a172-b70db5d5c9b8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:05:34 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-b97456b7-2978-4a9b-9720-382aed38a069/_temporary/0/task_202306241505325962426841764456757_0030_m_000000/' directory.\n",
      "23/06/24 15:05:34 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-b97456b7-2978-4a9b-9720-382aed38a069/' directory.\n",
      "23/06/24 15:05:34 INFO BlockManagerInfo: Removed broadcast_30_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:05:34 INFO BlockManagerInfo: Removed broadcast_29_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:05:35 INFO FileFormatWriter: Write Job 965c0f4a-ad2d-44dd-a172-b70db5d5c9b8 committed. Elapsed time: 1640 ms.\n",
      "23/06/24 15:05:35 INFO FileFormatWriter: Finished processing stats for write job 965c0f4a-ad2d-44dd-a172-b70db5d5c9b8.\n",
      "23/06/24 15:05:35 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-b97456b7-2978-4a9b-9720-382aed38a069/part-00000-98c9234a-f5c4-4967-a024-fa2ea2feea66-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=5d41c7c4-f866-4f52-8881-182d3d216750, location=US}\n",
      "23/06/24 15:05:38 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=5d41c7c4-f866-4f52-8881-182d3d216750, location=US}\n",
      "23/06/24 15:05:39 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/234 using temp file gs://kafka-spark-data/spark-metadata/commits/.234.6f17b4b1-fe2b-4ae1-a578-2c486aa1188c.tmp\n",
      "23/06/24 15:05:40 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.234.6f17b4b1-fe2b-4ae1-a578-2c486aa1188c.tmp to gs://kafka-spark-data/spark-metadata/commits/234\n",
      "23/06/24 15:05:40 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:05:30.002Z\",\n",
      "  \"batchId\" : 234,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.19998000199980004,\n",
      "  \"processedRowsPerSecond\" : 0.19747235387045814,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7334,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 5,\n",
      "    \"queryPlanning\" : 10,\n",
      "    \"triggerExecution\" : 10128,\n",
      "    \"walCommit\" : 1588\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4893\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4895\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.19998000199980004,\n",
      "    \"processedRowsPerSecond\" : 0.19747235387045814\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:05:40 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 10129 milliseconds\n",
      "23/06/24 15:05:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:05:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4897.\n",
      "23/06/24 15:05:40 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/235 using temp file gs://kafka-spark-data/spark-metadata/offsets/.235.d421f831-fe99-4513-a18c-b6654f0683f0.tmp\n",
      "23/06/24 15:05:41 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.235.d421f831-fe99-4513-a18c-b6654f0683f0.tmp to gs://kafka-spark-data/spark-metadata/offsets/235\n",
      "23/06/24 15:05:41 INFO MicroBatchExecution: Committed offsets for batch 235. Metadata OffsetSeqMetadata(0,1687637140147,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:05:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:05:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:05:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:05:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:05:42 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:05:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:05:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:05:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:05:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:05:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:05:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:05:42 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:05:42 INFO DAGScheduler: Got job 31 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:05:42 INFO DAGScheduler: Final stage: ResultStage 31 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:05:42 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:05:42 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:05:42 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[223] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:05:42 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:05:42 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:05:42 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:05:42 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:05:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[223] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:05:42 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:05:42 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 31) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:05:42 INFO Executor: Running task 0.0 in stage 31.0 (TID 31)\n",
      "23/06/24 15:05:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:05:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:05:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:05:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:05:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:05:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:05:42 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:05:42 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:05:42 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:05:42 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:05:42 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:05:42 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:05:42 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:05:42 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4896 for partition ticketmaster-0\n",
      "23/06/24 15:05:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:05:43 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:05:43 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:05:43 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4898.\n",
      "23/06/24 15:05:43 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-b7506038-6e90-456e-af06-2dc94f0a34b5/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:05:43 INFO FileOutputCommitter: Saved output of task 'attempt_202306241505427483779826083318061_0031_m_000000_31' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-b7506038-6e90-456e-af06-2dc94f0a34b5/_temporary/0/task_202306241505427483779826083318061_0031_m_000000\n",
      "23/06/24 15:05:43 INFO SparkHadoopMapRedUtil: attempt_202306241505427483779826083318061_0031_m_000000_31: Committed. Elapsed time: 588 ms.\n",
      "23/06/24 15:05:43 INFO Executor: Finished task 0.0 in stage 31.0 (TID 31). 2579 bytes result sent to driver\n",
      "23/06/24 15:05:43 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 31) in 1558 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:05:43 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:05:43 INFO DAGScheduler: ResultStage 31 (start at NativeMethodAccessorImpl.java:0) finished in 1.597 s\n",
      "23/06/24 15:05:43 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:05:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished\n",
      "23/06/24 15:05:43 INFO DAGScheduler: Job 31 finished: start at NativeMethodAccessorImpl.java:0, took 1.598707 s\n",
      "23/06/24 15:05:43 INFO FileFormatWriter: Start to commit write Job e2ce72a6-ddf4-4d9d-b785-33f3b177bc58.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:05:44 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-b7506038-6e90-456e-af06-2dc94f0a34b5/_temporary/0/task_202306241505427483779826083318061_0031_m_000000/' directory.\n",
      "23/06/24 15:05:44 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-b7506038-6e90-456e-af06-2dc94f0a34b5/' directory.\n",
      "23/06/24 15:05:45 INFO FileFormatWriter: Write Job e2ce72a6-ddf4-4d9d-b785-33f3b177bc58 committed. Elapsed time: 1391 ms.\n",
      "23/06/24 15:05:45 INFO FileFormatWriter: Finished processing stats for write job e2ce72a6-ddf4-4d9d-b785-33f3b177bc58.\n",
      "23/06/24 15:05:45 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-b7506038-6e90-456e-af06-2dc94f0a34b5/part-00000-b4dedaa6-dadc-41e1-b209-d49c5d9ceb62-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=46bc1a4e-ee1f-44bc-a244-f565d6b63a20, location=US}\n",
      "23/06/24 15:05:47 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=46bc1a4e-ee1f-44bc-a244-f565d6b63a20, location=US}\n",
      "23/06/24 15:05:48 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/235 using temp file gs://kafka-spark-data/spark-metadata/commits/.235.52e8f834-1c87-480a-8430-2057413adc54.tmp\n",
      "23/06/24 15:05:49 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.235.52e8f834-1c87-480a-8430-2057413adc54.tmp to gs://kafka-spark-data/spark-metadata/commits/235\n",
      "23/06/24 15:05:49 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:05:40.131Z\",\n",
      "  \"batchId\" : 235,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.19745285813012145,\n",
      "  \"processedRowsPerSecond\" : 0.2217049107637734,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6365,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 15,\n",
      "    \"queryPlanning\" : 4,\n",
      "    \"triggerExecution\" : 9021,\n",
      "    \"walCommit\" : 1668\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4895\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4897\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.19745285813012145,\n",
      "    \"processedRowsPerSecond\" : 0.2217049107637734\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:05:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:05:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4899.\n",
      "23/06/24 15:05:50 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/236 using temp file gs://kafka-spark-data/spark-metadata/offsets/.236.b9a9e0df-f7e8-475f-8a43-1392c56dc624.tmp\n",
      "23/06/24 15:05:51 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.236.b9a9e0df-f7e8-475f-8a43-1392c56dc624.tmp to gs://kafka-spark-data/spark-metadata/offsets/236\n",
      "23/06/24 15:05:51 INFO MicroBatchExecution: Committed offsets for batch 236. Metadata OffsetSeqMetadata(0,1687637150013,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:05:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:05:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:05:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:05:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:05:51 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:05:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:05:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:05:51 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:05:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:05:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:05:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:05:52 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:05:52 INFO DAGScheduler: Got job 32 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:05:52 INFO DAGScheduler: Final stage: ResultStage 32 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:05:52 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:05:52 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:05:52 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[230] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:05:52 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 295.4 KiB, free 433.7 MiB)\n",
      "23/06/24 15:05:52 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 433.6 MiB)\n",
      "23/06/24 15:05:52 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.2 MiB)\n",
      "23/06/24 15:05:52 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:05:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[230] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:05:52 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:05:52 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 32) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:05:52 INFO Executor: Running task 0.0 in stage 32.0 (TID 32)\n",
      "23/06/24 15:05:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:05:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:05:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:05:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:05:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:05:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:05:52 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:05:52 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:05:52 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:05:52 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:05:52 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:05:52 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:05:52 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:05:52 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4898 for partition ticketmaster-0\n",
      "23/06/24 15:05:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:05:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:05:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:05:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4900.\n",
      "23/06/24 15:05:53 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-a13da441-7cf8-4c4d-87b4-7c7ba36190e7/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:05:53 INFO FileOutputCommitter: Saved output of task 'attempt_202306241505521497205316373016071_0032_m_000000_32' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-a13da441-7cf8-4c4d-87b4-7c7ba36190e7/_temporary/0/task_202306241505521497205316373016071_0032_m_000000\n",
      "23/06/24 15:05:53 INFO SparkHadoopMapRedUtil: attempt_202306241505521497205316373016071_0032_m_000000_32: Committed. Elapsed time: 634 ms.\n",
      "23/06/24 15:05:53 INFO Executor: Finished task 0.0 in stage 32.0 (TID 32). 2579 bytes result sent to driver\n",
      "23/06/24 15:05:53 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 32) in 1571 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:05:53 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:05:53 INFO DAGScheduler: ResultStage 32 (start at NativeMethodAccessorImpl.java:0) finished in 1.595 s\n",
      "23/06/24 15:05:53 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:05:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished\n",
      "23/06/24 15:05:53 INFO DAGScheduler: Job 32 finished: start at NativeMethodAccessorImpl.java:0, took 1.596494 s\n",
      "23/06/24 15:05:53 INFO FileFormatWriter: Start to commit write Job 35b5bc09-1691-4b3c-a437-ce3d2b4db7af.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:05:54 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-a13da441-7cf8-4c4d-87b4-7c7ba36190e7/_temporary/0/task_202306241505521497205316373016071_0032_m_000000/' directory.\n",
      "23/06/24 15:05:54 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-a13da441-7cf8-4c4d-87b4-7c7ba36190e7/' directory.\n",
      "23/06/24 15:05:54 INFO BlockManagerInfo: Removed broadcast_32_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:05:54 INFO BlockManagerInfo: Removed broadcast_31_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:05:54 INFO FileFormatWriter: Write Job 35b5bc09-1691-4b3c-a437-ce3d2b4db7af committed. Elapsed time: 1350 ms.\n",
      "23/06/24 15:05:54 INFO FileFormatWriter: Finished processing stats for write job 35b5bc09-1691-4b3c-a437-ce3d2b4db7af.\n",
      "23/06/24 15:05:55 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-a13da441-7cf8-4c4d-87b4-7c7ba36190e7/part-00000-01fa03ce-520b-4f74-a406-305edc2cf91e-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=a898dd34-1b1a-4588-ac80-7f08b32ef962, location=US}\n",
      "23/06/24 15:05:57 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=a898dd34-1b1a-4588-ac80-7f08b32ef962, location=US}\n",
      "23/06/24 15:05:57 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/236 using temp file gs://kafka-spark-data/spark-metadata/commits/.236.1d4c652f-69bb-4524-b0a7-1255f647d4cd.tmp\n",
      "23/06/24 15:05:58 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.236.1d4c652f-69bb-4524-b0a7-1255f647d4cd.tmp to gs://kafka-spark-data/spark-metadata/commits/236\n",
      "23/06/24 15:05:58 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:05:50.002Z\",\n",
      "  \"batchId\" : 236,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.20261371694863742,\n",
      "  \"processedRowsPerSecond\" : 0.22914757103574704,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6149,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 11,\n",
      "    \"queryPlanning\" : 6,\n",
      "    \"triggerExecution\" : 8728,\n",
      "    \"walCommit\" : 1537\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4897\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4899\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.20261371694863742,\n",
      "    \"processedRowsPerSecond\" : 0.22914757103574704\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:06:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:06:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4901.\n",
      "23/06/24 15:06:00 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/237 using temp file gs://kafka-spark-data/spark-metadata/offsets/.237.1cf3f52b-f446-4e4d-b95b-dcbd2c4cc3d9.tmp\n",
      "23/06/24 15:06:01 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.237.1cf3f52b-f446-4e4d-b95b-dcbd2c4cc3d9.tmp to gs://kafka-spark-data/spark-metadata/offsets/237\n",
      "23/06/24 15:06:01 INFO MicroBatchExecution: Committed offsets for batch 237. Metadata OffsetSeqMetadata(0,1687637160018,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:06:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:06:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:06:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:06:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:06:01 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:06:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:06:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:06:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:06:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:06:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:06:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:06:01 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:06:01 INFO DAGScheduler: Got job 33 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:06:01 INFO DAGScheduler: Final stage: ResultStage 33 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:06:01 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:06:01 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:06:01 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[237] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:06:01 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:06:01 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:06:01 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:06:01 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:06:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[237] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:06:01 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:06:01 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 33) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:06:01 INFO Executor: Running task 0.0 in stage 33.0 (TID 33)\n",
      "23/06/24 15:06:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:06:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:06:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:06:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:06:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:06:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:06:01 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:06:01 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:06:01 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:06:01 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:06:01 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:06:01 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:06:01 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:06:02 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4900 for partition ticketmaster-0\n",
      "23/06/24 15:06:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 33:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:06:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:06:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:06:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4902.\n",
      "23/06/24 15:06:03 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-4cab9561-3cbe-42c1-838d-e8eb60e5b886/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:06:03 INFO FileOutputCommitter: Saved output of task 'attempt_20230624150601225951555775644777_0033_m_000000_33' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-4cab9561-3cbe-42c1-838d-e8eb60e5b886/_temporary/0/task_20230624150601225951555775644777_0033_m_000000\n",
      "23/06/24 15:06:03 INFO SparkHadoopMapRedUtil: attempt_20230624150601225951555775644777_0033_m_000000_33: Committed. Elapsed time: 554 ms.\n",
      "23/06/24 15:06:03 INFO Executor: Finished task 0.0 in stage 33.0 (TID 33). 2579 bytes result sent to driver\n",
      "23/06/24 15:06:03 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 33) in 1481 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:06:03 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:06:03 INFO DAGScheduler: ResultStage 33 (start at NativeMethodAccessorImpl.java:0) finished in 1.518 s\n",
      "23/06/24 15:06:03 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:06:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 33: Stage finished\n",
      "23/06/24 15:06:03 INFO DAGScheduler: Job 33 finished: start at NativeMethodAccessorImpl.java:0, took 1.518833 s\n",
      "23/06/24 15:06:03 INFO FileFormatWriter: Start to commit write Job d4efc0b3-58d7-4a82-8411-8db422735cca.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:06:04 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-4cab9561-3cbe-42c1-838d-e8eb60e5b886/_temporary/0/task_20230624150601225951555775644777_0033_m_000000/' directory.\n",
      "23/06/24 15:06:04 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-4cab9561-3cbe-42c1-838d-e8eb60e5b886/' directory.\n",
      "23/06/24 15:06:04 INFO FileFormatWriter: Write Job d4efc0b3-58d7-4a82-8411-8db422735cca committed. Elapsed time: 1496 ms.\n",
      "23/06/24 15:06:04 INFO FileFormatWriter: Finished processing stats for write job d4efc0b3-58d7-4a82-8411-8db422735cca.\n",
      "23/06/24 15:06:05 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-4cab9561-3cbe-42c1-838d-e8eb60e5b886/part-00000-e5065e03-9e89-4eef-82c9-694b7776d514-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=2321624f-86ef-4059-9bfe-c42ff9b37d9d, location=US}\n",
      "23/06/24 15:06:07 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=2321624f-86ef-4059-9bfe-c42ff9b37d9d, location=US}\n",
      "23/06/24 15:06:08 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/237 using temp file gs://kafka-spark-data/spark-metadata/commits/.237.ad4b045f-7d88-4f59-8e1f-054ea1fea12d.tmp\n",
      "23/06/24 15:06:08 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.237.ad4b045f-7d88-4f59-8e1f-054ea1fea12d.tmp to gs://kafka-spark-data/spark-metadata/commits/237\n",
      "23/06/24 15:06:08 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:06:00.004Z\",\n",
      "  \"batchId\" : 237,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.1999600079984003,\n",
      "  \"processedRowsPerSecond\" : 0.22436616558223021,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6626,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 14,\n",
      "    \"queryPlanning\" : 5,\n",
      "    \"triggerExecution\" : 8914,\n",
      "    \"walCommit\" : 1368\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4899\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4901\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.1999600079984003,\n",
      "    \"processedRowsPerSecond\" : 0.22436616558223021\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:06:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:06:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4903.\n",
      "23/06/24 15:06:10 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/238 using temp file gs://kafka-spark-data/spark-metadata/offsets/.238.a0a7137e-b757-410a-920b-52e29ac043f7.tmp\n",
      "23/06/24 15:06:11 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.238.a0a7137e-b757-410a-920b-52e29ac043f7.tmp to gs://kafka-spark-data/spark-metadata/offsets/238\n",
      "23/06/24 15:06:11 INFO MicroBatchExecution: Committed offsets for batch 238. Metadata OffsetSeqMetadata(0,1687637170009,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:06:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:06:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:06:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:06:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:06:12 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:06:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:06:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:06:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:06:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:06:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:06:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:06:12 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:06:12 INFO DAGScheduler: Got job 34 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:06:12 INFO DAGScheduler: Final stage: ResultStage 34 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:06:12 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:06:12 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:06:12 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[244] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:06:12 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 295.4 KiB, free 433.7 MiB)\n",
      "23/06/24 15:06:12 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 433.6 MiB)\n",
      "23/06/24 15:06:12 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.2 MiB)\n",
      "23/06/24 15:06:12 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:06:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[244] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:06:12 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:06:12 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 34) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:06:12 INFO Executor: Running task 0.0 in stage 34.0 (TID 34)\n",
      "23/06/24 15:06:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:06:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:06:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:06:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:06:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:06:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:06:12 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:06:12 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:06:12 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:06:12 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:06:12 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:06:12 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:06:12 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:06:12 INFO BlockManagerInfo: Removed broadcast_33_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:06:12 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4902 for partition ticketmaster-0\n",
      "23/06/24 15:06:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 34:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:06:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:06:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:06:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4904.\n",
      "23/06/24 15:06:13 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-1c6f31f1-40bd-4171-827c-c6b7641b4ed1/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:06:13 INFO FileOutputCommitter: Saved output of task 'attempt_202306241506124425032459805112030_0034_m_000000_34' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-1c6f31f1-40bd-4171-827c-c6b7641b4ed1/_temporary/0/task_202306241506124425032459805112030_0034_m_000000\n",
      "23/06/24 15:06:13 INFO SparkHadoopMapRedUtil: attempt_202306241506124425032459805112030_0034_m_000000_34: Committed. Elapsed time: 592 ms.\n",
      "23/06/24 15:06:13 INFO Executor: Finished task 0.0 in stage 34.0 (TID 34). 2536 bytes result sent to driver\n",
      "23/06/24 15:06:13 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 34) in 1563 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:06:13 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:06:13 INFO DAGScheduler: ResultStage 34 (start at NativeMethodAccessorImpl.java:0) finished in 1.603 s\n",
      "23/06/24 15:06:13 INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:06:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished\n",
      "23/06/24 15:06:13 INFO DAGScheduler: Job 34 finished: start at NativeMethodAccessorImpl.java:0, took 1.604216 s\n",
      "23/06/24 15:06:13 INFO FileFormatWriter: Start to commit write Job e7da9459-365f-4bf3-a0c3-064c215634b1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:06:14 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-1c6f31f1-40bd-4171-827c-c6b7641b4ed1/_temporary/0/task_202306241506124425032459805112030_0034_m_000000/' directory.\n",
      "23/06/24 15:06:14 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-1c6f31f1-40bd-4171-827c-c6b7641b4ed1/' directory.\n",
      "23/06/24 15:06:15 INFO FileFormatWriter: Write Job e7da9459-365f-4bf3-a0c3-064c215634b1 committed. Elapsed time: 1429 ms.\n",
      "23/06/24 15:06:15 INFO FileFormatWriter: Finished processing stats for write job e7da9459-365f-4bf3-a0c3-064c215634b1.\n",
      "23/06/24 15:06:15 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-1c6f31f1-40bd-4171-827c-c6b7641b4ed1/part-00000-1716484f-5c4b-44dd-be97-0bed43ab9c2d-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=a5e58e2a-d9fc-48cb-bb9b-900202530cee, location=US}\n",
      "23/06/24 15:06:17 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=a5e58e2a-d9fc-48cb-bb9b-900202530cee, location=US}\n",
      "23/06/24 15:06:17 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/238 using temp file gs://kafka-spark-data/spark-metadata/commits/.238.bd1551c2-e613-4d2f-a96c-274531994a6e.tmp\n",
      "23/06/24 15:06:18 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.238.bd1551c2-e613-4d2f-a96c-274531994a6e.tmp to gs://kafka-spark-data/spark-metadata/commits/238\n",
      "23/06/24 15:06:18 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:06:10.002Z\",\n",
      "  \"batchId\" : 238,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.20004000800160032,\n",
      "  \"processedRowsPerSecond\" : 0.234439104442621,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 5697,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 7,\n",
      "    \"queryPlanning\" : 10,\n",
      "    \"triggerExecution\" : 8531,\n",
      "    \"walCommit\" : 1755\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4901\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4903\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.20004000800160032,\n",
      "    \"processedRowsPerSecond\" : 0.234439104442621\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:06:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:06:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4905.\n",
      "23/06/24 15:06:20 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/239 using temp file gs://kafka-spark-data/spark-metadata/offsets/.239.662d3e47-1e64-46a6-bef5-0719b803e2f1.tmp\n",
      "23/06/24 15:06:21 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.239.662d3e47-1e64-46a6-bef5-0719b803e2f1.tmp to gs://kafka-spark-data/spark-metadata/offsets/239\n",
      "23/06/24 15:06:21 INFO MicroBatchExecution: Committed offsets for batch 239. Metadata OffsetSeqMetadata(0,1687637180007,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:06:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:06:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:06:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:06:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:06:22 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:06:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:06:22 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:06:22 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:06:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:06:22 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:06:22 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:06:22 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:06:22 INFO DAGScheduler: Got job 35 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:06:22 INFO DAGScheduler: Final stage: ResultStage 35 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:06:22 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:06:22 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:06:22 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[251] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:06:22 INFO BlockManagerInfo: Removed broadcast_34_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:06:22 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:06:22 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:06:22 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:06:22 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:06:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[251] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:06:22 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:06:22 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 35) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:06:22 INFO Executor: Running task 0.0 in stage 35.0 (TID 35)\n",
      "23/06/24 15:06:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:06:22 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:06:22 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:06:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:06:22 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:06:22 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:06:22 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:06:22 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:06:22 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:06:22 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:06:22 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:06:22 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:06:22 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:06:22 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4904 for partition ticketmaster-0\n",
      "23/06/24 15:06:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 35:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:06:23 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:06:23 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:06:23 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4906.\n",
      "23/06/24 15:06:24 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-a7257360-c16f-4c37-8c35-63c7c0bf1635/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:06:24 INFO FileOutputCommitter: Saved output of task 'attempt_202306241506222692934211560062712_0035_m_000000_35' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-a7257360-c16f-4c37-8c35-63c7c0bf1635/_temporary/0/task_202306241506222692934211560062712_0035_m_000000\n",
      "23/06/24 15:06:24 INFO SparkHadoopMapRedUtil: attempt_202306241506222692934211560062712_0035_m_000000_35: Committed. Elapsed time: 562 ms.\n",
      "23/06/24 15:06:24 INFO Executor: Finished task 0.0 in stage 35.0 (TID 35). 2579 bytes result sent to driver\n",
      "23/06/24 15:06:24 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 35) in 1593 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:06:24 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:06:24 INFO DAGScheduler: ResultStage 35 (start at NativeMethodAccessorImpl.java:0) finished in 1.628 s\n",
      "23/06/24 15:06:24 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:06:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished\n",
      "23/06/24 15:06:24 INFO DAGScheduler: Job 35 finished: start at NativeMethodAccessorImpl.java:0, took 1.630018 s\n",
      "23/06/24 15:06:24 INFO FileFormatWriter: Start to commit write Job b47c3a48-43cc-4723-822d-c127e5e45627.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:06:24 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-a7257360-c16f-4c37-8c35-63c7c0bf1635/_temporary/0/task_202306241506222692934211560062712_0035_m_000000/' directory.\n",
      "23/06/24 15:06:25 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-a7257360-c16f-4c37-8c35-63c7c0bf1635/' directory.\n",
      "23/06/24 15:06:25 INFO BlockManagerInfo: Removed broadcast_35_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:06:25 INFO FileFormatWriter: Write Job b47c3a48-43cc-4723-822d-c127e5e45627 committed. Elapsed time: 1316 ms.\n",
      "23/06/24 15:06:25 INFO FileFormatWriter: Finished processing stats for write job b47c3a48-43cc-4723-822d-c127e5e45627.\n",
      "23/06/24 15:06:25 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-a7257360-c16f-4c37-8c35-63c7c0bf1635/part-00000-80590e16-b9b3-4d91-a519-41d0c801a3da-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=efe1dfbc-8024-49fc-8ce9-8b4d7ac1e067, location=US}\n",
      "23/06/24 15:06:28 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=efe1dfbc-8024-49fc-8ce9-8b4d7ac1e067, location=US}\n",
      "23/06/24 15:06:29 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/239 using temp file gs://kafka-spark-data/spark-metadata/commits/.239.f3101af1-4a3f-401e-92c0-d26fc06efaa7.tmp\n",
      "23/06/24 15:06:30 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.239.f3101af1-4a3f-401e-92c0-d26fc06efaa7.tmp to gs://kafka-spark-data/spark-metadata/commits/239\n",
      "23/06/24 15:06:30 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:06:20.003Z\",\n",
      "  \"batchId\" : 239,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.19998000199980004,\n",
      "  \"processedRowsPerSecond\" : 0.19663749877101563,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7166,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 4,\n",
      "    \"queryPlanning\" : 4,\n",
      "    \"triggerExecution\" : 10171,\n",
      "    \"walCommit\" : 1967\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4903\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4905\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.19998000199980004,\n",
      "    \"processedRowsPerSecond\" : 0.19663749877101563\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:06:30 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 10172 milliseconds\n",
      "23/06/24 15:06:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:06:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4907.\n",
      "23/06/24 15:06:30 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/240 using temp file gs://kafka-spark-data/spark-metadata/offsets/.240.9174ca9c-7f47-4cda-958f-b95549e06adf.tmp\n",
      "23/06/24 15:06:31 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.240.9174ca9c-7f47-4cda-958f-b95549e06adf.tmp to gs://kafka-spark-data/spark-metadata/offsets/240\n",
      "23/06/24 15:06:31 INFO MicroBatchExecution: Committed offsets for batch 240. Metadata OffsetSeqMetadata(0,1687637190183,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:06:31 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:06:31 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:06:31 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:06:31 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:06:32 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:06:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:06:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:06:32 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:06:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:06:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:06:32 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:06:32 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:06:32 INFO DAGScheduler: Got job 36 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:06:32 INFO DAGScheduler: Final stage: ResultStage 36 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:06:32 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:06:32 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:06:32 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[258] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:06:32 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:06:32 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:06:32 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:06:32 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:06:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[258] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:06:32 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:06:32 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 36) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:06:32 INFO Executor: Running task 0.0 in stage 36.0 (TID 36)\n",
      "23/06/24 15:06:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:06:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:06:32 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:06:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:06:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:06:32 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:06:32 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:06:32 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:06:32 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:06:32 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:06:32 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:06:32 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:06:32 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:06:32 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4906 for partition ticketmaster-0\n",
      "23/06/24 15:06:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:06:33 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:06:33 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:06:33 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4908.\n",
      "23/06/24 15:06:33 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-5e1a2a84-b1e6-4247-88d4-ae57fc45e399/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:06:33 INFO FileOutputCommitter: Saved output of task 'attempt_202306241506325609436099503329224_0036_m_000000_36' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-5e1a2a84-b1e6-4247-88d4-ae57fc45e399/_temporary/0/task_202306241506325609436099503329224_0036_m_000000\n",
      "23/06/24 15:06:33 INFO SparkHadoopMapRedUtil: attempt_202306241506325609436099503329224_0036_m_000000_36: Committed. Elapsed time: 564 ms.\n",
      "23/06/24 15:06:33 INFO Executor: Finished task 0.0 in stage 36.0 (TID 36). 2536 bytes result sent to driver\n",
      "23/06/24 15:06:33 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 36) in 1462 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:06:33 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:06:33 INFO DAGScheduler: ResultStage 36 (start at NativeMethodAccessorImpl.java:0) finished in 1.481 s\n",
      "23/06/24 15:06:33 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:06:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished\n",
      "23/06/24 15:06:33 INFO DAGScheduler: Job 36 finished: start at NativeMethodAccessorImpl.java:0, took 1.482871 s\n",
      "23/06/24 15:06:33 INFO FileFormatWriter: Start to commit write Job 239e45f8-fdf8-4083-8aa4-aedc57478968.\n",
      "23/06/24 15:06:34 INFO BlockManagerInfo: Removed broadcast_36_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:06:35 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-5e1a2a84-b1e6-4247-88d4-ae57fc45e399/_temporary/0/task_202306241506325609436099503329224_0036_m_000000/' directory.\n",
      "23/06/24 15:06:35 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-5e1a2a84-b1e6-4247-88d4-ae57fc45e399/' directory.\n",
      "23/06/24 15:06:36 INFO FileFormatWriter: Write Job 239e45f8-fdf8-4083-8aa4-aedc57478968 committed. Elapsed time: 2250 ms.\n",
      "23/06/24 15:06:36 INFO FileFormatWriter: Finished processing stats for write job 239e45f8-fdf8-4083-8aa4-aedc57478968.\n",
      "23/06/24 15:06:36 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-5e1a2a84-b1e6-4247-88d4-ae57fc45e399/part-00000-42882dd9-679d-4441-b23d-7e26f8e4f04a-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=5ab398d8-f9ee-4f87-9f4e-9e8a4d3d93e6, location=US}\n",
      "23/06/24 15:06:38 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=5ab398d8-f9ee-4f87-9f4e-9e8a4d3d93e6, location=US}\n",
      "23/06/24 15:06:38 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/240 using temp file gs://kafka-spark-data/spark-metadata/commits/.240.a7b1a999-9ff9-4c15-9fa3-a58b985baa32.tmp\n",
      "23/06/24 15:06:39 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.240.a7b1a999-9ff9-4c15-9fa3-a58b985baa32.tmp to gs://kafka-spark-data/spark-metadata/commits/240\n",
      "23/06/24 15:06:39 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:06:30.175Z\",\n",
      "  \"batchId\" : 240,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.19661816751867872,\n",
      "  \"processedRowsPerSecond\" : 0.20933640360058614,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6782,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 8,\n",
      "    \"queryPlanning\" : 6,\n",
      "    \"triggerExecution\" : 9553,\n",
      "    \"walCommit\" : 1802\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4905\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4907\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.19661816751867872,\n",
      "    \"processedRowsPerSecond\" : 0.20933640360058614\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:06:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:06:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4909.\n",
      "23/06/24 15:06:40 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/241 using temp file gs://kafka-spark-data/spark-metadata/offsets/.241.a66cd591-7d98-4bb0-9f7d-350903188e7f.tmp\n",
      "23/06/24 15:06:40 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.241.a66cd591-7d98-4bb0-9f7d-350903188e7f.tmp to gs://kafka-spark-data/spark-metadata/offsets/241\n",
      "23/06/24 15:06:40 INFO MicroBatchExecution: Committed offsets for batch 241. Metadata OffsetSeqMetadata(0,1687637200007,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:06:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:06:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:06:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:06:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:06:41 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:06:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:06:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:06:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:06:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:06:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:06:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:06:41 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:06:41 INFO DAGScheduler: Got job 37 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:06:41 INFO DAGScheduler: Final stage: ResultStage 37 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:06:41 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:06:41 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:06:41 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[265] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:06:41 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:06:41 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:06:41 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:06:41 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:06:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[265] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:06:41 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:06:41 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 37) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:06:41 INFO Executor: Running task 0.0 in stage 37.0 (TID 37)\n",
      "23/06/24 15:06:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:06:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:06:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:06:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:06:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:06:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:06:41 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:06:41 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:06:41 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:06:41 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:06:41 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:06:41 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:06:41 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:06:42 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4908 for partition ticketmaster-0\n",
      "23/06/24 15:06:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:06:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:06:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:06:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4910.\n",
      "23/06/24 15:06:43 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c9b92bcf-37a5-4e25-8f0b-46fe0009dfa8/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:06:43 INFO FileOutputCommitter: Saved output of task 'attempt_202306241506418219098795876182639_0037_m_000000_37' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c9b92bcf-37a5-4e25-8f0b-46fe0009dfa8/_temporary/0/task_202306241506418219098795876182639_0037_m_000000\n",
      "23/06/24 15:06:43 INFO SparkHadoopMapRedUtil: attempt_202306241506418219098795876182639_0037_m_000000_37: Committed. Elapsed time: 611 ms.\n",
      "23/06/24 15:06:43 INFO Executor: Finished task 0.0 in stage 37.0 (TID 37). 2579 bytes result sent to driver\n",
      "23/06/24 15:06:43 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 37) in 1597 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:06:43 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:06:43 INFO DAGScheduler: ResultStage 37 (start at NativeMethodAccessorImpl.java:0) finished in 1.641 s\n",
      "23/06/24 15:06:43 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:06:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 37: Stage finished\n",
      "23/06/24 15:06:43 INFO DAGScheduler: Job 37 finished: start at NativeMethodAccessorImpl.java:0, took 1.641587 s\n",
      "23/06/24 15:06:43 INFO FileFormatWriter: Start to commit write Job 75a0e151-c2e7-4213-86f4-29bdbd8f08c4.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:06:44 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c9b92bcf-37a5-4e25-8f0b-46fe0009dfa8/_temporary/0/task_202306241506418219098795876182639_0037_m_000000/' directory.\n",
      "23/06/24 15:06:44 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c9b92bcf-37a5-4e25-8f0b-46fe0009dfa8/' directory.\n",
      "23/06/24 15:06:44 INFO BlockManagerInfo: Removed broadcast_37_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:06:45 INFO FileFormatWriter: Write Job 75a0e151-c2e7-4213-86f4-29bdbd8f08c4 committed. Elapsed time: 1651 ms.\n",
      "23/06/24 15:06:45 INFO FileFormatWriter: Finished processing stats for write job 75a0e151-c2e7-4213-86f4-29bdbd8f08c4.\n",
      "23/06/24 15:06:45 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c9b92bcf-37a5-4e25-8f0b-46fe0009dfa8/part-00000-e9aa1375-b345-46c3-84b7-c2294770f0b4-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=e0d48bb7-b1a5-4d5e-9f5f-a0fd5105880d, location=US}\n",
      "23/06/24 15:06:48 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=e0d48bb7-b1a5-4d5e-9f5f-a0fd5105880d, location=US}\n",
      "23/06/24 15:06:49 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/241 using temp file gs://kafka-spark-data/spark-metadata/commits/.241.3794e218-f16f-40c9-b4b8-70184f8d33b7.tmp\n",
      "23/06/24 15:06:50 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.241.3794e218-f16f-40c9-b4b8-70184f8d33b7.tmp to gs://kafka-spark-data/spark-metadata/commits/241\n",
      "23/06/24 15:06:50 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:06:40.001Z\",\n",
      "  \"batchId\" : 241,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.2035416242621616,\n",
      "  \"processedRowsPerSecond\" : 0.1950458357714063,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7685,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 6,\n",
      "    \"queryPlanning\" : 16,\n",
      "    \"triggerExecution\" : 10254,\n",
      "    \"walCommit\" : 1350\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4907\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4909\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.2035416242621616,\n",
      "    \"processedRowsPerSecond\" : 0.1950458357714063\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:06:50 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 10256 milliseconds\n",
      "23/06/24 15:06:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:06:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4911.\n",
      "23/06/24 15:06:50 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/242 using temp file gs://kafka-spark-data/spark-metadata/offsets/.242.3381826e-59b0-446e-a51e-799fb543175c.tmp\n",
      "23/06/24 15:06:51 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.242.3381826e-59b0-446e-a51e-799fb543175c.tmp to gs://kafka-spark-data/spark-metadata/offsets/242\n",
      "23/06/24 15:06:51 INFO MicroBatchExecution: Committed offsets for batch 242. Metadata OffsetSeqMetadata(0,1687637210265,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:06:52 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:06:52 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:06:52 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:06:52 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:06:52 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:06:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:06:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:06:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:06:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:06:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:06:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:06:52 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:06:52 INFO DAGScheduler: Got job 38 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:06:52 INFO DAGScheduler: Final stage: ResultStage 38 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:06:52 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:06:52 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:06:52 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[272] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:06:52 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:06:52 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:06:52 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:06:52 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:06:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[272] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:06:52 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:06:52 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 38) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:06:52 INFO Executor: Running task 0.0 in stage 38.0 (TID 38)\n",
      "23/06/24 15:06:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:06:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:06:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:06:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:06:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:06:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:06:52 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:06:52 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:06:52 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:06:52 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:06:52 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:06:52 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:06:52 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:06:52 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4910 for partition ticketmaster-0\n",
      "23/06/24 15:06:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 38:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:06:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:06:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:06:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4912.\n",
      "23/06/24 15:06:54 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-b1b60a46-0333-441c-be71-a24c52258b47/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:06:54 INFO FileOutputCommitter: Saved output of task 'attempt_202306241506523721226564326273993_0038_m_000000_38' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-b1b60a46-0333-441c-be71-a24c52258b47/_temporary/0/task_202306241506523721226564326273993_0038_m_000000\n",
      "23/06/24 15:06:54 INFO SparkHadoopMapRedUtil: attempt_202306241506523721226564326273993_0038_m_000000_38: Committed. Elapsed time: 633 ms.\n",
      "23/06/24 15:06:54 INFO Executor: Finished task 0.0 in stage 38.0 (TID 38). 2579 bytes result sent to driver\n",
      "23/06/24 15:06:54 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 38) in 1602 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:06:54 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:06:54 INFO DAGScheduler: ResultStage 38 (start at NativeMethodAccessorImpl.java:0) finished in 1.621 s\n",
      "23/06/24 15:06:54 INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:06:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 38: Stage finished\n",
      "23/06/24 15:06:54 INFO DAGScheduler: Job 38 finished: start at NativeMethodAccessorImpl.java:0, took 1.622230 s\n",
      "23/06/24 15:06:54 INFO FileFormatWriter: Start to commit write Job fa7aee97-866f-46e2-8728-16be02ef4491.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:06:54 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-b1b60a46-0333-441c-be71-a24c52258b47/_temporary/0/task_202306241506523721226564326273993_0038_m_000000/' directory.\n",
      "23/06/24 15:06:55 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-b1b60a46-0333-441c-be71-a24c52258b47/' directory.\n",
      "23/06/24 15:06:55 INFO FileFormatWriter: Write Job fa7aee97-866f-46e2-8728-16be02ef4491 committed. Elapsed time: 1435 ms.\n",
      "23/06/24 15:06:55 INFO FileFormatWriter: Finished processing stats for write job fa7aee97-866f-46e2-8728-16be02ef4491.\n",
      "23/06/24 15:06:56 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-b1b60a46-0333-441c-be71-a24c52258b47/part-00000-7b40cfa2-ca6e-48b6-bfea-4cc06b8f9450-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=18f90143-da42-4ad0-afac-010a5a914646, location=US}\n",
      "23/06/24 15:06:58 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=18f90143-da42-4ad0-afac-010a5a914646, location=US}\n",
      "23/06/24 15:06:58 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/242 using temp file gs://kafka-spark-data/spark-metadata/commits/.242.6fe03066-8ee3-41b7-b72d-bc6499a2ff88.tmp\n",
      "23/06/24 15:06:59 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.242.6fe03066-8ee3-41b7-b72d-bc6499a2ff88.tmp to gs://kafka-spark-data/spark-metadata/commits/242\n",
      "23/06/24 15:06:59 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:06:50.257Z\",\n",
      "  \"batchId\" : 242,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.19500780031201248,\n",
      "  \"processedRowsPerSecond\" : 0.21652051531882646,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6377,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 8,\n",
      "    \"queryPlanning\" : 13,\n",
      "    \"triggerExecution\" : 9237,\n",
      "    \"walCommit\" : 1895\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4909\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4911\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.19500780031201248,\n",
      "    \"processedRowsPerSecond\" : 0.21652051531882646\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:07:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:07:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4913.\n",
      "23/06/24 15:07:00 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/243 using temp file gs://kafka-spark-data/spark-metadata/offsets/.243.995aeb77-f947-4de2-9afe-5101af764fe7.tmp\n",
      "23/06/24 15:07:00 INFO BlockManagerInfo: Removed broadcast_38_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:07:01 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.243.995aeb77-f947-4de2-9afe-5101af764fe7.tmp to gs://kafka-spark-data/spark-metadata/offsets/243\n",
      "23/06/24 15:07:01 INFO MicroBatchExecution: Committed offsets for batch 243. Metadata OffsetSeqMetadata(0,1687637220019,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:07:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:07:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:07:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:07:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:07:02 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:07:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:07:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:07:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:07:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:07:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:07:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:07:02 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:07:02 INFO DAGScheduler: Got job 39 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:07:02 INFO DAGScheduler: Final stage: ResultStage 39 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:07:02 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:07:02 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:07:02 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[279] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:07:02 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:07:02 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:07:02 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:07:02 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:07:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[279] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:07:02 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:07:02 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 39) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:07:02 INFO Executor: Running task 0.0 in stage 39.0 (TID 39)\n",
      "23/06/24 15:07:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:07:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:07:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:07:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:07:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:07:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:07:02 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:07:02 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:07:02 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:07:02 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:07:02 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:07:02 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:07:02 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:07:02 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4912 for partition ticketmaster-0\n",
      "23/06/24 15:07:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 39:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:07:03 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:07:03 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:07:03 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4914.\n",
      "23/06/24 15:07:03 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-1ae98564-c2ad-4d51-8228-ec3b0f614d51/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:07:03 INFO FileOutputCommitter: Saved output of task 'attempt_202306241507021981469777754144133_0039_m_000000_39' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-1ae98564-c2ad-4d51-8228-ec3b0f614d51/_temporary/0/task_202306241507021981469777754144133_0039_m_000000\n",
      "23/06/24 15:07:03 INFO SparkHadoopMapRedUtil: attempt_202306241507021981469777754144133_0039_m_000000_39: Committed. Elapsed time: 532 ms.\n",
      "23/06/24 15:07:03 INFO Executor: Finished task 0.0 in stage 39.0 (TID 39). 2536 bytes result sent to driver\n",
      "23/06/24 15:07:03 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 39) in 1567 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:07:03 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:07:03 INFO DAGScheduler: ResultStage 39 (start at NativeMethodAccessorImpl.java:0) finished in 1.606 s\n",
      "23/06/24 15:07:03 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:07:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 39: Stage finished\n",
      "23/06/24 15:07:03 INFO DAGScheduler: Job 39 finished: start at NativeMethodAccessorImpl.java:0, took 1.608209 s\n",
      "23/06/24 15:07:03 INFO FileFormatWriter: Start to commit write Job 329a124f-df62-455e-bb2b-64201c424e95.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:07:04 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-1ae98564-c2ad-4d51-8228-ec3b0f614d51/_temporary/0/task_202306241507021981469777754144133_0039_m_000000/' directory.\n",
      "23/06/24 15:07:05 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-1ae98564-c2ad-4d51-8228-ec3b0f614d51/' directory.\n",
      "23/06/24 15:07:05 INFO FileFormatWriter: Write Job 329a124f-df62-455e-bb2b-64201c424e95 committed. Elapsed time: 1461 ms.\n",
      "23/06/24 15:07:05 INFO FileFormatWriter: Finished processing stats for write job 329a124f-df62-455e-bb2b-64201c424e95.\n",
      "23/06/24 15:07:05 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-1ae98564-c2ad-4d51-8228-ec3b0f614d51/part-00000-deeccd39-2de3-49ca-a2fc-7cc52d06e176-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=ad534668-ec3e-47a9-8a65-afe241349289, location=US}\n",
      "23/06/24 15:07:08 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=ad534668-ec3e-47a9-8a65-afe241349289, location=US}\n",
      "23/06/24 15:07:08 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/243 using temp file gs://kafka-spark-data/spark-metadata/commits/.243.3b94364d-c782-497e-a614-679d817c7f32.tmp\n",
      "23/06/24 15:07:09 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.243.3b94364d-c782-497e-a614-679d817c7f32.tmp to gs://kafka-spark-data/spark-metadata/commits/243\n",
      "23/06/24 15:07:09 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:07:00.011Z\",\n",
      "  \"batchId\" : 243,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.2050440844781628,\n",
      "  \"processedRowsPerSecond\" : 0.20911752404851527,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6900,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 6,\n",
      "    \"queryPlanning\" : 10,\n",
      "    \"triggerExecution\" : 9564,\n",
      "    \"walCommit\" : 1773\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4911\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4913\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.2050440844781628,\n",
      "    \"processedRowsPerSecond\" : 0.20911752404851527\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:07:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:07:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4915.\n",
      "23/06/24 15:07:10 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/244 using temp file gs://kafka-spark-data/spark-metadata/offsets/.244.1dab8f04-fa02-4821-b2c3-74588cd4bfc6.tmp\n",
      "23/06/24 15:07:11 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.244.1dab8f04-fa02-4821-b2c3-74588cd4bfc6.tmp to gs://kafka-spark-data/spark-metadata/offsets/244\n",
      "23/06/24 15:07:11 INFO MicroBatchExecution: Committed offsets for batch 244. Metadata OffsetSeqMetadata(0,1687637230009,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:07:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:07:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:07:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:07:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:07:11 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:07:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:07:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:07:11 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:07:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:07:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:07:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:07:11 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:07:11 INFO DAGScheduler: Got job 40 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:07:11 INFO DAGScheduler: Final stage: ResultStage 40 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:07:11 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:07:11 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:07:11 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[286] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:07:11 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 295.4 KiB, free 433.7 MiB)\n",
      "23/06/24 15:07:11 INFO BlockManagerInfo: Removed broadcast_39_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:07:11 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:07:11 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:07:11 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:07:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[286] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:07:11 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:07:11 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 40) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:07:11 INFO Executor: Running task 0.0 in stage 40.0 (TID 40)\n",
      "23/06/24 15:07:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:07:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:07:11 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:07:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:07:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:07:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:07:11 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:07:11 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:07:11 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:07:11 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:07:11 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:07:11 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:07:11 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:07:12 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4914 for partition ticketmaster-0\n",
      "23/06/24 15:07:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 40:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:07:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:07:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:07:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4916.\n",
      "23/06/24 15:07:13 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-072e5535-190e-4c9b-9ba3-19e6bb7e50fc/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:07:13 INFO FileOutputCommitter: Saved output of task 'attempt_202306241507116007725661363563743_0040_m_000000_40' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-072e5535-190e-4c9b-9ba3-19e6bb7e50fc/_temporary/0/task_202306241507116007725661363563743_0040_m_000000\n",
      "23/06/24 15:07:13 INFO SparkHadoopMapRedUtil: attempt_202306241507116007725661363563743_0040_m_000000_40: Committed. Elapsed time: 654 ms.\n",
      "23/06/24 15:07:13 INFO Executor: Finished task 0.0 in stage 40.0 (TID 40). 2579 bytes result sent to driver\n",
      "23/06/24 15:07:13 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 40) in 1644 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:07:13 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:07:13 INFO DAGScheduler: ResultStage 40 (start at NativeMethodAccessorImpl.java:0) finished in 1.680 s\n",
      "23/06/24 15:07:13 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:07:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 40: Stage finished\n",
      "23/06/24 15:07:13 INFO DAGScheduler: Job 40 finished: start at NativeMethodAccessorImpl.java:0, took 1.681475 s\n",
      "23/06/24 15:07:13 INFO FileFormatWriter: Start to commit write Job a4fbed1e-00d8-446e-8435-880809e8ba03.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:07:14 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-072e5535-190e-4c9b-9ba3-19e6bb7e50fc/_temporary/0/task_202306241507116007725661363563743_0040_m_000000/' directory.\n",
      "23/06/24 15:07:14 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-072e5535-190e-4c9b-9ba3-19e6bb7e50fc/' directory.\n",
      "23/06/24 15:07:15 INFO FileFormatWriter: Write Job a4fbed1e-00d8-446e-8435-880809e8ba03 committed. Elapsed time: 1508 ms.\n",
      "23/06/24 15:07:15 INFO FileFormatWriter: Finished processing stats for write job a4fbed1e-00d8-446e-8435-880809e8ba03.\n",
      "23/06/24 15:07:15 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-072e5535-190e-4c9b-9ba3-19e6bb7e50fc/part-00000-b0878839-3543-4b2c-8d71-77fa3f737e39-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=f59e1128-e770-45a0-9aec-ae8f4e6afdc5, location=US}\n",
      "23/06/24 15:07:17 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=f59e1128-e770-45a0-9aec-ae8f4e6afdc5, location=US}\n",
      "23/06/24 15:07:18 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/244 using temp file gs://kafka-spark-data/spark-metadata/commits/.244.83058dfc-66bf-447a-af36-bf3d490d41ef.tmp\n",
      "23/06/24 15:07:18 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.244.83058dfc-66bf-447a-af36-bf3d490d41ef.tmp to gs://kafka-spark-data/spark-metadata/commits/244\n",
      "23/06/24 15:07:18 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:07:10.005Z\",\n",
      "  \"batchId\" : 244,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.20012007204322593,\n",
      "  \"processedRowsPerSecond\" : 0.22326412145568206,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6492,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 4,\n",
      "    \"queryPlanning\" : 8,\n",
      "    \"triggerExecution\" : 8958,\n",
      "    \"walCommit\" : 1414\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4913\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4915\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.20012007204322593,\n",
      "    \"processedRowsPerSecond\" : 0.22326412145568206\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:07:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:07:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4917.\n",
      "23/06/24 15:07:20 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/245 using temp file gs://kafka-spark-data/spark-metadata/offsets/.245.d7f5ff59-e92d-4394-ad24-a841c05c08c2.tmp\n",
      "23/06/24 15:07:21 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.245.d7f5ff59-e92d-4394-ad24-a841c05c08c2.tmp to gs://kafka-spark-data/spark-metadata/offsets/245\n",
      "23/06/24 15:07:21 INFO MicroBatchExecution: Committed offsets for batch 245. Metadata OffsetSeqMetadata(0,1687637240004,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:07:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:07:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:07:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:07:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:07:21 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:07:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:07:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:07:21 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:07:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:07:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:07:21 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:07:21 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:07:21 INFO DAGScheduler: Got job 41 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:07:21 INFO DAGScheduler: Final stage: ResultStage 41 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:07:21 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:07:21 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:07:21 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[293] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:07:21 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 295.4 KiB, free 433.7 MiB)\n",
      "23/06/24 15:07:21 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 433.6 MiB)\n",
      "23/06/24 15:07:21 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.2 MiB)\n",
      "23/06/24 15:07:21 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:07:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[293] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:07:21 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:07:21 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 41) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:07:21 INFO Executor: Running task 0.0 in stage 41.0 (TID 41)\n",
      "23/06/24 15:07:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:07:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:07:21 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:07:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:07:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:07:21 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:07:21 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:07:21 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:07:21 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:07:21 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:07:21 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:07:21 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:07:21 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:07:22 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4916 for partition ticketmaster-0\n",
      "23/06/24 15:07:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 41:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:07:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:07:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:07:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4918.\n",
      "23/06/24 15:07:23 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8d51ee53-1543-47a3-b1bf-80719e3acbd6/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:07:23 INFO FileOutputCommitter: Saved output of task 'attempt_202306241507215256224900418079069_0041_m_000000_41' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8d51ee53-1543-47a3-b1bf-80719e3acbd6/_temporary/0/task_202306241507215256224900418079069_0041_m_000000\n",
      "23/06/24 15:07:23 INFO SparkHadoopMapRedUtil: attempt_202306241507215256224900418079069_0041_m_000000_41: Committed. Elapsed time: 545 ms.\n",
      "23/06/24 15:07:23 INFO Executor: Finished task 0.0 in stage 41.0 (TID 41). 2536 bytes result sent to driver\n",
      "23/06/24 15:07:23 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 41) in 1445 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:07:23 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:07:23 INFO DAGScheduler: ResultStage 41 (start at NativeMethodAccessorImpl.java:0) finished in 1.487 s\n",
      "23/06/24 15:07:23 INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:07:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 41: Stage finished\n",
      "23/06/24 15:07:23 INFO DAGScheduler: Job 41 finished: start at NativeMethodAccessorImpl.java:0, took 1.489198 s\n",
      "23/06/24 15:07:23 INFO FileFormatWriter: Start to commit write Job e8aff342-2944-427a-a076-926cd7252270.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:07:24 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8d51ee53-1543-47a3-b1bf-80719e3acbd6/_temporary/0/task_202306241507215256224900418079069_0041_m_000000/' directory.\n",
      "23/06/24 15:07:24 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8d51ee53-1543-47a3-b1bf-80719e3acbd6/' directory.\n",
      "23/06/24 15:07:25 INFO FileFormatWriter: Write Job e8aff342-2944-427a-a076-926cd7252270 committed. Elapsed time: 1671 ms.\n",
      "23/06/24 15:07:25 INFO FileFormatWriter: Finished processing stats for write job e8aff342-2944-427a-a076-926cd7252270.\n",
      "23/06/24 15:07:25 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8d51ee53-1543-47a3-b1bf-80719e3acbd6/part-00000-0d5d1dc3-741b-41cf-923e-f9b6b130f0e7-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=35eb2894-d3be-4f38-bb4a-f095a3fcf1e4, location=US}\n",
      "23/06/24 15:07:28 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=35eb2894-d3be-4f38-bb4a-f095a3fcf1e4, location=US}\n",
      "23/06/24 15:07:28 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/245 using temp file gs://kafka-spark-data/spark-metadata/commits/.245.d097961d-0ca3-4b18-b051-183f0c4dfca2.tmp\n",
      "23/06/24 15:07:29 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.245.d097961d-0ca3-4b18-b051-183f0c4dfca2.tmp to gs://kafka-spark-data/spark-metadata/commits/245\n",
      "23/06/24 15:07:29 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:07:20.000Z\",\n",
      "  \"batchId\" : 245,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.20010005002501252,\n",
      "  \"processedRowsPerSecond\" : 0.21296986476413587,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6859,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 4,\n",
      "    \"queryPlanning\" : 5,\n",
      "    \"triggerExecution\" : 9391,\n",
      "    \"walCommit\" : 1461\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4915\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4917\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.20010005002501252,\n",
      "    \"processedRowsPerSecond\" : 0.21296986476413587\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:07:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:07:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4919.\n",
      "23/06/24 15:07:30 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/246 using temp file gs://kafka-spark-data/spark-metadata/offsets/.246.a41a60e1-a1b5-4eaf-9cfa-271014139d02.tmp\n",
      "23/06/24 15:07:30 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.246.a41a60e1-a1b5-4eaf-9cfa-271014139d02.tmp to gs://kafka-spark-data/spark-metadata/offsets/246\n",
      "23/06/24 15:07:30 INFO MicroBatchExecution: Committed offsets for batch 246. Metadata OffsetSeqMetadata(0,1687637250008,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:07:31 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:07:31 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:07:31 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:07:31 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:07:31 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:07:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:07:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:07:31 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:07:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:07:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:07:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:07:31 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:07:31 INFO DAGScheduler: Got job 42 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:07:31 INFO DAGScheduler: Final stage: ResultStage 42 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:07:31 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:07:31 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:07:31 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[300] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:07:31 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 295.4 KiB, free 433.3 MiB)\n",
      "23/06/24 15:07:31 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 433.3 MiB)\n",
      "23/06/24 15:07:31 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.1 MiB)\n",
      "23/06/24 15:07:31 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:07:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[300] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:07:31 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:07:31 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 42) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:07:31 INFO Executor: Running task 0.0 in stage 42.0 (TID 42)\n",
      "23/06/24 15:07:31 INFO BlockManagerInfo: Removed broadcast_41_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.2 MiB)\n",
      "23/06/24 15:07:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:07:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:07:31 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:07:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:07:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:07:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:07:31 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:07:31 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:07:31 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:07:31 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:07:31 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:07:31 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:07:31 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:07:31 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4918 for partition ticketmaster-0\n",
      "23/06/24 15:07:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 42:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:07:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:07:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:07:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4920.\n",
      "23/06/24 15:07:33 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8e7ee93f-bc97-4315-81ed-ebbce4e8db8a/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:07:33 INFO FileOutputCommitter: Saved output of task 'attempt_202306241507312178270933632336864_0042_m_000000_42' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8e7ee93f-bc97-4315-81ed-ebbce4e8db8a/_temporary/0/task_202306241507312178270933632336864_0042_m_000000\n",
      "23/06/24 15:07:33 INFO SparkHadoopMapRedUtil: attempt_202306241507312178270933632336864_0042_m_000000_42: Committed. Elapsed time: 535 ms.\n",
      "23/06/24 15:07:33 INFO Executor: Finished task 0.0 in stage 42.0 (TID 42). 2579 bytes result sent to driver\n",
      "23/06/24 15:07:33 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 42) in 1469 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:07:33 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:07:33 INFO DAGScheduler: ResultStage 42 (start at NativeMethodAccessorImpl.java:0) finished in 1.507 s\n",
      "23/06/24 15:07:33 INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:07:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 42: Stage finished\n",
      "23/06/24 15:07:33 INFO DAGScheduler: Job 42 finished: start at NativeMethodAccessorImpl.java:0, took 1.510207 s\n",
      "23/06/24 15:07:33 INFO FileFormatWriter: Start to commit write Job 0307620d-87fa-4524-b7c1-fdf33bd7f500.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:07:33 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8e7ee93f-bc97-4315-81ed-ebbce4e8db8a/_temporary/0/task_202306241507312178270933632336864_0042_m_000000/' directory.\n",
      "23/06/24 15:07:34 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8e7ee93f-bc97-4315-81ed-ebbce4e8db8a/' directory.\n",
      "23/06/24 15:07:34 INFO FileFormatWriter: Write Job 0307620d-87fa-4524-b7c1-fdf33bd7f500 committed. Elapsed time: 1356 ms.\n",
      "23/06/24 15:07:34 INFO FileFormatWriter: Finished processing stats for write job 0307620d-87fa-4524-b7c1-fdf33bd7f500.\n",
      "23/06/24 15:07:35 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8e7ee93f-bc97-4315-81ed-ebbce4e8db8a/part-00000-b4675760-fda2-4b54-9911-8cad4791c7f7-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=b3065dfa-e2b4-46a3-834a-1df17ec6c36e, location=US}\n",
      "23/06/24 15:07:38 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=b3065dfa-e2b4-46a3-834a-1df17ec6c36e, location=US}\n",
      "23/06/24 15:07:39 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/246 using temp file gs://kafka-spark-data/spark-metadata/commits/.246.3100822a-6cdf-46c5-992b-6c27233697f6.tmp\n",
      "23/06/24 15:07:40 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.246.3100822a-6cdf-46c5-992b-6c27233697f6.tmp to gs://kafka-spark-data/spark-metadata/commits/246\n",
      "23/06/24 15:07:40 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:07:30.004Z\",\n",
      "  \"batchId\" : 246,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.19992003198720512,\n",
      "  \"processedRowsPerSecond\" : 0.19652156824211459,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7891,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 4,\n",
      "    \"queryPlanning\" : 17,\n",
      "    \"triggerExecution\" : 10177,\n",
      "    \"walCommit\" : 1272\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4917\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4919\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.19992003198720512,\n",
      "    \"processedRowsPerSecond\" : 0.19652156824211459\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:07:40 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 10179 milliseconds\n",
      "23/06/24 15:07:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:07:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4921.\n",
      "23/06/24 15:07:40 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/247 using temp file gs://kafka-spark-data/spark-metadata/offsets/.247.647d5ef3-6f07-4bf8-880c-30fa4b97c80b.tmp\n",
      "23/06/24 15:07:41 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.247.647d5ef3-6f07-4bf8-880c-30fa4b97c80b.tmp to gs://kafka-spark-data/spark-metadata/offsets/247\n",
      "23/06/24 15:07:41 INFO MicroBatchExecution: Committed offsets for batch 247. Metadata OffsetSeqMetadata(0,1687637260197,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:07:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:07:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:07:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:07:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:07:41 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:07:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:07:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:07:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:07:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:07:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:07:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:07:42 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:07:42 INFO DAGScheduler: Got job 43 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:07:42 INFO DAGScheduler: Final stage: ResultStage 43 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:07:42 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:07:42 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:07:42 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[307] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:07:42 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 295.4 KiB, free 433.3 MiB)\n",
      "23/06/24 15:07:42 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 433.3 MiB)\n",
      "23/06/24 15:07:42 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.1 MiB)\n",
      "23/06/24 15:07:42 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:07:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[307] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:07:42 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:07:42 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 43) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:07:42 INFO Executor: Running task 0.0 in stage 43.0 (TID 43)\n",
      "23/06/24 15:07:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:07:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:07:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:07:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:07:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:07:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:07:42 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:07:42 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:07:42 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:07:42 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:07:42 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:07:42 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:07:42 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:07:42 INFO BlockManagerInfo: Removed broadcast_40_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.2 MiB)\n",
      "23/06/24 15:07:42 INFO BlockManagerInfo: Removed broadcast_42_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:07:42 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4920 for partition ticketmaster-0\n",
      "23/06/24 15:07:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 43:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:07:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:07:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:07:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4922.\n",
      "23/06/24 15:07:43 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-a541ee49-5461-4630-a79c-33cfafa1f82d/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:07:43 INFO FileOutputCommitter: Saved output of task 'attempt_20230624150742340424776009238661_0043_m_000000_43' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-a541ee49-5461-4630-a79c-33cfafa1f82d/_temporary/0/task_20230624150742340424776009238661_0043_m_000000\n",
      "23/06/24 15:07:43 INFO SparkHadoopMapRedUtil: attempt_20230624150742340424776009238661_0043_m_000000_43: Committed. Elapsed time: 538 ms.\n",
      "23/06/24 15:07:43 INFO Executor: Finished task 0.0 in stage 43.0 (TID 43). 2536 bytes result sent to driver\n",
      "23/06/24 15:07:43 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 43) in 1485 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:07:43 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:07:43 INFO DAGScheduler: ResultStage 43 (start at NativeMethodAccessorImpl.java:0) finished in 1.507 s\n",
      "23/06/24 15:07:43 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:07:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 43: Stage finished\n",
      "23/06/24 15:07:43 INFO DAGScheduler: Job 43 finished: start at NativeMethodAccessorImpl.java:0, took 1.508212 s\n",
      "23/06/24 15:07:43 INFO FileFormatWriter: Start to commit write Job 46ac4f03-a94e-4c9f-b82c-253f1bf2d038.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:07:44 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-a541ee49-5461-4630-a79c-33cfafa1f82d/_temporary/0/task_20230624150742340424776009238661_0043_m_000000/' directory.\n",
      "23/06/24 15:07:44 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-a541ee49-5461-4630-a79c-33cfafa1f82d/' directory.\n",
      "23/06/24 15:07:45 INFO FileFormatWriter: Write Job 46ac4f03-a94e-4c9f-b82c-253f1bf2d038 committed. Elapsed time: 1455 ms.\n",
      "23/06/24 15:07:45 INFO FileFormatWriter: Finished processing stats for write job 46ac4f03-a94e-4c9f-b82c-253f1bf2d038.\n",
      "23/06/24 15:07:45 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-a541ee49-5461-4630-a79c-33cfafa1f82d/part-00000-944677eb-754e-45eb-b35e-7466f5d90799-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=e975a07f-6f4a-4081-9c1e-8c47fa218d00, location=US}\n",
      "23/06/24 15:07:47 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=e975a07f-6f4a-4081-9c1e-8c47fa218d00, location=US}\n",
      "23/06/24 15:07:47 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/247 using temp file gs://kafka-spark-data/spark-metadata/commits/.247.9c37a7a6-084c-4f64-bbf4-b4374cf995bd.tmp\n",
      "23/06/24 15:07:48 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.247.9c37a7a6-084c-4f64-bbf4-b4374cf995bd.tmp to gs://kafka-spark-data/spark-metadata/commits/247\n",
      "23/06/24 15:07:48 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:07:40.184Z\",\n",
      "  \"batchId\" : 247,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.19646365422396858,\n",
      "  \"processedRowsPerSecond\" : 0.24210144050357102,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 5772,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 13,\n",
      "    \"queryPlanning\" : 15,\n",
      "    \"triggerExecution\" : 8261,\n",
      "    \"walCommit\" : 1426\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4919\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4921\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.19646365422396858,\n",
      "    \"processedRowsPerSecond\" : 0.24210144050357102\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:07:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:07:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4923.\n",
      "23/06/24 15:07:50 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/248 using temp file gs://kafka-spark-data/spark-metadata/offsets/.248.60703621-82ea-4539-883f-212e1273ac8f.tmp\n",
      "23/06/24 15:07:51 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.248.60703621-82ea-4539-883f-212e1273ac8f.tmp to gs://kafka-spark-data/spark-metadata/offsets/248\n",
      "23/06/24 15:07:51 INFO MicroBatchExecution: Committed offsets for batch 248. Metadata OffsetSeqMetadata(0,1687637270010,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:07:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:07:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:07:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:07:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:07:51 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:07:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:07:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:07:51 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:07:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:07:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:07:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:07:52 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:07:52 INFO DAGScheduler: Got job 44 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:07:52 INFO DAGScheduler: Final stage: ResultStage 44 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:07:52 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:07:52 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:07:52 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[314] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:07:52 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 295.4 KiB, free 433.7 MiB)\n",
      "23/06/24 15:07:52 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 433.6 MiB)\n",
      "23/06/24 15:07:52 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.2 MiB)\n",
      "23/06/24 15:07:52 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:07:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[314] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:07:52 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:07:52 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 44) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:07:52 INFO Executor: Running task 0.0 in stage 44.0 (TID 44)\n",
      "23/06/24 15:07:52 INFO BlockManagerInfo: Removed broadcast_43_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:07:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:07:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:07:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:07:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:07:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:07:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:07:52 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:07:52 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:07:52 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:07:52 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:07:52 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:07:52 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:07:52 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:07:52 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4922 for partition ticketmaster-0\n",
      "23/06/24 15:07:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 44:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:07:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:07:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:07:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4924.\n",
      "23/06/24 15:07:53 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-943254d2-3284-4e41-ac93-b5110ea849c4/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:07:53 INFO FileOutputCommitter: Saved output of task 'attempt_202306241507524725334058925308798_0044_m_000000_44' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-943254d2-3284-4e41-ac93-b5110ea849c4/_temporary/0/task_202306241507524725334058925308798_0044_m_000000\n",
      "23/06/24 15:07:53 INFO SparkHadoopMapRedUtil: attempt_202306241507524725334058925308798_0044_m_000000_44: Committed. Elapsed time: 548 ms.\n",
      "23/06/24 15:07:53 INFO Executor: Finished task 0.0 in stage 44.0 (TID 44). 2579 bytes result sent to driver\n",
      "23/06/24 15:07:53 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 44) in 1479 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:07:53 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:07:53 INFO DAGScheduler: ResultStage 44 (start at NativeMethodAccessorImpl.java:0) finished in 1.502 s\n",
      "23/06/24 15:07:53 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:07:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished\n",
      "23/06/24 15:07:53 INFO DAGScheduler: Job 44 finished: start at NativeMethodAccessorImpl.java:0, took 1.508063 s\n",
      "23/06/24 15:07:53 INFO FileFormatWriter: Start to commit write Job 2f2a51c3-57cd-4f0c-ab93-3c85b9e870f7.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:07:54 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-943254d2-3284-4e41-ac93-b5110ea849c4/_temporary/0/task_202306241507524725334058925308798_0044_m_000000/' directory.\n",
      "23/06/24 15:07:54 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-943254d2-3284-4e41-ac93-b5110ea849c4/' directory.\n",
      "23/06/24 15:07:55 INFO FileFormatWriter: Write Job 2f2a51c3-57cd-4f0c-ab93-3c85b9e870f7 committed. Elapsed time: 1536 ms.\n",
      "23/06/24 15:07:55 INFO FileFormatWriter: Finished processing stats for write job 2f2a51c3-57cd-4f0c-ab93-3c85b9e870f7.\n",
      "23/06/24 15:07:55 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-943254d2-3284-4e41-ac93-b5110ea849c4/part-00000-4a440a26-82e5-4ac7-9ee6-0b2894074dd1-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=95ab5c96-1d6e-44d0-a28c-b1dc9634cb9b, location=US}\n",
      "23/06/24 15:07:58 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=95ab5c96-1d6e-44d0-a28c-b1dc9634cb9b, location=US}\n",
      "23/06/24 15:07:59 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/248 using temp file gs://kafka-spark-data/spark-metadata/commits/.248.06778ebc-76b7-438a-ad05-3401dc111c7c.tmp\n",
      "23/06/24 15:08:00 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.248.06778ebc-76b7-438a-ad05-3401dc111c7c.tmp to gs://kafka-spark-data/spark-metadata/commits/248\n",
      "23/06/24 15:08:00 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:07:50.005Z\",\n",
      "  \"batchId\" : 248,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.20364524997454436,\n",
      "  \"processedRowsPerSecond\" : 0.19334880123743234,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7749,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 5,\n",
      "    \"queryPlanning\" : 9,\n",
      "    \"triggerExecution\" : 10344,\n",
      "    \"walCommit\" : 1455\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4921\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4923\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.20364524997454436,\n",
      "    \"processedRowsPerSecond\" : 0.19334880123743234\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:08:00 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 10350 milliseconds\n",
      "23/06/24 15:08:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:08:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4925.\n",
      "23/06/24 15:08:00 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/249 using temp file gs://kafka-spark-data/spark-metadata/offsets/.249.cb0bdb2c-a483-468c-bb99-98e184d32b95.tmp\n",
      "23/06/24 15:08:00 INFO BlockManagerInfo: Removed broadcast_44_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:08:01 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.249.cb0bdb2c-a483-468c-bb99-98e184d32b95.tmp to gs://kafka-spark-data/spark-metadata/offsets/249\n",
      "23/06/24 15:08:01 INFO MicroBatchExecution: Committed offsets for batch 249. Metadata OffsetSeqMetadata(0,1687637280361,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:08:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:08:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:08:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:08:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:08:02 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:08:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:08:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:08:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:08:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:08:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:08:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:08:02 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:08:02 INFO DAGScheduler: Got job 45 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:08:02 INFO DAGScheduler: Final stage: ResultStage 45 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:08:02 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:08:02 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:08:02 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[321] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:08:02 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:08:02 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:08:02 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:08:02 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:08:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[321] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:08:02 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:08:02 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 45) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:08:02 INFO Executor: Running task 0.0 in stage 45.0 (TID 45)\n",
      "23/06/24 15:08:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:08:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:08:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:08:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:08:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:08:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:08:02 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:08:02 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:08:02 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:08:02 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:08:02 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:08:02 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:08:02 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:08:02 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4924 for partition ticketmaster-0\n",
      "23/06/24 15:08:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 45:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:08:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:08:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:08:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4926.\n",
      "23/06/24 15:08:04 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-1a3f71f0-9ebc-4708-9122-f3e7c8389aa5/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:08:04 INFO FileOutputCommitter: Saved output of task 'attempt_202306241508022951821211189903412_0045_m_000000_45' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-1a3f71f0-9ebc-4708-9122-f3e7c8389aa5/_temporary/0/task_202306241508022951821211189903412_0045_m_000000\n",
      "23/06/24 15:08:04 INFO SparkHadoopMapRedUtil: attempt_202306241508022951821211189903412_0045_m_000000_45: Committed. Elapsed time: 723 ms.\n",
      "23/06/24 15:08:04 INFO Executor: Finished task 0.0 in stage 45.0 (TID 45). 2536 bytes result sent to driver\n",
      "23/06/24 15:08:04 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 45) in 1691 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:08:04 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:08:04 INFO DAGScheduler: ResultStage 45 (start at NativeMethodAccessorImpl.java:0) finished in 1.746 s\n",
      "23/06/24 15:08:04 INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:08:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished\n",
      "23/06/24 15:08:04 INFO DAGScheduler: Job 45 finished: start at NativeMethodAccessorImpl.java:0, took 1.747944 s\n",
      "23/06/24 15:08:04 INFO FileFormatWriter: Start to commit write Job 1a9fb05d-46f6-45a7-bb65-e88a13384406.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:08:04 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-1a3f71f0-9ebc-4708-9122-f3e7c8389aa5/_temporary/0/task_202306241508022951821211189903412_0045_m_000000/' directory.\n",
      "23/06/24 15:08:05 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-1a3f71f0-9ebc-4708-9122-f3e7c8389aa5/' directory.\n",
      "23/06/24 15:08:05 INFO FileFormatWriter: Write Job 1a9fb05d-46f6-45a7-bb65-e88a13384406 committed. Elapsed time: 1487 ms.\n",
      "23/06/24 15:08:05 INFO FileFormatWriter: Finished processing stats for write job 1a9fb05d-46f6-45a7-bb65-e88a13384406.\n",
      "23/06/24 15:08:05 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-1a3f71f0-9ebc-4708-9122-f3e7c8389aa5/part-00000-49b2cf8a-b534-42b3-958a-fb99f14b4418-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=42bf5802-7adb-43a3-b1cb-d3f2a952aa4d, location=US}\n",
      "23/06/24 15:08:09 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=42bf5802-7adb-43a3-b1cb-d3f2a952aa4d, location=US}\n",
      "23/06/24 15:08:09 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/249 using temp file gs://kafka-spark-data/spark-metadata/commits/.249.f9beba0f-c7e7-4e32-847b-f83c628e3235.tmp\n",
      "23/06/24 15:08:09 INFO BlockManagerInfo: Removed broadcast_45_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:08:10 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.249.f9beba0f-c7e7-4e32-847b-f83c628e3235.tmp to gs://kafka-spark-data/spark-metadata/commits/249\n",
      "23/06/24 15:08:10 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:08:00.354Z\",\n",
      "  \"batchId\" : 249,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.19325538699391245,\n",
      "  \"processedRowsPerSecond\" : 0.19219680953296175,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7573,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 7,\n",
      "    \"queryPlanning\" : 8,\n",
      "    \"triggerExecution\" : 10406,\n",
      "    \"walCommit\" : 1443\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4923\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4925\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.19325538699391245,\n",
      "    \"processedRowsPerSecond\" : 0.19219680953296175\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:08:10 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 10410 milliseconds\n",
      "23/06/24 15:08:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:08:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4927.\n",
      "23/06/24 15:08:10 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/250 using temp file gs://kafka-spark-data/spark-metadata/offsets/.250.160034e8-08f7-44a4-8d43-d90647a45311.tmp\n",
      "23/06/24 15:08:11 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.250.160034e8-08f7-44a4-8d43-d90647a45311.tmp to gs://kafka-spark-data/spark-metadata/offsets/250\n",
      "23/06/24 15:08:11 INFO MicroBatchExecution: Committed offsets for batch 250. Metadata OffsetSeqMetadata(0,1687637290784,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:08:12 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:08:12 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:08:12 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:08:12 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:08:12 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:08:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:08:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:08:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:08:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:08:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:08:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:08:12 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:08:12 INFO DAGScheduler: Got job 46 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:08:12 INFO DAGScheduler: Final stage: ResultStage 46 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:08:12 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:08:12 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:08:12 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[328] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:08:12 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:08:12 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:08:12 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:08:12 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:08:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[328] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:08:12 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:08:12 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 46) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:08:12 INFO Executor: Running task 0.0 in stage 46.0 (TID 46)\n",
      "23/06/24 15:08:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:08:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:08:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:08:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:08:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:08:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:08:12 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:08:12 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:08:12 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:08:12 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:08:12 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:08:12 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:08:12 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:08:12 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4926 for partition ticketmaster-0\n",
      "23/06/24 15:08:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:08:13 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:08:13 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:08:13 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4928.\n",
      "23/06/24 15:08:14 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-20724787-f17c-48e8-bee0-1dd706821ca7/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:08:14 INFO FileOutputCommitter: Saved output of task 'attempt_202306241508121237174335579413830_0046_m_000000_46' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-20724787-f17c-48e8-bee0-1dd706821ca7/_temporary/0/task_202306241508121237174335579413830_0046_m_000000\n",
      "23/06/24 15:08:14 INFO SparkHadoopMapRedUtil: attempt_202306241508121237174335579413830_0046_m_000000_46: Committed. Elapsed time: 553 ms.\n",
      "23/06/24 15:08:14 INFO Executor: Finished task 0.0 in stage 46.0 (TID 46). 2536 bytes result sent to driver\n",
      "23/06/24 15:08:14 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 46) in 1497 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:08:14 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:08:14 INFO DAGScheduler: ResultStage 46 (start at NativeMethodAccessorImpl.java:0) finished in 1.536 s\n",
      "23/06/24 15:08:14 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:08:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 46: Stage finished\n",
      "23/06/24 15:08:14 INFO DAGScheduler: Job 46 finished: start at NativeMethodAccessorImpl.java:0, took 1.537203 s\n",
      "23/06/24 15:08:14 INFO FileFormatWriter: Start to commit write Job 19deb82f-b3a3-453a-92f8-59963550bf34.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:08:15 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-20724787-f17c-48e8-bee0-1dd706821ca7/_temporary/0/task_202306241508121237174335579413830_0046_m_000000/' directory.\n",
      "23/06/24 15:08:15 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-20724787-f17c-48e8-bee0-1dd706821ca7/' directory.\n",
      "23/06/24 15:08:25 INFO BlockManagerInfo: Removed broadcast_46_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:08:26 INFO FileFormatWriter: Write Job 19deb82f-b3a3-453a-92f8-59963550bf34 committed. Elapsed time: 12057 ms.\n",
      "23/06/24 15:08:26 INFO FileFormatWriter: Finished processing stats for write job 19deb82f-b3a3-453a-92f8-59963550bf34.\n",
      "23/06/24 15:08:26 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-20724787-f17c-48e8-bee0-1dd706821ca7/part-00000-91541810-5b39-4f35-a615-cf7ab954ac9c-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=3b5e2af8-2fcb-4cdb-b759-8ccb05023825, location=US}\n",
      "23/06/24 15:08:29 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=3b5e2af8-2fcb-4cdb-b759-8ccb05023825, location=US}\n",
      "23/06/24 15:08:30 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/250 using temp file gs://kafka-spark-data/spark-metadata/commits/.250.2e096346-4e26-4c7d-acb2-12974eaffc5b.tmp\n",
      "23/06/24 15:08:30 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.250.2e096346-4e26-4c7d-acb2-12974eaffc5b.tmp to gs://kafka-spark-data/spark-metadata/commits/250\n",
      "23/06/24 15:08:30 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:08:10.765Z\",\n",
      "  \"batchId\" : 250,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.19210450485063876,\n",
      "  \"processedRowsPerSecond\" : 0.09892175289346128,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 17669,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 19,\n",
      "    \"queryPlanning\" : 14,\n",
      "    \"triggerExecution\" : 20218,\n",
      "    \"walCommit\" : 1378\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4925\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4927\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.19210450485063876,\n",
      "    \"processedRowsPerSecond\" : 0.09892175289346128\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:08:30 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 20219 milliseconds\n",
      "23/06/24 15:08:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:08:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4931.\n",
      "23/06/24 15:08:31 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/251 using temp file gs://kafka-spark-data/spark-metadata/offsets/.251.d7b3c2ac-35a8-482f-a655-f63cbcb76abf.tmp\n",
      "23/06/24 15:08:31 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.251.d7b3c2ac-35a8-482f-a655-f63cbcb76abf.tmp to gs://kafka-spark-data/spark-metadata/offsets/251\n",
      "23/06/24 15:08:31 INFO MicroBatchExecution: Committed offsets for batch 251. Metadata OffsetSeqMetadata(0,1687637310988,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:08:32 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:08:32 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:08:32 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:08:32 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:08:32 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:08:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:08:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:08:32 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:08:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:08:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:08:32 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:08:32 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:08:32 INFO DAGScheduler: Got job 47 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:08:32 INFO DAGScheduler: Final stage: ResultStage 47 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:08:32 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:08:32 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:08:32 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[335] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:08:32 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:08:32 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:08:32 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:08:32 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:08:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[335] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:08:32 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:08:32 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 47) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:08:32 INFO Executor: Running task 0.0 in stage 47.0 (TID 47)\n",
      "23/06/24 15:08:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:08:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:08:32 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:08:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:08:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:08:32 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:08:32 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:08:32 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:08:32 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:08:32 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:08:32 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:08:32 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:08:32 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:08:32 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4928 for partition ticketmaster-0\n",
      "23/06/24 15:08:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 47:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:08:33 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:08:33 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:08:33 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4932.\n",
      "23/06/24 15:08:34 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-7e3fea1c-c6ce-4f55-ae25-9358e7abc905/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:08:34 INFO FileOutputCommitter: Saved output of task 'attempt_202306241508322277990971372686872_0047_m_000000_47' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-7e3fea1c-c6ce-4f55-ae25-9358e7abc905/_temporary/0/task_202306241508322277990971372686872_0047_m_000000\n",
      "23/06/24 15:08:34 INFO SparkHadoopMapRedUtil: attempt_202306241508322277990971372686872_0047_m_000000_47: Committed. Elapsed time: 565 ms.\n",
      "23/06/24 15:08:34 INFO Executor: Finished task 0.0 in stage 47.0 (TID 47). 2536 bytes result sent to driver\n",
      "23/06/24 15:08:34 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 47) in 1483 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:08:34 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:08:34 INFO DAGScheduler: ResultStage 47 (start at NativeMethodAccessorImpl.java:0) finished in 1.510 s\n",
      "23/06/24 15:08:34 INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:08:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 47: Stage finished\n",
      "23/06/24 15:08:34 INFO DAGScheduler: Job 47 finished: start at NativeMethodAccessorImpl.java:0, took 1.512857 s\n",
      "23/06/24 15:08:34 INFO FileFormatWriter: Start to commit write Job 71e1eff3-195c-4afd-9b88-2be96db835d2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:08:34 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-7e3fea1c-c6ce-4f55-ae25-9358e7abc905/_temporary/0/task_202306241508322277990971372686872_0047_m_000000/' directory.\n",
      "23/06/24 15:08:35 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-7e3fea1c-c6ce-4f55-ae25-9358e7abc905/' directory.\n",
      "23/06/24 15:08:35 INFO BlockManagerInfo: Removed broadcast_47_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:08:35 INFO FileFormatWriter: Write Job 71e1eff3-195c-4afd-9b88-2be96db835d2 committed. Elapsed time: 1380 ms.\n",
      "23/06/24 15:08:35 INFO FileFormatWriter: Finished processing stats for write job 71e1eff3-195c-4afd-9b88-2be96db835d2.\n",
      "23/06/24 15:08:36 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-7e3fea1c-c6ce-4f55-ae25-9358e7abc905/part-00000-63198863-9caa-49ad-a3c8-8a5292a3ad59-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=b0cb91cb-2a73-4406-a283-660df9a1e86d, location=US}\n",
      "23/06/24 15:08:38 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=b0cb91cb-2a73-4406-a283-660df9a1e86d, location=US}\n",
      "23/06/24 15:08:39 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/251 using temp file gs://kafka-spark-data/spark-metadata/commits/.251.f2d9561e-cd1d-4306-b384-3b779113b091.tmp\n",
      "23/06/24 15:08:39 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.251.f2d9561e-cd1d-4306-b384-3b779113b091.tmp to gs://kafka-spark-data/spark-metadata/commits/251\n",
      "23/06/24 15:08:39 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:08:30.984Z\",\n",
      "  \"batchId\" : 251,\n",
      "  \"numInputRows\" : 4,\n",
      "  \"inputRowsPerSecond\" : 0.19783372075770314,\n",
      "  \"processedRowsPerSecond\" : 0.44667783361250696,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6589,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 4,\n",
      "    \"queryPlanning\" : 14,\n",
      "    \"triggerExecution\" : 8955,\n",
      "    \"walCommit\" : 1321\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4927\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4931\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 4,\n",
      "    \"inputRowsPerSecond\" : 0.19783372075770314,\n",
      "    \"processedRowsPerSecond\" : 0.44667783361250696\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:08:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:08:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4933.\n",
      "23/06/24 15:08:40 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/252 using temp file gs://kafka-spark-data/spark-metadata/offsets/.252.a9921824-5325-4f4b-a063-84c1ed92a6c8.tmp\n",
      "23/06/24 15:08:41 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.252.a9921824-5325-4f4b-a063-84c1ed92a6c8.tmp to gs://kafka-spark-data/spark-metadata/offsets/252\n",
      "23/06/24 15:08:41 INFO MicroBatchExecution: Committed offsets for batch 252. Metadata OffsetSeqMetadata(0,1687637320012,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:08:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:08:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:08:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:08:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:08:41 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:08:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:08:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:08:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:08:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:08:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:08:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:08:42 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:08:42 INFO DAGScheduler: Got job 48 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:08:42 INFO DAGScheduler: Final stage: ResultStage 48 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:08:42 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:08:42 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:08:42 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[342] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:08:42 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:08:42 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:08:42 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:08:42 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:08:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[342] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:08:42 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:08:42 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 48) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:08:42 INFO Executor: Running task 0.0 in stage 48.0 (TID 48)\n",
      "23/06/24 15:08:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:08:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:08:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:08:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:08:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:08:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:08:42 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:08:42 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:08:42 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:08:42 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:08:42 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:08:42 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:08:42 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:08:42 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4932 for partition ticketmaster-0\n",
      "23/06/24 15:08:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 48:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:08:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:08:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:08:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4934.\n",
      "23/06/24 15:08:43 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-dba9bfdc-0f16-44a4-9473-18e4fd3de8ab/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:08:43 INFO FileOutputCommitter: Saved output of task 'attempt_202306241508421536189370056696925_0048_m_000000_48' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-dba9bfdc-0f16-44a4-9473-18e4fd3de8ab/_temporary/0/task_202306241508421536189370056696925_0048_m_000000\n",
      "23/06/24 15:08:43 INFO SparkHadoopMapRedUtil: attempt_202306241508421536189370056696925_0048_m_000000_48: Committed. Elapsed time: 604 ms.\n",
      "23/06/24 15:08:43 INFO Executor: Finished task 0.0 in stage 48.0 (TID 48). 2536 bytes result sent to driver\n",
      "23/06/24 15:08:43 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 48) in 1534 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:08:43 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:08:43 INFO DAGScheduler: ResultStage 48 (start at NativeMethodAccessorImpl.java:0) finished in 1.574 s\n",
      "23/06/24 15:08:43 INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:08:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished\n",
      "23/06/24 15:08:43 INFO DAGScheduler: Job 48 finished: start at NativeMethodAccessorImpl.java:0, took 1.576313 s\n",
      "23/06/24 15:08:43 INFO FileFormatWriter: Start to commit write Job 8884fc97-c2e8-44da-8e69-3d4bf8edf8dc.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:08:44 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-dba9bfdc-0f16-44a4-9473-18e4fd3de8ab/_temporary/0/task_202306241508421536189370056696925_0048_m_000000/' directory.\n",
      "23/06/24 15:08:44 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-dba9bfdc-0f16-44a4-9473-18e4fd3de8ab/' directory.\n",
      "23/06/24 15:08:44 INFO BlockManagerInfo: Removed broadcast_48_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:08:45 INFO FileFormatWriter: Write Job 8884fc97-c2e8-44da-8e69-3d4bf8edf8dc committed. Elapsed time: 1387 ms.\n",
      "23/06/24 15:08:45 INFO FileFormatWriter: Finished processing stats for write job 8884fc97-c2e8-44da-8e69-3d4bf8edf8dc.\n",
      "23/06/24 15:08:45 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-dba9bfdc-0f16-44a4-9473-18e4fd3de8ab/part-00000-2fe7ac8b-db1b-4b30-ba26-bce17b3af687-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=0b86901a-65cc-4e02-8ef6-108e131c7def, location=US}\n",
      "23/06/24 15:08:47 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=0b86901a-65cc-4e02-8ef6-108e131c7def, location=US}\n",
      "23/06/24 15:08:47 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/252 using temp file gs://kafka-spark-data/spark-metadata/commits/.252.4ae49022-4bda-43f3-a3e0-f7eff53ccc40.tmp\n",
      "23/06/24 15:08:48 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.252.4ae49022-4bda-43f3-a3e0-f7eff53ccc40.tmp to gs://kafka-spark-data/spark-metadata/commits/252\n",
      "23/06/24 15:08:48 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:08:40.001Z\",\n",
      "  \"batchId\" : 252,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.22180326050792948,\n",
      "  \"processedRowsPerSecond\" : 0.23299161230195714,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6145,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 11,\n",
      "    \"queryPlanning\" : 19,\n",
      "    \"triggerExecution\" : 8584,\n",
      "    \"walCommit\" : 1420\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4931\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4933\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.22180326050792948,\n",
      "    \"processedRowsPerSecond\" : 0.23299161230195714\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:08:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:08:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4935.\n",
      "23/06/24 15:08:50 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/253 using temp file gs://kafka-spark-data/spark-metadata/offsets/.253.d60b2de1-2d33-4bbb-9135-4238eed8f750.tmp\n",
      "23/06/24 15:08:51 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.253.d60b2de1-2d33-4bbb-9135-4238eed8f750.tmp to gs://kafka-spark-data/spark-metadata/offsets/253\n",
      "23/06/24 15:08:51 INFO MicroBatchExecution: Committed offsets for batch 253. Metadata OffsetSeqMetadata(0,1687637330009,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:08:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:08:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:08:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:08:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:08:51 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:08:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:08:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:08:51 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:08:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:08:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:08:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:08:52 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:08:52 INFO DAGScheduler: Got job 49 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:08:52 INFO DAGScheduler: Final stage: ResultStage 49 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:08:52 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:08:52 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:08:52 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[349] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:08:52 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:08:52 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:08:52 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:08:52 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:08:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[349] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:08:52 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:08:52 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 49) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:08:52 INFO Executor: Running task 0.0 in stage 49.0 (TID 49)\n",
      "23/06/24 15:08:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:08:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:08:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:08:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:08:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:08:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:08:52 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:08:52 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:08:52 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:08:52 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:08:52 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:08:52 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:08:52 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:08:52 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4934 for partition ticketmaster-0\n",
      "23/06/24 15:08:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 49:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:08:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:08:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:08:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4936.\n",
      "23/06/24 15:08:53 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-467a7ee1-fa4d-47f0-9588-ad5c9e7ced89/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:08:53 INFO FileOutputCommitter: Saved output of task 'attempt_202306241508525795703324245936144_0049_m_000000_49' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-467a7ee1-fa4d-47f0-9588-ad5c9e7ced89/_temporary/0/task_202306241508525795703324245936144_0049_m_000000\n",
      "23/06/24 15:08:53 INFO SparkHadoopMapRedUtil: attempt_202306241508525795703324245936144_0049_m_000000_49: Committed. Elapsed time: 595 ms.\n",
      "23/06/24 15:08:53 INFO Executor: Finished task 0.0 in stage 49.0 (TID 49). 2536 bytes result sent to driver\n",
      "23/06/24 15:08:53 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 49) in 1597 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:08:53 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:08:53 INFO DAGScheduler: ResultStage 49 (start at NativeMethodAccessorImpl.java:0) finished in 1.635 s\n",
      "23/06/24 15:08:53 INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:08:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 49: Stage finished\n",
      "23/06/24 15:08:53 INFO DAGScheduler: Job 49 finished: start at NativeMethodAccessorImpl.java:0, took 1.636047 s\n",
      "23/06/24 15:08:53 INFO FileFormatWriter: Start to commit write Job 85b0a7b5-b943-4deb-a151-4ea425f71f55.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:08:54 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-467a7ee1-fa4d-47f0-9588-ad5c9e7ced89/_temporary/0/task_202306241508525795703324245936144_0049_m_000000/' directory.\n",
      "23/06/24 15:08:54 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-467a7ee1-fa4d-47f0-9588-ad5c9e7ced89/' directory.\n",
      "23/06/24 15:08:54 INFO BlockManagerInfo: Removed broadcast_49_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:08:55 INFO FileFormatWriter: Write Job 85b0a7b5-b943-4deb-a151-4ea425f71f55 committed. Elapsed time: 1822 ms.\n",
      "23/06/24 15:08:55 INFO FileFormatWriter: Finished processing stats for write job 85b0a7b5-b943-4deb-a151-4ea425f71f55.\n",
      "23/06/24 15:08:55 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-467a7ee1-fa4d-47f0-9588-ad5c9e7ced89/part-00000-c550871d-988f-4007-8f46-2d3b743607cd-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=fdd8139b-89ed-4e3c-81ec-7b4bfd7abc78, location=US}\n",
      "23/06/24 15:09:00 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=fdd8139b-89ed-4e3c-81ec-7b4bfd7abc78, location=US}\n",
      "23/06/24 15:09:00 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/253 using temp file gs://kafka-spark-data/spark-metadata/commits/.253.5dc86721-2b84-4b02-adfa-b5ec43178dc1.tmp\n",
      "23/06/24 15:09:01 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.253.5dc86721-2b84-4b02-adfa-b5ec43178dc1.tmp to gs://kafka-spark-data/spark-metadata/commits/253\n",
      "23/06/24 15:09:01 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:08:50.004Z\",\n",
      "  \"batchId\" : 253,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.19994001799460162,\n",
      "  \"processedRowsPerSecond\" : 0.17344549475327378,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 8937,\n",
      "    \"getBatch\" : 2,\n",
      "    \"latestOffset\" : 5,\n",
      "    \"queryPlanning\" : 19,\n",
      "    \"triggerExecution\" : 11531,\n",
      "    \"walCommit\" : 1545\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4933\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4935\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.19994001799460162,\n",
      "    \"processedRowsPerSecond\" : 0.17344549475327378\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:09:01 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 11535 milliseconds\n",
      "23/06/24 15:09:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:09:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4937.\n",
      "23/06/24 15:09:01 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/254 using temp file gs://kafka-spark-data/spark-metadata/offsets/.254.b1f539d4-7444-440e-92a0-303b2c39fd0f.tmp\n",
      "23/06/24 15:09:02 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.254.b1f539d4-7444-440e-92a0-303b2c39fd0f.tmp to gs://kafka-spark-data/spark-metadata/offsets/254\n",
      "23/06/24 15:09:02 INFO MicroBatchExecution: Committed offsets for batch 254. Metadata OffsetSeqMetadata(0,1687637341556,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:09:02 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:09:02 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:09:02 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:09:02 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:09:03 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:09:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:09:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:09:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:09:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:09:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:09:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:09:03 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:09:03 INFO DAGScheduler: Got job 50 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:09:03 INFO DAGScheduler: Final stage: ResultStage 50 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:09:03 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:09:03 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:09:03 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[356] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:09:03 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:09:03 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:09:03 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:09:03 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:09:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[356] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:09:03 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:09:03 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 50) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:09:03 INFO Executor: Running task 0.0 in stage 50.0 (TID 50)\n",
      "23/06/24 15:09:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:09:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:09:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:09:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:09:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:09:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:09:03 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:09:03 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:09:03 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:09:03 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:09:03 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:09:03 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:09:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:09:03 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4936 for partition ticketmaster-0\n",
      "23/06/24 15:09:03 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:09:04 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:09:04 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:09:04 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4938.\n",
      "23/06/24 15:09:04 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-abe9fbbb-d422-4806-b22d-3013b912d551/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:09:04 INFO FileOutputCommitter: Saved output of task 'attempt_202306241509033530018308660631577_0050_m_000000_50' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-abe9fbbb-d422-4806-b22d-3013b912d551/_temporary/0/task_202306241509033530018308660631577_0050_m_000000\n",
      "23/06/24 15:09:04 INFO SparkHadoopMapRedUtil: attempt_202306241509033530018308660631577_0050_m_000000_50: Committed. Elapsed time: 570 ms.\n",
      "23/06/24 15:09:04 INFO Executor: Finished task 0.0 in stage 50.0 (TID 50). 2536 bytes result sent to driver\n",
      "23/06/24 15:09:04 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 50) in 1476 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:09:04 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:09:04 INFO DAGScheduler: ResultStage 50 (start at NativeMethodAccessorImpl.java:0) finished in 1.496 s\n",
      "23/06/24 15:09:04 INFO DAGScheduler: Job 50 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:09:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 50: Stage finished\n",
      "23/06/24 15:09:04 INFO DAGScheduler: Job 50 finished: start at NativeMethodAccessorImpl.java:0, took 1.498277 s\n",
      "23/06/24 15:09:04 INFO FileFormatWriter: Start to commit write Job 3656812c-6be3-4ea0-a525-70310e97b5ab.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:09:05 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-abe9fbbb-d422-4806-b22d-3013b912d551/_temporary/0/task_202306241509033530018308660631577_0050_m_000000/' directory.\n",
      "23/06/24 15:09:06 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-abe9fbbb-d422-4806-b22d-3013b912d551/' directory.\n",
      "23/06/24 15:09:06 INFO BlockManagerInfo: Removed broadcast_50_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:09:06 INFO FileFormatWriter: Write Job 3656812c-6be3-4ea0-a525-70310e97b5ab committed. Elapsed time: 1468 ms.\n",
      "23/06/24 15:09:06 INFO FileFormatWriter: Finished processing stats for write job 3656812c-6be3-4ea0-a525-70310e97b5ab.\n",
      "23/06/24 15:09:06 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-abe9fbbb-d422-4806-b22d-3013b912d551/part-00000-b7ce83c4-6fe2-46f6-82cb-657497b554dc-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=6c0ae808-cddb-48e2-87c4-21e5db329c0f, location=US}\n",
      "23/06/24 15:09:08 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=6c0ae808-cddb-48e2-87c4-21e5db329c0f, location=US}\n",
      "23/06/24 15:09:08 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/254 using temp file gs://kafka-spark-data/spark-metadata/commits/.254.6effd777-1846-481d-b428-2745b438f425.tmp\n",
      "23/06/24 15:09:09 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.254.6effd777-1846-481d-b428-2745b438f425.tmp to gs://kafka-spark-data/spark-metadata/commits/254\n",
      "23/06/24 15:09:09 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:09:01.539Z\",\n",
      "  \"batchId\" : 254,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.17338534893801474,\n",
      "  \"processedRowsPerSecond\" : 0.2470660901791229,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 5722,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 16,\n",
      "    \"queryPlanning\" : 5,\n",
      "    \"triggerExecution\" : 8095,\n",
      "    \"walCommit\" : 1332\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4935\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4937\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.17338534893801474,\n",
      "    \"processedRowsPerSecond\" : 0.2470660901791229\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:09:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:09:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4939.\n",
      "23/06/24 15:09:10 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/255 using temp file gs://kafka-spark-data/spark-metadata/offsets/.255.46908e02-7b75-47db-b5ec-ae76f951f4c0.tmp\n",
      "23/06/24 15:09:11 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.255.46908e02-7b75-47db-b5ec-ae76f951f4c0.tmp to gs://kafka-spark-data/spark-metadata/offsets/255\n",
      "23/06/24 15:09:11 INFO MicroBatchExecution: Committed offsets for batch 255. Metadata OffsetSeqMetadata(0,1687637350008,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:09:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:09:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:09:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:09:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:09:11 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:09:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:09:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:09:11 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:09:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:09:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:09:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:09:12 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:09:12 INFO DAGScheduler: Got job 51 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:09:12 INFO DAGScheduler: Final stage: ResultStage 51 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:09:12 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:09:12 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:09:12 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[363] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:09:12 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:09:12 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:09:12 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:09:12 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:09:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[363] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:09:12 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:09:12 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 51) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:09:12 INFO Executor: Running task 0.0 in stage 51.0 (TID 51)\n",
      "23/06/24 15:09:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:09:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:09:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:09:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:09:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:09:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:09:12 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:09:12 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:09:12 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:09:12 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:09:12 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:09:12 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:09:12 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:09:12 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4938 for partition ticketmaster-0\n",
      "23/06/24 15:09:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 51:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:09:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:09:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:09:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4940.\n",
      "23/06/24 15:09:13 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c8a0dbb2-b05d-48e9-949f-4d3bfd07a24e/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:09:13 INFO FileOutputCommitter: Saved output of task 'attempt_20230624150912383453411916949984_0051_m_000000_51' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c8a0dbb2-b05d-48e9-949f-4d3bfd07a24e/_temporary/0/task_20230624150912383453411916949984_0051_m_000000\n",
      "23/06/24 15:09:13 INFO SparkHadoopMapRedUtil: attempt_20230624150912383453411916949984_0051_m_000000_51: Committed. Elapsed time: 631 ms.\n",
      "23/06/24 15:09:13 INFO Executor: Finished task 0.0 in stage 51.0 (TID 51). 2536 bytes result sent to driver\n",
      "23/06/24 15:09:13 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 51) in 1544 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:09:13 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:09:13 INFO DAGScheduler: ResultStage 51 (start at NativeMethodAccessorImpl.java:0) finished in 1.576 s\n",
      "23/06/24 15:09:13 INFO DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:09:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished\n",
      "23/06/24 15:09:13 INFO DAGScheduler: Job 51 finished: start at NativeMethodAccessorImpl.java:0, took 1.577858 s\n",
      "23/06/24 15:09:13 INFO FileFormatWriter: Start to commit write Job d74d31fa-e4c3-49ab-b0b4-4b610f087fa6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:09:14 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c8a0dbb2-b05d-48e9-949f-4d3bfd07a24e/_temporary/0/task_20230624150912383453411916949984_0051_m_000000/' directory.\n",
      "23/06/24 15:09:14 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c8a0dbb2-b05d-48e9-949f-4d3bfd07a24e/' directory.\n",
      "23/06/24 15:09:14 INFO BlockManagerInfo: Removed broadcast_51_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:09:15 INFO FileFormatWriter: Write Job d74d31fa-e4c3-49ab-b0b4-4b610f087fa6 committed. Elapsed time: 1537 ms.\n",
      "23/06/24 15:09:15 INFO FileFormatWriter: Finished processing stats for write job d74d31fa-e4c3-49ab-b0b4-4b610f087fa6.\n",
      "23/06/24 15:09:15 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c8a0dbb2-b05d-48e9-949f-4d3bfd07a24e/part-00000-c69eede4-3dcf-4ac4-91b6-cf8822be0fd9-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=fcd8955b-2ffd-47da-b9d6-0d562cc0a203, location=US}\n",
      "23/06/24 15:09:17 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=fcd8955b-2ffd-47da-b9d6-0d562cc0a203, location=US}\n",
      "23/06/24 15:09:17 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/255 using temp file gs://kafka-spark-data/spark-metadata/commits/.255.31e167b2-ce25-460f-8675-bb6f5502c81c.tmp\n",
      "23/06/24 15:09:18 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.255.31e167b2-ce25-460f-8675-bb6f5502c81c.tmp to gs://kafka-spark-data/spark-metadata/commits/255\n",
      "23/06/24 15:09:18 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:09:10.003Z\",\n",
      "  \"batchId\" : 255,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.23629489603024573,\n",
      "  \"processedRowsPerSecond\" : 0.23089355806972983,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6182,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 5,\n",
      "    \"queryPlanning\" : 9,\n",
      "    \"triggerExecution\" : 8662,\n",
      "    \"walCommit\" : 1388\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4937\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4939\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.23629489603024573,\n",
      "    \"processedRowsPerSecond\" : 0.23089355806972983\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:09:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:09:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4941.\n",
      "23/06/24 15:09:20 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/256 using temp file gs://kafka-spark-data/spark-metadata/offsets/.256.33f56fdf-1c64-4aba-965c-0a19b5d6d24d.tmp\n",
      "23/06/24 15:09:21 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.256.33f56fdf-1c64-4aba-965c-0a19b5d6d24d.tmp to gs://kafka-spark-data/spark-metadata/offsets/256\n",
      "23/06/24 15:09:21 INFO MicroBatchExecution: Committed offsets for batch 256. Metadata OffsetSeqMetadata(0,1687637360009,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:09:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:09:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:09:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:09:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:09:21 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:09:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:09:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:09:21 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:09:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:09:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:09:21 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:09:22 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:09:22 INFO DAGScheduler: Got job 52 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:09:22 INFO DAGScheduler: Final stage: ResultStage 52 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:09:22 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:09:22 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:09:22 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[370] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:09:22 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:09:22 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:09:22 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:09:22 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:09:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[370] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:09:22 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:09:22 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 52) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:09:22 INFO Executor: Running task 0.0 in stage 52.0 (TID 52)\n",
      "23/06/24 15:09:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:09:22 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:09:22 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:09:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:09:22 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:09:22 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:09:22 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:09:22 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:09:22 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:09:22 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:09:22 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:09:22 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:09:22 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:09:22 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4940 for partition ticketmaster-0\n",
      "23/06/24 15:09:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 52:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:09:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:09:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:09:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4942.\n",
      "23/06/24 15:09:23 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c26f788a-d456-4063-8b6c-73864a2b83e7/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:09:23 INFO FileOutputCommitter: Saved output of task 'attempt_20230624150921531019179259024628_0052_m_000000_52' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c26f788a-d456-4063-8b6c-73864a2b83e7/_temporary/0/task_20230624150921531019179259024628_0052_m_000000\n",
      "23/06/24 15:09:23 INFO SparkHadoopMapRedUtil: attempt_20230624150921531019179259024628_0052_m_000000_52: Committed. Elapsed time: 551 ms.\n",
      "23/06/24 15:09:23 INFO Executor: Finished task 0.0 in stage 52.0 (TID 52). 2536 bytes result sent to driver\n",
      "23/06/24 15:09:23 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 52) in 1478 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:09:23 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:09:23 INFO DAGScheduler: ResultStage 52 (start at NativeMethodAccessorImpl.java:0) finished in 1.501 s\n",
      "23/06/24 15:09:23 INFO DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:09:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 52: Stage finished\n",
      "23/06/24 15:09:23 INFO DAGScheduler: Job 52 finished: start at NativeMethodAccessorImpl.java:0, took 1.502545 s\n",
      "23/06/24 15:09:23 INFO FileFormatWriter: Start to commit write Job 2b3cd431-5dec-4e5b-aa20-16e7db15afc6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:09:24 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c26f788a-d456-4063-8b6c-73864a2b83e7/_temporary/0/task_20230624150921531019179259024628_0052_m_000000/' directory.\n",
      "23/06/24 15:09:24 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c26f788a-d456-4063-8b6c-73864a2b83e7/' directory.\n",
      "23/06/24 15:09:24 INFO BlockManagerInfo: Removed broadcast_52_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:09:24 INFO FileFormatWriter: Write Job 2b3cd431-5dec-4e5b-aa20-16e7db15afc6 committed. Elapsed time: 1314 ms.\n",
      "23/06/24 15:09:24 INFO FileFormatWriter: Finished processing stats for write job 2b3cd431-5dec-4e5b-aa20-16e7db15afc6.\n",
      "23/06/24 15:09:25 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c26f788a-d456-4063-8b6c-73864a2b83e7/part-00000-1fec785a-37df-489f-a2a8-ad9369f95932-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=2b6e3520-e6dc-4a0e-a911-bb98eac94146, location=US}\n",
      "23/06/24 15:09:28 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=2b6e3520-e6dc-4a0e-a911-bb98eac94146, location=US}\n",
      "23/06/24 15:09:28 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/256 using temp file gs://kafka-spark-data/spark-metadata/commits/.256.443bd204-06e7-4ef6-8582-24ed9ef4fe0d.tmp\n",
      "23/06/24 15:09:29 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.256.443bd204-06e7-4ef6-8582-24ed9ef4fe0d.tmp to gs://kafka-spark-data/spark-metadata/commits/256\n",
      "23/06/24 15:09:29 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:09:20.006Z\",\n",
      "  \"batchId\" : 256,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.19994001799460162,\n",
      "  \"processedRowsPerSecond\" : 0.2126980750824205,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6894,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 3,\n",
      "    \"queryPlanning\" : 6,\n",
      "    \"triggerExecution\" : 9403,\n",
      "    \"walCommit\" : 1472\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4939\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4941\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.19994001799460162,\n",
      "    \"processedRowsPerSecond\" : 0.2126980750824205\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:09:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:09:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4943.\n",
      "23/06/24 15:09:30 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/257 using temp file gs://kafka-spark-data/spark-metadata/offsets/.257.4384110c-4139-4866-bf69-c86a8b87b656.tmp\n",
      "23/06/24 15:09:31 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.257.4384110c-4139-4866-bf69-c86a8b87b656.tmp to gs://kafka-spark-data/spark-metadata/offsets/257\n",
      "23/06/24 15:09:31 INFO MicroBatchExecution: Committed offsets for batch 257. Metadata OffsetSeqMetadata(0,1687637370016,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:09:31 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:09:31 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:09:31 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:09:31 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:09:31 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:09:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:09:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:09:31 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:09:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:09:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:09:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:09:31 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:09:31 INFO DAGScheduler: Got job 53 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:09:31 INFO DAGScheduler: Final stage: ResultStage 53 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:09:31 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:09:31 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:09:31 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[377] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:09:31 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:09:31 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:09:31 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:09:31 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:09:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[377] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:09:31 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:09:31 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 53) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:09:31 INFO Executor: Running task 0.0 in stage 53.0 (TID 53)\n",
      "23/06/24 15:09:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:09:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:09:31 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:09:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:09:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:09:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:09:31 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:09:31 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:09:31 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:09:31 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:09:31 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:09:31 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:09:31 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:09:31 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4942 for partition ticketmaster-0\n",
      "23/06/24 15:09:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:09:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:09:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:09:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4944.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 53:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:09:32 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-e257688b-246c-4794-b8e7-1a5fe7016876/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:09:32 INFO FileOutputCommitter: Saved output of task 'attempt_202306241509316574720568022488856_0053_m_000000_53' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-e257688b-246c-4794-b8e7-1a5fe7016876/_temporary/0/task_202306241509316574720568022488856_0053_m_000000\n",
      "23/06/24 15:09:32 INFO SparkHadoopMapRedUtil: attempt_202306241509316574720568022488856_0053_m_000000_53: Committed. Elapsed time: 537 ms.\n",
      "23/06/24 15:09:32 INFO Executor: Finished task 0.0 in stage 53.0 (TID 53). 2536 bytes result sent to driver\n",
      "23/06/24 15:09:32 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 53) in 1021 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:09:32 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:09:32 INFO DAGScheduler: ResultStage 53 (start at NativeMethodAccessorImpl.java:0) finished in 1.038 s\n",
      "23/06/24 15:09:32 INFO DAGScheduler: Job 53 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:09:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished\n",
      "23/06/24 15:09:32 INFO DAGScheduler: Job 53 finished: start at NativeMethodAccessorImpl.java:0, took 1.039510 s\n",
      "23/06/24 15:09:32 INFO FileFormatWriter: Start to commit write Job d166def2-eaf9-4403-870c-91539722e26c.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:09:33 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-e257688b-246c-4794-b8e7-1a5fe7016876/_temporary/0/task_202306241509316574720568022488856_0053_m_000000/' directory.\n",
      "23/06/24 15:09:33 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-e257688b-246c-4794-b8e7-1a5fe7016876/' directory.\n",
      "23/06/24 15:09:33 INFO BlockManagerInfo: Removed broadcast_53_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:09:34 INFO FileFormatWriter: Write Job d166def2-eaf9-4403-870c-91539722e26c committed. Elapsed time: 1350 ms.\n",
      "23/06/24 15:09:34 INFO FileFormatWriter: Finished processing stats for write job d166def2-eaf9-4403-870c-91539722e26c.\n",
      "23/06/24 15:09:34 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-e257688b-246c-4794-b8e7-1a5fe7016876/part-00000-ff0e185a-73a7-4cc0-8d30-2a703523c945-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=b393f742-4e37-4eb5-a372-3a2c86da7432, location=US}\n",
      "23/06/24 15:09:37 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=b393f742-4e37-4eb5-a372-3a2c86da7432, location=US}\n",
      "23/06/24 15:09:37 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/257 using temp file gs://kafka-spark-data/spark-metadata/commits/.257.820a7161-6bfa-4c5a-bb7a-b391fb925dfb.tmp\n",
      "23/06/24 15:09:38 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.257.820a7161-6bfa-4c5a-bb7a-b391fb925dfb.tmp to gs://kafka-spark-data/spark-metadata/commits/257\n",
      "23/06/24 15:09:38 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:09:30.003Z\",\n",
      "  \"batchId\" : 257,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.20006001800540163,\n",
      "  \"processedRowsPerSecond\" : 0.23674242424242423,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 5928,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 13,\n",
      "    \"queryPlanning\" : 4,\n",
      "    \"triggerExecution\" : 8448,\n",
      "    \"walCommit\" : 1435\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4941\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4943\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.20006001800540163,\n",
      "    \"processedRowsPerSecond\" : 0.23674242424242423\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:09:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:09:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4945.\n",
      "23/06/24 15:09:40 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/258 using temp file gs://kafka-spark-data/spark-metadata/offsets/.258.2aea9d1a-0484-48c6-97c2-ab37a4aeab49.tmp\n",
      "23/06/24 15:09:40 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.258.2aea9d1a-0484-48c6-97c2-ab37a4aeab49.tmp to gs://kafka-spark-data/spark-metadata/offsets/258\n",
      "23/06/24 15:09:40 INFO MicroBatchExecution: Committed offsets for batch 258. Metadata OffsetSeqMetadata(0,1687637380008,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:09:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:09:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:09:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:09:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:09:41 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:09:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:09:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:09:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:09:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:09:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:09:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:09:41 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:09:41 INFO DAGScheduler: Got job 54 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:09:41 INFO DAGScheduler: Final stage: ResultStage 54 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:09:41 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:09:41 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:09:41 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[384] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:09:41 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:09:41 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:09:41 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:09:41 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:09:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[384] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:09:41 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:09:41 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 54) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:09:41 INFO Executor: Running task 0.0 in stage 54.0 (TID 54)\n",
      "23/06/24 15:09:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:09:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:09:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:09:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:09:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:09:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:09:41 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:09:41 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:09:41 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:09:41 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:09:41 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:09:41 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:09:41 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:09:42 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4943 for partition ticketmaster-0\n",
      "23/06/24 15:09:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:09:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:09:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:09:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4945.\n",
      "23/06/24 15:09:42 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4944 for partition ticketmaster-0\n",
      "23/06/24 15:09:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:09:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:09:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:09:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4946.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 54:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:09:42 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-983ae854-49c0-4351-b3ad-37fc108bb412/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:09:42 INFO FileOutputCommitter: Saved output of task 'attempt_202306241509416304960090107419847_0054_m_000000_54' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-983ae854-49c0-4351-b3ad-37fc108bb412/_temporary/0/task_202306241509416304960090107419847_0054_m_000000\n",
      "23/06/24 15:09:42 INFO SparkHadoopMapRedUtil: attempt_202306241509416304960090107419847_0054_m_000000_54: Committed. Elapsed time: 549 ms.\n",
      "23/06/24 15:09:42 INFO Executor: Finished task 0.0 in stage 54.0 (TID 54). 2536 bytes result sent to driver\n",
      "23/06/24 15:09:42 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 54) in 1036 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:09:42 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:09:42 INFO DAGScheduler: ResultStage 54 (start at NativeMethodAccessorImpl.java:0) finished in 1.084 s\n",
      "23/06/24 15:09:42 INFO DAGScheduler: Job 54 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:09:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 54: Stage finished\n",
      "23/06/24 15:09:42 INFO DAGScheduler: Job 54 finished: start at NativeMethodAccessorImpl.java:0, took 1.086354 s\n",
      "23/06/24 15:09:42 INFO FileFormatWriter: Start to commit write Job 474a0467-054d-40b8-9b96-2770b6f9e65a.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:09:43 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-983ae854-49c0-4351-b3ad-37fc108bb412/_temporary/0/task_202306241509416304960090107419847_0054_m_000000/' directory.\n",
      "23/06/24 15:09:44 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-983ae854-49c0-4351-b3ad-37fc108bb412/' directory.\n",
      "23/06/24 15:09:44 INFO FileFormatWriter: Write Job 474a0467-054d-40b8-9b96-2770b6f9e65a committed. Elapsed time: 1548 ms.\n",
      "23/06/24 15:09:44 INFO FileFormatWriter: Finished processing stats for write job 474a0467-054d-40b8-9b96-2770b6f9e65a.\n",
      "23/06/24 15:09:44 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-983ae854-49c0-4351-b3ad-37fc108bb412/part-00000-7fbf7329-0b78-4660-b1c8-5dce6235a9b8-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=96782c91-2837-4d3e-87ad-7c138a626128, location=US}\n",
      "23/06/24 15:09:46 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=96782c91-2837-4d3e-87ad-7c138a626128, location=US}\n",
      "23/06/24 15:09:46 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/258 using temp file gs://kafka-spark-data/spark-metadata/commits/.258.886ef39f-fba4-4567-a843-403b0135b973.tmp\n",
      "23/06/24 15:09:47 INFO BlockManagerInfo: Removed broadcast_54_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:09:47 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.258.886ef39f-fba4-4567-a843-403b0135b973.tmp to gs://kafka-spark-data/spark-metadata/commits/258\n",
      "23/06/24 15:09:47 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:09:40.005Z\",\n",
      "  \"batchId\" : 258,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.1999600079984003,\n",
      "  \"processedRowsPerSecond\" : 0.25779840164990975,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 5426,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 3,\n",
      "    \"queryPlanning\" : 18,\n",
      "    \"triggerExecution\" : 7757,\n",
      "    \"walCommit\" : 1318\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4943\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4945\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.1999600079984003,\n",
      "    \"processedRowsPerSecond\" : 0.25779840164990975\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:09:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:09:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4947.\n",
      "23/06/24 15:09:50 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/259 using temp file gs://kafka-spark-data/spark-metadata/offsets/.259.f129cba1-79ba-4f80-a2bd-ca39bdd95ddb.tmp\n",
      "23/06/24 15:09:51 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.259.f129cba1-79ba-4f80-a2bd-ca39bdd95ddb.tmp to gs://kafka-spark-data/spark-metadata/offsets/259\n",
      "23/06/24 15:09:51 INFO MicroBatchExecution: Committed offsets for batch 259. Metadata OffsetSeqMetadata(0,1687637390019,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:09:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:09:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:09:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:09:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:09:51 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:09:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:09:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:09:51 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:09:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:09:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:09:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:09:52 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:09:52 INFO DAGScheduler: Got job 55 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:09:52 INFO DAGScheduler: Final stage: ResultStage 55 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:09:52 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:09:52 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:09:52 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[391] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:09:52 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:09:52 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:09:52 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:09:52 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:09:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[391] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:09:52 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:09:52 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 55) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:09:52 INFO Executor: Running task 0.0 in stage 55.0 (TID 55)\n",
      "23/06/24 15:09:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:09:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:09:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:09:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:09:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:09:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:09:52 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:09:52 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:09:52 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:09:52 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:09:52 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:09:52 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:09:52 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:09:52 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4945 for partition ticketmaster-0\n",
      "23/06/24 15:09:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:09:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:09:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:09:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4948.\n",
      "23/06/24 15:09:52 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4946 for partition ticketmaster-0\n",
      "23/06/24 15:09:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 55:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:09:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:09:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:09:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4948.\n",
      "23/06/24 15:09:53 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-e065c57a-f69a-4152-9ed7-27eb1d02cc2b/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:09:53 INFO FileOutputCommitter: Saved output of task 'attempt_202306241509517689862071563898589_0055_m_000000_55' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-e065c57a-f69a-4152-9ed7-27eb1d02cc2b/_temporary/0/task_202306241509517689862071563898589_0055_m_000000\n",
      "23/06/24 15:09:53 INFO SparkHadoopMapRedUtil: attempt_202306241509517689862071563898589_0055_m_000000_55: Committed. Elapsed time: 591 ms.\n",
      "23/06/24 15:09:53 INFO Executor: Finished task 0.0 in stage 55.0 (TID 55). 2579 bytes result sent to driver\n",
      "23/06/24 15:09:53 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 55) in 1516 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:09:53 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:09:53 INFO DAGScheduler: ResultStage 55 (start at NativeMethodAccessorImpl.java:0) finished in 1.534 s\n",
      "23/06/24 15:09:53 INFO DAGScheduler: Job 55 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:09:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished\n",
      "23/06/24 15:09:53 INFO DAGScheduler: Job 55 finished: start at NativeMethodAccessorImpl.java:0, took 1.535223 s\n",
      "23/06/24 15:09:53 INFO FileFormatWriter: Start to commit write Job d352a22b-8097-4852-95f7-04b91600e531.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:09:54 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-e065c57a-f69a-4152-9ed7-27eb1d02cc2b/_temporary/0/task_202306241509517689862071563898589_0055_m_000000/' directory.\n",
      "23/06/24 15:09:54 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-e065c57a-f69a-4152-9ed7-27eb1d02cc2b/' directory.\n",
      "23/06/24 15:09:54 INFO FileFormatWriter: Write Job d352a22b-8097-4852-95f7-04b91600e531 committed. Elapsed time: 1429 ms.\n",
      "23/06/24 15:09:55 INFO FileFormatWriter: Finished processing stats for write job d352a22b-8097-4852-95f7-04b91600e531.\n",
      "23/06/24 15:09:55 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-e065c57a-f69a-4152-9ed7-27eb1d02cc2b/part-00000-31db9f44-9c5d-4780-a7ee-835b34ae96a5-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=83e17fa3-6686-40a0-a2db-20857182ecc5, location=US}\n",
      "23/06/24 15:09:57 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=83e17fa3-6686-40a0-a2db-20857182ecc5, location=US}\n",
      "23/06/24 15:09:58 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/259 using temp file gs://kafka-spark-data/spark-metadata/commits/.259.92bbe784-db9c-4b33-b65b-0ab1305f355a.tmp\n",
      "23/06/24 15:09:58 INFO BlockManagerInfo: Removed broadcast_55_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:09:58 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.259.92bbe784-db9c-4b33-b65b-0ab1305f355a.tmp to gs://kafka-spark-data/spark-metadata/commits/259\n",
      "23/06/24 15:09:58 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:09:50.002Z\",\n",
      "  \"batchId\" : 259,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.20006001800540163,\n",
      "  \"processedRowsPerSecond\" : 0.22241992882562275,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6554,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 17,\n",
      "    \"queryPlanning\" : 6,\n",
      "    \"triggerExecution\" : 8992,\n",
      "    \"walCommit\" : 1458\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4945\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4947\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.20006001800540163,\n",
      "    \"processedRowsPerSecond\" : 0.22241992882562275\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:10:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:10:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4949.\n",
      "23/06/24 15:10:00 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/260 using temp file gs://kafka-spark-data/spark-metadata/offsets/.260.541ffc93-9209-41d0-9bce-b5cd4ffa4637.tmp\n",
      "23/06/24 15:10:00 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.260.541ffc93-9209-41d0-9bce-b5cd4ffa4637.tmp to gs://kafka-spark-data/spark-metadata/offsets/260\n",
      "23/06/24 15:10:00 INFO MicroBatchExecution: Committed offsets for batch 260. Metadata OffsetSeqMetadata(0,1687637400020,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:10:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:10:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:10:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:10:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:10:01 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:10:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:10:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:10:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:10:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:10:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:10:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:10:01 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:10:01 INFO DAGScheduler: Got job 56 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:10:01 INFO DAGScheduler: Final stage: ResultStage 56 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:10:01 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:10:01 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:10:01 INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[398] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:10:01 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:10:01 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:10:01 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:10:01 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:10:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[398] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:10:01 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:10:01 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 56) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:10:01 INFO Executor: Running task 0.0 in stage 56.0 (TID 56)\n",
      "23/06/24 15:10:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:10:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:10:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:10:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:10:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:10:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:10:01 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:10:01 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:10:01 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:10:01 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:10:01 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:10:01 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:10:01 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:10:02 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4948 for partition ticketmaster-0\n",
      "23/06/24 15:10:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:10:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:10:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:10:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4950.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 56:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:10:03 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-4979a800-164c-4282-87ca-c5d12386bd04/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:10:03 INFO FileOutputCommitter: Saved output of task 'attempt_202306241510015974015320456885562_0056_m_000000_56' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-4979a800-164c-4282-87ca-c5d12386bd04/_temporary/0/task_202306241510015974015320456885562_0056_m_000000\n",
      "23/06/24 15:10:03 INFO SparkHadoopMapRedUtil: attempt_202306241510015974015320456885562_0056_m_000000_56: Committed. Elapsed time: 686 ms.\n",
      "23/06/24 15:10:03 INFO Executor: Finished task 0.0 in stage 56.0 (TID 56). 2536 bytes result sent to driver\n",
      "23/06/24 15:10:03 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 56) in 1266 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:10:03 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:10:03 INFO DAGScheduler: ResultStage 56 (start at NativeMethodAccessorImpl.java:0) finished in 1.286 s\n",
      "23/06/24 15:10:03 INFO DAGScheduler: Job 56 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:10:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 56: Stage finished\n",
      "23/06/24 15:10:03 INFO DAGScheduler: Job 56 finished: start at NativeMethodAccessorImpl.java:0, took 1.288085 s\n",
      "23/06/24 15:10:03 INFO FileFormatWriter: Start to commit write Job 40cf21d5-4180-4b45-9a7c-8558b30eef70.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:10:03 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-4979a800-164c-4282-87ca-c5d12386bd04/_temporary/0/task_202306241510015974015320456885562_0056_m_000000/' directory.\n",
      "23/06/24 15:10:04 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-4979a800-164c-4282-87ca-c5d12386bd04/' directory.\n",
      "23/06/24 15:10:04 INFO BlockManagerInfo: Removed broadcast_56_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:10:04 INFO FileFormatWriter: Write Job 40cf21d5-4180-4b45-9a7c-8558b30eef70 committed. Elapsed time: 1449 ms.\n",
      "23/06/24 15:10:04 INFO FileFormatWriter: Finished processing stats for write job 40cf21d5-4180-4b45-9a7c-8558b30eef70.\n",
      "23/06/24 15:10:05 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-4979a800-164c-4282-87ca-c5d12386bd04/part-00000-d3c4958c-3208-4ce5-a02a-9933a753bbb8-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=e6404e4e-fecc-4505-af17-e04963f56cf6, location=US}\n",
      "23/06/24 15:10:08 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=e6404e4e-fecc-4505-af17-e04963f56cf6, location=US}\n",
      "23/06/24 15:10:08 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/260 using temp file gs://kafka-spark-data/spark-metadata/commits/.260.9e348d79-1763-4ce6-8f7d-a7cb6b14f425.tmp\n",
      "23/06/24 15:10:09 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.260.9e348d79-1763-4ce6-8f7d-a7cb6b14f425.tmp to gs://kafka-spark-data/spark-metadata/commits/260\n",
      "23/06/24 15:10:09 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:10:00.012Z\",\n",
      "  \"batchId\" : 260,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.1998001998001998,\n",
      "  \"processedRowsPerSecond\" : 0.2144542140253056,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7005,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 5,\n",
      "    \"queryPlanning\" : 21,\n",
      "    \"triggerExecution\" : 9324,\n",
      "    \"walCommit\" : 1324\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4947\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4949\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.1998001998001998,\n",
      "    \"processedRowsPerSecond\" : 0.2144542140253056\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:10:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:10:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4951.\n",
      "23/06/24 15:10:10 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/261 using temp file gs://kafka-spark-data/spark-metadata/offsets/.261.d2969720-e13f-42db-9f61-ea08ed732067.tmp\n",
      "23/06/24 15:10:11 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.261.d2969720-e13f-42db-9f61-ea08ed732067.tmp to gs://kafka-spark-data/spark-metadata/offsets/261\n",
      "23/06/24 15:10:11 INFO MicroBatchExecution: Committed offsets for batch 261. Metadata OffsetSeqMetadata(0,1687637410021,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:10:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:10:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:10:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:10:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:10:11 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:10:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:10:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:10:11 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:10:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:10:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:10:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:10:11 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:10:11 INFO DAGScheduler: Got job 57 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:10:11 INFO DAGScheduler: Final stage: ResultStage 57 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:10:11 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:10:11 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:10:11 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[405] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:10:11 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:10:11 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:10:11 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:10:11 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:10:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[405] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:10:11 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:10:11 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 57) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:10:11 INFO Executor: Running task 0.0 in stage 57.0 (TID 57)\n",
      "23/06/24 15:10:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:10:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:10:11 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:10:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:10:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:10:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:10:11 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:10:11 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:10:11 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:10:11 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:10:11 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:10:11 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:10:11 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:10:12 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4949 for partition ticketmaster-0\n",
      "23/06/24 15:10:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:10:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:10:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:10:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4951.\n",
      "23/06/24 15:10:12 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4950 for partition ticketmaster-0\n",
      "23/06/24 15:10:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:10:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:10:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:10:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4952.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:10:13 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-4c9e1fb7-8b3f-4f57-b9cc-fa0745c5a45d/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:10:13 INFO FileOutputCommitter: Saved output of task 'attempt_202306241510115521281652197161_0057_m_000000_57' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-4c9e1fb7-8b3f-4f57-b9cc-fa0745c5a45d/_temporary/0/task_202306241510115521281652197161_0057_m_000000\n",
      "23/06/24 15:10:13 INFO SparkHadoopMapRedUtil: attempt_202306241510115521281652197161_0057_m_000000_57: Committed. Elapsed time: 543 ms.\n",
      "23/06/24 15:10:13 INFO Executor: Finished task 0.0 in stage 57.0 (TID 57). 2536 bytes result sent to driver\n",
      "23/06/24 15:10:13 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 57) in 1159 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:10:13 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:10:13 INFO DAGScheduler: ResultStage 57 (start at NativeMethodAccessorImpl.java:0) finished in 1.201 s\n",
      "23/06/24 15:10:13 INFO DAGScheduler: Job 57 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:10:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished\n",
      "23/06/24 15:10:13 INFO DAGScheduler: Job 57 finished: start at NativeMethodAccessorImpl.java:0, took 1.202478 s\n",
      "23/06/24 15:10:13 INFO FileFormatWriter: Start to commit write Job be749564-1607-41e7-9938-44ba41db5da8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:10:13 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-4c9e1fb7-8b3f-4f57-b9cc-fa0745c5a45d/_temporary/0/task_202306241510115521281652197161_0057_m_000000/' directory.\n",
      "23/06/24 15:10:14 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-4c9e1fb7-8b3f-4f57-b9cc-fa0745c5a45d/' directory.\n",
      "23/06/24 15:10:14 INFO BlockManagerInfo: Removed broadcast_57_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:10:14 INFO FileFormatWriter: Write Job be749564-1607-41e7-9938-44ba41db5da8 committed. Elapsed time: 1313 ms.\n",
      "23/06/24 15:10:14 INFO FileFormatWriter: Finished processing stats for write job be749564-1607-41e7-9938-44ba41db5da8.\n",
      "23/06/24 15:10:14 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-4c9e1fb7-8b3f-4f57-b9cc-fa0745c5a45d/part-00000-f87652b1-1abe-4e6f-b4e0-1e94b0411759-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=d8b8c2d8-9968-4e67-bd2b-dca86516f005, location=US}\n",
      "23/06/24 15:10:18 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=d8b8c2d8-9968-4e67-bd2b-dca86516f005, location=US}\n",
      "23/06/24 15:10:18 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/261 using temp file gs://kafka-spark-data/spark-metadata/commits/.261.f1ad8e83-c26c-4c3b-8870-438ffa70b166.tmp\n",
      "23/06/24 15:10:19 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.261.f1ad8e83-c26c-4c3b-8870-438ffa70b166.tmp to gs://kafka-spark-data/spark-metadata/commits/261\n",
      "23/06/24 15:10:19 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:10:10.001Z\",\n",
      "  \"batchId\" : 261,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.20022024226649313,\n",
      "  \"processedRowsPerSecond\" : 0.2157031924072476,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6863,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 19,\n",
      "    \"queryPlanning\" : 7,\n",
      "    \"triggerExecution\" : 9272,\n",
      "    \"walCommit\" : 1372\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4949\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4951\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.20022024226649313,\n",
      "    \"processedRowsPerSecond\" : 0.2157031924072476\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:10:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:10:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4953.\n",
      "23/06/24 15:10:20 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/262 using temp file gs://kafka-spark-data/spark-metadata/offsets/.262.84aa4268-080b-4da2-947e-9ba163fa837f.tmp\n",
      "23/06/24 15:10:21 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.262.84aa4268-080b-4da2-947e-9ba163fa837f.tmp to gs://kafka-spark-data/spark-metadata/offsets/262\n",
      "23/06/24 15:10:21 INFO MicroBatchExecution: Committed offsets for batch 262. Metadata OffsetSeqMetadata(0,1687637420004,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:10:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:10:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:10:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:10:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:10:21 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:10:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:10:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:10:21 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:10:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:10:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:10:21 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:10:22 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:10:22 INFO DAGScheduler: Got job 58 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:10:22 INFO DAGScheduler: Final stage: ResultStage 58 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:10:22 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:10:22 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:10:22 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[412] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:10:22 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:10:22 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:10:22 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:10:22 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:10:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[412] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:10:22 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:10:22 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 58) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:10:22 INFO Executor: Running task 0.0 in stage 58.0 (TID 58)\n",
      "23/06/24 15:10:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:10:22 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:10:22 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:10:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:10:22 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:10:22 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:10:22 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:10:22 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:10:22 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:10:22 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:10:22 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:10:22 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:10:22 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:10:22 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4951 for partition ticketmaster-0\n",
      "23/06/24 15:10:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:10:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:10:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:10:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4954.\n",
      "23/06/24 15:10:22 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4952 for partition ticketmaster-0\n",
      "23/06/24 15:10:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 58:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:10:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:10:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:10:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4954.\n",
      "23/06/24 15:10:23 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-b414cbae-8ac9-4bca-8137-c067f3e2d824/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:10:23 INFO FileOutputCommitter: Saved output of task 'attempt_20230624151022310814052828519173_0058_m_000000_58' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-b414cbae-8ac9-4bca-8137-c067f3e2d824/_temporary/0/task_20230624151022310814052828519173_0058_m_000000\n",
      "23/06/24 15:10:23 INFO SparkHadoopMapRedUtil: attempt_20230624151022310814052828519173_0058_m_000000_58: Committed. Elapsed time: 547 ms.\n",
      "23/06/24 15:10:23 INFO Executor: Finished task 0.0 in stage 58.0 (TID 58). 2579 bytes result sent to driver\n",
      "23/06/24 15:10:23 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 58) in 1576 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:10:23 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:10:23 INFO DAGScheduler: ResultStage 58 (start at NativeMethodAccessorImpl.java:0) finished in 1.594 s\n",
      "23/06/24 15:10:23 INFO DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:10:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 58: Stage finished\n",
      "23/06/24 15:10:23 INFO DAGScheduler: Job 58 finished: start at NativeMethodAccessorImpl.java:0, took 1.594948 s\n",
      "23/06/24 15:10:23 INFO FileFormatWriter: Start to commit write Job 08bf5b8d-7d0f-441e-ab69-fb4591568c77.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:10:24 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-b414cbae-8ac9-4bca-8137-c067f3e2d824/_temporary/0/task_20230624151022310814052828519173_0058_m_000000/' directory.\n",
      "23/06/24 15:10:24 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-b414cbae-8ac9-4bca-8137-c067f3e2d824/' directory.\n",
      "23/06/24 15:10:24 INFO BlockManagerInfo: Removed broadcast_58_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:10:25 INFO FileFormatWriter: Write Job 08bf5b8d-7d0f-441e-ab69-fb4591568c77 committed. Elapsed time: 1319 ms.\n",
      "23/06/24 15:10:25 INFO FileFormatWriter: Finished processing stats for write job 08bf5b8d-7d0f-441e-ab69-fb4591568c77.\n",
      "23/06/24 15:10:25 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-b414cbae-8ac9-4bca-8137-c067f3e2d824/part-00000-bedc6daf-ef75-4a8d-928a-6df33d170222-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=cba51e28-52c2-4511-876f-ebab97b23f9e, location=US}\n",
      "23/06/24 15:10:28 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=cba51e28-52c2-4511-876f-ebab97b23f9e, location=US}\n",
      "23/06/24 15:10:29 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/262 using temp file gs://kafka-spark-data/spark-metadata/commits/.262.99c396d4-d03f-4a13-88d8-c2b72c67bdbe.tmp\n",
      "23/06/24 15:10:29 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.262.99c396d4-d03f-4a13-88d8-c2b72c67bdbe.tmp to gs://kafka-spark-data/spark-metadata/commits/262\n",
      "23/06/24 15:10:29 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:10:20.000Z\",\n",
      "  \"batchId\" : 262,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.2000200020002,\n",
      "  \"processedRowsPerSecond\" : 0.2047082906857728,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7372,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 4,\n",
      "    \"queryPlanning\" : 14,\n",
      "    \"triggerExecution\" : 9770,\n",
      "    \"walCommit\" : 1479\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4951\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4953\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.2000200020002,\n",
      "    \"processedRowsPerSecond\" : 0.2047082906857728\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:10:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:10:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4955.\n",
      "23/06/24 15:10:30 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/263 using temp file gs://kafka-spark-data/spark-metadata/offsets/.263.38ac8c47-328e-4636-8b07-1ebffbac2e2b.tmp\n",
      "23/06/24 15:10:30 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.263.38ac8c47-328e-4636-8b07-1ebffbac2e2b.tmp to gs://kafka-spark-data/spark-metadata/offsets/263\n",
      "23/06/24 15:10:30 INFO MicroBatchExecution: Committed offsets for batch 263. Metadata OffsetSeqMetadata(0,1687637430008,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:10:31 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:10:31 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:10:31 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:10:31 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:10:31 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:10:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:10:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:10:31 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:10:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:10:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:10:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:10:31 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:10:31 INFO DAGScheduler: Got job 59 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:10:31 INFO DAGScheduler: Final stage: ResultStage 59 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:10:31 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:10:31 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:10:31 INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[419] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:10:31 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:10:31 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:10:31 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:10:31 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:10:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[419] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:10:31 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:10:31 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 59) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:10:31 INFO Executor: Running task 0.0 in stage 59.0 (TID 59)\n",
      "23/06/24 15:10:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:10:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:10:31 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:10:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:10:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:10:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:10:31 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:10:31 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:10:31 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:10:31 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:10:31 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:10:31 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:10:31 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:10:31 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4954 for partition ticketmaster-0\n",
      "23/06/24 15:10:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:10:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:10:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:10:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4956.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 59:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:10:33 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-ef106926-d91b-47a5-b8cb-3622fb17d972/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:10:33 INFO FileOutputCommitter: Saved output of task 'attempt_202306241510312030177855140576657_0059_m_000000_59' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-ef106926-d91b-47a5-b8cb-3622fb17d972/_temporary/0/task_202306241510312030177855140576657_0059_m_000000\n",
      "23/06/24 15:10:33 INFO SparkHadoopMapRedUtil: attempt_202306241510312030177855140576657_0059_m_000000_59: Committed. Elapsed time: 692 ms.\n",
      "23/06/24 15:10:33 INFO Executor: Finished task 0.0 in stage 59.0 (TID 59). 2579 bytes result sent to driver\n",
      "23/06/24 15:10:33 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 59) in 1265 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:10:33 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:10:33 INFO DAGScheduler: ResultStage 59 (start at NativeMethodAccessorImpl.java:0) finished in 1.287 s\n",
      "23/06/24 15:10:33 INFO DAGScheduler: Job 59 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:10:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 59: Stage finished\n",
      "23/06/24 15:10:33 INFO DAGScheduler: Job 59 finished: start at NativeMethodAccessorImpl.java:0, took 1.288473 s\n",
      "23/06/24 15:10:33 INFO FileFormatWriter: Start to commit write Job ec9c6f12-4ffb-4425-bed2-9e6601a06fda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:10:33 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-ef106926-d91b-47a5-b8cb-3622fb17d972/_temporary/0/task_202306241510312030177855140576657_0059_m_000000/' directory.\n",
      "23/06/24 15:10:34 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-ef106926-d91b-47a5-b8cb-3622fb17d972/' directory.\n",
      "23/06/24 15:10:34 INFO FileFormatWriter: Write Job ec9c6f12-4ffb-4425-bed2-9e6601a06fda committed. Elapsed time: 1560 ms.\n",
      "23/06/24 15:10:34 INFO FileFormatWriter: Finished processing stats for write job ec9c6f12-4ffb-4425-bed2-9e6601a06fda.\n",
      "23/06/24 15:10:35 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-ef106926-d91b-47a5-b8cb-3622fb17d972/part-00000-c322e522-c493-4191-ab49-711367476aad-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=05bbedfa-9a57-4a69-84c3-35e8028440f1, location=US}\n",
      "23/06/24 15:10:37 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=05bbedfa-9a57-4a69-84c3-35e8028440f1, location=US}\n",
      "23/06/24 15:10:38 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/263 using temp file gs://kafka-spark-data/spark-metadata/commits/.263.ae65fa62-90b8-4ed2-8eff-d9d1f35c7672.tmp\n",
      "23/06/24 15:10:39 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.263.ae65fa62-90b8-4ed2-8eff-d9d1f35c7672.tmp to gs://kafka-spark-data/spark-metadata/commits/263\n",
      "23/06/24 15:10:39 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:10:30.001Z\",\n",
      "  \"batchId\" : 263,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.19998000199980004,\n",
      "  \"processedRowsPerSecond\" : 0.21893814997263272,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6797,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 5,\n",
      "    \"queryPlanning\" : 8,\n",
      "    \"triggerExecution\" : 9134,\n",
      "    \"walCommit\" : 1284\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4953\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4955\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.19998000199980004,\n",
      "    \"processedRowsPerSecond\" : 0.21893814997263272\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:10:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:10:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4957.\n",
      "23/06/24 15:10:40 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/264 using temp file gs://kafka-spark-data/spark-metadata/offsets/.264.db5aa4fc-b4ed-4c92-b748-11df27ad2469.tmp\n",
      "23/06/24 15:10:41 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.264.db5aa4fc-b4ed-4c92-b748-11df27ad2469.tmp to gs://kafka-spark-data/spark-metadata/offsets/264\n",
      "23/06/24 15:10:41 INFO MicroBatchExecution: Committed offsets for batch 264. Metadata OffsetSeqMetadata(0,1687637440025,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:10:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:10:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:10:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:10:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:10:41 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:10:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:10:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:10:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:10:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:10:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:10:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:10:41 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:10:42 INFO DAGScheduler: Got job 60 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:10:42 INFO DAGScheduler: Final stage: ResultStage 60 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:10:42 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:10:42 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:10:42 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[426] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:10:42 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 295.4 KiB, free 433.7 MiB)\n",
      "23/06/24 15:10:42 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 433.6 MiB)\n",
      "23/06/24 15:10:42 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.2 MiB)\n",
      "23/06/24 15:10:42 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:10:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[426] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:10:42 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:10:42 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 60) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:10:42 INFO Executor: Running task 0.0 in stage 60.0 (TID 60)\n",
      "23/06/24 15:10:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:10:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:10:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:10:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:10:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:10:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:10:42 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:10:42 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:10:42 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:10:42 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:10:42 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:10:42 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:10:42 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:10:42 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4955 for partition ticketmaster-0\n",
      "23/06/24 15:10:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:10:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:10:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:10:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4958.\n",
      "23/06/24 15:10:42 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4956 for partition ticketmaster-0\n",
      "23/06/24 15:10:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 60:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:10:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:10:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:10:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4958.\n",
      "23/06/24 15:10:43 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-f63f1209-68f1-4709-88b9-b001d528d7c8/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:10:43 INFO FileOutputCommitter: Saved output of task 'attempt_202306241510416476917328913752939_0060_m_000000_60' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-f63f1209-68f1-4709-88b9-b001d528d7c8/_temporary/0/task_202306241510416476917328913752939_0060_m_000000\n",
      "23/06/24 15:10:43 INFO SparkHadoopMapRedUtil: attempt_202306241510416476917328913752939_0060_m_000000_60: Committed. Elapsed time: 576 ms.\n",
      "23/06/24 15:10:43 INFO Executor: Finished task 0.0 in stage 60.0 (TID 60). 2579 bytes result sent to driver\n",
      "23/06/24 15:10:43 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 60) in 1570 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:10:43 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:10:43 INFO DAGScheduler: ResultStage 60 (start at NativeMethodAccessorImpl.java:0) finished in 1.608 s\n",
      "23/06/24 15:10:43 INFO DAGScheduler: Job 60 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:10:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 60: Stage finished\n",
      "23/06/24 15:10:43 INFO DAGScheduler: Job 60 finished: start at NativeMethodAccessorImpl.java:0, took 1.611685 s\n",
      "23/06/24 15:10:43 INFO FileFormatWriter: Start to commit write Job 42c6a6d6-404b-43af-9e8c-a3f99e7c6fa6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:10:44 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-f63f1209-68f1-4709-88b9-b001d528d7c8/_temporary/0/task_202306241510416476917328913752939_0060_m_000000/' directory.\n",
      "23/06/24 15:10:44 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-f63f1209-68f1-4709-88b9-b001d528d7c8/' directory.\n",
      "23/06/24 15:10:44 INFO BlockManagerInfo: Removed broadcast_60_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:10:44 INFO BlockManagerInfo: Removed broadcast_59_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:10:45 INFO FileFormatWriter: Write Job 42c6a6d6-404b-43af-9e8c-a3f99e7c6fa6 committed. Elapsed time: 1571 ms.\n",
      "23/06/24 15:10:45 INFO FileFormatWriter: Finished processing stats for write job 42c6a6d6-404b-43af-9e8c-a3f99e7c6fa6.\n",
      "23/06/24 15:10:45 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-f63f1209-68f1-4709-88b9-b001d528d7c8/part-00000-73886524-45b8-4ac1-8208-455d7f688713-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=0070cec5-84d2-4dad-b976-a96cc353bea0, location=US}\n",
      "23/06/24 15:10:47 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=0070cec5-84d2-4dad-b976-a96cc353bea0, location=US}\n",
      "23/06/24 15:10:47 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/264 using temp file gs://kafka-spark-data/spark-metadata/commits/.264.2be3bace-ca1d-4679-9faf-19bfc5787b39.tmp\n",
      "23/06/24 15:10:48 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.264.2be3bace-ca1d-4679-9faf-19bfc5787b39.tmp to gs://kafka-spark-data/spark-metadata/commits/264\n",
      "23/06/24 15:10:48 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:10:40.007Z\",\n",
      "  \"batchId\" : 264,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.1998800719568259,\n",
      "  \"processedRowsPerSecond\" : 0.22917382834880257,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6305,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 17,\n",
      "    \"queryPlanning\" : 27,\n",
      "    \"triggerExecution\" : 8727,\n",
      "    \"walCommit\" : 1441\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4955\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4957\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.1998800719568259,\n",
      "    \"processedRowsPerSecond\" : 0.22917382834880257\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:10:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:10:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4959.\n",
      "23/06/24 15:10:50 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/265 using temp file gs://kafka-spark-data/spark-metadata/offsets/.265.22975fd6-65ad-4ed1-8827-e4b93ccae8fe.tmp\n",
      "23/06/24 15:10:51 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.265.22975fd6-65ad-4ed1-8827-e4b93ccae8fe.tmp to gs://kafka-spark-data/spark-metadata/offsets/265\n",
      "23/06/24 15:10:51 INFO MicroBatchExecution: Committed offsets for batch 265. Metadata OffsetSeqMetadata(0,1687637450008,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:10:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:10:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:10:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:10:51 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:10:52 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:10:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:10:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:10:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:10:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:10:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:10:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:10:52 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:10:52 INFO DAGScheduler: Got job 61 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:10:52 INFO DAGScheduler: Final stage: ResultStage 61 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:10:52 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:10:52 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:10:52 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[433] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:10:52 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:10:52 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:10:52 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:10:52 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:10:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[433] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:10:52 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:10:52 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 61) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:10:52 INFO Executor: Running task 0.0 in stage 61.0 (TID 61)\n",
      "23/06/24 15:10:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:10:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:10:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:10:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:10:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:10:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:10:52 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:10:52 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:10:52 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:10:52 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:10:52 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:10:52 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:10:52 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:10:52 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4958 for partition ticketmaster-0\n",
      "23/06/24 15:10:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 61:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:10:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:10:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:10:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4960.\n",
      "23/06/24 15:10:53 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-05e2f041-8a10-4f99-b6ef-a7bd87815a7d/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:10:53 INFO FileOutputCommitter: Saved output of task 'attempt_202306241510523878378086516605187_0061_m_000000_61' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-05e2f041-8a10-4f99-b6ef-a7bd87815a7d/_temporary/0/task_202306241510523878378086516605187_0061_m_000000\n",
      "23/06/24 15:10:53 INFO SparkHadoopMapRedUtil: attempt_202306241510523878378086516605187_0061_m_000000_61: Committed. Elapsed time: 608 ms.\n",
      "23/06/24 15:10:53 INFO Executor: Finished task 0.0 in stage 61.0 (TID 61). 2579 bytes result sent to driver\n",
      "23/06/24 15:10:53 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 61) in 1516 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:10:53 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:10:53 INFO DAGScheduler: ResultStage 61 (start at NativeMethodAccessorImpl.java:0) finished in 1.546 s\n",
      "23/06/24 15:10:53 INFO DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:10:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 61: Stage finished\n",
      "23/06/24 15:10:53 INFO DAGScheduler: Job 61 finished: start at NativeMethodAccessorImpl.java:0, took 1.550794 s\n",
      "23/06/24 15:10:53 INFO FileFormatWriter: Start to commit write Job 92441a4c-70a1-4400-8269-a7439467beb8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:10:54 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-05e2f041-8a10-4f99-b6ef-a7bd87815a7d/_temporary/0/task_202306241510523878378086516605187_0061_m_000000/' directory.\n",
      "23/06/24 15:10:54 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-05e2f041-8a10-4f99-b6ef-a7bd87815a7d/' directory.\n",
      "23/06/24 15:10:55 INFO FileFormatWriter: Write Job 92441a4c-70a1-4400-8269-a7439467beb8 committed. Elapsed time: 1642 ms.\n",
      "23/06/24 15:10:55 INFO FileFormatWriter: Finished processing stats for write job 92441a4c-70a1-4400-8269-a7439467beb8.\n",
      "23/06/24 15:10:55 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-05e2f041-8a10-4f99-b6ef-a7bd87815a7d/part-00000-40cc4f13-ce60-4d85-af92-4913d422a36e-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=fbc4b70a-ef80-4d9f-b747-dabaee012eb9, location=US}\n",
      "23/06/24 15:10:57 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=fbc4b70a-ef80-4d9f-b747-dabaee012eb9, location=US}\n",
      "23/06/24 15:10:58 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/265 using temp file gs://kafka-spark-data/spark-metadata/commits/.265.46b3ac6c-d67b-4656-baa0-6444f3ca0dcb.tmp\n",
      "23/06/24 15:10:59 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.265.46b3ac6c-d67b-4656-baa0-6444f3ca0dcb.tmp to gs://kafka-spark-data/spark-metadata/commits/265\n",
      "23/06/24 15:10:59 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:10:50.000Z\",\n",
      "  \"batchId\" : 265,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.20014009806864805,\n",
      "  \"processedRowsPerSecond\" : 0.22007042253521128,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6196,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 8,\n",
      "    \"queryPlanning\" : 18,\n",
      "    \"triggerExecution\" : 9088,\n",
      "    \"walCommit\" : 1584\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4957\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4959\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.20014009806864805,\n",
      "    \"processedRowsPerSecond\" : 0.22007042253521128\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:11:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:11:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4961.\n",
      "23/06/24 15:11:00 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/266 using temp file gs://kafka-spark-data/spark-metadata/offsets/.266.d5538e65-8728-4b90-85ed-665078a765e6.tmp\n",
      "23/06/24 15:11:01 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.266.d5538e65-8728-4b90-85ed-665078a765e6.tmp to gs://kafka-spark-data/spark-metadata/offsets/266\n",
      "23/06/24 15:11:01 INFO MicroBatchExecution: Committed offsets for batch 266. Metadata OffsetSeqMetadata(0,1687637460012,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:11:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:11:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:11:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:11:01 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:11:01 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:11:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:11:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:11:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:11:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:11:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:11:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:11:01 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:11:01 INFO DAGScheduler: Got job 62 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:11:01 INFO DAGScheduler: Final stage: ResultStage 62 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:11:01 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:11:01 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:11:01 INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[440] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:11:01 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 295.4 KiB, free 433.7 MiB)\n",
      "23/06/24 15:11:01 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 433.6 MiB)\n",
      "23/06/24 15:11:01 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.2 MiB)\n",
      "23/06/24 15:11:01 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:11:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[440] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:11:01 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:11:01 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 62) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:11:01 INFO Executor: Running task 0.0 in stage 62.0 (TID 62)\n",
      "23/06/24 15:11:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:11:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:11:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:11:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:11:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:11:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:11:01 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:11:01 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:11:01 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:11:01 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:11:01 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:11:01 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:11:01 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:11:02 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4960 for partition ticketmaster-0\n",
      "23/06/24 15:11:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:11:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:11:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:11:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4962.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 62:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:11:02 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-945413e6-2915-4349-a875-502566ab1ff7/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:11:02 INFO FileOutputCommitter: Saved output of task 'attempt_202306241511017016306090372861541_0062_m_000000_62' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-945413e6-2915-4349-a875-502566ab1ff7/_temporary/0/task_202306241511017016306090372861541_0062_m_000000\n",
      "23/06/24 15:11:02 INFO SparkHadoopMapRedUtil: attempt_202306241511017016306090372861541_0062_m_000000_62: Committed. Elapsed time: 528 ms.\n",
      "23/06/24 15:11:02 INFO Executor: Finished task 0.0 in stage 62.0 (TID 62). 2536 bytes result sent to driver\n",
      "23/06/24 15:11:02 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 62) in 980 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:11:02 INFO DAGScheduler: ResultStage 62 (start at NativeMethodAccessorImpl.java:0) finished in 1.032 s\n",
      "23/06/24 15:11:02 INFO DAGScheduler: Job 62 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:11:02 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:11:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 62: Stage finished\n",
      "23/06/24 15:11:02 INFO DAGScheduler: Job 62 finished: start at NativeMethodAccessorImpl.java:0, took 1.035509 s\n",
      "23/06/24 15:11:02 INFO FileFormatWriter: Start to commit write Job 81e12be8-4682-4dd1-91c5-1ca33f8ad38a.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:11:03 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-945413e6-2915-4349-a875-502566ab1ff7/_temporary/0/task_202306241511017016306090372861541_0062_m_000000/' directory.\n",
      "23/06/24 15:11:03 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-945413e6-2915-4349-a875-502566ab1ff7/' directory.\n",
      "23/06/24 15:11:03 INFO BlockManagerInfo: Removed broadcast_62_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:11:04 INFO FileFormatWriter: Write Job 81e12be8-4682-4dd1-91c5-1ca33f8ad38a committed. Elapsed time: 1274 ms.\n",
      "23/06/24 15:11:04 INFO FileFormatWriter: Finished processing stats for write job 81e12be8-4682-4dd1-91c5-1ca33f8ad38a.\n",
      "23/06/24 15:11:04 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-945413e6-2915-4349-a875-502566ab1ff7/part-00000-7d11d4b5-2d12-42ad-ae07-01064d98fe84-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=586c50e7-3d48-4119-9793-58e16338614c, location=US}\n",
      "23/06/24 15:11:06 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=586c50e7-3d48-4119-9793-58e16338614c, location=US}\n",
      "23/06/24 15:11:07 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/266 using temp file gs://kafka-spark-data/spark-metadata/commits/.266.f574dd7d-4aae-4289-8d9a-ef5efb836a8e.tmp\n",
      "23/06/24 15:11:07 INFO BlockManagerInfo: Removed broadcast_61_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:11:07 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.266.f574dd7d-4aae-4289-8d9a-ef5efb836a8e.tmp to gs://kafka-spark-data/spark-metadata/commits/266\n",
      "23/06/24 15:11:07 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:11:00.008Z\",\n",
      "  \"batchId\" : 266,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.19984012789768188,\n",
      "  \"processedRowsPerSecond\" : 0.25549310168625444,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 5470,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 4,\n",
      "    \"queryPlanning\" : 4,\n",
      "    \"triggerExecution\" : 7828,\n",
      "    \"walCommit\" : 1407\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4959\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4961\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.19984012789768188,\n",
      "    \"processedRowsPerSecond\" : 0.25549310168625444\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:11:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:11:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4963.\n",
      "23/06/24 15:11:10 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/267 using temp file gs://kafka-spark-data/spark-metadata/offsets/.267.e64cb997-8df9-45e8-9ba4-0faba2e03867.tmp\n",
      "23/06/24 15:11:11 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.267.e64cb997-8df9-45e8-9ba4-0faba2e03867.tmp to gs://kafka-spark-data/spark-metadata/offsets/267\n",
      "23/06/24 15:11:11 INFO MicroBatchExecution: Committed offsets for batch 267. Metadata OffsetSeqMetadata(0,1687637470019,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:11:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:11:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:11:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:11:11 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:11:11 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:11:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:11:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:11:11 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:11:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:11:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:11:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:11:11 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:11:11 INFO DAGScheduler: Got job 63 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:11:11 INFO DAGScheduler: Final stage: ResultStage 63 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:11:11 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:11:11 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:11:11 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[447] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:11:11 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:11:11 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:11:11 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:11:11 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:11:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[447] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:11:11 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:11:11 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 63) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:11:11 INFO Executor: Running task 0.0 in stage 63.0 (TID 63)\n",
      "23/06/24 15:11:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:11:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:11:11 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:11:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:11:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:11:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:11:11 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:11:11 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:11:11 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:11:11 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:11:11 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:11:11 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:11:11 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:11:12 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4961 for partition ticketmaster-0\n",
      "23/06/24 15:11:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:11:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:11:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:11:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4963.\n",
      "23/06/24 15:11:12 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4962 for partition ticketmaster-0\n",
      "23/06/24 15:11:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:11:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:11:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:11:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4964.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 63:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:11:12 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-ab109096-b0ae-47a2-822c-81136f4f6bc6/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:11:12 INFO FileOutputCommitter: Saved output of task 'attempt_202306241511111005545729455595757_0063_m_000000_63' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-ab109096-b0ae-47a2-822c-81136f4f6bc6/_temporary/0/task_202306241511111005545729455595757_0063_m_000000\n",
      "23/06/24 15:11:12 INFO SparkHadoopMapRedUtil: attempt_202306241511111005545729455595757_0063_m_000000_63: Committed. Elapsed time: 534 ms.\n",
      "23/06/24 15:11:12 INFO Executor: Finished task 0.0 in stage 63.0 (TID 63). 2536 bytes result sent to driver\n",
      "23/06/24 15:11:12 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 63) in 1026 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:11:12 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:11:12 INFO DAGScheduler: ResultStage 63 (start at NativeMethodAccessorImpl.java:0) finished in 1.047 s\n",
      "23/06/24 15:11:12 INFO DAGScheduler: Job 63 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:11:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 63: Stage finished\n",
      "23/06/24 15:11:12 INFO DAGScheduler: Job 63 finished: start at NativeMethodAccessorImpl.java:0, took 1.051260 s\n",
      "23/06/24 15:11:12 INFO FileFormatWriter: Start to commit write Job 5784b325-5d61-4153-9c2f-00df87d71ec3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:11:13 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-ab109096-b0ae-47a2-822c-81136f4f6bc6/_temporary/0/task_202306241511111005545729455595757_0063_m_000000/' directory.\n",
      "23/06/24 15:11:14 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-ab109096-b0ae-47a2-822c-81136f4f6bc6/' directory.\n",
      "23/06/24 15:11:14 INFO BlockManagerInfo: Removed broadcast_63_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:11:14 INFO FileFormatWriter: Write Job 5784b325-5d61-4153-9c2f-00df87d71ec3 committed. Elapsed time: 1502 ms.\n",
      "23/06/24 15:11:14 INFO FileFormatWriter: Finished processing stats for write job 5784b325-5d61-4153-9c2f-00df87d71ec3.\n",
      "23/06/24 15:11:14 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-ab109096-b0ae-47a2-822c-81136f4f6bc6/part-00000-d71c9072-8348-4caa-8b5f-ebfee6649a46-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=a4e7bfcc-5b75-4106-b934-4a45d4568076, location=US}\n",
      "23/06/24 15:11:17 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=a4e7bfcc-5b75-4106-b934-4a45d4568076, location=US}\n",
      "23/06/24 15:11:18 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/267 using temp file gs://kafka-spark-data/spark-metadata/commits/.267.c1e17c34-8c04-4bc3-840a-989b7ee60583.tmp\n",
      "23/06/24 15:11:19 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.267.c1e17c34-8c04-4bc3-840a-989b7ee60583.tmp to gs://kafka-spark-data/spark-metadata/commits/267\n",
      "23/06/24 15:11:19 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:11:10.005Z\",\n",
      "  \"batchId\" : 267,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.20006001800540163,\n",
      "  \"processedRowsPerSecond\" : 0.21819768710451667,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6752,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 13,\n",
      "    \"queryPlanning\" : 19,\n",
      "    \"triggerExecution\" : 9165,\n",
      "    \"walCommit\" : 1370\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4961\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4963\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.20006001800540163,\n",
      "    \"processedRowsPerSecond\" : 0.21819768710451667\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:11:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:11:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4965.\n",
      "23/06/24 15:11:20 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/268 using temp file gs://kafka-spark-data/spark-metadata/offsets/.268.0dcc3b71-e51b-4312-bb82-a471a298ff2a.tmp\n",
      "23/06/24 15:11:21 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.268.0dcc3b71-e51b-4312-bb82-a471a298ff2a.tmp to gs://kafka-spark-data/spark-metadata/offsets/268\n",
      "23/06/24 15:11:21 INFO MicroBatchExecution: Committed offsets for batch 268. Metadata OffsetSeqMetadata(0,1687637480012,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:11:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:11:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:11:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:11:21 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:11:21 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:11:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:11:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:11:21 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:11:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:11:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:11:21 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:11:21 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:11:21 INFO DAGScheduler: Got job 64 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:11:21 INFO DAGScheduler: Final stage: ResultStage 64 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:11:21 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:11:21 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:11:21 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[454] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:11:21 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:11:21 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:11:21 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:11:21 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:11:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[454] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:11:21 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:11:21 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 64) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:11:21 INFO Executor: Running task 0.0 in stage 64.0 (TID 64)\n",
      "23/06/24 15:11:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:11:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:11:21 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:11:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:11:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:11:21 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:11:21 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:11:21 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:11:21 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:11:21 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:11:21 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:11:21 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:11:21 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:11:22 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4963 for partition ticketmaster-0\n",
      "23/06/24 15:11:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:11:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:11:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:11:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4965.\n",
      "23/06/24 15:11:22 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4964 for partition ticketmaster-0\n",
      "23/06/24 15:11:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:11:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:11:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:11:22 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4966.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 64:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:11:22 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-10f3d67d-4457-4057-a625-6d82eb042b9e/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:11:22 INFO FileOutputCommitter: Saved output of task 'attempt_202306241511218268767926889688222_0064_m_000000_64' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-10f3d67d-4457-4057-a625-6d82eb042b9e/_temporary/0/task_202306241511218268767926889688222_0064_m_000000\n",
      "23/06/24 15:11:22 INFO SparkHadoopMapRedUtil: attempt_202306241511218268767926889688222_0064_m_000000_64: Committed. Elapsed time: 528 ms.\n",
      "23/06/24 15:11:22 INFO Executor: Finished task 0.0 in stage 64.0 (TID 64). 2536 bytes result sent to driver\n",
      "23/06/24 15:11:22 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 64) in 1046 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:11:22 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:11:22 INFO DAGScheduler: ResultStage 64 (start at NativeMethodAccessorImpl.java:0) finished in 1.086 s\n",
      "23/06/24 15:11:22 INFO DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:11:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 64: Stage finished\n",
      "23/06/24 15:11:22 INFO DAGScheduler: Job 64 finished: start at NativeMethodAccessorImpl.java:0, took 1.089572 s\n",
      "23/06/24 15:11:22 INFO FileFormatWriter: Start to commit write Job 738b9256-8b57-485a-9f90-4048bad513e4.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:11:23 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-10f3d67d-4457-4057-a625-6d82eb042b9e/_temporary/0/task_202306241511218268767926889688222_0064_m_000000/' directory.\n",
      "23/06/24 15:11:23 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-10f3d67d-4457-4057-a625-6d82eb042b9e/' directory.\n",
      "23/06/24 15:11:24 INFO BlockManagerInfo: Removed broadcast_64_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:11:24 INFO FileFormatWriter: Write Job 738b9256-8b57-485a-9f90-4048bad513e4 committed. Elapsed time: 1351 ms.\n",
      "23/06/24 15:11:24 INFO FileFormatWriter: Finished processing stats for write job 738b9256-8b57-485a-9f90-4048bad513e4.\n",
      "23/06/24 15:11:24 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-10f3d67d-4457-4057-a625-6d82eb042b9e/part-00000-68e28aa7-6bf0-4c84-b14e-7097f64525e7-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=778ee57e-7148-45ab-9211-9959f89893eb, location=US}\n",
      "23/06/24 15:11:26 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=778ee57e-7148-45ab-9211-9959f89893eb, location=US}\n",
      "23/06/24 15:11:27 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/268 using temp file gs://kafka-spark-data/spark-metadata/commits/.268.95b6f704-1a95-4179-9c28-ea818b67c84c.tmp\n",
      "23/06/24 15:11:28 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.268.95b6f704-1a95-4179-9c28-ea818b67c84c.tmp to gs://kafka-spark-data/spark-metadata/commits/268\n",
      "23/06/24 15:11:28 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:11:20.004Z\",\n",
      "  \"batchId\" : 268,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.2000200020002,\n",
      "  \"processedRowsPerSecond\" : 0.2352664392424421,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 5844,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 6,\n",
      "    \"queryPlanning\" : 14,\n",
      "    \"triggerExecution\" : 8500,\n",
      "    \"walCommit\" : 1354\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4963\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4965\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.2000200020002,\n",
      "    \"processedRowsPerSecond\" : 0.2352664392424421\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:11:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:11:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4967.\n",
      "23/06/24 15:11:30 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/269 using temp file gs://kafka-spark-data/spark-metadata/offsets/.269.954bc5ad-bad4-40d0-8b55-86bbea0d16f8.tmp\n",
      "23/06/24 15:11:31 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.269.954bc5ad-bad4-40d0-8b55-86bbea0d16f8.tmp to gs://kafka-spark-data/spark-metadata/offsets/269\n",
      "23/06/24 15:11:31 INFO MicroBatchExecution: Committed offsets for batch 269. Metadata OffsetSeqMetadata(0,1687637490018,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:11:31 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:11:31 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:11:31 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:11:31 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:11:31 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:11:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:11:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:11:31 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:11:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:11:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:11:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:11:31 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:11:31 INFO DAGScheduler: Got job 65 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:11:31 INFO DAGScheduler: Final stage: ResultStage 65 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:11:31 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:11:31 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:11:31 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[461] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:11:31 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:11:31 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:11:31 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:11:31 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:11:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[461] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:11:31 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:11:31 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 65) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:11:31 INFO Executor: Running task 0.0 in stage 65.0 (TID 65)\n",
      "23/06/24 15:11:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:11:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:11:31 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:11:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:11:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:11:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:11:31 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:11:31 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:11:31 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:11:31 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:11:31 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:11:31 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:11:31 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:11:32 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4965 for partition ticketmaster-0\n",
      "23/06/24 15:11:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:11:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:11:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:11:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4967.\n",
      "23/06/24 15:11:32 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4966 for partition ticketmaster-0\n",
      "23/06/24 15:11:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:11:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:11:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:11:32 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4968.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 65:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:11:32 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-9ebe935f-5446-4dd2-a210-ee9af0058a0d/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:11:32 INFO FileOutputCommitter: Saved output of task 'attempt_20230624151131684836327619584411_0065_m_000000_65' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-9ebe935f-5446-4dd2-a210-ee9af0058a0d/_temporary/0/task_20230624151131684836327619584411_0065_m_000000\n",
      "23/06/24 15:11:32 INFO SparkHadoopMapRedUtil: attempt_20230624151131684836327619584411_0065_m_000000_65: Committed. Elapsed time: 545 ms.\n",
      "23/06/24 15:11:32 INFO Executor: Finished task 0.0 in stage 65.0 (TID 65). 2579 bytes result sent to driver\n",
      "23/06/24 15:11:32 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 65) in 1026 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:11:32 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:11:32 INFO DAGScheduler: ResultStage 65 (start at NativeMethodAccessorImpl.java:0) finished in 1.063 s\n",
      "23/06/24 15:11:32 INFO DAGScheduler: Job 65 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:11:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 65: Stage finished\n",
      "23/06/24 15:11:32 INFO DAGScheduler: Job 65 finished: start at NativeMethodAccessorImpl.java:0, took 1.064511 s\n",
      "23/06/24 15:11:32 INFO FileFormatWriter: Start to commit write Job 95c1af48-040b-45cc-b133-05ee439150df.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:11:33 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-9ebe935f-5446-4dd2-a210-ee9af0058a0d/_temporary/0/task_20230624151131684836327619584411_0065_m_000000/' directory.\n",
      "23/06/24 15:11:34 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-9ebe935f-5446-4dd2-a210-ee9af0058a0d/' directory.\n",
      "23/06/24 15:11:34 INFO BlockManagerInfo: Removed broadcast_65_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:11:34 INFO FileFormatWriter: Write Job 95c1af48-040b-45cc-b133-05ee439150df committed. Elapsed time: 1444 ms.\n",
      "23/06/24 15:11:34 INFO FileFormatWriter: Finished processing stats for write job 95c1af48-040b-45cc-b133-05ee439150df.\n",
      "23/06/24 15:11:35 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-9ebe935f-5446-4dd2-a210-ee9af0058a0d/part-00000-521e4f80-3fa1-4314-9df3-c214d80509c0-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=b53b3d31-0f90-47cf-933f-48fb31a534cc, location=US}\n",
      "23/06/24 15:11:36 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=b53b3d31-0f90-47cf-933f-48fb31a534cc, location=US}\n",
      "23/06/24 15:11:36 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/269 using temp file gs://kafka-spark-data/spark-metadata/commits/.269.195cc224-7761-4813-95b4-b437fe66b731.tmp\n",
      "23/06/24 15:11:37 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.269.195cc224-7761-4813-95b4-b437fe66b731.tmp to gs://kafka-spark-data/spark-metadata/commits/269\n",
      "23/06/24 15:11:37 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:11:30.005Z\",\n",
      "  \"batchId\" : 269,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.19998000199980004,\n",
      "  \"processedRowsPerSecond\" : 0.2629503023928478,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 5254,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 13,\n",
      "    \"queryPlanning\" : 13,\n",
      "    \"triggerExecution\" : 7606,\n",
      "    \"walCommit\" : 1379\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4965\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4967\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.19998000199980004,\n",
      "    \"processedRowsPerSecond\" : 0.2629503023928478\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:11:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:11:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4969.\n",
      "23/06/24 15:11:40 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/270 using temp file gs://kafka-spark-data/spark-metadata/offsets/.270.ae97ea5b-9aa9-4987-aa4b-8fbabe407a4f.tmp\n",
      "23/06/24 15:11:41 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.270.ae97ea5b-9aa9-4987-aa4b-8fbabe407a4f.tmp to gs://kafka-spark-data/spark-metadata/offsets/270\n",
      "23/06/24 15:11:41 INFO MicroBatchExecution: Committed offsets for batch 270. Metadata OffsetSeqMetadata(0,1687637500009,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:11:42 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:11:42 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:11:42 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:11:42 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:11:42 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:11:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:11:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:11:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:11:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:11:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:11:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:11:43 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:11:43 INFO DAGScheduler: Got job 66 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:11:43 INFO DAGScheduler: Final stage: ResultStage 66 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:11:43 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:11:43 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:11:43 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[468] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:11:43 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:11:43 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:11:43 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:11:43 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:11:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[468] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:11:43 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:11:43 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 66) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:11:43 INFO Executor: Running task 0.0 in stage 66.0 (TID 66)\n",
      "23/06/24 15:11:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:11:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:11:43 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:11:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:11:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:11:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:11:43 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:11:43 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:11:43 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:11:43 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:11:43 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:11:43 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:11:43 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:11:43 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4967 for partition ticketmaster-0\n",
      "23/06/24 15:11:43 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:11:43 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:11:43 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:11:43 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4970.\n",
      "23/06/24 15:11:43 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4968 for partition ticketmaster-0\n",
      "23/06/24 15:11:43 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 66:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:11:44 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:11:44 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:11:44 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4970.\n",
      "23/06/24 15:11:45 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-e91e051d-1eac-4850-bf39-c4bc6c51990d/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:11:45 INFO FileOutputCommitter: Saved output of task 'attempt_202306241511437093691318813860133_0066_m_000000_66' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-e91e051d-1eac-4850-bf39-c4bc6c51990d/_temporary/0/task_202306241511437093691318813860133_0066_m_000000\n",
      "23/06/24 15:11:45 INFO SparkHadoopMapRedUtil: attempt_202306241511437093691318813860133_0066_m_000000_66: Committed. Elapsed time: 866 ms.\n",
      "23/06/24 15:11:45 INFO Executor: Finished task 0.0 in stage 66.0 (TID 66). 2579 bytes result sent to driver\n",
      "23/06/24 15:11:45 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 66) in 1979 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:11:45 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:11:45 INFO DAGScheduler: ResultStage 66 (start at NativeMethodAccessorImpl.java:0) finished in 2.020 s\n",
      "23/06/24 15:11:45 INFO DAGScheduler: Job 66 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:11:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 66: Stage finished\n",
      "23/06/24 15:11:45 INFO DAGScheduler: Job 66 finished: start at NativeMethodAccessorImpl.java:0, took 2.024757 s\n",
      "23/06/24 15:11:45 INFO FileFormatWriter: Start to commit write Job 7da1f61a-f44f-4455-b54b-df7e88f2b974.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:11:46 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-e91e051d-1eac-4850-bf39-c4bc6c51990d/_temporary/0/task_202306241511437093691318813860133_0066_m_000000/' directory.\n",
      "23/06/24 15:11:47 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-e91e051d-1eac-4850-bf39-c4bc6c51990d/' directory.\n",
      "23/06/24 15:11:47 INFO FileFormatWriter: Write Job 7da1f61a-f44f-4455-b54b-df7e88f2b974 committed. Elapsed time: 2285 ms.\n",
      "23/06/24 15:11:47 INFO FileFormatWriter: Finished processing stats for write job 7da1f61a-f44f-4455-b54b-df7e88f2b974.\n",
      "23/06/24 15:11:48 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-e91e051d-1eac-4850-bf39-c4bc6c51990d/part-00000-415f988e-4efe-4ae9-9949-b5ca10d5caa9-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=396ad4a8-8005-4684-b49f-1e811fea8121, location=US}\n",
      "23/06/24 15:11:51 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=396ad4a8-8005-4684-b49f-1e811fea8121, location=US}\n",
      "23/06/24 15:11:51 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/270 using temp file gs://kafka-spark-data/spark-metadata/commits/.270.7ba3b349-cc2e-4b23-8f1a-b5bc455fea97.tmp\n",
      "23/06/24 15:11:52 INFO BlockManagerInfo: Removed broadcast_66_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:11:53 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.270.7ba3b349-cc2e-4b23-8f1a-b5bc455fea97.tmp to gs://kafka-spark-data/spark-metadata/commits/270\n",
      "23/06/24 15:11:53 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:11:40.005Z\",\n",
      "  \"batchId\" : 270,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.2,\n",
      "  \"processedRowsPerSecond\" : 0.15121729925903524,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 9206,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 4,\n",
      "    \"queryPlanning\" : 26,\n",
      "    \"triggerExecution\" : 13226,\n",
      "    \"walCommit\" : 2350\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4967\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4969\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.2,\n",
      "    \"processedRowsPerSecond\" : 0.15121729925903524\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:11:53 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 13228 milliseconds\n",
      "23/06/24 15:11:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:11:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4972.\n",
      "23/06/24 15:11:53 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/271 using temp file gs://kafka-spark-data/spark-metadata/offsets/.271.b2155e57-9515-4640-9d2a-ac71e2d9ca84.tmp\n",
      "23/06/24 15:11:54 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.271.b2155e57-9515-4640-9d2a-ac71e2d9ca84.tmp to gs://kafka-spark-data/spark-metadata/offsets/271\n",
      "23/06/24 15:11:54 INFO MicroBatchExecution: Committed offsets for batch 271. Metadata OffsetSeqMetadata(0,1687637513237,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:11:55 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:11:55 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:11:55 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:11:55 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:11:55 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:11:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:11:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:11:55 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:11:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:11:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:11:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:11:55 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:11:55 INFO DAGScheduler: Got job 67 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:11:55 INFO DAGScheduler: Final stage: ResultStage 67 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:11:55 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:11:55 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:11:55 INFO DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[475] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:11:55 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:11:55 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:11:55 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:11:55 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:11:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[475] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:11:55 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:11:55 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 67) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:11:55 INFO Executor: Running task 0.0 in stage 67.0 (TID 67)\n",
      "23/06/24 15:11:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:11:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:11:55 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:11:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:11:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:11:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:11:55 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:11:55 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:11:55 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:11:55 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:11:55 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:11:55 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:11:55 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:11:56 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4970 for partition ticketmaster-0\n",
      "23/06/24 15:11:56 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 67:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:11:56 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:11:56 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:11:56 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4972.\n",
      "23/06/24 15:11:57 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-037c0342-d7ed-4442-a3bc-123698813315/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:11:57 INFO FileOutputCommitter: Saved output of task 'attempt_202306241511554146628160077348318_0067_m_000000_67' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-037c0342-d7ed-4442-a3bc-123698813315/_temporary/0/task_202306241511554146628160077348318_0067_m_000000\n",
      "23/06/24 15:11:57 INFO SparkHadoopMapRedUtil: attempt_202306241511554146628160077348318_0067_m_000000_67: Committed. Elapsed time: 935 ms.\n",
      "23/06/24 15:11:57 INFO Executor: Finished task 0.0 in stage 67.0 (TID 67). 2536 bytes result sent to driver\n",
      "23/06/24 15:11:57 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 67) in 2100 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:11:57 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:11:57 INFO DAGScheduler: ResultStage 67 (start at NativeMethodAccessorImpl.java:0) finished in 2.145 s\n",
      "23/06/24 15:11:57 INFO DAGScheduler: Job 67 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:11:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 67: Stage finished\n",
      "23/06/24 15:11:57 INFO DAGScheduler: Job 67 finished: start at NativeMethodAccessorImpl.java:0, took 2.146933 s\n",
      "23/06/24 15:11:57 INFO FileFormatWriter: Start to commit write Job 80681e1e-171f-4f74-8478-18819cd3ca08.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:11:58 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-037c0342-d7ed-4442-a3bc-123698813315/_temporary/0/task_202306241511554146628160077348318_0067_m_000000/' directory.\n",
      "23/06/24 15:11:59 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-037c0342-d7ed-4442-a3bc-123698813315/' directory.\n",
      "23/06/24 15:11:59 INFO FileFormatWriter: Write Job 80681e1e-171f-4f74-8478-18819cd3ca08 committed. Elapsed time: 1940 ms.\n",
      "23/06/24 15:11:59 INFO FileFormatWriter: Finished processing stats for write job 80681e1e-171f-4f74-8478-18819cd3ca08.\n",
      "23/06/24 15:12:00 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-037c0342-d7ed-4442-a3bc-123698813315/part-00000-63af032e-342a-4eab-8d1f-fa8083668643-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=194cfd57-6dc7-467a-9226-7365ec55199f, location=US}\n",
      "23/06/24 15:12:02 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=194cfd57-6dc7-467a-9226-7365ec55199f, location=US}\n",
      "23/06/24 15:12:03 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/271 using temp file gs://kafka-spark-data/spark-metadata/commits/.271.5e27ec60-f0ee-4123-9b60-0d5e554b3c09.tmp\n",
      "23/06/24 15:12:04 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.271.5e27ec60-f0ee-4123-9b60-0d5e554b3c09.tmp to gs://kafka-spark-data/spark-metadata/commits/271\n",
      "23/06/24 15:12:04 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:11:53.232Z\",\n",
      "  \"batchId\" : 271,\n",
      "  \"numInputRows\" : 3,\n",
      "  \"inputRowsPerSecond\" : 0.22680880018144703,\n",
      "  \"processedRowsPerSecond\" : 0.26260504201680673,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7864,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 5,\n",
      "    \"queryPlanning\" : 29,\n",
      "    \"triggerExecution\" : 11424,\n",
      "    \"walCommit\" : 1952\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4969\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4972\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 3,\n",
      "    \"inputRowsPerSecond\" : 0.22680880018144703,\n",
      "    \"processedRowsPerSecond\" : 0.26260504201680673\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:12:04 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 11425 milliseconds\n",
      "23/06/24 15:12:04 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:12:04 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4974.\n",
      "23/06/24 15:12:04 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/272 using temp file gs://kafka-spark-data/spark-metadata/offsets/.272.f775ac0b-1be9-4137-81ed-7854b058c19f.tmp\n",
      "23/06/24 15:12:06 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.272.f775ac0b-1be9-4137-81ed-7854b058c19f.tmp to gs://kafka-spark-data/spark-metadata/offsets/272\n",
      "23/06/24 15:12:06 INFO MicroBatchExecution: Committed offsets for batch 272. Metadata OffsetSeqMetadata(0,1687637524663,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:12:06 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:12:06 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:12:06 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:12:06 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:12:07 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:12:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:12:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:12:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:12:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:12:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:12:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:12:07 INFO BlockManagerInfo: Removed broadcast_67_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:12:07 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:12:07 INFO DAGScheduler: Got job 68 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:12:07 INFO DAGScheduler: Final stage: ResultStage 68 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:12:07 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:12:07 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:12:07 INFO DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[482] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:12:07 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:12:07 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:12:07 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:12:07 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:12:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 68 (MapPartitionsRDD[482] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:12:07 INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:12:07 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 68) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:12:07 INFO Executor: Running task 0.0 in stage 68.0 (TID 68)\n",
      "23/06/24 15:12:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:12:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:12:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:12:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:12:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:12:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:12:07 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:12:07 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:12:07 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:12:07 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:12:07 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:12:07 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:12:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:12:07 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4972 for partition ticketmaster-0\n",
      "23/06/24 15:12:07 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 68:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:12:08 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:12:08 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:12:08 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4975.\n",
      "23/06/24 15:12:09 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-b8f5187d-d58b-49c0-9aa3-4a5af86df2bf/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:12:09 INFO FileOutputCommitter: Saved output of task 'attempt_202306241512072230407177462105491_0068_m_000000_68' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-b8f5187d-d58b-49c0-9aa3-4a5af86df2bf/_temporary/0/task_202306241512072230407177462105491_0068_m_000000\n",
      "23/06/24 15:12:09 INFO SparkHadoopMapRedUtil: attempt_202306241512072230407177462105491_0068_m_000000_68: Committed. Elapsed time: 848 ms.\n",
      "23/06/24 15:12:09 INFO Executor: Finished task 0.0 in stage 68.0 (TID 68). 2579 bytes result sent to driver\n",
      "23/06/24 15:12:09 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 68) in 2021 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:12:09 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:12:09 INFO DAGScheduler: ResultStage 68 (start at NativeMethodAccessorImpl.java:0) finished in 2.044 s\n",
      "23/06/24 15:12:09 INFO DAGScheduler: Job 68 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:12:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 68: Stage finished\n",
      "23/06/24 15:12:09 INFO DAGScheduler: Job 68 finished: start at NativeMethodAccessorImpl.java:0, took 2.044674 s\n",
      "23/06/24 15:12:09 INFO FileFormatWriter: Start to commit write Job db1673c5-b20e-433f-9f3c-73bb4743a427.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:12:10 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-b8f5187d-d58b-49c0-9aa3-4a5af86df2bf/_temporary/0/task_202306241512072230407177462105491_0068_m_000000/' directory.\n",
      "23/06/24 15:12:11 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-b8f5187d-d58b-49c0-9aa3-4a5af86df2bf/' directory.\n",
      "23/06/24 15:12:11 INFO BlockManagerInfo: Removed broadcast_68_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:12:11 INFO FileFormatWriter: Write Job db1673c5-b20e-433f-9f3c-73bb4743a427 committed. Elapsed time: 2200 ms.\n",
      "23/06/24 15:12:11 INFO FileFormatWriter: Finished processing stats for write job db1673c5-b20e-433f-9f3c-73bb4743a427.\n",
      "23/06/24 15:12:12 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-b8f5187d-d58b-49c0-9aa3-4a5af86df2bf/part-00000-ca0ddf37-190b-47e8-8a29-33bdcf006585-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=8b701ba7-0cca-4361-a858-7c18069efe01, location=US}\n",
      "23/06/24 15:12:14 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=8b701ba7-0cca-4361-a858-7c18069efe01, location=US}\n",
      "23/06/24 15:12:14 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/272 using temp file gs://kafka-spark-data/spark-metadata/commits/.272.6fbd3d96-fb10-4e98-a441-71be98fc53d3.tmp\n",
      "23/06/24 15:12:16 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.272.6fbd3d96-fb10-4e98-a441-71be98fc53d3.tmp to gs://kafka-spark-data/spark-metadata/commits/272\n",
      "23/06/24 15:12:16 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:12:04.657Z\",\n",
      "  \"batchId\" : 272,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.175054704595186,\n",
      "  \"processedRowsPerSecond\" : 0.17132088401576154,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7616,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 6,\n",
      "    \"queryPlanning\" : 12,\n",
      "    \"triggerExecution\" : 11674,\n",
      "    \"walCommit\" : 2144\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4972\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4974\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.175054704595186,\n",
      "    \"processedRowsPerSecond\" : 0.17132088401576154\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:12:16 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 11675 milliseconds\n",
      "23/06/24 15:12:16 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:12:16 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4976.\n",
      "23/06/24 15:12:16 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/273 using temp file gs://kafka-spark-data/spark-metadata/offsets/.273.d01e11d5-cb5e-4507-88b4-220693158955.tmp\n",
      "23/06/24 15:12:17 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.273.d01e11d5-cb5e-4507-88b4-220693158955.tmp to gs://kafka-spark-data/spark-metadata/offsets/273\n",
      "23/06/24 15:12:17 INFO MicroBatchExecution: Committed offsets for batch 273. Metadata OffsetSeqMetadata(0,1687637536334,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:12:18 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:12:18 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:12:18 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:12:18 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:12:18 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:12:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:12:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:12:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:12:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:12:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:12:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:12:18 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:12:18 INFO DAGScheduler: Got job 69 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:12:18 INFO DAGScheduler: Final stage: ResultStage 69 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:12:18 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:12:18 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:12:18 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[489] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:12:19 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:12:19 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:12:19 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:12:19 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:12:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[489] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:12:19 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:12:19 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 69) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:12:19 INFO Executor: Running task 0.0 in stage 69.0 (TID 69)\n",
      "23/06/24 15:12:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:12:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:12:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:12:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:12:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:12:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:12:19 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:12:19 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:12:19 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:12:19 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:12:19 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:12:19 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:12:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:12:19 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4975 for partition ticketmaster-0\n",
      "23/06/24 15:12:19 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 69:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:12:19 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:12:19 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:12:19 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4977.\n",
      "23/06/24 15:12:21 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-2efb1eb8-da2b-429a-9679-6acf76d21b1a/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:12:21 INFO FileOutputCommitter: Saved output of task 'attempt_202306241512181461415189239938818_0069_m_000000_69' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-2efb1eb8-da2b-429a-9679-6acf76d21b1a/_temporary/0/task_202306241512181461415189239938818_0069_m_000000\n",
      "23/06/24 15:12:21 INFO SparkHadoopMapRedUtil: attempt_202306241512181461415189239938818_0069_m_000000_69: Committed. Elapsed time: 892 ms.\n",
      "23/06/24 15:12:21 INFO Executor: Finished task 0.0 in stage 69.0 (TID 69). 2536 bytes result sent to driver\n",
      "23/06/24 15:12:21 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 69) in 2036 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:12:21 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:12:21 INFO DAGScheduler: ResultStage 69 (start at NativeMethodAccessorImpl.java:0) finished in 2.075 s\n",
      "23/06/24 15:12:21 INFO DAGScheduler: Job 69 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:12:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 69: Stage finished\n",
      "23/06/24 15:12:21 INFO DAGScheduler: Job 69 finished: start at NativeMethodAccessorImpl.java:0, took 2.076851 s\n",
      "23/06/24 15:12:21 INFO FileFormatWriter: Start to commit write Job c3bbceb9-6002-4e00-be8d-76202b6831fe.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:12:21 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-2efb1eb8-da2b-429a-9679-6acf76d21b1a/_temporary/0/task_202306241512181461415189239938818_0069_m_000000/' directory.\n",
      "23/06/24 15:12:22 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-2efb1eb8-da2b-429a-9679-6acf76d21b1a/' directory.\n",
      "23/06/24 15:12:23 INFO FileFormatWriter: Write Job c3bbceb9-6002-4e00-be8d-76202b6831fe committed. Elapsed time: 2151 ms.\n",
      "23/06/24 15:12:23 INFO FileFormatWriter: Finished processing stats for write job c3bbceb9-6002-4e00-be8d-76202b6831fe.\n",
      "23/06/24 15:12:23 INFO BlockManagerInfo: Removed broadcast_69_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:12:23 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-2efb1eb8-da2b-429a-9679-6acf76d21b1a/part-00000-12f1fda0-be97-40ba-8454-0ee8b49b905a-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=98611357-db26-4d7e-9ab7-05d1ceea0bf7, location=US}\n",
      "23/06/24 15:12:25 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=98611357-db26-4d7e-9ab7-05d1ceea0bf7, location=US}\n",
      "23/06/24 15:12:25 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/273 using temp file gs://kafka-spark-data/spark-metadata/commits/.273.5c996035-ceda-4f69-954b-014e4018e9d7.tmp\n",
      "23/06/24 15:12:27 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.273.5c996035-ceda-4f69-954b-014e4018e9d7.tmp to gs://kafka-spark-data/spark-metadata/commits/273\n",
      "23/06/24 15:12:27 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:12:16.332Z\",\n",
      "  \"batchId\" : 273,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.17130620985010706,\n",
      "  \"processedRowsPerSecond\" : 0.17919541259743751,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6934,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 2,\n",
      "    \"queryPlanning\" : 24,\n",
      "    \"triggerExecution\" : 11161,\n",
      "    \"walCommit\" : 2091\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4974\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4976\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.17130620985010706,\n",
      "    \"processedRowsPerSecond\" : 0.17919541259743751\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:12:27 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 11163 milliseconds\n",
      "23/06/24 15:12:27 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:12:27 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4979.\n",
      "23/06/24 15:12:27 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/274 using temp file gs://kafka-spark-data/spark-metadata/offsets/.274.ecab6cc1-db31-4973-8578-6491f26e3faf.tmp\n",
      "23/06/24 15:12:29 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.274.ecab6cc1-db31-4973-8578-6491f26e3faf.tmp to gs://kafka-spark-data/spark-metadata/offsets/274\n",
      "23/06/24 15:12:29 INFO MicroBatchExecution: Committed offsets for batch 274. Metadata OffsetSeqMetadata(0,1687637547504,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:12:29 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:12:29 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:12:29 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:12:29 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:12:30 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:12:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:12:30 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:12:30 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:12:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:12:30 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:12:30 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:12:30 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:12:30 INFO DAGScheduler: Got job 70 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:12:30 INFO DAGScheduler: Final stage: ResultStage 70 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:12:30 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:12:30 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:12:30 INFO DAGScheduler: Submitting ResultStage 70 (MapPartitionsRDD[496] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:12:30 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:12:30 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:12:30 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:12:30 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:12:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 70 (MapPartitionsRDD[496] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:12:30 INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:12:30 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 70) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:12:30 INFO Executor: Running task 0.0 in stage 70.0 (TID 70)\n",
      "23/06/24 15:12:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:12:30 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:12:30 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:12:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:12:30 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:12:30 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:12:30 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:12:30 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:12:30 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:12:30 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:12:30 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:12:30 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:12:30 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:12:30 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4977 for partition ticketmaster-0\n",
      "23/06/24 15:12:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 70:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:12:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:12:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:12:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4979.\n",
      "23/06/24 15:12:32 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c616309e-c7b1-4d54-9f6a-41a4a6aabba1/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:12:32 INFO FileOutputCommitter: Saved output of task 'attempt_202306241512302128865514463358877_0070_m_000000_70' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c616309e-c7b1-4d54-9f6a-41a4a6aabba1/_temporary/0/task_202306241512302128865514463358877_0070_m_000000\n",
      "23/06/24 15:12:32 INFO SparkHadoopMapRedUtil: attempt_202306241512302128865514463358877_0070_m_000000_70: Committed. Elapsed time: 956 ms.\n",
      "23/06/24 15:12:32 INFO Executor: Finished task 0.0 in stage 70.0 (TID 70). 2536 bytes result sent to driver\n",
      "23/06/24 15:12:32 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 70) in 2105 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:12:32 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:12:32 INFO DAGScheduler: ResultStage 70 (start at NativeMethodAccessorImpl.java:0) finished in 2.149 s\n",
      "23/06/24 15:12:32 INFO DAGScheduler: Job 70 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:12:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 70: Stage finished\n",
      "23/06/24 15:12:32 INFO DAGScheduler: Job 70 finished: start at NativeMethodAccessorImpl.java:0, took 2.153428 s\n",
      "23/06/24 15:12:32 INFO FileFormatWriter: Start to commit write Job eceacf36-e14b-45fc-9265-f1a8628efaa6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:12:33 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c616309e-c7b1-4d54-9f6a-41a4a6aabba1/_temporary/0/task_202306241512302128865514463358877_0070_m_000000/' directory.\n",
      "23/06/24 15:12:34 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c616309e-c7b1-4d54-9f6a-41a4a6aabba1/' directory.\n",
      "23/06/24 15:12:34 INFO FileFormatWriter: Write Job eceacf36-e14b-45fc-9265-f1a8628efaa6 committed. Elapsed time: 2123 ms.\n",
      "23/06/24 15:12:34 INFO FileFormatWriter: Finished processing stats for write job eceacf36-e14b-45fc-9265-f1a8628efaa6.\n",
      "23/06/24 15:12:34 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c616309e-c7b1-4d54-9f6a-41a4a6aabba1/part-00000-65db7f0b-f2c2-4e88-bdd6-58b5a96fe567-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=23d5dcd7-4356-44bb-873f-6da9162dcbbd, location=US}\n",
      "23/06/24 15:12:37 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=23d5dcd7-4356-44bb-873f-6da9162dcbbd, location=US}\n",
      "23/06/24 15:12:37 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/274 using temp file gs://kafka-spark-data/spark-metadata/commits/.274.07500e2c-eff8-4949-9c3a-95ffcb99a4a2.tmp\n",
      "23/06/24 15:12:38 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.274.07500e2c-eff8-4949-9c3a-95ffcb99a4a2.tmp to gs://kafka-spark-data/spark-metadata/commits/274\n",
      "23/06/24 15:12:38 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:12:27.495Z\",\n",
      "  \"batchId\" : 274,\n",
      "  \"numInputRows\" : 3,\n",
      "  \"inputRowsPerSecond\" : 0.26874496103198064,\n",
      "  \"processedRowsPerSecond\" : 0.26445698166431597,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7710,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 9,\n",
      "    \"queryPlanning\" : 16,\n",
      "    \"triggerExecution\" : 11344,\n",
      "    \"walCommit\" : 2186\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4976\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4979\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 3,\n",
      "    \"inputRowsPerSecond\" : 0.26874496103198064,\n",
      "    \"processedRowsPerSecond\" : 0.26445698166431597\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:12:38 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 11346 milliseconds\n",
      "23/06/24 15:12:38 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:12:38 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4981.\n",
      "23/06/24 15:12:39 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/275 using temp file gs://kafka-spark-data/spark-metadata/offsets/.275.555e38cf-fb0b-46bd-8e38-035de8161251.tmp\n",
      "23/06/24 15:12:40 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.275.555e38cf-fb0b-46bd-8e38-035de8161251.tmp to gs://kafka-spark-data/spark-metadata/offsets/275\n",
      "23/06/24 15:12:40 INFO MicroBatchExecution: Committed offsets for batch 275. Metadata OffsetSeqMetadata(0,1687637558855,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:12:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:12:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:12:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:12:40 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:12:41 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:12:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:12:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:12:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:12:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:12:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:12:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:12:41 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:12:41 INFO DAGScheduler: Got job 71 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:12:41 INFO DAGScheduler: Final stage: ResultStage 71 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:12:41 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:12:41 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:12:41 INFO DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[503] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:12:41 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 295.4 KiB, free 433.7 MiB)\n",
      "23/06/24 15:12:41 INFO BlockManagerInfo: Removed broadcast_70_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:12:41 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:12:41 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:12:41 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:12:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 71 (MapPartitionsRDD[503] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:12:41 INFO TaskSchedulerImpl: Adding task set 71.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:12:41 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 71) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:12:41 INFO Executor: Running task 0.0 in stage 71.0 (TID 71)\n",
      "23/06/24 15:12:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:12:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:12:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:12:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:12:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:12:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:12:41 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:12:41 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:12:41 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:12:41 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:12:41 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:12:41 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:12:41 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:12:41 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4979 for partition ticketmaster-0\n",
      "23/06/24 15:12:41 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 71:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:12:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:12:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:12:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4982.\n",
      "23/06/24 15:12:43 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-bbba369f-bb21-4f2d-80b3-19c64a401880/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:12:43 INFO FileOutputCommitter: Saved output of task 'attempt_202306241512417936312280002324320_0071_m_000000_71' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-bbba369f-bb21-4f2d-80b3-19c64a401880/_temporary/0/task_202306241512417936312280002324320_0071_m_000000\n",
      "23/06/24 15:12:43 INFO SparkHadoopMapRedUtil: attempt_202306241512417936312280002324320_0071_m_000000_71: Committed. Elapsed time: 829 ms.\n",
      "23/06/24 15:12:43 INFO Executor: Finished task 0.0 in stage 71.0 (TID 71). 2579 bytes result sent to driver\n",
      "23/06/24 15:12:43 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 71) in 1861 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:12:43 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:12:43 INFO DAGScheduler: ResultStage 71 (start at NativeMethodAccessorImpl.java:0) finished in 1.903 s\n",
      "23/06/24 15:12:43 INFO DAGScheduler: Job 71 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:12:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 71: Stage finished\n",
      "23/06/24 15:12:43 INFO DAGScheduler: Job 71 finished: start at NativeMethodAccessorImpl.java:0, took 1.906928 s\n",
      "23/06/24 15:12:43 INFO FileFormatWriter: Start to commit write Job d01751d2-d3db-4d80-a8d7-decc0c4c8d09.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:12:44 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-bbba369f-bb21-4f2d-80b3-19c64a401880/_temporary/0/task_202306241512417936312280002324320_0071_m_000000/' directory.\n",
      "23/06/24 15:12:45 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-bbba369f-bb21-4f2d-80b3-19c64a401880/' directory.\n",
      "23/06/24 15:12:45 INFO FileFormatWriter: Write Job d01751d2-d3db-4d80-a8d7-decc0c4c8d09 committed. Elapsed time: 2038 ms.\n",
      "23/06/24 15:12:45 INFO FileFormatWriter: Finished processing stats for write job d01751d2-d3db-4d80-a8d7-decc0c4c8d09.\n",
      "23/06/24 15:12:45 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-bbba369f-bb21-4f2d-80b3-19c64a401880/part-00000-1ecda7f2-0b21-4c75-acab-00cce2d17020-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=12433d42-3b2a-42ab-9de0-b88919c7015e, location=US}\n",
      "23/06/24 15:12:48 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=12433d42-3b2a-42ab-9de0-b88919c7015e, location=US}\n",
      "23/06/24 15:12:49 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/275 using temp file gs://kafka-spark-data/spark-metadata/commits/.275.3613239d-d9ea-45ec-b35f-3e1f0c6754ae.tmp\n",
      "23/06/24 15:12:50 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.275.3613239d-d9ea-45ec-b35f-3e1f0c6754ae.tmp to gs://kafka-spark-data/spark-metadata/commits/275\n",
      "23/06/24 15:12:50 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:12:38.841Z\",\n",
      "  \"batchId\" : 275,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.17627357659086904,\n",
      "  \"processedRowsPerSecond\" : 0.17260723224303098,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7967,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 14,\n",
      "    \"queryPlanning\" : 20,\n",
      "    \"triggerExecution\" : 11586,\n",
      "    \"walCommit\" : 2092\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4979\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4981\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.17627357659086904,\n",
      "    \"processedRowsPerSecond\" : 0.17260723224303098\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:12:50 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 11592 milliseconds\n",
      "23/06/24 15:12:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:12:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4983.\n",
      "23/06/24 15:12:50 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/276 using temp file gs://kafka-spark-data/spark-metadata/offsets/.276.0fd2fccd-7c34-4737-99b8-5d6211911831.tmp\n",
      "23/06/24 15:12:51 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.276.0fd2fccd-7c34-4737-99b8-5d6211911831.tmp to gs://kafka-spark-data/spark-metadata/offsets/276\n",
      "23/06/24 15:12:51 INFO MicroBatchExecution: Committed offsets for batch 276. Metadata OffsetSeqMetadata(0,1687637570440,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:12:52 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:12:52 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:12:52 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:12:52 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:12:52 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:12:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:12:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:12:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:12:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:12:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:12:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:12:53 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:12:53 INFO DAGScheduler: Got job 72 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:12:53 INFO DAGScheduler: Final stage: ResultStage 72 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:12:53 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:12:53 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:12:53 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[510] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:12:53 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 295.4 KiB, free 433.7 MiB)\n",
      "23/06/24 15:12:53 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 433.6 MiB)\n",
      "23/06/24 15:12:53 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.2 MiB)\n",
      "23/06/24 15:12:53 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:12:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[510] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:12:53 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:12:53 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 72) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:12:53 INFO Executor: Running task 0.0 in stage 72.0 (TID 72)\n",
      "23/06/24 15:12:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:12:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:12:53 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:12:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:12:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:12:53 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:12:53 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:12:53 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:12:53 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:12:53 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:12:53 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:12:53 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:12:53 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:12:53 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4981 for partition ticketmaster-0\n",
      "23/06/24 15:12:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:12:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:12:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:12:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4984.\n",
      "23/06/24 15:12:53 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4982 for partition ticketmaster-0\n",
      "23/06/24 15:12:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 72:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:12:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:12:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:12:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4984.\n",
      "23/06/24 15:12:55 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-66f45c5c-697a-4166-9793-b07ed0e4ee01/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:12:55 INFO FileOutputCommitter: Saved output of task 'attempt_202306241512537335528410452766521_0072_m_000000_72' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-66f45c5c-697a-4166-9793-b07ed0e4ee01/_temporary/0/task_202306241512537335528410452766521_0072_m_000000\n",
      "23/06/24 15:12:55 INFO SparkHadoopMapRedUtil: attempt_202306241512537335528410452766521_0072_m_000000_72: Committed. Elapsed time: 1305 ms.\n",
      "23/06/24 15:12:55 INFO Executor: Finished task 0.0 in stage 72.0 (TID 72). 2536 bytes result sent to driver\n",
      "23/06/24 15:12:55 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 72) in 2513 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:12:55 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:12:55 INFO DAGScheduler: ResultStage 72 (start at NativeMethodAccessorImpl.java:0) finished in 2.548 s\n",
      "23/06/24 15:12:55 INFO DAGScheduler: Job 72 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:12:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 72: Stage finished\n",
      "23/06/24 15:12:55 INFO DAGScheduler: Job 72 finished: start at NativeMethodAccessorImpl.java:0, took 2.553867 s\n",
      "23/06/24 15:12:55 INFO FileFormatWriter: Start to commit write Job d36a6e6a-80ab-471b-a475-e7da4c53da23.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:12:56 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-66f45c5c-697a-4166-9793-b07ed0e4ee01/_temporary/0/task_202306241512537335528410452766521_0072_m_000000/' directory.\n",
      "23/06/24 15:12:57 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-66f45c5c-697a-4166-9793-b07ed0e4ee01/' directory.\n",
      "23/06/24 15:12:57 INFO BlockManagerInfo: Removed broadcast_72_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:12:57 INFO FileFormatWriter: Write Job d36a6e6a-80ab-471b-a475-e7da4c53da23 committed. Elapsed time: 2182 ms.\n",
      "23/06/24 15:12:57 INFO FileFormatWriter: Finished processing stats for write job d36a6e6a-80ab-471b-a475-e7da4c53da23.\n",
      "23/06/24 15:12:58 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-66f45c5c-697a-4166-9793-b07ed0e4ee01/part-00000-0ad3dff8-2e3b-4ebc-aef8-252d46312ad7-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=93f8509e-2eed-478a-a133-c9fcd9cf112c, location=US}\n",
      "23/06/24 15:13:01 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=93f8509e-2eed-478a-a133-c9fcd9cf112c, location=US}\n",
      "23/06/24 15:13:01 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/276 using temp file gs://kafka-spark-data/spark-metadata/commits/.276.342d9668-8e3d-4174-b808-0183975d660d.tmp\n",
      "23/06/24 15:13:02 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.276.342d9668-8e3d-4174-b808-0183975d660d.tmp to gs://kafka-spark-data/spark-metadata/commits/276\n",
      "23/06/24 15:13:02 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:12:50.433Z\",\n",
      "  \"batchId\" : 276,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.1725327812284334,\n",
      "  \"processedRowsPerSecond\" : 0.15941335883947075,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 9077,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 7,\n",
      "    \"queryPlanning\" : 29,\n",
      "    \"triggerExecution\" : 12546,\n",
      "    \"walCommit\" : 1931\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4981\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4983\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.1725327812284334,\n",
      "    \"processedRowsPerSecond\" : 0.15941335883947075\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:13:02 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 12552 milliseconds\n",
      "23/06/24 15:13:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:13:03 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4986.\n",
      "23/06/24 15:13:03 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/277 using temp file gs://kafka-spark-data/spark-metadata/offsets/.277.6adfb05a-a4c2-4bfc-a8ad-6b17c2573cae.tmp\n",
      "23/06/24 15:13:04 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.277.6adfb05a-a4c2-4bfc-a8ad-6b17c2573cae.tmp to gs://kafka-spark-data/spark-metadata/offsets/277\n",
      "23/06/24 15:13:04 INFO MicroBatchExecution: Committed offsets for batch 277. Metadata OffsetSeqMetadata(0,1687637583002,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:13:04 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:13:04 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:13:04 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:13:04 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:13:05 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:13:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:13:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:13:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:13:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:13:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:13:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:13:05 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:13:05 INFO DAGScheduler: Got job 73 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:13:05 INFO DAGScheduler: Final stage: ResultStage 73 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:13:05 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:13:05 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:13:05 INFO DAGScheduler: Submitting ResultStage 73 (MapPartitionsRDD[517] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:13:05 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 295.4 KiB, free 433.7 MiB)\n",
      "23/06/24 15:13:05 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 433.6 MiB)\n",
      "23/06/24 15:13:05 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.2 MiB)\n",
      "23/06/24 15:13:05 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:13:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 73 (MapPartitionsRDD[517] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:13:05 INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:13:05 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 73) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:13:05 INFO Executor: Running task 0.0 in stage 73.0 (TID 73)\n",
      "23/06/24 15:13:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:13:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:13:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:13:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:13:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:13:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:13:05 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:13:05 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:13:05 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:13:05 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:13:05 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:13:05 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:13:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:13:05 INFO BlockManagerInfo: Removed broadcast_71_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:13:05 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4984 for partition ticketmaster-0\n",
      "23/06/24 15:13:05 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 73:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:13:06 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:13:06 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:13:06 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4986.\n",
      "23/06/24 15:13:07 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-6f9e4bdd-86a6-4163-9be5-989507bfc59c/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:13:07 INFO FileOutputCommitter: Saved output of task 'attempt_202306241513055216996818498186179_0073_m_000000_73' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-6f9e4bdd-86a6-4163-9be5-989507bfc59c/_temporary/0/task_202306241513055216996818498186179_0073_m_000000\n",
      "23/06/24 15:13:07 INFO SparkHadoopMapRedUtil: attempt_202306241513055216996818498186179_0073_m_000000_73: Committed. Elapsed time: 1039 ms.\n",
      "23/06/24 15:13:07 INFO Executor: Finished task 0.0 in stage 73.0 (TID 73). 2536 bytes result sent to driver\n",
      "23/06/24 15:13:07 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 73) in 2192 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:13:07 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:13:07 INFO DAGScheduler: ResultStage 73 (start at NativeMethodAccessorImpl.java:0) finished in 2.213 s\n",
      "23/06/24 15:13:07 INFO DAGScheduler: Job 73 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:13:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 73: Stage finished\n",
      "23/06/24 15:13:07 INFO DAGScheduler: Job 73 finished: start at NativeMethodAccessorImpl.java:0, took 2.214374 s\n",
      "23/06/24 15:13:07 INFO FileFormatWriter: Start to commit write Job 65a3fc62-9f2c-47fe-b711-cb00990ce27d.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:13:08 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-6f9e4bdd-86a6-4163-9be5-989507bfc59c/_temporary/0/task_202306241513055216996818498186179_0073_m_000000/' directory.\n",
      "23/06/24 15:13:09 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-6f9e4bdd-86a6-4163-9be5-989507bfc59c/' directory.\n",
      "23/06/24 15:13:09 INFO FileFormatWriter: Write Job 65a3fc62-9f2c-47fe-b711-cb00990ce27d committed. Elapsed time: 2000 ms.\n",
      "23/06/24 15:13:09 INFO FileFormatWriter: Finished processing stats for write job 65a3fc62-9f2c-47fe-b711-cb00990ce27d.\n",
      "23/06/24 15:13:10 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-6f9e4bdd-86a6-4163-9be5-989507bfc59c/part-00000-13e7549b-b122-490d-ac21-c2e3e5dcdc7c-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=133609e3-5cce-4333-9166-94cc380c3356, location=US}\n",
      "23/06/24 15:13:12 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=133609e3-5cce-4333-9166-94cc380c3356, location=US}\n",
      "23/06/24 15:13:13 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/277 using temp file gs://kafka-spark-data/spark-metadata/commits/.277.84dd4674-22fb-44a1-904d-9f8f0f0ff59c.tmp\n",
      "23/06/24 15:13:14 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.277.84dd4674-22fb-44a1-904d-9f8f0f0ff59c.tmp to gs://kafka-spark-data/spark-metadata/commits/277\n",
      "23/06/24 15:13:14 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:13:02.985Z\",\n",
      "  \"batchId\" : 277,\n",
      "  \"numInputRows\" : 3,\n",
      "  \"inputRowsPerSecond\" : 0.23900573613766732,\n",
      "  \"processedRowsPerSecond\" : 0.26068821689259647,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 8112,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 16,\n",
      "    \"queryPlanning\" : 21,\n",
      "    \"triggerExecution\" : 11508,\n",
      "    \"walCommit\" : 1959\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4983\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4986\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 3,\n",
      "    \"inputRowsPerSecond\" : 0.23900573613766732,\n",
      "    \"processedRowsPerSecond\" : 0.26068821689259647\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:13:14 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 11514 milliseconds\n",
      "23/06/24 15:13:14 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:13:14 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4988.\n",
      "23/06/24 15:13:14 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/278 using temp file gs://kafka-spark-data/spark-metadata/offsets/.278.c077a5a8-e334-4a16-b742-37634136b281.tmp\n",
      "23/06/24 15:13:15 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.278.c077a5a8-e334-4a16-b742-37634136b281.tmp to gs://kafka-spark-data/spark-metadata/offsets/278\n",
      "23/06/24 15:13:15 INFO MicroBatchExecution: Committed offsets for batch 278. Metadata OffsetSeqMetadata(0,1687637594506,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:13:16 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:13:16 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:13:16 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:13:16 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:13:16 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:13:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:13:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:13:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:13:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:13:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:13:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:13:16 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:13:16 INFO DAGScheduler: Got job 74 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:13:16 INFO DAGScheduler: Final stage: ResultStage 74 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:13:16 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:13:16 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:13:16 INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[524] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:13:16 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 295.4 KiB, free 433.7 MiB)\n",
      "23/06/24 15:13:16 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 433.6 MiB)\n",
      "23/06/24 15:13:16 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.2 MiB)\n",
      "23/06/24 15:13:16 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:13:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[524] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:13:16 INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:13:16 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 74) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:13:16 INFO Executor: Running task 0.0 in stage 74.0 (TID 74)\n",
      "23/06/24 15:13:16 INFO BlockManagerInfo: Removed broadcast_73_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:13:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:13:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:13:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:13:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:13:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:13:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:13:16 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:13:16 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:13:16 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:13:16 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:13:16 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:13:16 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:13:16 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:13:17 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4986 for partition ticketmaster-0\n",
      "23/06/24 15:13:17 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:13:17 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:13:17 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:13:17 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4989.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 74:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:13:18 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-41b6e2a4-4660-4f40-b25c-c3d1cf08caa0/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:13:18 INFO FileOutputCommitter: Saved output of task 'attempt_202306241513164997540457783122323_0074_m_000000_74' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-41b6e2a4-4660-4f40-b25c-c3d1cf08caa0/_temporary/0/task_202306241513164997540457783122323_0074_m_000000\n",
      "23/06/24 15:13:18 INFO SparkHadoopMapRedUtil: attempt_202306241513164997540457783122323_0074_m_000000_74: Committed. Elapsed time: 967 ms.\n",
      "23/06/24 15:13:18 INFO Executor: Finished task 0.0 in stage 74.0 (TID 74). 2579 bytes result sent to driver\n",
      "23/06/24 15:13:18 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 74) in 1750 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:13:18 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:13:18 INFO DAGScheduler: ResultStage 74 (start at NativeMethodAccessorImpl.java:0) finished in 1.769 s\n",
      "23/06/24 15:13:18 INFO DAGScheduler: Job 74 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:13:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 74: Stage finished\n",
      "23/06/24 15:13:18 INFO DAGScheduler: Job 74 finished: start at NativeMethodAccessorImpl.java:0, took 1.771344 s\n",
      "23/06/24 15:13:18 INFO FileFormatWriter: Start to commit write Job 74f80c97-5a27-4f4e-bd77-78ae2ec2e7c4.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:13:19 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-41b6e2a4-4660-4f40-b25c-c3d1cf08caa0/_temporary/0/task_202306241513164997540457783122323_0074_m_000000/' directory.\n",
      "23/06/24 15:13:20 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-41b6e2a4-4660-4f40-b25c-c3d1cf08caa0/' directory.\n",
      "23/06/24 15:13:20 INFO BlockManagerInfo: Removed broadcast_74_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:13:20 INFO FileFormatWriter: Write Job 74f80c97-5a27-4f4e-bd77-78ae2ec2e7c4 committed. Elapsed time: 1799 ms.\n",
      "23/06/24 15:13:20 INFO FileFormatWriter: Finished processing stats for write job 74f80c97-5a27-4f4e-bd77-78ae2ec2e7c4.\n",
      "23/06/24 15:13:20 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-41b6e2a4-4660-4f40-b25c-c3d1cf08caa0/part-00000-be70c60c-7d87-455c-9042-94441615b655-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=7aa6c8f6-a67d-434b-9a03-67f1f7502251, location=US}\n",
      "23/06/24 15:13:23 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=7aa6c8f6-a67d-434b-9a03-67f1f7502251, location=US}\n",
      "23/06/24 15:13:23 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/278 using temp file gs://kafka-spark-data/spark-metadata/commits/.278.ecb41a01-b8d4-47db-90b5-516f558bb775.tmp\n",
      "23/06/24 15:13:24 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.278.ecb41a01-b8d4-47db-90b5-516f558bb775.tmp to gs://kafka-spark-data/spark-metadata/commits/278\n",
      "23/06/24 15:13:24 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:13:14.499Z\",\n",
      "  \"batchId\" : 278,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.17370158068438424,\n",
      "  \"processedRowsPerSecond\" : 0.1928268414963363,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7069,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 6,\n",
      "    \"queryPlanning\" : 13,\n",
      "    \"triggerExecution\" : 10371,\n",
      "    \"walCommit\" : 1826\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4986\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4988\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.17370158068438424,\n",
      "    \"processedRowsPerSecond\" : 0.1928268414963363\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:13:24 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 10378 milliseconds\n",
      "23/06/24 15:13:24 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:13:24 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4990.\n",
      "23/06/24 15:13:25 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/279 using temp file gs://kafka-spark-data/spark-metadata/offsets/.279.61bc6f7c-0003-4e86-8950-9d6640709780.tmp\n",
      "23/06/24 15:13:26 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.279.61bc6f7c-0003-4e86-8950-9d6640709780.tmp to gs://kafka-spark-data/spark-metadata/offsets/279\n",
      "23/06/24 15:13:26 INFO MicroBatchExecution: Committed offsets for batch 279. Metadata OffsetSeqMetadata(0,1687637604885,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:13:26 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:13:26 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:13:26 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:13:26 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:13:27 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:13:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:13:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:13:27 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:13:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:13:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:13:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:13:27 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:13:27 INFO DAGScheduler: Got job 75 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:13:27 INFO DAGScheduler: Final stage: ResultStage 75 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:13:27 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:13:27 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:13:27 INFO DAGScheduler: Submitting ResultStage 75 (MapPartitionsRDD[531] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:13:27 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:13:27 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:13:27 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:13:27 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:13:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 75 (MapPartitionsRDD[531] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:13:27 INFO TaskSchedulerImpl: Adding task set 75.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:13:27 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 75) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:13:27 INFO Executor: Running task 0.0 in stage 75.0 (TID 75)\n",
      "23/06/24 15:13:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:13:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:13:27 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:13:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:13:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:13:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:13:27 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:13:27 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:13:27 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:13:27 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:13:27 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:13:27 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:13:27 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:13:28 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4988 for partition ticketmaster-0\n",
      "23/06/24 15:13:28 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:13:28 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:13:28 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:13:28 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4991.\n",
      "23/06/24 15:13:28 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4989 for partition ticketmaster-0\n",
      "23/06/24 15:13:28 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 75:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:13:28 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:13:28 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:13:28 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4991.\n",
      "23/06/24 15:13:29 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-3590d203-def3-4ac4-99ff-7408147ccacc/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:13:29 INFO FileOutputCommitter: Saved output of task 'attempt_202306241513273821233321791150617_0075_m_000000_75' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-3590d203-def3-4ac4-99ff-7408147ccacc/_temporary/0/task_202306241513273821233321791150617_0075_m_000000\n",
      "23/06/24 15:13:29 INFO SparkHadoopMapRedUtil: attempt_202306241513273821233321791150617_0075_m_000000_75: Committed. Elapsed time: 906 ms.\n",
      "23/06/24 15:13:29 INFO Executor: Finished task 0.0 in stage 75.0 (TID 75). 2579 bytes result sent to driver\n",
      "23/06/24 15:13:29 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 75) in 2097 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:13:29 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:13:29 INFO DAGScheduler: ResultStage 75 (start at NativeMethodAccessorImpl.java:0) finished in 2.130 s\n",
      "23/06/24 15:13:29 INFO DAGScheduler: Job 75 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:13:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 75: Stage finished\n",
      "23/06/24 15:13:29 INFO DAGScheduler: Job 75 finished: start at NativeMethodAccessorImpl.java:0, took 2.131920 s\n",
      "23/06/24 15:13:29 INFO FileFormatWriter: Start to commit write Job 0a23457d-6761-45ce-8715-067fccb5ba8c.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:13:30 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-3590d203-def3-4ac4-99ff-7408147ccacc/_temporary/0/task_202306241513273821233321791150617_0075_m_000000/' directory.\n",
      "23/06/24 15:13:31 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-3590d203-def3-4ac4-99ff-7408147ccacc/' directory.\n",
      "23/06/24 15:13:32 INFO FileFormatWriter: Write Job 0a23457d-6761-45ce-8715-067fccb5ba8c committed. Elapsed time: 2249 ms.\n",
      "23/06/24 15:13:32 INFO FileFormatWriter: Finished processing stats for write job 0a23457d-6761-45ce-8715-067fccb5ba8c.\n",
      "23/06/24 15:13:32 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-3590d203-def3-4ac4-99ff-7408147ccacc/part-00000-5c0ce595-7966-4164-9cb6-de911bad54a4-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=9d827077-0380-4eb4-85d6-45dff6d26a57, location=US}\n",
      "23/06/24 15:13:35 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=9d827077-0380-4eb4-85d6-45dff6d26a57, location=US}\n",
      "23/06/24 15:13:36 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/279 using temp file gs://kafka-spark-data/spark-metadata/commits/.279.965003da-555b-4026-9730-73c10f107c53.tmp\n",
      "23/06/24 15:13:37 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.279.965003da-555b-4026-9730-73c10f107c53.tmp to gs://kafka-spark-data/spark-metadata/commits/279\n",
      "23/06/24 15:13:37 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:13:24.877Z\",\n",
      "  \"batchId\" : 279,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.1927153594141453,\n",
      "  \"processedRowsPerSecond\" : 0.16106950148989288,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 8813,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 8,\n",
      "    \"queryPlanning\" : 24,\n",
      "    \"triggerExecution\" : 12417,\n",
      "    \"walCommit\" : 2018\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4988\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4990\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.1927153594141453,\n",
      "    \"processedRowsPerSecond\" : 0.16106950148989288\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:13:37 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 12419 milliseconds\n",
      "23/06/24 15:13:37 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:13:37 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4992.\n",
      "23/06/24 15:13:37 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/280 using temp file gs://kafka-spark-data/spark-metadata/offsets/.280.3405563d-55f6-4856-bf60-cecc1498d24c.tmp\n",
      "23/06/24 15:13:38 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.280.3405563d-55f6-4856-bf60-cecc1498d24c.tmp to gs://kafka-spark-data/spark-metadata/offsets/280\n",
      "23/06/24 15:13:38 INFO MicroBatchExecution: Committed offsets for batch 280. Metadata OffsetSeqMetadata(0,1687637617314,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:13:39 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:13:39 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:13:39 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:13:39 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:13:39 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:13:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:13:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:13:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:13:40 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:13:40 INFO DAGScheduler: Got job 76 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:13:40 INFO DAGScheduler: Final stage: ResultStage 76 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:13:40 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:13:40 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:13:40 INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[538] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:13:40 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 295.4 KiB, free 433.7 MiB)\n",
      "23/06/24 15:13:40 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 433.6 MiB)\n",
      "23/06/24 15:13:40 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.2 MiB)\n",
      "23/06/24 15:13:40 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:13:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[538] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:13:40 INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:13:40 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 76) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:13:40 INFO Executor: Running task 0.0 in stage 76.0 (TID 76)\n",
      "23/06/24 15:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:13:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:13:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:13:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:13:40 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:13:40 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:13:40 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:13:40 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:13:40 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:13:40 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:13:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:13:40 INFO BlockManagerInfo: Removed broadcast_75_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:13:40 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4991 for partition ticketmaster-0\n",
      "23/06/24 15:13:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 76:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:13:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:13:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:13:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4993.\n",
      "23/06/24 15:13:42 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-2d162a7b-c083-4c1d-bbc0-79a34bf66fd9/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:13:42 INFO FileOutputCommitter: Saved output of task 'attempt_202306241513395042906488171393414_0076_m_000000_76' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-2d162a7b-c083-4c1d-bbc0-79a34bf66fd9/_temporary/0/task_202306241513395042906488171393414_0076_m_000000\n",
      "23/06/24 15:13:42 INFO SparkHadoopMapRedUtil: attempt_202306241513395042906488171393414_0076_m_000000_76: Committed. Elapsed time: 1031 ms.\n",
      "23/06/24 15:13:42 INFO Executor: Finished task 0.0 in stage 76.0 (TID 76). 2536 bytes result sent to driver\n",
      "23/06/24 15:13:42 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 76) in 2140 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:13:42 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:13:42 INFO DAGScheduler: ResultStage 76 (start at NativeMethodAccessorImpl.java:0) finished in 2.160 s\n",
      "23/06/24 15:13:42 INFO DAGScheduler: Job 76 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:13:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 76: Stage finished\n",
      "23/06/24 15:13:42 INFO DAGScheduler: Job 76 finished: start at NativeMethodAccessorImpl.java:0, took 2.160869 s\n",
      "23/06/24 15:13:42 INFO FileFormatWriter: Start to commit write Job 025989ab-18fd-4602-a03b-e6c9714b9295.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:13:43 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-2d162a7b-c083-4c1d-bbc0-79a34bf66fd9/_temporary/0/task_202306241513395042906488171393414_0076_m_000000/' directory.\n",
      "23/06/24 15:13:43 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-2d162a7b-c083-4c1d-bbc0-79a34bf66fd9/' directory.\n",
      "23/06/24 15:13:44 INFO FileFormatWriter: Write Job 025989ab-18fd-4602-a03b-e6c9714b9295 committed. Elapsed time: 2105 ms.\n",
      "23/06/24 15:13:44 INFO FileFormatWriter: Finished processing stats for write job 025989ab-18fd-4602-a03b-e6c9714b9295.\n",
      "23/06/24 15:13:44 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-2d162a7b-c083-4c1d-bbc0-79a34bf66fd9/part-00000-e5628442-1d0e-4942-a123-f66fccf9aa3f-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=4ff6e1a7-321a-49da-a4f4-97dc8a3e2721, location=US}\n",
      "23/06/24 15:13:47 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=4ff6e1a7-321a-49da-a4f4-97dc8a3e2721, location=US}\n",
      "23/06/24 15:13:48 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/280 using temp file gs://kafka-spark-data/spark-metadata/commits/.280.71e9662f-3d3d-470f-980d-07ea3ce3d3ff.tmp\n",
      "23/06/24 15:13:49 INFO BlockManagerInfo: Removed broadcast_76_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:13:50 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.280.71e9662f-3d3d-470f-980d-07ea3ce3d3ff.tmp to gs://kafka-spark-data/spark-metadata/commits/280\n",
      "23/06/24 15:13:50 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:13:37.297Z\",\n",
      "  \"batchId\" : 280,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.1610305958132045,\n",
      "  \"processedRowsPerSecond\" : 0.15535187199005748,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 9217,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 17,\n",
      "    \"queryPlanning\" : 15,\n",
      "    \"triggerExecution\" : 12874,\n",
      "    \"walCommit\" : 2091\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4990\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4992\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.1610305958132045,\n",
      "    \"processedRowsPerSecond\" : 0.15535187199005748\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:13:50 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 12876 milliseconds\n",
      "23/06/24 15:13:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:13:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4995.\n",
      "23/06/24 15:13:50 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/281 using temp file gs://kafka-spark-data/spark-metadata/offsets/.281.44e15578-f944-4417-ad5e-68d6bd95b59a.tmp\n",
      "23/06/24 15:13:51 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.281.44e15578-f944-4417-ad5e-68d6bd95b59a.tmp to gs://kafka-spark-data/spark-metadata/offsets/281\n",
      "23/06/24 15:13:51 INFO MicroBatchExecution: Committed offsets for batch 281. Metadata OffsetSeqMetadata(0,1687637630182,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:13:52 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:13:52 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:13:52 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:13:52 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:13:52 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:13:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:13:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:13:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:13:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:13:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:13:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:13:53 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:13:53 INFO DAGScheduler: Got job 77 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:13:53 INFO DAGScheduler: Final stage: ResultStage 77 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:13:53 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:13:53 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:13:53 INFO DAGScheduler: Submitting ResultStage 77 (MapPartitionsRDD[545] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:13:53 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:13:53 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:13:53 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:13:53 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:13:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 77 (MapPartitionsRDD[545] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:13:53 INFO TaskSchedulerImpl: Adding task set 77.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:13:53 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 77) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:13:53 INFO Executor: Running task 0.0 in stage 77.0 (TID 77)\n",
      "23/06/24 15:13:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:13:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:13:53 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:13:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:13:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:13:53 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:13:53 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:13:53 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:13:53 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:13:53 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:13:53 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:13:53 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:13:53 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:13:53 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4993 for partition ticketmaster-0\n",
      "23/06/24 15:13:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 77:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:13:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:13:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:13:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4996.\n",
      "23/06/24 15:13:55 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-025a1d89-7c22-4ec9-8c66-ab084ee24388/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:13:55 INFO FileOutputCommitter: Saved output of task 'attempt_202306241513524783558100448034128_0077_m_000000_77' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-025a1d89-7c22-4ec9-8c66-ab084ee24388/_temporary/0/task_202306241513524783558100448034128_0077_m_000000\n",
      "23/06/24 15:13:55 INFO SparkHadoopMapRedUtil: attempt_202306241513524783558100448034128_0077_m_000000_77: Committed. Elapsed time: 1004 ms.\n",
      "23/06/24 15:13:55 INFO Executor: Finished task 0.0 in stage 77.0 (TID 77). 2536 bytes result sent to driver\n",
      "23/06/24 15:13:55 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 77) in 2152 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:13:55 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:13:55 INFO DAGScheduler: ResultStage 77 (start at NativeMethodAccessorImpl.java:0) finished in 2.177 s\n",
      "23/06/24 15:13:55 INFO DAGScheduler: Job 77 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:13:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 77: Stage finished\n",
      "23/06/24 15:13:55 INFO DAGScheduler: Job 77 finished: start at NativeMethodAccessorImpl.java:0, took 2.178318 s\n",
      "23/06/24 15:13:55 INFO FileFormatWriter: Start to commit write Job d4a4f138-1c0d-4737-bf55-53626d560844.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:13:56 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-025a1d89-7c22-4ec9-8c66-ab084ee24388/_temporary/0/task_202306241513524783558100448034128_0077_m_000000/' directory.\n",
      "23/06/24 15:13:56 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-025a1d89-7c22-4ec9-8c66-ab084ee24388/' directory.\n",
      "23/06/24 15:13:57 INFO FileFormatWriter: Write Job d4a4f138-1c0d-4737-bf55-53626d560844 committed. Elapsed time: 2214 ms.\n",
      "23/06/24 15:13:57 INFO FileFormatWriter: Finished processing stats for write job d4a4f138-1c0d-4737-bf55-53626d560844.\n",
      "23/06/24 15:13:57 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-025a1d89-7c22-4ec9-8c66-ab084ee24388/part-00000-5ae85900-83a3-4010-a6c0-9f86aa871872-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=5c209d2d-0ed1-47b1-a2ea-6af08e2b1f62, location=US}\n",
      "23/06/24 15:14:01 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=5c209d2d-0ed1-47b1-a2ea-6af08e2b1f62, location=US}\n",
      "23/06/24 15:14:01 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/281 using temp file gs://kafka-spark-data/spark-metadata/commits/.281.a1ef5002-12c5-4f73-9f74-1f2f4e82b22a.tmp\n",
      "23/06/24 15:14:03 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.281.a1ef5002-12c5-4f73-9f74-1f2f4e82b22a.tmp to gs://kafka-spark-data/spark-metadata/commits/281\n",
      "23/06/24 15:14:03 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:13:50.173Z\",\n",
      "  \"batchId\" : 281,\n",
      "  \"numInputRows\" : 3,\n",
      "  \"inputRowsPerSecond\" : 0.23299161230195714,\n",
      "  \"processedRowsPerSecond\" : 0.22770398481973433,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 9305,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 9,\n",
      "    \"queryPlanning\" : 21,\n",
      "    \"triggerExecution\" : 13175,\n",
      "    \"walCommit\" : 2133\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4992\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4995\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 3,\n",
      "    \"inputRowsPerSecond\" : 0.23299161230195714,\n",
      "    \"processedRowsPerSecond\" : 0.22770398481973433\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:14:03 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 13176 milliseconds\n",
      "23/06/24 15:14:03 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:14:03 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 4998.\n",
      "23/06/24 15:14:03 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/282 using temp file gs://kafka-spark-data/spark-metadata/offsets/.282.6632c6f4-10e3-499c-90db-c04713192565.tmp\n",
      "23/06/24 15:14:04 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.282.6632c6f4-10e3-499c-90db-c04713192565.tmp to gs://kafka-spark-data/spark-metadata/offsets/282\n",
      "23/06/24 15:14:04 INFO MicroBatchExecution: Committed offsets for batch 282. Metadata OffsetSeqMetadata(0,1687637643355,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:14:05 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:14:05 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:14:05 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:14:05 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:14:05 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:14:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:14:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:14:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:14:06 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:14:06 INFO DAGScheduler: Got job 78 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:14:06 INFO DAGScheduler: Final stage: ResultStage 78 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:14:06 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:14:06 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:14:06 INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[552] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:14:06 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 295.4 KiB, free 433.7 MiB)\n",
      "23/06/24 15:14:06 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 433.7 MiB)\n",
      "23/06/24 15:14:06 INFO BlockManagerInfo: Removed broadcast_77_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:14:06 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:14:06 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:14:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 78 (MapPartitionsRDD[552] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:14:06 INFO TaskSchedulerImpl: Adding task set 78.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:14:06 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 78) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:14:06 INFO Executor: Running task 0.0 in stage 78.0 (TID 78)\n",
      "23/06/24 15:14:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:14:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:14:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:14:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:14:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:14:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:14:06 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:14:06 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:14:06 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:14:06 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:14:06 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:14:06 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:14:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:14:06 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4996 for partition ticketmaster-0\n",
      "23/06/24 15:14:06 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 78:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:14:07 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:14:07 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:14:07 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 4998.\n",
      "23/06/24 15:14:08 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-9d931277-0c6f-4103-8bed-edbb57bdd077/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:14:08 INFO FileOutputCommitter: Saved output of task 'attempt_202306241514063990656530942239626_0078_m_000000_78' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-9d931277-0c6f-4103-8bed-edbb57bdd077/_temporary/0/task_202306241514063990656530942239626_0078_m_000000\n",
      "23/06/24 15:14:08 INFO SparkHadoopMapRedUtil: attempt_202306241514063990656530942239626_0078_m_000000_78: Committed. Elapsed time: 913 ms.\n",
      "23/06/24 15:14:08 INFO Executor: Finished task 0.0 in stage 78.0 (TID 78). 2579 bytes result sent to driver\n",
      "23/06/24 15:14:08 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 78) in 2062 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:14:08 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:14:08 INFO DAGScheduler: ResultStage 78 (start at NativeMethodAccessorImpl.java:0) finished in 2.101 s\n",
      "23/06/24 15:14:08 INFO DAGScheduler: Job 78 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:14:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 78: Stage finished\n",
      "23/06/24 15:14:08 INFO DAGScheduler: Job 78 finished: start at NativeMethodAccessorImpl.java:0, took 2.103307 s\n",
      "23/06/24 15:14:08 INFO FileFormatWriter: Start to commit write Job da8107c4-0bea-444e-97ff-e3c6ed4d7181.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:14:09 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-9d931277-0c6f-4103-8bed-edbb57bdd077/_temporary/0/task_202306241514063990656530942239626_0078_m_000000/' directory.\n",
      "23/06/24 15:14:09 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-9d931277-0c6f-4103-8bed-edbb57bdd077/' directory.\n",
      "23/06/24 15:14:10 INFO FileFormatWriter: Write Job da8107c4-0bea-444e-97ff-e3c6ed4d7181 committed. Elapsed time: 2101 ms.\n",
      "23/06/24 15:14:10 INFO FileFormatWriter: Finished processing stats for write job da8107c4-0bea-444e-97ff-e3c6ed4d7181.\n",
      "23/06/24 15:14:10 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-9d931277-0c6f-4103-8bed-edbb57bdd077/part-00000-40074282-2a52-45f5-95fa-e244be169e19-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=3210d2f1-1cd0-459d-8a10-dcecf1cf4d01, location=US}\n",
      "23/06/24 15:14:13 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=3210d2f1-1cd0-459d-8a10-dcecf1cf4d01, location=US}\n",
      "23/06/24 15:14:14 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/282 using temp file gs://kafka-spark-data/spark-metadata/commits/.282.67c3db6c-31e4-411a-82b9-a8e1720d1aee.tmp\n",
      "23/06/24 15:14:15 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.282.67c3db6c-31e4-411a-82b9-a8e1720d1aee.tmp to gs://kafka-spark-data/spark-metadata/commits/282\n",
      "23/06/24 15:14:15 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:14:03.349Z\",\n",
      "  \"batchId\" : 282,\n",
      "  \"numInputRows\" : 3,\n",
      "  \"inputRowsPerSecond\" : 0.22768670309653916,\n",
      "  \"processedRowsPerSecond\" : 0.24009603841536617,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 8616,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 6,\n",
      "    \"queryPlanning\" : 23,\n",
      "    \"triggerExecution\" : 12495,\n",
      "    \"walCommit\" : 2284\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4995\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4998\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 3,\n",
      "    \"inputRowsPerSecond\" : 0.22768670309653916,\n",
      "    \"processedRowsPerSecond\" : 0.24009603841536617\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:14:15 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 12497 milliseconds\n",
      "23/06/24 15:14:15 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:14:15 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 5000.\n",
      "23/06/24 15:14:16 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/283 using temp file gs://kafka-spark-data/spark-metadata/offsets/.283.2228a8bf-151a-4574-bd00-0e6e6ebd41dc.tmp\n",
      "23/06/24 15:14:17 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.283.2228a8bf-151a-4574-bd00-0e6e6ebd41dc.tmp to gs://kafka-spark-data/spark-metadata/offsets/283\n",
      "23/06/24 15:14:17 INFO MicroBatchExecution: Committed offsets for batch 283. Metadata OffsetSeqMetadata(0,1687637655856,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:14:18 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:14:18 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:14:18 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:14:18 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:14:18 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:14:18 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:14:18 INFO DAGScheduler: Got job 79 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:14:18 INFO DAGScheduler: Final stage: ResultStage 79 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:14:18 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:14:18 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:14:18 INFO DAGScheduler: Submitting ResultStage 79 (MapPartitionsRDD[559] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:14:18 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 295.4 KiB, free 433.7 MiB)\n",
      "23/06/24 15:14:18 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 433.6 MiB)\n",
      "23/06/24 15:14:18 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.2 MiB)\n",
      "23/06/24 15:14:18 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:14:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 79 (MapPartitionsRDD[559] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:14:18 INFO TaskSchedulerImpl: Adding task set 79.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:14:18 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 79) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:14:18 INFO Executor: Running task 0.0 in stage 79.0 (TID 79)\n",
      "23/06/24 15:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:14:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:14:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:14:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:14:18 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:14:18 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:14:18 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:14:18 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:14:18 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:14:18 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:14:18 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:14:18 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 4998 for partition ticketmaster-0\n",
      "23/06/24 15:14:18 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 79:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:14:19 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:14:19 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:14:19 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5001.\n",
      "23/06/24 15:14:20 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-99238d36-fa87-4a2f-a97c-2b5a0919ab96/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:14:20 INFO FileOutputCommitter: Saved output of task 'attempt_202306241514186092311500327357053_0079_m_000000_79' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-99238d36-fa87-4a2f-a97c-2b5a0919ab96/_temporary/0/task_202306241514186092311500327357053_0079_m_000000\n",
      "23/06/24 15:14:20 INFO SparkHadoopMapRedUtil: attempt_202306241514186092311500327357053_0079_m_000000_79: Committed. Elapsed time: 830 ms.\n",
      "23/06/24 15:14:20 INFO Executor: Finished task 0.0 in stage 79.0 (TID 79). 2579 bytes result sent to driver\n",
      "23/06/24 15:14:20 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 79) in 1907 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:14:20 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:14:20 INFO DAGScheduler: ResultStage 79 (start at NativeMethodAccessorImpl.java:0) finished in 1.943 s\n",
      "23/06/24 15:14:20 INFO DAGScheduler: Job 79 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:14:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 79: Stage finished\n",
      "23/06/24 15:14:20 INFO DAGScheduler: Job 79 finished: start at NativeMethodAccessorImpl.java:0, took 1.944455 s\n",
      "23/06/24 15:14:20 INFO FileFormatWriter: Start to commit write Job 0f27141e-a25d-4918-b1e7-ebc84a46de1a.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:14:21 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-99238d36-fa87-4a2f-a97c-2b5a0919ab96/_temporary/0/task_202306241514186092311500327357053_0079_m_000000/' directory.\n",
      "23/06/24 15:14:22 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-99238d36-fa87-4a2f-a97c-2b5a0919ab96/' directory.\n",
      "23/06/24 15:14:22 INFO FileFormatWriter: Write Job 0f27141e-a25d-4918-b1e7-ebc84a46de1a committed. Elapsed time: 1962 ms.\n",
      "23/06/24 15:14:22 INFO FileFormatWriter: Finished processing stats for write job 0f27141e-a25d-4918-b1e7-ebc84a46de1a.\n",
      "23/06/24 15:14:22 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-99238d36-fa87-4a2f-a97c-2b5a0919ab96/part-00000-669f55e8-9bfe-44e3-8880-48a044e45fc9-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=4cd89008-c9f5-4933-aa31-16ff5d30f60d, location=US}\n",
      "23/06/24 15:14:26 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=4cd89008-c9f5-4933-aa31-16ff5d30f60d, location=US}\n",
      "23/06/24 15:14:26 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/283 using temp file gs://kafka-spark-data/spark-metadata/commits/.283.5f6113db-4308-47f4-ba32-521f1d779b68.tmp\n",
      "23/06/24 15:14:28 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.283.5f6113db-4308-47f4-ba32-521f1d779b68.tmp to gs://kafka-spark-data/spark-metadata/commits/283\n",
      "23/06/24 15:14:28 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:14:15.846Z\",\n",
      "  \"batchId\" : 283,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.16003840921821239,\n",
      "  \"processedRowsPerSecond\" : 0.16240357287860333,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 8527,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 10,\n",
      "    \"queryPlanning\" : 25,\n",
      "    \"triggerExecution\" : 12315,\n",
      "    \"walCommit\" : 2130\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 4998\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5000\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.16003840921821239,\n",
      "    \"processedRowsPerSecond\" : 0.16240357287860333\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:14:28 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 12322 milliseconds\n",
      "23/06/24 15:14:28 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:14:28 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 5003.\n",
      "23/06/24 15:14:28 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/284 using temp file gs://kafka-spark-data/spark-metadata/offsets/.284.f5f52932-b2e9-4386-b6b4-c911e1b92c1e.tmp\n",
      "23/06/24 15:14:29 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.284.f5f52932-b2e9-4386-b6b4-c911e1b92c1e.tmp to gs://kafka-spark-data/spark-metadata/offsets/284\n",
      "23/06/24 15:14:29 INFO MicroBatchExecution: Committed offsets for batch 284. Metadata OffsetSeqMetadata(0,1687637668184,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:14:30 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:14:30 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:14:30 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:14:30 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:14:30 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:14:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:14:30 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:14:30 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:14:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:14:30 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:14:30 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:14:30 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:14:30 INFO DAGScheduler: Got job 80 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:14:30 INFO DAGScheduler: Final stage: ResultStage 80 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:14:30 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:14:30 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:14:30 INFO DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[566] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:14:30 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 295.4 KiB, free 433.3 MiB)\n",
      "23/06/24 15:14:30 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 433.3 MiB)\n",
      "23/06/24 15:14:30 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.1 MiB)\n",
      "23/06/24 15:14:30 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:14:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[566] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:14:30 INFO TaskSchedulerImpl: Adding task set 80.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:14:30 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 80) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:14:30 INFO Executor: Running task 0.0 in stage 80.0 (TID 80)\n",
      "23/06/24 15:14:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:14:30 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:14:30 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:14:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:14:30 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:14:30 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:14:30 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:14:30 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:14:30 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:14:30 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:14:30 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:14:30 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:14:30 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:14:30 INFO BlockManagerInfo: Removed broadcast_79_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.2 MiB)\n",
      "23/06/24 15:14:30 INFO BlockManagerInfo: Removed broadcast_78_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:14:31 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5001 for partition ticketmaster-0\n",
      "23/06/24 15:14:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 80:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:14:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:14:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:14:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5003.\n",
      "23/06/24 15:14:32 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-3a136e4e-f98f-40e8-bfcf-b18d9ee84744/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:14:32 INFO FileOutputCommitter: Saved output of task 'attempt_202306241514308514397496836436820_0080_m_000000_80' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-3a136e4e-f98f-40e8-bfcf-b18d9ee84744/_temporary/0/task_202306241514308514397496836436820_0080_m_000000\n",
      "23/06/24 15:14:32 INFO SparkHadoopMapRedUtil: attempt_202306241514308514397496836436820_0080_m_000000_80: Committed. Elapsed time: 931 ms.\n",
      "23/06/24 15:14:32 INFO Executor: Finished task 0.0 in stage 80.0 (TID 80). 2536 bytes result sent to driver\n",
      "23/06/24 15:14:32 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 80) in 2055 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:14:32 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:14:32 INFO DAGScheduler: ResultStage 80 (start at NativeMethodAccessorImpl.java:0) finished in 2.100 s\n",
      "23/06/24 15:14:32 INFO DAGScheduler: Job 80 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:14:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 80: Stage finished\n",
      "23/06/24 15:14:32 INFO DAGScheduler: Job 80 finished: start at NativeMethodAccessorImpl.java:0, took 2.102796 s\n",
      "23/06/24 15:14:32 INFO FileFormatWriter: Start to commit write Job f0b02386-80d6-407e-b794-05da0090dcce.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:14:34 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-3a136e4e-f98f-40e8-bfcf-b18d9ee84744/_temporary/0/task_202306241514308514397496836436820_0080_m_000000/' directory.\n",
      "23/06/24 15:14:34 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-3a136e4e-f98f-40e8-bfcf-b18d9ee84744/' directory.\n",
      "23/06/24 15:14:34 INFO FileFormatWriter: Write Job f0b02386-80d6-407e-b794-05da0090dcce committed. Elapsed time: 1997 ms.\n",
      "23/06/24 15:14:34 INFO FileFormatWriter: Finished processing stats for write job f0b02386-80d6-407e-b794-05da0090dcce.\n",
      "23/06/24 15:14:35 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-3a136e4e-f98f-40e8-bfcf-b18d9ee84744/part-00000-8ea3ef02-6f9e-4e22-978e-69ebdf34a395-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=c09a2fe4-6f1f-4ddb-9367-1e47cec59af8, location=US}\n",
      "23/06/24 15:14:37 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=c09a2fe4-6f1f-4ddb-9367-1e47cec59af8, location=US}\n",
      "23/06/24 15:14:38 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/284 using temp file gs://kafka-spark-data/spark-metadata/commits/.284.86c594b4-f5fa-4024-847f-4c2c477f0aa4.tmp\n",
      "23/06/24 15:14:39 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.284.86c594b4-f5fa-4024-847f-4c2c477f0aa4.tmp to gs://kafka-spark-data/spark-metadata/commits/284\n",
      "23/06/24 15:14:39 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:14:28.168Z\",\n",
      "  \"batchId\" : 284,\n",
      "  \"numInputRows\" : 3,\n",
      "  \"inputRowsPerSecond\" : 0.24346696964778447,\n",
      "  \"processedRowsPerSecond\" : 0.258086717136958,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7598,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 14,\n",
      "    \"queryPlanning\" : 23,\n",
      "    \"triggerExecution\" : 11624,\n",
      "    \"walCommit\" : 2083\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5000\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5003\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 3,\n",
      "    \"inputRowsPerSecond\" : 0.24346696964778447,\n",
      "    \"processedRowsPerSecond\" : 0.258086717136958\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:14:39 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 11630 milliseconds\n",
      "23/06/24 15:14:39 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:14:39 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 5005.\n",
      "23/06/24 15:14:40 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/285 using temp file gs://kafka-spark-data/spark-metadata/offsets/.285.1118cdfb-107c-4de1-9c6d-349ee5d8eac7.tmp\n",
      "23/06/24 15:14:41 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.285.1118cdfb-107c-4de1-9c6d-349ee5d8eac7.tmp to gs://kafka-spark-data/spark-metadata/offsets/285\n",
      "23/06/24 15:14:41 INFO MicroBatchExecution: Committed offsets for batch 285. Metadata OffsetSeqMetadata(0,1687637679813,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:14:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:14:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:14:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:14:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:14:42 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:14:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:14:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:14:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:14:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:14:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:14:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:14:42 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:14:42 INFO DAGScheduler: Got job 81 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:14:42 INFO DAGScheduler: Final stage: ResultStage 81 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:14:42 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:14:42 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:14:42 INFO DAGScheduler: Submitting ResultStage 81 (MapPartitionsRDD[573] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:14:42 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 295.4 KiB, free 433.7 MiB)\n",
      "23/06/24 15:14:42 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 433.6 MiB)\n",
      "23/06/24 15:14:42 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.2 MiB)\n",
      "23/06/24 15:14:42 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:14:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 81 (MapPartitionsRDD[573] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:14:42 INFO TaskSchedulerImpl: Adding task set 81.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:14:42 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 81) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:14:42 INFO Executor: Running task 0.0 in stage 81.0 (TID 81)\n",
      "23/06/24 15:14:42 INFO BlockManagerInfo: Removed broadcast_80_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:14:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:14:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:14:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:14:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:14:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:14:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:14:42 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:14:42 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:14:42 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:14:42 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:14:42 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:14:42 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:14:42 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:14:42 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5003 for partition ticketmaster-0\n",
      "23/06/24 15:14:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 81:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:14:43 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:14:43 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:14:43 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5006.\n",
      "23/06/24 15:14:44 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-b8563a3e-cbec-4529-b2bd-eb53daba6503/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:14:44 INFO FileOutputCommitter: Saved output of task 'attempt_202306241514429121558292356887768_0081_m_000000_81' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-b8563a3e-cbec-4529-b2bd-eb53daba6503/_temporary/0/task_202306241514429121558292356887768_0081_m_000000\n",
      "23/06/24 15:14:44 INFO SparkHadoopMapRedUtil: attempt_202306241514429121558292356887768_0081_m_000000_81: Committed. Elapsed time: 940 ms.\n",
      "23/06/24 15:14:44 INFO Executor: Finished task 0.0 in stage 81.0 (TID 81). 2579 bytes result sent to driver\n",
      "23/06/24 15:14:44 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 81) in 2066 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:14:44 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:14:44 INFO DAGScheduler: ResultStage 81 (start at NativeMethodAccessorImpl.java:0) finished in 2.106 s\n",
      "23/06/24 15:14:44 INFO DAGScheduler: Job 81 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:14:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 81: Stage finished\n",
      "23/06/24 15:14:44 INFO DAGScheduler: Job 81 finished: start at NativeMethodAccessorImpl.java:0, took 2.108360 s\n",
      "23/06/24 15:14:44 INFO FileFormatWriter: Start to commit write Job 1680944f-154f-4f94-8c7c-67d5b20ec484.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:14:45 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-b8563a3e-cbec-4529-b2bd-eb53daba6503/_temporary/0/task_202306241514429121558292356887768_0081_m_000000/' directory.\n",
      "23/06/24 15:14:46 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-b8563a3e-cbec-4529-b2bd-eb53daba6503/' directory.\n",
      "23/06/24 15:14:46 INFO BlockManagerInfo: Removed broadcast_81_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:14:46 INFO FileFormatWriter: Write Job 1680944f-154f-4f94-8c7c-67d5b20ec484 committed. Elapsed time: 1945 ms.\n",
      "23/06/24 15:14:46 INFO FileFormatWriter: Finished processing stats for write job 1680944f-154f-4f94-8c7c-67d5b20ec484.\n",
      "23/06/24 15:14:47 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-b8563a3e-cbec-4529-b2bd-eb53daba6503/part-00000-467dd4b7-cef5-4838-b8f1-390d68ccce15-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=36eba9ec-ad5a-4ffa-99e1-78eff4d97ed6, location=US}\n",
      "23/06/24 15:14:49 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=36eba9ec-ad5a-4ffa-99e1-78eff4d97ed6, location=US}\n",
      "23/06/24 15:14:50 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/285 using temp file gs://kafka-spark-data/spark-metadata/commits/.285.4f9b2fa9-8254-4678-82e2-90679a57f717.tmp\n",
      "23/06/24 15:14:51 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.285.4f9b2fa9-8254-4678-82e2-90679a57f717.tmp to gs://kafka-spark-data/spark-metadata/commits/285\n",
      "23/06/24 15:14:51 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:14:39.798Z\",\n",
      "  \"batchId\" : 285,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.17196904557179707,\n",
      "  \"processedRowsPerSecond\" : 0.16843523665150748,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 8305,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 14,\n",
      "    \"queryPlanning\" : 22,\n",
      "    \"triggerExecution\" : 11873,\n",
      "    \"walCommit\" : 2074\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5003\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5005\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.17196904557179707,\n",
      "    \"processedRowsPerSecond\" : 0.16843523665150748\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:14:51 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 11879 milliseconds\n",
      "23/06/24 15:14:51 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:14:51 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 5007.\n",
      "23/06/24 15:14:51 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/286 using temp file gs://kafka-spark-data/spark-metadata/offsets/.286.dd93f8cc-452e-44b3-a614-eca826e9f961.tmp\n",
      "23/06/24 15:14:53 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.286.dd93f8cc-452e-44b3-a614-eca826e9f961.tmp to gs://kafka-spark-data/spark-metadata/offsets/286\n",
      "23/06/24 15:14:53 INFO MicroBatchExecution: Committed offsets for batch 286. Metadata OffsetSeqMetadata(0,1687637691691,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:14:53 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:14:53 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:14:53 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:14:53 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:14:53 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:14:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:14:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:14:53 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:14:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:14:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:14:53 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:14:54 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:14:54 INFO DAGScheduler: Got job 82 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:14:54 INFO DAGScheduler: Final stage: ResultStage 82 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:14:54 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:14:54 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:14:54 INFO DAGScheduler: Submitting ResultStage 82 (MapPartitionsRDD[580] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:14:54 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:14:54 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:14:54 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:14:54 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:14:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 82 (MapPartitionsRDD[580] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:14:54 INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:14:54 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 82) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:14:54 INFO Executor: Running task 0.0 in stage 82.0 (TID 82)\n",
      "23/06/24 15:14:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:14:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:14:54 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:14:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:14:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:14:54 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:14:54 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:14:54 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:14:54 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:14:54 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:14:54 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:14:54 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:14:54 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:14:54 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5006 for partition ticketmaster-0\n",
      "23/06/24 15:14:54 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 82:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:14:55 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:14:55 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:14:55 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5008.\n",
      "23/06/24 15:14:56 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-ddab5771-21d6-4463-9096-7b2b412342de/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:14:56 INFO FileOutputCommitter: Saved output of task 'attempt_202306241514546393835704918385370_0082_m_000000_82' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-ddab5771-21d6-4463-9096-7b2b412342de/_temporary/0/task_202306241514546393835704918385370_0082_m_000000\n",
      "23/06/24 15:14:56 INFO SparkHadoopMapRedUtil: attempt_202306241514546393835704918385370_0082_m_000000_82: Committed. Elapsed time: 799 ms.\n",
      "23/06/24 15:14:56 INFO Executor: Finished task 0.0 in stage 82.0 (TID 82). 2536 bytes result sent to driver\n",
      "23/06/24 15:14:56 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 82) in 1941 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:14:56 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:14:56 INFO DAGScheduler: ResultStage 82 (start at NativeMethodAccessorImpl.java:0) finished in 1.984 s\n",
      "23/06/24 15:14:56 INFO DAGScheduler: Job 82 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:14:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 82: Stage finished\n",
      "23/06/24 15:14:56 INFO DAGScheduler: Job 82 finished: start at NativeMethodAccessorImpl.java:0, took 1.986301 s\n",
      "23/06/24 15:14:56 INFO FileFormatWriter: Start to commit write Job 0c0113e0-a3e3-47f6-ac78-d851b95d0367.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:14:57 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-ddab5771-21d6-4463-9096-7b2b412342de/_temporary/0/task_202306241514546393835704918385370_0082_m_000000/' directory.\n",
      "23/06/24 15:14:57 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-ddab5771-21d6-4463-9096-7b2b412342de/' directory.\n",
      "23/06/24 15:14:58 INFO FileFormatWriter: Write Job 0c0113e0-a3e3-47f6-ac78-d851b95d0367 committed. Elapsed time: 1975 ms.\n",
      "23/06/24 15:14:58 INFO FileFormatWriter: Finished processing stats for write job 0c0113e0-a3e3-47f6-ac78-d851b95d0367.\n",
      "23/06/24 15:14:58 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-ddab5771-21d6-4463-9096-7b2b412342de/part-00000-eabfc937-e428-4911-8f25-8a7491ab8b65-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=2db9734d-b482-41a5-8ad7-e75be69885fd, location=US}\n",
      "23/06/24 15:15:01 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=2db9734d-b482-41a5-8ad7-e75be69885fd, location=US}\n",
      "23/06/24 15:15:01 INFO BlockManagerInfo: Removed broadcast_82_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:15:02 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/286 using temp file gs://kafka-spark-data/spark-metadata/commits/.286.1c403a04-1004-42c6-a881-5eceba330af7.tmp\n",
      "23/06/24 15:15:03 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.286.1c403a04-1004-42c6-a881-5eceba330af7.tmp to gs://kafka-spark-data/spark-metadata/commits/286\n",
      "23/06/24 15:15:03 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:14:51.677Z\",\n",
      "  \"batchId\" : 286,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.16836434043269635,\n",
      "  \"processedRowsPerSecond\" : 0.17014036580178646,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 8389,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 14,\n",
      "    \"queryPlanning\" : 7,\n",
      "    \"triggerExecution\" : 11755,\n",
      "    \"walCommit\" : 1945\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5005\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5007\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.16836434043269635,\n",
      "    \"processedRowsPerSecond\" : 0.17014036580178646\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:15:03 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 11767 milliseconds\n",
      "23/06/24 15:15:03 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:15:03 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 5010.\n",
      "23/06/24 15:15:03 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/287 using temp file gs://kafka-spark-data/spark-metadata/offsets/.287.78cbec76-57f5-4bd0-bc88-09642dd4ac1c.tmp\n",
      "23/06/24 15:15:04 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.287.78cbec76-57f5-4bd0-bc88-09642dd4ac1c.tmp to gs://kafka-spark-data/spark-metadata/offsets/287\n",
      "23/06/24 15:15:04 INFO MicroBatchExecution: Committed offsets for batch 287. Metadata OffsetSeqMetadata(0,1687637703456,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:15:05 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:15:05 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:15:05 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:15:05 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:15:05 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:15:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:15:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:15:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:15:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:15:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:15:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:15:06 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:15:06 INFO DAGScheduler: Got job 83 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:15:06 INFO DAGScheduler: Final stage: ResultStage 83 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:15:06 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:15:06 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:15:06 INFO DAGScheduler: Submitting ResultStage 83 (MapPartitionsRDD[587] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:15:06 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:15:06 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:15:06 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:15:06 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:15:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 83 (MapPartitionsRDD[587] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:15:06 INFO TaskSchedulerImpl: Adding task set 83.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:15:06 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 83) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:15:06 INFO Executor: Running task 0.0 in stage 83.0 (TID 83)\n",
      "23/06/24 15:15:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:15:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:15:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:15:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:15:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:15:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:15:06 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:15:06 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:15:06 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:15:06 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:15:06 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:15:06 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:15:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:15:06 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5008 for partition ticketmaster-0\n",
      "23/06/24 15:15:06 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 83:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:15:07 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:15:07 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:15:07 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5010.\n",
      "23/06/24 15:15:08 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-38b4d8a6-1a7d-4a20-a603-322e20bae388/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:15:08 INFO FileOutputCommitter: Saved output of task 'attempt_20230624151506361104982646459390_0083_m_000000_83' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-38b4d8a6-1a7d-4a20-a603-322e20bae388/_temporary/0/task_20230624151506361104982646459390_0083_m_000000\n",
      "23/06/24 15:15:08 INFO SparkHadoopMapRedUtil: attempt_20230624151506361104982646459390_0083_m_000000_83: Committed. Elapsed time: 959 ms.\n",
      "23/06/24 15:15:08 INFO Executor: Finished task 0.0 in stage 83.0 (TID 83). 2536 bytes result sent to driver\n",
      "23/06/24 15:15:08 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 83) in 2078 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:15:08 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:15:08 INFO DAGScheduler: ResultStage 83 (start at NativeMethodAccessorImpl.java:0) finished in 2.101 s\n",
      "23/06/24 15:15:08 INFO DAGScheduler: Job 83 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:15:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 83: Stage finished\n",
      "23/06/24 15:15:08 INFO DAGScheduler: Job 83 finished: start at NativeMethodAccessorImpl.java:0, took 2.103266 s\n",
      "23/06/24 15:15:08 INFO FileFormatWriter: Start to commit write Job beeaa2fd-aa2b-4ccc-9fcf-569abae3b5a1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:15:09 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-38b4d8a6-1a7d-4a20-a603-322e20bae388/_temporary/0/task_20230624151506361104982646459390_0083_m_000000/' directory.\n",
      "23/06/24 15:15:09 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-38b4d8a6-1a7d-4a20-a603-322e20bae388/' directory.\n",
      "23/06/24 15:15:10 INFO FileFormatWriter: Write Job beeaa2fd-aa2b-4ccc-9fcf-569abae3b5a1 committed. Elapsed time: 1997 ms.\n",
      "23/06/24 15:15:10 INFO FileFormatWriter: Finished processing stats for write job beeaa2fd-aa2b-4ccc-9fcf-569abae3b5a1.\n",
      "23/06/24 15:15:10 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-38b4d8a6-1a7d-4a20-a603-322e20bae388/part-00000-67adf9e8-a70e-47e7-8119-24d5c7e35c9d-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=c07bfcc2-dc8b-42a2-a063-deb5762c3ee4, location=US}\n",
      "23/06/24 15:15:14 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=c07bfcc2-dc8b-42a2-a063-deb5762c3ee4, location=US}\n",
      "23/06/24 15:15:15 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/287 using temp file gs://kafka-spark-data/spark-metadata/commits/.287.d8f4aca6-f46a-4a46-98ed-e4f71e8143bb.tmp\n",
      "23/06/24 15:15:15 INFO BlockManagerInfo: Removed broadcast_83_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:15:16 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.287.d8f4aca6-f46a-4a46-98ed-e4f71e8143bb.tmp to gs://kafka-spark-data/spark-metadata/commits/287\n",
      "23/06/24 15:15:16 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:15:03.444Z\",\n",
      "  \"batchId\" : 287,\n",
      "  \"numInputRows\" : 3,\n",
      "  \"inputRowsPerSecond\" : 0.2549502846944846,\n",
      "  \"processedRowsPerSecond\" : 0.2218278615794144,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 9921,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 11,\n",
      "    \"queryPlanning\" : 20,\n",
      "    \"triggerExecution\" : 13524,\n",
      "    \"walCommit\" : 2084\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5007\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5010\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 3,\n",
      "    \"inputRowsPerSecond\" : 0.2549502846944846,\n",
      "    \"processedRowsPerSecond\" : 0.2218278615794144\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:15:16 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 13528 milliseconds\n",
      "23/06/24 15:15:16 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:15:17 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 5012.\n",
      "23/06/24 15:15:17 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/288 using temp file gs://kafka-spark-data/spark-metadata/offsets/.288.e00d002c-bed3-4f24-99c7-f90636107cac.tmp\n",
      "23/06/24 15:15:18 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.288.e00d002c-bed3-4f24-99c7-f90636107cac.tmp to gs://kafka-spark-data/spark-metadata/offsets/288\n",
      "23/06/24 15:15:18 INFO MicroBatchExecution: Committed offsets for batch 288. Metadata OffsetSeqMetadata(0,1687637717015,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:15:18 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:15:18 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:15:18 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:15:18 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:15:19 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:15:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:15:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:15:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:15:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:15:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:15:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:15:19 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:15:19 INFO DAGScheduler: Got job 84 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:15:19 INFO DAGScheduler: Final stage: ResultStage 84 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:15:19 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:15:19 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:15:19 INFO DAGScheduler: Submitting ResultStage 84 (MapPartitionsRDD[594] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:15:19 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:15:19 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:15:19 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:15:19 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:15:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 84 (MapPartitionsRDD[594] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:15:19 INFO TaskSchedulerImpl: Adding task set 84.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:15:19 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 84) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:15:19 INFO Executor: Running task 0.0 in stage 84.0 (TID 84)\n",
      "23/06/24 15:15:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:15:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:15:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:15:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:15:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:15:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:15:19 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:15:19 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:15:19 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:15:19 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:15:19 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:15:19 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:15:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 84:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:15:20 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5010 for partition ticketmaster-0\n",
      "23/06/24 15:15:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:15:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:15:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:15:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5013.\n",
      "23/06/24 15:15:21 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-36332ad8-8d95-4601-b578-b2f77dc161cf/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:15:21 INFO FileOutputCommitter: Saved output of task 'attempt_202306241515192402420703572830437_0084_m_000000_84' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-36332ad8-8d95-4601-b578-b2f77dc161cf/_temporary/0/task_202306241515192402420703572830437_0084_m_000000\n",
      "23/06/24 15:15:21 INFO SparkHadoopMapRedUtil: attempt_202306241515192402420703572830437_0084_m_000000_84: Committed. Elapsed time: 794 ms.\n",
      "23/06/24 15:15:21 INFO Executor: Finished task 0.0 in stage 84.0 (TID 84). 2536 bytes result sent to driver\n",
      "23/06/24 15:15:21 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 84) in 2248 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:15:21 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:15:21 INFO DAGScheduler: ResultStage 84 (start at NativeMethodAccessorImpl.java:0) finished in 2.297 s\n",
      "23/06/24 15:15:21 INFO DAGScheduler: Job 84 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:15:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 84: Stage finished\n",
      "23/06/24 15:15:21 INFO DAGScheduler: Job 84 finished: start at NativeMethodAccessorImpl.java:0, took 2.311931 s\n",
      "23/06/24 15:15:21 INFO FileFormatWriter: Start to commit write Job ab3b72a7-0bd1-41c2-ba36-02be03b10a3f.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:15:22 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-36332ad8-8d95-4601-b578-b2f77dc161cf/_temporary/0/task_202306241515192402420703572830437_0084_m_000000/' directory.\n",
      "23/06/24 15:15:23 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-36332ad8-8d95-4601-b578-b2f77dc161cf/' directory.\n",
      "23/06/24 15:15:23 INFO FileFormatWriter: Write Job ab3b72a7-0bd1-41c2-ba36-02be03b10a3f committed. Elapsed time: 1898 ms.\n",
      "23/06/24 15:15:23 INFO FileFormatWriter: Finished processing stats for write job ab3b72a7-0bd1-41c2-ba36-02be03b10a3f.\n",
      "23/06/24 15:15:24 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-36332ad8-8d95-4601-b578-b2f77dc161cf/part-00000-748606e3-4fd5-413e-adce-e0413a967a56-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=ef826fe0-cdca-4644-923f-d2f7b022465c, location=US}\n",
      "23/06/24 15:15:26 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=ef826fe0-cdca-4644-923f-d2f7b022465c, location=US}\n",
      "23/06/24 15:15:27 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/288 using temp file gs://kafka-spark-data/spark-metadata/commits/.288.1bf443ec-e0e1-4e35-93f8-c341c7e3b965.tmp\n",
      "23/06/24 15:15:28 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.288.1bf443ec-e0e1-4e35-93f8-c341c7e3b965.tmp to gs://kafka-spark-data/spark-metadata/commits/288\n",
      "23/06/24 15:15:28 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:15:16.972Z\",\n",
      "  \"batchId\" : 288,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.1478415138971023,\n",
      "  \"processedRowsPerSecond\" : 0.17576236927673786,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7888,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 43,\n",
      "    \"queryPlanning\" : 20,\n",
      "    \"triggerExecution\" : 11379,\n",
      "    \"walCommit\" : 1946\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5010\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5012\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.1478415138971023,\n",
      "    \"processedRowsPerSecond\" : 0.17576236927673786\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:15:28 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 11381 milliseconds\n",
      "23/06/24 15:15:28 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:15:28 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 5015.\n",
      "23/06/24 15:15:28 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/289 using temp file gs://kafka-spark-data/spark-metadata/offsets/.289.37d54b3a-2eb9-439e-af0b-57f98814466e.tmp\n",
      "23/06/24 15:15:29 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.289.37d54b3a-2eb9-439e-af0b-57f98814466e.tmp to gs://kafka-spark-data/spark-metadata/offsets/289\n",
      "23/06/24 15:15:29 INFO MicroBatchExecution: Committed offsets for batch 289. Metadata OffsetSeqMetadata(0,1687637728364,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:15:30 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:15:30 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:15:30 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:15:30 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:15:30 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:15:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:15:30 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:15:30 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:15:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:15:30 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:15:30 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:15:30 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:15:30 INFO DAGScheduler: Got job 85 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:15:30 INFO DAGScheduler: Final stage: ResultStage 85 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:15:30 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:15:30 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:15:30 INFO DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[601] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:15:30 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 295.4 KiB, free 433.7 MiB)\n",
      "23/06/24 15:15:30 INFO BlockManagerInfo: Removed broadcast_84_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:15:30 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:15:30 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:15:30 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:15:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 85 (MapPartitionsRDD[601] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:15:30 INFO TaskSchedulerImpl: Adding task set 85.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:15:30 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 85) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:15:30 INFO Executor: Running task 0.0 in stage 85.0 (TID 85)\n",
      "23/06/24 15:15:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:15:30 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:15:30 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:15:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:15:30 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:15:30 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:15:30 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:15:30 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:15:30 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:15:30 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:15:30 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:15:30 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:15:30 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:15:31 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5013 for partition ticketmaster-0\n",
      "23/06/24 15:15:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 85:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:15:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:15:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:15:31 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5015.\n",
      "23/06/24 15:15:33 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-167d4de2-9f3e-4662-8901-521e2c6f5bc4/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:15:33 INFO FileOutputCommitter: Saved output of task 'attempt_202306241515306747489531693799822_0085_m_000000_85' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-167d4de2-9f3e-4662-8901-521e2c6f5bc4/_temporary/0/task_202306241515306747489531693799822_0085_m_000000\n",
      "23/06/24 15:15:33 INFO SparkHadoopMapRedUtil: attempt_202306241515306747489531693799822_0085_m_000000_85: Committed. Elapsed time: 1106 ms.\n",
      "23/06/24 15:15:33 INFO Executor: Finished task 0.0 in stage 85.0 (TID 85). 2579 bytes result sent to driver\n",
      "23/06/24 15:15:33 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 85) in 2396 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:15:33 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:15:33 INFO DAGScheduler: ResultStage 85 (start at NativeMethodAccessorImpl.java:0) finished in 2.442 s\n",
      "23/06/24 15:15:33 INFO DAGScheduler: Job 85 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:15:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 85: Stage finished\n",
      "23/06/24 15:15:33 INFO DAGScheduler: Job 85 finished: start at NativeMethodAccessorImpl.java:0, took 2.443897 s\n",
      "23/06/24 15:15:33 INFO FileFormatWriter: Start to commit write Job 170239ee-eba4-41cd-9725-c393759c3940.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:15:34 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-167d4de2-9f3e-4662-8901-521e2c6f5bc4/_temporary/0/task_202306241515306747489531693799822_0085_m_000000/' directory.\n",
      "23/06/24 15:15:34 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-167d4de2-9f3e-4662-8901-521e2c6f5bc4/' directory.\n",
      "23/06/24 15:15:35 INFO FileFormatWriter: Write Job 170239ee-eba4-41cd-9725-c393759c3940 committed. Elapsed time: 2050 ms.\n",
      "23/06/24 15:15:35 INFO FileFormatWriter: Finished processing stats for write job 170239ee-eba4-41cd-9725-c393759c3940.\n",
      "23/06/24 15:15:35 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-167d4de2-9f3e-4662-8901-521e2c6f5bc4/part-00000-e1be390e-7ffc-4cc9-aa39-49d60a67c605-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=0c10f90e-8f74-499d-981d-94dd92962797, location=US}\n",
      "23/06/24 15:15:37 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=0c10f90e-8f74-499d-981d-94dd92962797, location=US}\n",
      "23/06/24 15:15:38 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/289 using temp file gs://kafka-spark-data/spark-metadata/commits/.289.1360f984-df9e-42d7-8648-0355ca5f38c9.tmp\n",
      "23/06/24 15:15:39 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.289.1360f984-df9e-42d7-8648-0355ca5f38c9.tmp to gs://kafka-spark-data/spark-metadata/commits/289\n",
      "23/06/24 15:15:39 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:15:28.353Z\",\n",
      "  \"batchId\" : 289,\n",
      "  \"numInputRows\" : 3,\n",
      "  \"inputRowsPerSecond\" : 0.26359722344257974,\n",
      "  \"processedRowsPerSecond\" : 0.27527986786566344,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7511,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 11,\n",
      "    \"queryPlanning\" : 12,\n",
      "    \"triggerExecution\" : 10897,\n",
      "    \"walCommit\" : 1897\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5012\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5015\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 3,\n",
      "    \"inputRowsPerSecond\" : 0.26359722344257974,\n",
      "    \"processedRowsPerSecond\" : 0.27527986786566344\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:15:39 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 10907 milliseconds\n",
      "23/06/24 15:15:39 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:15:39 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 5017.\n",
      "23/06/24 15:15:39 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/290 using temp file gs://kafka-spark-data/spark-metadata/offsets/.290.4b5d12c3-6c0b-4c7f-af39-628c09ba9987.tmp\n",
      "23/06/24 15:15:40 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.290.4b5d12c3-6c0b-4c7f-af39-628c09ba9987.tmp to gs://kafka-spark-data/spark-metadata/offsets/290\n",
      "23/06/24 15:15:40 INFO MicroBatchExecution: Committed offsets for batch 290. Metadata OffsetSeqMetadata(0,1687637739268,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:15:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:15:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:15:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:15:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:15:41 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:15:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:15:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:15:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:15:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:15:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:15:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:15:42 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:15:42 INFO DAGScheduler: Got job 86 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:15:42 INFO DAGScheduler: Final stage: ResultStage 86 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:15:42 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:15:42 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:15:42 INFO DAGScheduler: Submitting ResultStage 86 (MapPartitionsRDD[608] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:15:42 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 295.4 KiB, free 433.7 MiB)\n",
      "23/06/24 15:15:42 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 433.6 MiB)\n",
      "23/06/24 15:15:42 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.2 MiB)\n",
      "23/06/24 15:15:42 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:15:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 86 (MapPartitionsRDD[608] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:15:42 INFO TaskSchedulerImpl: Adding task set 86.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:15:42 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 86) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:15:42 INFO Executor: Running task 0.0 in stage 86.0 (TID 86)\n",
      "23/06/24 15:15:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:15:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:15:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:15:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:15:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:15:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:15:42 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:15:42 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:15:42 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:15:42 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:15:42 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:15:42 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:15:42 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:15:42 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5015 for partition ticketmaster-0\n",
      "23/06/24 15:15:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:15:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:15:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:15:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5018.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 86:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:15:43 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-7f3f420b-2ea4-4369-ad65-ffeb46c76517/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:15:43 INFO FileOutputCommitter: Saved output of task 'attempt_202306241515414403550368726684921_0086_m_000000_86' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-7f3f420b-2ea4-4369-ad65-ffeb46c76517/_temporary/0/task_202306241515414403550368726684921_0086_m_000000\n",
      "23/06/24 15:15:43 INFO SparkHadoopMapRedUtil: attempt_202306241515414403550368726684921_0086_m_000000_86: Committed. Elapsed time: 920 ms.\n",
      "23/06/24 15:15:43 INFO Executor: Finished task 0.0 in stage 86.0 (TID 86). 2579 bytes result sent to driver\n",
      "23/06/24 15:15:43 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 86) in 1870 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:15:43 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:15:43 INFO DAGScheduler: ResultStage 86 (start at NativeMethodAccessorImpl.java:0) finished in 1.901 s\n",
      "23/06/24 15:15:43 INFO DAGScheduler: Job 86 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:15:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 86: Stage finished\n",
      "23/06/24 15:15:43 INFO DAGScheduler: Job 86 finished: start at NativeMethodAccessorImpl.java:0, took 1.902918 s\n",
      "23/06/24 15:15:43 INFO FileFormatWriter: Start to commit write Job e76d0432-e005-47e9-9465-336b9c878a7f.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:15:44 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-7f3f420b-2ea4-4369-ad65-ffeb46c76517/_temporary/0/task_202306241515414403550368726684921_0086_m_000000/' directory.\n",
      "23/06/24 15:15:45 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-7f3f420b-2ea4-4369-ad65-ffeb46c76517/' directory.\n",
      "23/06/24 15:15:45 INFO FileFormatWriter: Write Job e76d0432-e005-47e9-9465-336b9c878a7f committed. Elapsed time: 2000 ms.\n",
      "23/06/24 15:15:45 INFO FileFormatWriter: Finished processing stats for write job e76d0432-e005-47e9-9465-336b9c878a7f.\n",
      "23/06/24 15:15:46 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-7f3f420b-2ea4-4369-ad65-ffeb46c76517/part-00000-01f52728-9377-4701-838b-2febb876a5b6-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=3ac2c202-0439-45c0-8083-86805e3e13e3, location=US}\n",
      "23/06/24 15:15:47 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=3ac2c202-0439-45c0-8083-86805e3e13e3, location=US}\n",
      "23/06/24 15:15:48 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/290 using temp file gs://kafka-spark-data/spark-metadata/commits/.290.237e19a7-9901-4878-99fe-88beb6cba410.tmp\n",
      "23/06/24 15:15:48 INFO BlockManagerInfo: Removed broadcast_85_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:15:48 INFO BlockManagerInfo: Removed broadcast_86_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:15:49 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.290.237e19a7-9901-4878-99fe-88beb6cba410.tmp to gs://kafka-spark-data/spark-metadata/commits/290\n",
      "23/06/24 15:15:49 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:15:39.260Z\",\n",
      "  \"batchId\" : 290,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.18336847895846703,\n",
      "  \"processedRowsPerSecond\" : 0.18953752843062927,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6990,\n",
      "    \"getBatch\" : 3,\n",
      "    \"latestOffset\" : 8,\n",
      "    \"queryPlanning\" : 23,\n",
      "    \"triggerExecution\" : 10552,\n",
      "    \"walCommit\" : 2009\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5015\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5017\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.18336847895846703,\n",
      "    \"processedRowsPerSecond\" : 0.18953752843062927\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:15:49 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 10555 milliseconds\n",
      "23/06/24 15:15:49 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:15:49 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 5019.\n",
      "23/06/24 15:15:50 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/291 using temp file gs://kafka-spark-data/spark-metadata/offsets/.291.8778d725-2a51-4fce-b978-320306a33639.tmp\n",
      "23/06/24 15:15:51 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.291.8778d725-2a51-4fce-b978-320306a33639.tmp to gs://kafka-spark-data/spark-metadata/offsets/291\n",
      "23/06/24 15:15:51 INFO MicroBatchExecution: Committed offsets for batch 291. Metadata OffsetSeqMetadata(0,1687637749830,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:15:52 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:15:52 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:15:52 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:15:52 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:15:52 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:15:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:15:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:15:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:15:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:15:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:15:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:15:52 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:15:52 INFO DAGScheduler: Got job 87 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:15:52 INFO DAGScheduler: Final stage: ResultStage 87 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:15:52 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:15:52 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:15:52 INFO DAGScheduler: Submitting ResultStage 87 (MapPartitionsRDD[615] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:15:52 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:15:52 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:15:52 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:15:52 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:15:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 87 (MapPartitionsRDD[615] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:15:52 INFO TaskSchedulerImpl: Adding task set 87.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:15:52 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 87) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:15:52 INFO Executor: Running task 0.0 in stage 87.0 (TID 87)\n",
      "23/06/24 15:15:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:15:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:15:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:15:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:15:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:15:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:15:52 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:15:52 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:15:52 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:15:52 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:15:52 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:15:52 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:15:52 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:15:52 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5017 for partition ticketmaster-0\n",
      "23/06/24 15:15:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:15:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:15:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:15:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5020.\n",
      "23/06/24 15:15:52 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5018 for partition ticketmaster-0\n",
      "23/06/24 15:15:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 87:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:15:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:15:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:15:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5020.\n",
      "23/06/24 15:15:54 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8948f8c6-982a-4cdc-9fc3-34307c270e2c/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:15:54 INFO FileOutputCommitter: Saved output of task 'attempt_202306241515524143695570749239053_0087_m_000000_87' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8948f8c6-982a-4cdc-9fc3-34307c270e2c/_temporary/0/task_202306241515524143695570749239053_0087_m_000000\n",
      "23/06/24 15:15:54 INFO SparkHadoopMapRedUtil: attempt_202306241515524143695570749239053_0087_m_000000_87: Committed. Elapsed time: 892 ms.\n",
      "23/06/24 15:15:54 INFO Executor: Finished task 0.0 in stage 87.0 (TID 87). 2536 bytes result sent to driver\n",
      "23/06/24 15:15:54 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 87) in 1989 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:15:54 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:15:54 INFO DAGScheduler: ResultStage 87 (start at NativeMethodAccessorImpl.java:0) finished in 2.027 s\n",
      "23/06/24 15:15:54 INFO DAGScheduler: Job 87 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:15:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 87: Stage finished\n",
      "23/06/24 15:15:54 INFO DAGScheduler: Job 87 finished: start at NativeMethodAccessorImpl.java:0, took 2.029098 s\n",
      "23/06/24 15:15:54 INFO FileFormatWriter: Start to commit write Job b640b5f3-3291-4acc-a412-c379d402c48a.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:15:55 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8948f8c6-982a-4cdc-9fc3-34307c270e2c/_temporary/0/task_202306241515524143695570749239053_0087_m_000000/' directory.\n",
      "23/06/24 15:15:56 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8948f8c6-982a-4cdc-9fc3-34307c270e2c/' directory.\n",
      "23/06/24 15:15:56 INFO BlockManagerInfo: Removed broadcast_87_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:15:56 INFO FileFormatWriter: Write Job b640b5f3-3291-4acc-a412-c379d402c48a committed. Elapsed time: 1906 ms.\n",
      "23/06/24 15:15:56 INFO FileFormatWriter: Finished processing stats for write job b640b5f3-3291-4acc-a412-c379d402c48a.\n",
      "23/06/24 15:15:56 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-8948f8c6-982a-4cdc-9fc3-34307c270e2c/part-00000-f60eb5df-ac24-40cb-9e0e-d287bc5e29e1-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=0f7beda7-def2-4746-89b8-9e4fa27c23f1, location=US}\n",
      "23/06/24 15:15:59 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=0f7beda7-def2-4746-89b8-9e4fa27c23f1, location=US}\n",
      "23/06/24 15:16:00 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/291 using temp file gs://kafka-spark-data/spark-metadata/commits/.291.0f660258-17cf-4835-b734-870a68e04196.tmp\n",
      "23/06/24 15:16:01 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.291.0f660258-17cf-4835-b734-870a68e04196.tmp to gs://kafka-spark-data/spark-metadata/commits/291\n",
      "23/06/24 15:16:01 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:15:49.815Z\",\n",
      "  \"batchId\" : 291,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.18948365703458078,\n",
      "  \"processedRowsPerSecond\" : 0.17560804284836246,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7590,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 15,\n",
      "    \"queryPlanning\" : 14,\n",
      "    \"triggerExecution\" : 11389,\n",
      "    \"walCommit\" : 2200\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5017\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5019\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.18948365703458078,\n",
      "    \"processedRowsPerSecond\" : 0.17560804284836246\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:16:01 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 11392 milliseconds\n",
      "23/06/24 15:16:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:16:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 5021.\n",
      "23/06/24 15:16:01 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/292 using temp file gs://kafka-spark-data/spark-metadata/offsets/.292.d764d119-788d-428e-9b1d-7e73329f6d46.tmp\n",
      "23/06/24 15:16:02 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.292.d764d119-788d-428e-9b1d-7e73329f6d46.tmp to gs://kafka-spark-data/spark-metadata/offsets/292\n",
      "23/06/24 15:16:02 INFO MicroBatchExecution: Committed offsets for batch 292. Metadata OffsetSeqMetadata(0,1687637761219,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:16:03 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:16:03 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:16:03 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:16:03 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:16:03 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:16:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:16:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:16:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:16:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:16:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:16:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:16:03 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:16:03 INFO DAGScheduler: Got job 88 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:16:03 INFO DAGScheduler: Final stage: ResultStage 88 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:16:03 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:16:03 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:16:03 INFO DAGScheduler: Submitting ResultStage 88 (MapPartitionsRDD[622] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:16:03 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:16:03 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:16:03 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:16:03 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:16:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 88 (MapPartitionsRDD[622] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:16:03 INFO TaskSchedulerImpl: Adding task set 88.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:16:03 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 88) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:16:03 INFO Executor: Running task 0.0 in stage 88.0 (TID 88)\n",
      "23/06/24 15:16:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:16:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:16:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:16:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:16:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:16:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:16:03 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:16:03 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:16:03 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:16:03 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:16:03 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:16:03 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:16:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:16:04 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5020 for partition ticketmaster-0\n",
      "23/06/24 15:16:04 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 88:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:16:04 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:16:04 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:16:04 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5022.\n",
      "23/06/24 15:16:06 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-a4eaf252-caab-4337-b3cd-46ecf12da476/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:16:06 INFO FileOutputCommitter: Saved output of task 'attempt_202306241516032506698607533627579_0088_m_000000_88' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-a4eaf252-caab-4337-b3cd-46ecf12da476/_temporary/0/task_202306241516032506698607533627579_0088_m_000000\n",
      "23/06/24 15:16:06 INFO SparkHadoopMapRedUtil: attempt_202306241516032506698607533627579_0088_m_000000_88: Committed. Elapsed time: 1027 ms.\n",
      "23/06/24 15:16:06 INFO Executor: Finished task 0.0 in stage 88.0 (TID 88). 2536 bytes result sent to driver\n",
      "23/06/24 15:16:06 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 88) in 2221 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:16:06 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:16:06 INFO DAGScheduler: ResultStage 88 (start at NativeMethodAccessorImpl.java:0) finished in 2.242 s\n",
      "23/06/24 15:16:06 INFO DAGScheduler: Job 88 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:16:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 88: Stage finished\n",
      "23/06/24 15:16:06 INFO DAGScheduler: Job 88 finished: start at NativeMethodAccessorImpl.java:0, took 2.242697 s\n",
      "23/06/24 15:16:06 INFO FileFormatWriter: Start to commit write Job 84faf5f4-66c6-4313-81a7-762b09363034.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:16:07 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-a4eaf252-caab-4337-b3cd-46ecf12da476/_temporary/0/task_202306241516032506698607533627579_0088_m_000000/' directory.\n",
      "23/06/24 15:16:07 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-a4eaf252-caab-4337-b3cd-46ecf12da476/' directory.\n",
      "23/06/24 15:16:08 INFO FileFormatWriter: Write Job 84faf5f4-66c6-4313-81a7-762b09363034 committed. Elapsed time: 1850 ms.\n",
      "23/06/24 15:16:08 INFO FileFormatWriter: Finished processing stats for write job 84faf5f4-66c6-4313-81a7-762b09363034.\n",
      "23/06/24 15:16:08 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-a4eaf252-caab-4337-b3cd-46ecf12da476/part-00000-ce07bf32-1363-447d-a87d-559e063a3615-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=dcd19605-fee0-4082-8f7a-f3148949fddb, location=US}\n",
      "23/06/24 15:16:11 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=dcd19605-fee0-4082-8f7a-f3148949fddb, location=US}\n",
      "23/06/24 15:16:12 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/292 using temp file gs://kafka-spark-data/spark-metadata/commits/.292.1e6f288b-d59e-4d3f-beaa-061b172a1170.tmp\n",
      "23/06/24 15:16:12 INFO BlockManagerInfo: Removed broadcast_88_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:16:13 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.292.1e6f288b-d59e-4d3f-beaa-061b172a1170.tmp to gs://kafka-spark-data/spark-metadata/commits/292\n",
      "23/06/24 15:16:13 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:16:01.207Z\",\n",
      "  \"batchId\" : 292,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.175561797752809,\n",
      "  \"processedRowsPerSecond\" : 0.16435204207412277,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 8653,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 12,\n",
      "    \"queryPlanning\" : 12,\n",
      "    \"triggerExecution\" : 12169,\n",
      "    \"walCommit\" : 2076\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5019\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5021\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.175561797752809,\n",
      "    \"processedRowsPerSecond\" : 0.16435204207412277\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:16:13 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 12172 milliseconds\n",
      "23/06/24 15:16:13 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:16:13 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 5024.\n",
      "23/06/24 15:16:13 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/293 using temp file gs://kafka-spark-data/spark-metadata/offsets/.293.bd3e554f-c89d-4ba9-9f4f-b9b85af93848.tmp\n",
      "23/06/24 15:16:14 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.293.bd3e554f-c89d-4ba9-9f4f-b9b85af93848.tmp to gs://kafka-spark-data/spark-metadata/offsets/293\n",
      "23/06/24 15:16:14 INFO MicroBatchExecution: Committed offsets for batch 293. Metadata OffsetSeqMetadata(0,1687637773392,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:16:15 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:16:15 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:16:15 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:16:15 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:16:15 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:16:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:16:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:16:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:16:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:16:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:16:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:16:16 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:16:16 INFO DAGScheduler: Got job 89 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:16:16 INFO DAGScheduler: Final stage: ResultStage 89 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:16:16 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:16:16 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:16:16 INFO DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[629] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:16:16 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:16:16 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:16:16 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:16:16 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:16:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 89 (MapPartitionsRDD[629] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:16:16 INFO TaskSchedulerImpl: Adding task set 89.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:16:16 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 89) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:16:16 INFO Executor: Running task 0.0 in stage 89.0 (TID 89)\n",
      "23/06/24 15:16:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:16:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:16:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:16:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:16:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:16:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:16:16 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:16:16 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:16:16 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:16:16 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:16:16 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:16:16 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:16:16 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:16:16 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5022 for partition ticketmaster-0\n",
      "23/06/24 15:16:16 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 89:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:16:16 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:16:16 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:16:16 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5024.\n",
      "23/06/24 15:16:18 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-5b7ff0c3-7ee9-4ac4-a7b0-0f51fb671879/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:16:18 INFO FileOutputCommitter: Saved output of task 'attempt_202306241516165028735632606118302_0089_m_000000_89' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-5b7ff0c3-7ee9-4ac4-a7b0-0f51fb671879/_temporary/0/task_202306241516165028735632606118302_0089_m_000000\n",
      "23/06/24 15:16:18 INFO SparkHadoopMapRedUtil: attempt_202306241516165028735632606118302_0089_m_000000_89: Committed. Elapsed time: 805 ms.\n",
      "23/06/24 15:16:18 INFO Executor: Finished task 0.0 in stage 89.0 (TID 89). 2579 bytes result sent to driver\n",
      "23/06/24 15:16:18 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 89) in 1900 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:16:18 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:16:18 INFO DAGScheduler: ResultStage 89 (start at NativeMethodAccessorImpl.java:0) finished in 1.940 s\n",
      "23/06/24 15:16:18 INFO DAGScheduler: Job 89 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:16:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 89: Stage finished\n",
      "23/06/24 15:16:18 INFO DAGScheduler: Job 89 finished: start at NativeMethodAccessorImpl.java:0, took 1.941925 s\n",
      "23/06/24 15:16:18 INFO FileFormatWriter: Start to commit write Job 4b4bf7fd-1aff-4aee-98fa-04138d035b01.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:16:18 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-5b7ff0c3-7ee9-4ac4-a7b0-0f51fb671879/_temporary/0/task_202306241516165028735632606118302_0089_m_000000/' directory.\n",
      "23/06/24 15:16:19 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-5b7ff0c3-7ee9-4ac4-a7b0-0f51fb671879/' directory.\n",
      "23/06/24 15:16:20 INFO FileFormatWriter: Write Job 4b4bf7fd-1aff-4aee-98fa-04138d035b01 committed. Elapsed time: 2032 ms.\n",
      "23/06/24 15:16:20 INFO FileFormatWriter: Finished processing stats for write job 4b4bf7fd-1aff-4aee-98fa-04138d035b01.\n",
      "23/06/24 15:16:20 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-5b7ff0c3-7ee9-4ac4-a7b0-0f51fb671879/part-00000-632af3a0-00ac-4349-a714-462869c274dd-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=7aa24c61-b142-466c-a9d9-172537ea51e1, location=US}\n",
      "23/06/24 15:16:23 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=7aa24c61-b142-466c-a9d9-172537ea51e1, location=US}\n",
      "23/06/24 15:16:24 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/293 using temp file gs://kafka-spark-data/spark-metadata/commits/.293.d40a34ef-fdb3-4f81-898d-c326178b3a1b.tmp\n",
      "23/06/24 15:16:25 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.293.d40a34ef-fdb3-4f81-898d-c326178b3a1b.tmp to gs://kafka-spark-data/spark-metadata/commits/293\n",
      "23/06/24 15:16:25 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:16:13.379Z\",\n",
      "  \"batchId\" : 293,\n",
      "  \"numInputRows\" : 3,\n",
      "  \"inputRowsPerSecond\" : 0.2464673020046007,\n",
      "  \"processedRowsPerSecond\" : 0.2548636479483476,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 8389,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 12,\n",
      "    \"queryPlanning\" : 15,\n",
      "    \"triggerExecution\" : 11770,\n",
      "    \"walCommit\" : 2041\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5021\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5024\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 3,\n",
      "    \"inputRowsPerSecond\" : 0.2464673020046007,\n",
      "    \"processedRowsPerSecond\" : 0.2548636479483476\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:16:25 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 11773 milliseconds\n",
      "23/06/24 15:16:25 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:16:25 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 5026.\n",
      "23/06/24 15:16:25 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/294 using temp file gs://kafka-spark-data/spark-metadata/offsets/.294.87d86525-5858-4e01-8103-f37155a7caa5.tmp\n",
      "23/06/24 15:16:26 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.294.87d86525-5858-4e01-8103-f37155a7caa5.tmp to gs://kafka-spark-data/spark-metadata/offsets/294\n",
      "23/06/24 15:16:26 INFO MicroBatchExecution: Committed offsets for batch 294. Metadata OffsetSeqMetadata(0,1687637785158,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:16:27 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:16:27 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:16:27 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:16:27 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:16:27 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:16:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:16:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:16:27 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:16:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:16:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:16:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:16:27 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:16:27 INFO DAGScheduler: Got job 90 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:16:27 INFO DAGScheduler: Final stage: ResultStage 90 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:16:27 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:16:27 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:16:27 INFO DAGScheduler: Submitting ResultStage 90 (MapPartitionsRDD[636] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:16:27 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 295.4 KiB, free 433.7 MiB)\n",
      "23/06/24 15:16:27 INFO BlockManagerInfo: Removed broadcast_89_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:16:27 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:16:27 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:16:27 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:16:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 90 (MapPartitionsRDD[636] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:16:27 INFO TaskSchedulerImpl: Adding task set 90.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:16:27 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 90) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:16:27 INFO Executor: Running task 0.0 in stage 90.0 (TID 90)\n",
      "23/06/24 15:16:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:16:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:16:27 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:16:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:16:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:16:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:16:27 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:16:27 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:16:27 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:16:27 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:16:27 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:16:27 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:16:27 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:16:28 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5024 for partition ticketmaster-0\n",
      "23/06/24 15:16:28 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 90:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:16:28 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:16:28 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:16:28 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5027.\n",
      "23/06/24 15:16:29 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-6d2e2810-330c-4626-85ea-661290975fa8/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:16:29 INFO FileOutputCommitter: Saved output of task 'attempt_202306241516271091617830352447604_0090_m_000000_90' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-6d2e2810-330c-4626-85ea-661290975fa8/_temporary/0/task_202306241516271091617830352447604_0090_m_000000\n",
      "23/06/24 15:16:29 INFO SparkHadoopMapRedUtil: attempt_202306241516271091617830352447604_0090_m_000000_90: Committed. Elapsed time: 942 ms.\n",
      "23/06/24 15:16:29 INFO Executor: Finished task 0.0 in stage 90.0 (TID 90). 2579 bytes result sent to driver\n",
      "23/06/24 15:16:29 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 90) in 2023 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:16:29 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:16:29 INFO DAGScheduler: ResultStage 90 (start at NativeMethodAccessorImpl.java:0) finished in 2.062 s\n",
      "23/06/24 15:16:29 INFO DAGScheduler: Job 90 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:16:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 90: Stage finished\n",
      "23/06/24 15:16:29 INFO DAGScheduler: Job 90 finished: start at NativeMethodAccessorImpl.java:0, took 2.063920 s\n",
      "23/06/24 15:16:29 INFO FileFormatWriter: Start to commit write Job 22e1eb90-10ed-4dd8-85db-62bc66c639f8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:16:30 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-6d2e2810-330c-4626-85ea-661290975fa8/_temporary/0/task_202306241516271091617830352447604_0090_m_000000/' directory.\n",
      "23/06/24 15:16:31 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-6d2e2810-330c-4626-85ea-661290975fa8/' directory.\n",
      "23/06/24 15:16:32 INFO FileFormatWriter: Write Job 22e1eb90-10ed-4dd8-85db-62bc66c639f8 committed. Elapsed time: 2390 ms.\n",
      "23/06/24 15:16:32 INFO FileFormatWriter: Finished processing stats for write job 22e1eb90-10ed-4dd8-85db-62bc66c639f8.\n",
      "23/06/24 15:16:32 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-6d2e2810-330c-4626-85ea-661290975fa8/part-00000-28f8120d-8940-4459-9adb-0d24d6ee53f0-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=ebd5917b-c1f9-4788-b3e1-34bd2edaec3a, location=US}\n",
      "23/06/24 15:16:35 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=ebd5917b-c1f9-4788-b3e1-34bd2edaec3a, location=US}\n",
      "23/06/24 15:16:36 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/294 using temp file gs://kafka-spark-data/spark-metadata/commits/.294.8d488822-b897-46b4-b0f1-ead85e16933b.tmp\n",
      "23/06/24 15:16:37 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.294.8d488822-b897-46b4-b0f1-ead85e16933b.tmp to gs://kafka-spark-data/spark-metadata/commits/294\n",
      "23/06/24 15:16:37 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:16:25.152Z\",\n",
      "  \"batchId\" : 294,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.16988023443472353,\n",
      "  \"processedRowsPerSecond\" : 0.1654259718775848,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 8539,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 4,\n",
      "    \"queryPlanning\" : 18,\n",
      "    \"triggerExecution\" : 12090,\n",
      "    \"walCommit\" : 1971\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5024\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5026\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.16988023443472353,\n",
      "    \"processedRowsPerSecond\" : 0.1654259718775848\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:16:37 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 12101 milliseconds\n",
      "23/06/24 15:16:37 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:16:37 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 5028.\n",
      "23/06/24 15:16:37 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/295 using temp file gs://kafka-spark-data/spark-metadata/offsets/.295.bfbac11f-1737-435c-a96b-3f90ecf7602c.tmp\n",
      "23/06/24 15:16:38 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.295.bfbac11f-1737-435c-a96b-3f90ecf7602c.tmp to gs://kafka-spark-data/spark-metadata/offsets/295\n",
      "23/06/24 15:16:38 INFO MicroBatchExecution: Committed offsets for batch 295. Metadata OffsetSeqMetadata(0,1687637797265,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:16:39 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:16:39 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:16:39 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:16:39 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:16:39 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:16:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:16:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:16:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:16:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:16:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:16:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:16:40 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:16:40 INFO DAGScheduler: Got job 91 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:16:40 INFO DAGScheduler: Final stage: ResultStage 91 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:16:40 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:16:40 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:16:40 INFO DAGScheduler: Submitting ResultStage 91 (MapPartitionsRDD[643] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:16:40 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 295.4 KiB, free 433.7 MiB)\n",
      "23/06/24 15:16:40 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 433.6 MiB)\n",
      "23/06/24 15:16:40 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.2 MiB)\n",
      "23/06/24 15:16:40 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:16:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 91 (MapPartitionsRDD[643] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:16:40 INFO TaskSchedulerImpl: Adding task set 91.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:16:40 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 91) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:16:40 INFO Executor: Running task 0.0 in stage 91.0 (TID 91)\n",
      "23/06/24 15:16:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:16:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:16:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:16:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:16:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:16:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:16:40 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:16:40 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:16:40 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:16:40 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:16:40 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:16:40 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:16:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:16:40 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5027 for partition ticketmaster-0\n",
      "23/06/24 15:16:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 91:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:16:41 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:16:41 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:16:41 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5029.\n",
      "23/06/24 15:16:42 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-ebd831d6-ca85-4bfb-84b9-3bfd48675e25/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:16:42 INFO FileOutputCommitter: Saved output of task 'attempt_20230624151640380640093961077338_0091_m_000000_91' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-ebd831d6-ca85-4bfb-84b9-3bfd48675e25/_temporary/0/task_20230624151640380640093961077338_0091_m_000000\n",
      "23/06/24 15:16:42 INFO SparkHadoopMapRedUtil: attempt_20230624151640380640093961077338_0091_m_000000_91: Committed. Elapsed time: 954 ms.\n",
      "23/06/24 15:16:42 INFO Executor: Finished task 0.0 in stage 91.0 (TID 91). 2536 bytes result sent to driver\n",
      "23/06/24 15:16:42 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 91) in 2104 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:16:42 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:16:42 INFO DAGScheduler: ResultStage 91 (start at NativeMethodAccessorImpl.java:0) finished in 2.128 s\n",
      "23/06/24 15:16:42 INFO DAGScheduler: Job 91 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:16:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 91: Stage finished\n",
      "23/06/24 15:16:42 INFO DAGScheduler: Job 91 finished: start at NativeMethodAccessorImpl.java:0, took 2.130425 s\n",
      "23/06/24 15:16:42 INFO FileFormatWriter: Start to commit write Job 1efcbaf6-33b8-43e3-a1e3-a9ae4f29a8ce.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:16:43 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-ebd831d6-ca85-4bfb-84b9-3bfd48675e25/_temporary/0/task_20230624151640380640093961077338_0091_m_000000/' directory.\n",
      "23/06/24 15:16:44 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-ebd831d6-ca85-4bfb-84b9-3bfd48675e25/' directory.\n",
      "23/06/24 15:16:44 INFO BlockManagerInfo: Removed broadcast_91_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:16:44 INFO FileFormatWriter: Write Job 1efcbaf6-33b8-43e3-a1e3-a9ae4f29a8ce committed. Elapsed time: 2211 ms.\n",
      "23/06/24 15:16:44 INFO FileFormatWriter: Finished processing stats for write job 1efcbaf6-33b8-43e3-a1e3-a9ae4f29a8ce.\n",
      "23/06/24 15:16:45 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-ebd831d6-ca85-4bfb-84b9-3bfd48675e25/part-00000-67cd06e0-c9fd-4162-944d-d10cb35fd0f7-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=cb93730f-4801-41ae-baf7-ac676282e660, location=US}\n",
      "23/06/24 15:16:48 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=cb93730f-4801-41ae-baf7-ac676282e660, location=US}\n",
      "23/06/24 15:16:49 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/295 using temp file gs://kafka-spark-data/spark-metadata/commits/.295.734d26c0-b440-47ac-977d-151c9755d99e.tmp\n",
      "23/06/24 15:16:50 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.295.734d26c0-b440-47ac-977d-151c9755d99e.tmp to gs://kafka-spark-data/spark-metadata/commits/295\n",
      "23/06/24 15:16:50 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:16:37.253Z\",\n",
      "  \"batchId\" : 295,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.16527559705809436,\n",
      "  \"processedRowsPerSecond\" : 0.15572685509616133,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 9338,\n",
      "    \"getBatch\" : 2,\n",
      "    \"latestOffset\" : 11,\n",
      "    \"queryPlanning\" : 26,\n",
      "    \"triggerExecution\" : 12842,\n",
      "    \"walCommit\" : 2072\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5026\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5028\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.16527559705809436,\n",
      "    \"processedRowsPerSecond\" : 0.15572685509616133\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:16:50 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 12845 milliseconds\n",
      "23/06/24 15:16:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:16:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 5031.\n",
      "23/06/24 15:16:50 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/296 using temp file gs://kafka-spark-data/spark-metadata/offsets/.296.294d7db2-aeec-4995-8722-32b0cb1a2ab6.tmp\n",
      "23/06/24 15:16:51 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.296.294d7db2-aeec-4995-8722-32b0cb1a2ab6.tmp to gs://kafka-spark-data/spark-metadata/offsets/296\n",
      "23/06/24 15:16:51 INFO MicroBatchExecution: Committed offsets for batch 296. Metadata OffsetSeqMetadata(0,1687637810111,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:16:52 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:16:52 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:16:52 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:16:52 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:16:52 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:16:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:16:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:16:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:16:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:16:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:16:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:16:52 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:16:52 INFO DAGScheduler: Got job 92 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:16:52 INFO DAGScheduler: Final stage: ResultStage 92 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:16:52 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:16:52 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:16:52 INFO DAGScheduler: Submitting ResultStage 92 (MapPartitionsRDD[650] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:16:53 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 295.4 KiB, free 433.7 MiB)\n",
      "23/06/24 15:16:53 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 433.6 MiB)\n",
      "23/06/24 15:16:53 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.2 MiB)\n",
      "23/06/24 15:16:53 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:16:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 92 (MapPartitionsRDD[650] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:16:53 INFO TaskSchedulerImpl: Adding task set 92.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:16:53 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 92) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:16:53 INFO Executor: Running task 0.0 in stage 92.0 (TID 92)\n",
      "23/06/24 15:16:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:16:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:16:53 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:16:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:16:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:16:53 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:16:53 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:16:53 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:16:53 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:16:53 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:16:53 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:16:53 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:16:53 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:16:53 INFO BlockManagerInfo: Removed broadcast_90_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:16:53 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5029 for partition ticketmaster-0\n",
      "23/06/24 15:16:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 92:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:16:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:16:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:16:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5032.\n",
      "23/06/24 15:16:54 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-9b7ebf25-e3f1-4a7e-9723-10a56ccdd6f4/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:16:54 INFO FileOutputCommitter: Saved output of task 'attempt_202306241516523294023424637932651_0092_m_000000_92' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-9b7ebf25-e3f1-4a7e-9723-10a56ccdd6f4/_temporary/0/task_202306241516523294023424637932651_0092_m_000000\n",
      "23/06/24 15:16:54 INFO SparkHadoopMapRedUtil: attempt_202306241516523294023424637932651_0092_m_000000_92: Committed. Elapsed time: 796 ms.\n",
      "23/06/24 15:16:54 INFO Executor: Finished task 0.0 in stage 92.0 (TID 92). 2536 bytes result sent to driver\n",
      "23/06/24 15:16:54 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 92) in 1910 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:16:54 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:16:54 INFO DAGScheduler: ResultStage 92 (start at NativeMethodAccessorImpl.java:0) finished in 1.939 s\n",
      "23/06/24 15:16:54 INFO DAGScheduler: Job 92 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:16:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 92: Stage finished\n",
      "23/06/24 15:16:54 INFO DAGScheduler: Job 92 finished: start at NativeMethodAccessorImpl.java:0, took 1.940433 s\n",
      "23/06/24 15:16:54 INFO FileFormatWriter: Start to commit write Job f5bdd786-5f41-4691-aabc-e3d00c077f46.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:16:55 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-9b7ebf25-e3f1-4a7e-9723-10a56ccdd6f4/_temporary/0/task_202306241516523294023424637932651_0092_m_000000/' directory.\n",
      "23/06/24 15:16:56 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-9b7ebf25-e3f1-4a7e-9723-10a56ccdd6f4/' directory.\n",
      "23/06/24 15:16:57 INFO FileFormatWriter: Write Job f5bdd786-5f41-4691-aabc-e3d00c077f46 committed. Elapsed time: 2110 ms.\n",
      "23/06/24 15:16:57 INFO FileFormatWriter: Finished processing stats for write job f5bdd786-5f41-4691-aabc-e3d00c077f46.\n",
      "23/06/24 15:16:57 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-9b7ebf25-e3f1-4a7e-9723-10a56ccdd6f4/part-00000-f210bc7e-b3dc-415e-99cc-fca67b3e1576-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=6f9c0ade-1c24-4573-a670-a6ee82a3b905, location=US}\n",
      "23/06/24 15:16:59 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=6f9c0ade-1c24-4573-a670-a6ee82a3b905, location=US}\n",
      "23/06/24 15:17:00 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/296 using temp file gs://kafka-spark-data/spark-metadata/commits/.296.ce927325-d4f7-4a84-b46b-fd2e7fdd87fa.tmp\n",
      "23/06/24 15:17:01 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.296.ce927325-d4f7-4a84-b46b-fd2e7fdd87fa.tmp to gs://kafka-spark-data/spark-metadata/commits/296\n",
      "23/06/24 15:17:01 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:16:50.099Z\",\n",
      "  \"batchId\" : 296,\n",
      "  \"numInputRows\" : 3,\n",
      "  \"inputRowsPerSecond\" : 0.2335357309668379,\n",
      "  \"processedRowsPerSecond\" : 0.25573267411132894,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7809,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 12,\n",
      "    \"queryPlanning\" : 20,\n",
      "    \"triggerExecution\" : 11731,\n",
      "    \"walCommit\" : 2128\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5028\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5031\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 3,\n",
      "    \"inputRowsPerSecond\" : 0.2335357309668379,\n",
      "    \"processedRowsPerSecond\" : 0.25573267411132894\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:17:01 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 11731 milliseconds\n",
      "23/06/24 15:17:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:17:01 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 5033.\n",
      "23/06/24 15:17:02 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/297 using temp file gs://kafka-spark-data/spark-metadata/offsets/.297.e49a8802-6d29-4925-a907-6ebe78ba8256.tmp\n",
      "23/06/24 15:17:03 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.297.e49a8802-6d29-4925-a907-6ebe78ba8256.tmp to gs://kafka-spark-data/spark-metadata/offsets/297\n",
      "23/06/24 15:17:03 INFO MicroBatchExecution: Committed offsets for batch 297. Metadata OffsetSeqMetadata(0,1687637821836,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:17:03 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:17:03 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:17:03 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:17:03 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:17:04 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:17:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:17:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:17:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:17:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:17:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:17:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:17:04 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:17:04 INFO DAGScheduler: Got job 93 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:17:04 INFO DAGScheduler: Final stage: ResultStage 93 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:17:04 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:17:04 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:17:04 INFO DAGScheduler: Submitting ResultStage 93 (MapPartitionsRDD[657] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:17:04 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 295.4 KiB, free 433.7 MiB)\n",
      "23/06/24 15:17:04 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 433.6 MiB)\n",
      "23/06/24 15:17:04 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.2 MiB)\n",
      "23/06/24 15:17:04 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:17:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 93 (MapPartitionsRDD[657] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:17:04 INFO TaskSchedulerImpl: Adding task set 93.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:17:04 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 93) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:17:04 INFO Executor: Running task 0.0 in stage 93.0 (TID 93)\n",
      "23/06/24 15:17:04 INFO BlockManagerInfo: Removed broadcast_92_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:17:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:17:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:17:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:17:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:17:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:17:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:17:04 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:17:04 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:17:04 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:17:04 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:17:04 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:17:04 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:17:04 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:17:04 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5032 for partition ticketmaster-0\n",
      "23/06/24 15:17:04 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 93:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:17:05 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:17:05 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:17:05 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5034.\n",
      "23/06/24 15:17:06 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-7a9291c1-18c6-4791-a02d-5cf30e073067/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:17:06 INFO FileOutputCommitter: Saved output of task 'attempt_202306241517043746024887550642395_0093_m_000000_93' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-7a9291c1-18c6-4791-a02d-5cf30e073067/_temporary/0/task_202306241517043746024887550642395_0093_m_000000\n",
      "23/06/24 15:17:06 INFO SparkHadoopMapRedUtil: attempt_202306241517043746024887550642395_0093_m_000000_93: Committed. Elapsed time: 808 ms.\n",
      "23/06/24 15:17:06 INFO Executor: Finished task 0.0 in stage 93.0 (TID 93). 2579 bytes result sent to driver\n",
      "23/06/24 15:17:06 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 93) in 1949 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:17:06 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:17:06 INFO DAGScheduler: ResultStage 93 (start at NativeMethodAccessorImpl.java:0) finished in 1.979 s\n",
      "23/06/24 15:17:06 INFO DAGScheduler: Job 93 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:17:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 93: Stage finished\n",
      "23/06/24 15:17:06 INFO DAGScheduler: Job 93 finished: start at NativeMethodAccessorImpl.java:0, took 1.980533 s\n",
      "23/06/24 15:17:06 INFO FileFormatWriter: Start to commit write Job 2d355e81-8ba9-4ff1-a342-df31607718eb.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:17:07 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-7a9291c1-18c6-4791-a02d-5cf30e073067/_temporary/0/task_202306241517043746024887550642395_0093_m_000000/' directory.\n",
      "23/06/24 15:17:08 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-7a9291c1-18c6-4791-a02d-5cf30e073067/' directory.\n",
      "23/06/24 15:17:08 INFO FileFormatWriter: Write Job 2d355e81-8ba9-4ff1-a342-df31607718eb committed. Elapsed time: 2127 ms.\n",
      "23/06/24 15:17:08 INFO FileFormatWriter: Finished processing stats for write job 2d355e81-8ba9-4ff1-a342-df31607718eb.\n",
      "23/06/24 15:17:09 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-7a9291c1-18c6-4791-a02d-5cf30e073067/part-00000-c3ec030b-415b-48da-a398-dd82b49ea0bf-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=dd8089b1-180d-412d-8ae0-0638e68c1925, location=US}\n",
      "23/06/24 15:17:11 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=dd8089b1-180d-412d-8ae0-0638e68c1925, location=US}\n",
      "23/06/24 15:17:12 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/297 using temp file gs://kafka-spark-data/spark-metadata/commits/.297.f8fad179-32be-4731-a550-36e6f0756f4e.tmp\n",
      "23/06/24 15:17:13 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.297.f8fad179-32be-4731-a550-36e6f0756f4e.tmp to gs://kafka-spark-data/spark-metadata/commits/297\n",
      "23/06/24 15:17:13 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:17:01.830Z\",\n",
      "  \"batchId\" : 297,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.17048844940755264,\n",
      "  \"processedRowsPerSecond\" : 0.1680248676804167,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 8437,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 5,\n",
      "    \"queryPlanning\" : 22,\n",
      "    \"triggerExecution\" : 11903,\n",
      "    \"walCommit\" : 2078\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5031\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5033\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.17048844940755264,\n",
      "    \"processedRowsPerSecond\" : 0.1680248676804167\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:17:13 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 11911 milliseconds\n",
      "23/06/24 15:17:13 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:17:13 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 5036.\n",
      "23/06/24 15:17:14 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/298 using temp file gs://kafka-spark-data/spark-metadata/offsets/.298.e9333a09-bdee-4446-9ffd-a73c7ec473c5.tmp\n",
      "23/06/24 15:17:15 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.298.e9333a09-bdee-4446-9ffd-a73c7ec473c5.tmp to gs://kafka-spark-data/spark-metadata/offsets/298\n",
      "23/06/24 15:17:15 INFO MicroBatchExecution: Committed offsets for batch 298. Metadata OffsetSeqMetadata(0,1687637833758,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:17:15 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:17:15 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:17:15 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:17:15 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:17:16 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:17:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:17:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:17:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:17:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:17:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:17:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:17:16 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:17:16 INFO DAGScheduler: Got job 94 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:17:16 INFO DAGScheduler: Final stage: ResultStage 94 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:17:16 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:17:16 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:17:16 INFO DAGScheduler: Submitting ResultStage 94 (MapPartitionsRDD[664] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:17:16 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 295.4 KiB, free 433.7 MiB)\n",
      "23/06/24 15:17:16 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 433.6 MiB)\n",
      "23/06/24 15:17:16 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.2 MiB)\n",
      "23/06/24 15:17:16 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:17:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 94 (MapPartitionsRDD[664] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:17:16 INFO TaskSchedulerImpl: Adding task set 94.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:17:16 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 94) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:17:16 INFO Executor: Running task 0.0 in stage 94.0 (TID 94)\n",
      "23/06/24 15:17:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:17:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:17:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:17:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:17:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:17:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:17:16 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:17:16 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:17:16 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:17:16 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:17:16 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:17:16 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:17:16 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:17:16 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5034 for partition ticketmaster-0\n",
      "23/06/24 15:17:16 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 94:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:17:17 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:17:17 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:17:17 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5036.\n",
      "23/06/24 15:17:18 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-5020dc2d-a965-41c5-af2e-a7895bed0482/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:17:18 INFO FileOutputCommitter: Saved output of task 'attempt_202306241517162098973001209414355_0094_m_000000_94' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-5020dc2d-a965-41c5-af2e-a7895bed0482/_temporary/0/task_202306241517162098973001209414355_0094_m_000000\n",
      "23/06/24 15:17:18 INFO SparkHadoopMapRedUtil: attempt_202306241517162098973001209414355_0094_m_000000_94: Committed. Elapsed time: 879 ms.\n",
      "23/06/24 15:17:18 INFO Executor: Finished task 0.0 in stage 94.0 (TID 94). 2579 bytes result sent to driver\n",
      "23/06/24 15:17:18 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 94) in 2012 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:17:18 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:17:18 INFO DAGScheduler: ResultStage 94 (start at NativeMethodAccessorImpl.java:0) finished in 2.039 s\n",
      "23/06/24 15:17:18 INFO DAGScheduler: Job 94 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:17:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 94: Stage finished\n",
      "23/06/24 15:17:18 INFO DAGScheduler: Job 94 finished: start at NativeMethodAccessorImpl.java:0, took 2.041146 s\n",
      "23/06/24 15:17:18 INFO FileFormatWriter: Start to commit write Job 3c42678b-ac52-4de7-838a-697396472057.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:17:19 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-5020dc2d-a965-41c5-af2e-a7895bed0482/_temporary/0/task_202306241517162098973001209414355_0094_m_000000/' directory.\n",
      "23/06/24 15:17:20 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-5020dc2d-a965-41c5-af2e-a7895bed0482/' directory.\n",
      "23/06/24 15:17:20 INFO FileFormatWriter: Write Job 3c42678b-ac52-4de7-838a-697396472057 committed. Elapsed time: 2028 ms.\n",
      "23/06/24 15:17:20 INFO FileFormatWriter: Finished processing stats for write job 3c42678b-ac52-4de7-838a-697396472057.\n",
      "23/06/24 15:17:21 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-5020dc2d-a965-41c5-af2e-a7895bed0482/part-00000-8d790f75-2cfb-4fdf-8fb8-4cc549fc9acf-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=d5ca8917-841b-4e31-a388-530bfd997c32, location=US}\n",
      "23/06/24 15:17:23 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=d5ca8917-841b-4e31-a388-530bfd997c32, location=US}\n",
      "23/06/24 15:17:24 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/298 using temp file gs://kafka-spark-data/spark-metadata/commits/.298.18c93340-b25e-4fc0-8723-2d60ae8e37e1.tmp\n",
      "23/06/24 15:17:25 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.298.18c93340-b25e-4fc0-8723-2d60ae8e37e1.tmp to gs://kafka-spark-data/spark-metadata/commits/298\n",
      "23/06/24 15:17:25 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:17:13.741Z\",\n",
      "  \"batchId\" : 298,\n",
      "  \"numInputRows\" : 3,\n",
      "  \"inputRowsPerSecond\" : 0.2518680211569138,\n",
      "  \"processedRowsPerSecond\" : 0.25115110925073253,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 8419,\n",
      "    \"getBatch\" : 2,\n",
      "    \"latestOffset\" : 17,\n",
      "    \"queryPlanning\" : 25,\n",
      "    \"triggerExecution\" : 11945,\n",
      "    \"walCommit\" : 2136\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5033\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5036\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 3,\n",
      "    \"inputRowsPerSecond\" : 0.2518680211569138,\n",
      "    \"processedRowsPerSecond\" : 0.25115110925073253\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:17:25 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 11952 milliseconds\n",
      "23/06/24 15:17:25 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:17:25 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 5038.\n",
      "23/06/24 15:17:26 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/299 using temp file gs://kafka-spark-data/spark-metadata/offsets/.299.8935a7f0-0c88-4733-97ab-80b5e22a0d3e.tmp\n",
      "23/06/24 15:17:26 INFO BlockManagerInfo: Removed broadcast_94_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:17:26 INFO BlockManagerInfo: Removed broadcast_93_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:17:27 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.299.8935a7f0-0c88-4733-97ab-80b5e22a0d3e.tmp to gs://kafka-spark-data/spark-metadata/offsets/299\n",
      "23/06/24 15:17:27 INFO MicroBatchExecution: Committed offsets for batch 299. Metadata OffsetSeqMetadata(0,1687637845700,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:17:27 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:17:27 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:17:27 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:17:27 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:17:28 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:17:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:17:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:17:28 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:17:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:17:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:17:28 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:17:28 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:17:28 INFO DAGScheduler: Got job 95 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:17:28 INFO DAGScheduler: Final stage: ResultStage 95 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:17:28 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:17:28 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:17:28 INFO DAGScheduler: Submitting ResultStage 95 (MapPartitionsRDD[671] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:17:28 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:17:28 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:17:28 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:17:28 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:17:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 95 (MapPartitionsRDD[671] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:17:28 INFO TaskSchedulerImpl: Adding task set 95.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:17:28 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 95) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:17:28 INFO Executor: Running task 0.0 in stage 95.0 (TID 95)\n",
      "23/06/24 15:17:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:17:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:17:28 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:17:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:17:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:17:28 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:17:28 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:17:28 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:17:28 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:17:28 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:17:28 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:17:28 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:17:28 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:17:28 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5036 for partition ticketmaster-0\n",
      "23/06/24 15:17:28 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 95:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:17:29 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:17:29 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:17:29 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5039.\n",
      "23/06/24 15:17:30 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-7fb4a9ba-60c7-4cc2-8ecf-ce6bb2acb6df/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:17:30 INFO FileOutputCommitter: Saved output of task 'attempt_202306241517281898891662841666857_0095_m_000000_95' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-7fb4a9ba-60c7-4cc2-8ecf-ce6bb2acb6df/_temporary/0/task_202306241517281898891662841666857_0095_m_000000\n",
      "23/06/24 15:17:30 INFO SparkHadoopMapRedUtil: attempt_202306241517281898891662841666857_0095_m_000000_95: Committed. Elapsed time: 812 ms.\n",
      "23/06/24 15:17:30 INFO Executor: Finished task 0.0 in stage 95.0 (TID 95). 2536 bytes result sent to driver\n",
      "23/06/24 15:17:30 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 95) in 1949 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:17:30 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:17:30 INFO DAGScheduler: ResultStage 95 (start at NativeMethodAccessorImpl.java:0) finished in 1.967 s\n",
      "23/06/24 15:17:30 INFO DAGScheduler: Job 95 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:17:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 95: Stage finished\n",
      "23/06/24 15:17:30 INFO DAGScheduler: Job 95 finished: start at NativeMethodAccessorImpl.java:0, took 1.970400 s\n",
      "23/06/24 15:17:30 INFO FileFormatWriter: Start to commit write Job 4009119e-0259-404d-ba70-c02505903d4f.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:17:31 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-7fb4a9ba-60c7-4cc2-8ecf-ce6bb2acb6df/_temporary/0/task_202306241517281898891662841666857_0095_m_000000/' directory.\n",
      "23/06/24 15:17:32 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-7fb4a9ba-60c7-4cc2-8ecf-ce6bb2acb6df/' directory.\n",
      "23/06/24 15:17:32 INFO FileFormatWriter: Write Job 4009119e-0259-404d-ba70-c02505903d4f committed. Elapsed time: 2167 ms.\n",
      "23/06/24 15:17:32 INFO FileFormatWriter: Finished processing stats for write job 4009119e-0259-404d-ba70-c02505903d4f.\n",
      "23/06/24 15:17:32 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-7fb4a9ba-60c7-4cc2-8ecf-ce6bb2acb6df/part-00000-4620e465-33ef-4375-b152-be19b70e12e1-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=0f574131-eca1-4092-b085-f3cd123cf88f, location=US}\n",
      "23/06/24 15:17:37 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=0f574131-eca1-4092-b085-f3cd123cf88f, location=US}\n",
      "23/06/24 15:17:38 INFO BlockManagerInfo: Removed broadcast_95_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:17:38 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/299 using temp file gs://kafka-spark-data/spark-metadata/commits/.299.be565936-ee65-4e52-acb7-2762b76e27bf.tmp\n",
      "23/06/24 15:17:39 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.299.be565936-ee65-4e52-acb7-2762b76e27bf.tmp to gs://kafka-spark-data/spark-metadata/commits/299\n",
      "23/06/24 15:17:39 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:17:25.693Z\",\n",
      "  \"batchId\" : 299,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.16733601070950468,\n",
      "  \"processedRowsPerSecond\" : 0.14630577907827358,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 10119,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 6,\n",
      "    \"queryPlanning\" : 23,\n",
      "    \"triggerExecution\" : 13670,\n",
      "    \"walCommit\" : 2072\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5036\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5038\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.16733601070950468,\n",
      "    \"processedRowsPerSecond\" : 0.14630577907827358\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:17:39 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 13675 milliseconds\n",
      "23/06/24 15:17:39 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:17:39 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 5041.\n",
      "23/06/24 15:17:39 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/300 using temp file gs://kafka-spark-data/spark-metadata/offsets/.300.b0834a1c-e407-4c72-a3d5-faec120fbade.tmp\n",
      "23/06/24 15:17:40 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.300.b0834a1c-e407-4c72-a3d5-faec120fbade.tmp to gs://kafka-spark-data/spark-metadata/offsets/300\n",
      "23/06/24 15:17:40 INFO MicroBatchExecution: Committed offsets for batch 300. Metadata OffsetSeqMetadata(0,1687637859379,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:17:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:17:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:17:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:17:41 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:17:41 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:17:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:17:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:17:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:17:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:17:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:17:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:17:41 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:17:41 INFO DAGScheduler: Got job 96 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:17:41 INFO DAGScheduler: Final stage: ResultStage 96 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:17:41 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:17:41 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:17:41 INFO DAGScheduler: Submitting ResultStage 96 (MapPartitionsRDD[678] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:17:41 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:17:41 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:17:41 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:17:41 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:17:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 96 (MapPartitionsRDD[678] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:17:41 INFO TaskSchedulerImpl: Adding task set 96.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:17:41 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 96) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:17:41 INFO Executor: Running task 0.0 in stage 96.0 (TID 96)\n",
      "23/06/24 15:17:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:17:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:17:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:17:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:17:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:17:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:17:42 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:17:42 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:17:42 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:17:42 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:17:42 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:17:42 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:17:42 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:17:42 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5039 for partition ticketmaster-0\n",
      "23/06/24 15:17:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 96:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:17:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:17:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:17:42 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5042.\n",
      "23/06/24 15:17:43 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-f3665f86-4923-4cb0-b3f5-6c1270681f79/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:17:43 INFO FileOutputCommitter: Saved output of task 'attempt_202306241517416351503253641085835_0096_m_000000_96' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-f3665f86-4923-4cb0-b3f5-6c1270681f79/_temporary/0/task_202306241517416351503253641085835_0096_m_000000\n",
      "23/06/24 15:17:43 INFO SparkHadoopMapRedUtil: attempt_202306241517416351503253641085835_0096_m_000000_96: Committed. Elapsed time: 820 ms.\n",
      "23/06/24 15:17:43 INFO Executor: Finished task 0.0 in stage 96.0 (TID 96). 2536 bytes result sent to driver\n",
      "23/06/24 15:17:43 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 96) in 1883 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:17:43 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:17:43 INFO DAGScheduler: ResultStage 96 (start at NativeMethodAccessorImpl.java:0) finished in 1.908 s\n",
      "23/06/24 15:17:43 INFO DAGScheduler: Job 96 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:17:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 96: Stage finished\n",
      "23/06/24 15:17:43 INFO DAGScheduler: Job 96 finished: start at NativeMethodAccessorImpl.java:0, took 1.908430 s\n",
      "23/06/24 15:17:43 INFO FileFormatWriter: Start to commit write Job 502c3365-a94a-499d-bfc4-ec179329df5a.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:17:44 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-f3665f86-4923-4cb0-b3f5-6c1270681f79/_temporary/0/task_202306241517416351503253641085835_0096_m_000000/' directory.\n",
      "23/06/24 15:17:45 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-f3665f86-4923-4cb0-b3f5-6c1270681f79/' directory.\n",
      "23/06/24 15:17:45 INFO FileFormatWriter: Write Job 502c3365-a94a-499d-bfc4-ec179329df5a committed. Elapsed time: 1898 ms.\n",
      "23/06/24 15:17:45 INFO FileFormatWriter: Finished processing stats for write job 502c3365-a94a-499d-bfc4-ec179329df5a.\n",
      "23/06/24 15:17:46 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-f3665f86-4923-4cb0-b3f5-6c1270681f79/part-00000-291c8883-e548-4806-8640-7b04d9ecf2b5-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=d90d4a6d-8ea1-418b-ad1d-68fdf8e25327, location=US}\n",
      "23/06/24 15:17:48 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=d90d4a6d-8ea1-418b-ad1d-68fdf8e25327, location=US}\n",
      "23/06/24 15:17:49 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/300 using temp file gs://kafka-spark-data/spark-metadata/commits/.300.a0c1e6ab-967d-47ec-84f7-fce253454aff.tmp\n",
      "23/06/24 15:17:50 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.300.a0c1e6ab-967d-47ec-84f7-fce253454aff.tmp to gs://kafka-spark-data/spark-metadata/commits/300\n",
      "23/06/24 15:17:50 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:17:39.368Z\",\n",
      "  \"batchId\" : 300,\n",
      "  \"numInputRows\" : 3,\n",
      "  \"inputRowsPerSecond\" : 0.21937842778793418,\n",
      "  \"processedRowsPerSecond\" : 0.26848040093073205,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7822,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 11,\n",
      "    \"queryPlanning\" : 11,\n",
      "    \"triggerExecution\" : 11174,\n",
      "    \"walCommit\" : 1956\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5038\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5041\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 3,\n",
      "    \"inputRowsPerSecond\" : 0.21937842778793418,\n",
      "    \"processedRowsPerSecond\" : 0.26848040093073205\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:17:50 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 11178 milliseconds\n",
      "23/06/24 15:17:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:17:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 5043.\n",
      "23/06/24 15:17:50 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/301 using temp file gs://kafka-spark-data/spark-metadata/offsets/.301.13256f63-4d2b-4a06-97e8-ee9eb5acf170.tmp\n",
      "23/06/24 15:17:51 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.301.13256f63-4d2b-4a06-97e8-ee9eb5acf170.tmp to gs://kafka-spark-data/spark-metadata/offsets/301\n",
      "23/06/24 15:17:51 INFO MicroBatchExecution: Committed offsets for batch 301. Metadata OffsetSeqMetadata(0,1687637870561,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:17:52 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:17:52 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:17:52 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:17:52 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:17:52 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:17:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:17:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:17:52 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:17:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:17:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:17:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:17:53 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:17:53 INFO DAGScheduler: Got job 97 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:17:53 INFO DAGScheduler: Final stage: ResultStage 97 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:17:53 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:17:53 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:17:53 INFO DAGScheduler: Submitting ResultStage 97 (MapPartitionsRDD[685] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:17:53 INFO BlockManagerInfo: Removed broadcast_96_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:17:53 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:17:53 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:17:53 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:17:53 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:17:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 97 (MapPartitionsRDD[685] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:17:53 INFO TaskSchedulerImpl: Adding task set 97.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:17:53 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 97) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:17:53 INFO Executor: Running task 0.0 in stage 97.0 (TID 97)\n",
      "23/06/24 15:17:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:17:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:17:53 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:17:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:17:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:17:53 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:17:53 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:17:53 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:17:53 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:17:53 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:17:53 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:17:53 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:17:53 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:17:53 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5041 for partition ticketmaster-0\n",
      "23/06/24 15:17:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:17:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:17:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:17:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5044.\n",
      "23/06/24 15:17:53 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5042 for partition ticketmaster-0\n",
      "23/06/24 15:17:53 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 97:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:17:54 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:17:54 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:17:54 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5044.\n",
      "23/06/24 15:17:55 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-922f2e89-2a2a-464c-bd30-7eaa4223fec8/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:17:55 INFO FileOutputCommitter: Saved output of task 'attempt_202306241517535252060903859482088_0097_m_000000_97' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-922f2e89-2a2a-464c-bd30-7eaa4223fec8/_temporary/0/task_202306241517535252060903859482088_0097_m_000000\n",
      "23/06/24 15:17:55 INFO SparkHadoopMapRedUtil: attempt_202306241517535252060903859482088_0097_m_000000_97: Committed. Elapsed time: 1101 ms.\n",
      "23/06/24 15:17:55 INFO Executor: Finished task 0.0 in stage 97.0 (TID 97). 2579 bytes result sent to driver\n",
      "23/06/24 15:17:55 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 97) in 2252 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:17:55 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:17:55 INFO DAGScheduler: ResultStage 97 (start at NativeMethodAccessorImpl.java:0) finished in 2.291 s\n",
      "23/06/24 15:17:55 INFO DAGScheduler: Job 97 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:17:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 97: Stage finished\n",
      "23/06/24 15:17:55 INFO DAGScheduler: Job 97 finished: start at NativeMethodAccessorImpl.java:0, took 2.292468 s\n",
      "23/06/24 15:17:55 INFO FileFormatWriter: Start to commit write Job 1825979c-9732-4442-87f6-2e4d9704002b.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:17:56 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-922f2e89-2a2a-464c-bd30-7eaa4223fec8/_temporary/0/task_202306241517535252060903859482088_0097_m_000000/' directory.\n",
      "23/06/24 15:17:57 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-922f2e89-2a2a-464c-bd30-7eaa4223fec8/' directory.\n",
      "23/06/24 15:17:58 INFO FileFormatWriter: Write Job 1825979c-9732-4442-87f6-2e4d9704002b committed. Elapsed time: 2539 ms.\n",
      "23/06/24 15:17:58 INFO FileFormatWriter: Finished processing stats for write job 1825979c-9732-4442-87f6-2e4d9704002b.\n",
      "23/06/24 15:17:58 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-922f2e89-2a2a-464c-bd30-7eaa4223fec8/part-00000-3e7f53d3-9e63-40f3-a57d-3652b6946331-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=7bc36e43-4c2c-4fa8-b708-82eadf851c5b, location=US}\n",
      "23/06/24 15:18:00 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=7bc36e43-4c2c-4fa8-b708-82eadf851c5b, location=US}\n",
      "23/06/24 15:18:01 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/301 using temp file gs://kafka-spark-data/spark-metadata/commits/.301.87738131-971e-47c6-93e0-4615ded73d0a.tmp\n",
      "23/06/24 15:18:02 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.301.87738131-971e-47c6-93e0-4615ded73d0a.tmp to gs://kafka-spark-data/spark-metadata/commits/301\n",
      "23/06/24 15:18:02 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:17:50.546Z\",\n",
      "  \"batchId\" : 301,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.1789228842368939,\n",
      "  \"processedRowsPerSecond\" : 0.1704303365999148,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 8129,\n",
      "    \"getBatch\" : 2,\n",
      "    \"latestOffset\" : 14,\n",
      "    \"queryPlanning\" : 32,\n",
      "    \"triggerExecution\" : 11734,\n",
      "    \"walCommit\" : 1934\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5041\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5043\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.1789228842368939,\n",
      "    \"processedRowsPerSecond\" : 0.1704303365999148\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:18:02 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 11737 milliseconds\n",
      "23/06/24 15:18:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:18:02 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 5045.\n",
      "23/06/24 15:18:02 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/302 using temp file gs://kafka-spark-data/spark-metadata/offsets/.302.7b6c5529-f886-4222-a225-21cbb0ff6e68.tmp\n",
      "23/06/24 15:18:03 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.302.7b6c5529-f886-4222-a225-21cbb0ff6e68.tmp to gs://kafka-spark-data/spark-metadata/offsets/302\n",
      "23/06/24 15:18:03 INFO MicroBatchExecution: Committed offsets for batch 302. Metadata OffsetSeqMetadata(0,1687637882287,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:18:04 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:18:04 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:18:04 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:18:04 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:18:04 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:18:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:18:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:18:04 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:18:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:18:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:18:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:18:05 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:18:05 INFO DAGScheduler: Got job 98 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:18:05 INFO DAGScheduler: Final stage: ResultStage 98 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:18:05 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:18:05 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:18:05 INFO DAGScheduler: Submitting ResultStage 98 (MapPartitionsRDD[692] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:18:05 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 295.4 KiB, free 433.7 MiB)\n",
      "23/06/24 15:18:05 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 433.6 MiB)\n",
      "23/06/24 15:18:05 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.2 MiB)\n",
      "23/06/24 15:18:05 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:18:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 98 (MapPartitionsRDD[692] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:18:05 INFO TaskSchedulerImpl: Adding task set 98.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:18:05 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 98) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:18:05 INFO Executor: Running task 0.0 in stage 98.0 (TID 98)\n",
      "23/06/24 15:18:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:18:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:18:05 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:18:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:18:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:18:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:18:05 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:18:05 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:18:05 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:18:05 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:18:05 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:18:05 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:18:05 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:18:05 INFO BlockManagerInfo: Removed broadcast_97_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:18:05 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5044 for partition ticketmaster-0\n",
      "23/06/24 15:18:05 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 98:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:18:05 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:18:05 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:18:05 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5046.\n",
      "23/06/24 15:18:07 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-e59c680c-a7ab-4408-91dc-4bd5a08b471e/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:18:07 INFO FileOutputCommitter: Saved output of task 'attempt_202306241518053728827238604608187_0098_m_000000_98' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-e59c680c-a7ab-4408-91dc-4bd5a08b471e/_temporary/0/task_202306241518053728827238604608187_0098_m_000000\n",
      "23/06/24 15:18:07 INFO SparkHadoopMapRedUtil: attempt_202306241518053728827238604608187_0098_m_000000_98: Committed. Elapsed time: 1008 ms.\n",
      "23/06/24 15:18:07 INFO Executor: Finished task 0.0 in stage 98.0 (TID 98). 2579 bytes result sent to driver\n",
      "23/06/24 15:18:07 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 98) in 2134 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:18:07 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:18:07 INFO DAGScheduler: ResultStage 98 (start at NativeMethodAccessorImpl.java:0) finished in 2.161 s\n",
      "23/06/24 15:18:07 INFO DAGScheduler: Job 98 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:18:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 98: Stage finished\n",
      "23/06/24 15:18:07 INFO DAGScheduler: Job 98 finished: start at NativeMethodAccessorImpl.java:0, took 2.162956 s\n",
      "23/06/24 15:18:07 INFO FileFormatWriter: Start to commit write Job f30d7f2a-a9a7-44f2-b985-c37c07bf48d6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:18:08 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-e59c680c-a7ab-4408-91dc-4bd5a08b471e/_temporary/0/task_202306241518053728827238604608187_0098_m_000000/' directory.\n",
      "23/06/24 15:18:08 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-e59c680c-a7ab-4408-91dc-4bd5a08b471e/' directory.\n",
      "23/06/24 15:18:09 INFO FileFormatWriter: Write Job f30d7f2a-a9a7-44f2-b985-c37c07bf48d6 committed. Elapsed time: 2104 ms.\n",
      "23/06/24 15:18:09 INFO FileFormatWriter: Finished processing stats for write job f30d7f2a-a9a7-44f2-b985-c37c07bf48d6.\n",
      "23/06/24 15:18:09 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-e59c680c-a7ab-4408-91dc-4bd5a08b471e/part-00000-f404389a-8686-4301-8082-0f5a846d9f1a-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=59bd710e-35e4-46fc-9578-8a80390c265e, location=US}\n",
      "23/06/24 15:18:12 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=59bd710e-35e4-46fc-9578-8a80390c265e, location=US}\n",
      "23/06/24 15:18:13 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/302 using temp file gs://kafka-spark-data/spark-metadata/commits/.302.47a6a348-0ab3-40dc-b7ae-8efbb217d723.tmp\n",
      "23/06/24 15:18:13 INFO BlockManagerInfo: Removed broadcast_98_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:18:13 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.302.47a6a348-0ab3-40dc-b7ae-8efbb217d723.tmp to gs://kafka-spark-data/spark-metadata/commits/302\n",
      "23/06/24 15:18:13 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:18:02.283Z\",\n",
      "  \"batchId\" : 302,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.1704012950498424,\n",
      "  \"processedRowsPerSecond\" : 0.17228012748729435,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 8422,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 3,\n",
      "    \"queryPlanning\" : 29,\n",
      "    \"triggerExecution\" : 11609,\n",
      "    \"walCommit\" : 2142\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5043\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5045\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.1704012950498424,\n",
      "    \"processedRowsPerSecond\" : 0.17228012748729435\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:18:13 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 11612 milliseconds\n",
      "23/06/24 15:18:13 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:18:13 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 5048.\n",
      "23/06/24 15:18:14 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/303 using temp file gs://kafka-spark-data/spark-metadata/offsets/.303.2afcc3d7-83a6-49ce-bf6a-378fb31668a6.tmp\n",
      "23/06/24 15:18:14 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.303.2afcc3d7-83a6-49ce-bf6a-378fb31668a6.tmp to gs://kafka-spark-data/spark-metadata/offsets/303\n",
      "23/06/24 15:18:14 INFO MicroBatchExecution: Committed offsets for batch 303. Metadata OffsetSeqMetadata(0,1687637893906,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:18:15 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:18:15 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:18:15 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:18:15 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:18:15 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:18:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:18:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:18:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:18:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:18:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:18:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:18:15 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:18:15 INFO DAGScheduler: Got job 99 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:18:15 INFO DAGScheduler: Final stage: ResultStage 99 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:18:15 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:18:15 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:18:15 INFO DAGScheduler: Submitting ResultStage 99 (MapPartitionsRDD[699] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:18:15 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:18:15 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:18:15 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:18:15 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:18:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 99 (MapPartitionsRDD[699] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:18:15 INFO TaskSchedulerImpl: Adding task set 99.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:18:15 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 99) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:18:15 INFO Executor: Running task 0.0 in stage 99.0 (TID 99)\n",
      "23/06/24 15:18:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:18:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:18:15 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:18:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:18:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:18:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:18:15 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:18:15 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:18:15 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:18:15 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:18:15 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:18:15 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:18:15 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:18:16 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5046 for partition ticketmaster-0\n",
      "23/06/24 15:18:16 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 99:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:18:16 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:18:16 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:18:16 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5048.\n",
      "23/06/24 15:18:17 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-fbdf1290-b746-4474-b577-bbef468e6831/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:18:17 INFO FileOutputCommitter: Saved output of task 'attempt_202306241518158571607553972581451_0099_m_000000_99' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-fbdf1290-b746-4474-b577-bbef468e6831/_temporary/0/task_202306241518158571607553972581451_0099_m_000000\n",
      "23/06/24 15:18:17 INFO SparkHadoopMapRedUtil: attempt_202306241518158571607553972581451_0099_m_000000_99: Committed. Elapsed time: 940 ms.\n",
      "23/06/24 15:18:17 INFO Executor: Finished task 0.0 in stage 99.0 (TID 99). 2536 bytes result sent to driver\n",
      "23/06/24 15:18:17 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 99) in 1855 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:18:17 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:18:17 INFO DAGScheduler: ResultStage 99 (start at NativeMethodAccessorImpl.java:0) finished in 1.893 s\n",
      "23/06/24 15:18:17 INFO DAGScheduler: Job 99 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:18:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 99: Stage finished\n",
      "23/06/24 15:18:17 INFO DAGScheduler: Job 99 finished: start at NativeMethodAccessorImpl.java:0, took 1.895035 s\n",
      "23/06/24 15:18:17 INFO FileFormatWriter: Start to commit write Job 6513602e-9035-479c-814d-3c23d0c92447.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:18:18 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-fbdf1290-b746-4474-b577-bbef468e6831/_temporary/0/task_202306241518158571607553972581451_0099_m_000000/' directory.\n",
      "23/06/24 15:18:19 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-fbdf1290-b746-4474-b577-bbef468e6831/' directory.\n",
      "23/06/24 15:18:19 INFO FileFormatWriter: Write Job 6513602e-9035-479c-814d-3c23d0c92447 committed. Elapsed time: 1862 ms.\n",
      "23/06/24 15:18:19 INFO FileFormatWriter: Finished processing stats for write job 6513602e-9035-479c-814d-3c23d0c92447.\n",
      "23/06/24 15:18:20 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-fbdf1290-b746-4474-b577-bbef468e6831/part-00000-1b801d7f-1904-4fb5-829a-6022cc0d4ca8-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=63a0bcff-b405-4a30-aa56-221cad86e4dc, location=US}\n",
      "23/06/24 15:18:20 INFO BlockManagerInfo: Removed broadcast_99_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:18:23 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=63a0bcff-b405-4a30-aa56-221cad86e4dc, location=US}\n",
      "23/06/24 15:18:23 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/303 using temp file gs://kafka-spark-data/spark-metadata/commits/.303.1bd265a2-0c47-4b9f-afd2-166f92147eb0.tmp\n",
      "23/06/24 15:18:25 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.303.1bd265a2-0c47-4b9f-afd2-166f92147eb0.tmp to gs://kafka-spark-data/spark-metadata/commits/303\n",
      "23/06/24 15:18:25 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:18:13.895Z\",\n",
      "  \"batchId\" : 303,\n",
      "  \"numInputRows\" : 3,\n",
      "  \"inputRowsPerSecond\" : 0.2583534274888047,\n",
      "  \"processedRowsPerSecond\" : 0.2690100430416069,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 8508,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 10,\n",
      "    \"queryPlanning\" : 4,\n",
      "    \"triggerExecution\" : 11152,\n",
      "    \"walCommit\" : 1366\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5045\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5048\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 3,\n",
      "    \"inputRowsPerSecond\" : 0.2583534274888047,\n",
      "    \"processedRowsPerSecond\" : 0.2690100430416069\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:18:25 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 11156 milliseconds\n",
      "23/06/24 15:18:25 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:18:25 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 5050.\n",
      "23/06/24 15:18:25 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/304 using temp file gs://kafka-spark-data/spark-metadata/offsets/.304.ee3985d0-d5f5-425f-9b6c-08b24963b67a.tmp\n",
      "23/06/24 15:18:25 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.304.ee3985d0-d5f5-425f-9b6c-08b24963b67a.tmp to gs://kafka-spark-data/spark-metadata/offsets/304\n",
      "23/06/24 15:18:25 INFO MicroBatchExecution: Committed offsets for batch 304. Metadata OffsetSeqMetadata(0,1687637905060,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:18:26 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:18:26 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:18:26 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:18:26 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:18:26 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:18:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:18:26 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:18:26 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:18:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:18:26 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:18:26 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:18:26 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:18:26 INFO DAGScheduler: Got job 100 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:18:26 INFO DAGScheduler: Final stage: ResultStage 100 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:18:26 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:18:26 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:18:26 INFO DAGScheduler: Submitting ResultStage 100 (MapPartitionsRDD[706] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:18:26 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:18:26 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:18:26 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:18:26 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:18:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 100 (MapPartitionsRDD[706] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:18:26 INFO TaskSchedulerImpl: Adding task set 100.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:18:26 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 100) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:18:26 INFO Executor: Running task 0.0 in stage 100.0 (TID 100)\n",
      "23/06/24 15:18:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:18:26 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:18:26 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:18:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:18:26 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:18:26 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:18:26 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:18:26 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:18:26 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:18:26 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:18:26 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:18:26 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:18:26 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:18:27 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5048 for partition ticketmaster-0\n",
      "23/06/24 15:18:27 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 100:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:18:27 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:18:27 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:18:27 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5050.\n",
      "23/06/24 15:18:28 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-510d3ff5-7792-4c04-bb08-55d2b25023ae/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:18:28 INFO FileOutputCommitter: Saved output of task 'attempt_202306241518268929131323412572316_0100_m_000000_100' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-510d3ff5-7792-4c04-bb08-55d2b25023ae/_temporary/0/task_202306241518268929131323412572316_0100_m_000000\n",
      "23/06/24 15:18:28 INFO SparkHadoopMapRedUtil: attempt_202306241518268929131323412572316_0100_m_000000_100: Committed. Elapsed time: 1003 ms.\n",
      "23/06/24 15:18:28 INFO Executor: Finished task 0.0 in stage 100.0 (TID 100). 2579 bytes result sent to driver\n",
      "23/06/24 15:18:28 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 100) in 2034 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:18:28 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:18:28 INFO DAGScheduler: ResultStage 100 (start at NativeMethodAccessorImpl.java:0) finished in 2.090 s\n",
      "23/06/24 15:18:28 INFO DAGScheduler: Job 100 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:18:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 100: Stage finished\n",
      "23/06/24 15:18:28 INFO DAGScheduler: Job 100 finished: start at NativeMethodAccessorImpl.java:0, took 2.093477 s\n",
      "23/06/24 15:18:28 INFO FileFormatWriter: Start to commit write Job 2b2813d8-9bc8-4e77-95b9-da8187b592d6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:18:30 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-510d3ff5-7792-4c04-bb08-55d2b25023ae/_temporary/0/task_202306241518268929131323412572316_0100_m_000000/' directory.\n",
      "23/06/24 15:18:30 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-510d3ff5-7792-4c04-bb08-55d2b25023ae/' directory.\n",
      "23/06/24 15:18:31 INFO FileFormatWriter: Write Job 2b2813d8-9bc8-4e77-95b9-da8187b592d6 committed. Elapsed time: 2026 ms.\n",
      "23/06/24 15:18:31 INFO FileFormatWriter: Finished processing stats for write job 2b2813d8-9bc8-4e77-95b9-da8187b592d6.\n",
      "23/06/24 15:18:31 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-510d3ff5-7792-4c04-bb08-55d2b25023ae/part-00000-e2e5e1be-9371-49d1-9de8-9ca33d64ac01-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=d1e4946e-3e2b-43ee-a17a-586e0ff0773c, location=US}\n",
      "23/06/24 15:18:34 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=d1e4946e-3e2b-43ee-a17a-586e0ff0773c, location=US}\n",
      "23/06/24 15:18:35 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/304 using temp file gs://kafka-spark-data/spark-metadata/commits/.304.d688f444-98ac-48f4-97c6-861b080d3bdc.tmp\n",
      "23/06/24 15:18:35 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.304.d688f444-98ac-48f4-97c6-861b080d3bdc.tmp to gs://kafka-spark-data/spark-metadata/commits/304\n",
      "23/06/24 15:18:35 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:18:25.051Z\",\n",
      "  \"batchId\" : 304,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.17927572606669057,\n",
      "  \"processedRowsPerSecond\" : 0.18520233354940274,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 8513,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 9,\n",
      "    \"queryPlanning\" : 17,\n",
      "    \"triggerExecution\" : 10799,\n",
      "    \"walCommit\" : 1237\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5048\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5050\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.17927572606669057,\n",
      "    \"processedRowsPerSecond\" : 0.18520233354940274\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:18:35 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 10803 milliseconds\n",
      "23/06/24 15:18:35 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:18:35 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 5052.\n",
      "23/06/24 15:18:36 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/305 using temp file gs://kafka-spark-data/spark-metadata/offsets/.305.b166d4ba-cdfa-4238-9252-8964df6ffd41.tmp\n",
      "23/06/24 15:18:36 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.305.b166d4ba-cdfa-4238-9252-8964df6ffd41.tmp to gs://kafka-spark-data/spark-metadata/offsets/305\n",
      "23/06/24 15:18:36 INFO MicroBatchExecution: Committed offsets for batch 305. Metadata OffsetSeqMetadata(0,1687637915862,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:18:37 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:18:37 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:18:37 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:18:37 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:18:37 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:18:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:18:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:18:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:18:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:18:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:18:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:18:37 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:18:37 INFO DAGScheduler: Got job 101 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:18:37 INFO DAGScheduler: Final stage: ResultStage 101 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:18:37 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:18:37 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:18:37 INFO DAGScheduler: Submitting ResultStage 101 (MapPartitionsRDD[713] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:18:37 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 295.4 KiB, free 433.7 MiB)\n",
      "23/06/24 15:18:37 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 433.6 MiB)\n",
      "23/06/24 15:18:37 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.2 MiB)\n",
      "23/06/24 15:18:37 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:18:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 101 (MapPartitionsRDD[713] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:18:37 INFO TaskSchedulerImpl: Adding task set 101.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:18:37 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 101) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:18:37 INFO Executor: Running task 0.0 in stage 101.0 (TID 101)\n",
      "23/06/24 15:18:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:18:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:18:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:18:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:18:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:18:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:18:37 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:18:37 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:18:37 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:18:37 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:18:37 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:18:37 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:18:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:18:37 INFO BlockManagerInfo: Removed broadcast_100_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:18:38 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5050 for partition ticketmaster-0\n",
      "23/06/24 15:18:38 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 101:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:18:38 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:18:38 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:18:38 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5053.\n",
      "23/06/24 15:18:39 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-296e2e58-1b3d-4936-a6d7-74cf3a134a81/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:18:39 INFO FileOutputCommitter: Saved output of task 'attempt_202306241518378817881606940127996_0101_m_000000_101' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-296e2e58-1b3d-4936-a6d7-74cf3a134a81/_temporary/0/task_202306241518378817881606940127996_0101_m_000000\n",
      "23/06/24 15:18:39 INFO SparkHadoopMapRedUtil: attempt_202306241518378817881606940127996_0101_m_000000_101: Committed. Elapsed time: 1115 ms.\n",
      "23/06/24 15:18:39 INFO Executor: Finished task 0.0 in stage 101.0 (TID 101). 2579 bytes result sent to driver\n",
      "23/06/24 15:18:39 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 101) in 2101 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:18:39 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:18:39 INFO DAGScheduler: ResultStage 101 (start at NativeMethodAccessorImpl.java:0) finished in 2.126 s\n",
      "23/06/24 15:18:39 INFO DAGScheduler: Job 101 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:18:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 101: Stage finished\n",
      "23/06/24 15:18:39 INFO DAGScheduler: Job 101 finished: start at NativeMethodAccessorImpl.java:0, took 2.127710 s\n",
      "23/06/24 15:18:39 INFO FileFormatWriter: Start to commit write Job 89c32d06-0cee-4d4f-a7a0-d9f78420fa38.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:18:40 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-296e2e58-1b3d-4936-a6d7-74cf3a134a81/_temporary/0/task_202306241518378817881606940127996_0101_m_000000/' directory.\n",
      "23/06/24 15:18:41 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-296e2e58-1b3d-4936-a6d7-74cf3a134a81/' directory.\n",
      "23/06/24 15:18:41 INFO BlockManagerInfo: Removed broadcast_101_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:18:41 INFO FileFormatWriter: Write Job 89c32d06-0cee-4d4f-a7a0-d9f78420fa38 committed. Elapsed time: 1967 ms.\n",
      "23/06/24 15:18:41 INFO FileFormatWriter: Finished processing stats for write job 89c32d06-0cee-4d4f-a7a0-d9f78420fa38.\n",
      "23/06/24 15:18:42 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-296e2e58-1b3d-4936-a6d7-74cf3a134a81/part-00000-1bf58571-e30b-4d4b-99f6-65b480ea3ac6-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=11bf3219-4beb-481d-a223-0a7d76e3ddb8, location=US}\n",
      "23/06/24 15:18:43 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=11bf3219-4beb-481d-a223-0a7d76e3ddb8, location=US}\n",
      "23/06/24 15:18:44 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/305 using temp file gs://kafka-spark-data/spark-metadata/commits/.305.840e1a8a-e28b-40da-b2f7-f6f50aba52da.tmp\n",
      "23/06/24 15:18:45 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.305.840e1a8a-e28b-40da-b2f7-f6f50aba52da.tmp to gs://kafka-spark-data/spark-metadata/commits/305\n",
      "23/06/24 15:18:45 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:18:35.854Z\",\n",
      "  \"batchId\" : 305,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.18513375914097935,\n",
      "  \"processedRowsPerSecond\" : 0.20929259104227713,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7115,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 8,\n",
      "    \"queryPlanning\" : 19,\n",
      "    \"triggerExecution\" : 9556,\n",
      "    \"walCommit\" : 1375\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5050\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5052\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.18513375914097935,\n",
      "    \"processedRowsPerSecond\" : 0.20929259104227713\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:18:45 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:18:45 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 5054.\n",
      "23/06/24 15:18:45 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/306 using temp file gs://kafka-spark-data/spark-metadata/offsets/.306.38ee6b41-23f2-462e-961e-7292ca111612.tmp\n",
      "23/06/24 15:18:46 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.306.38ee6b41-23f2-462e-961e-7292ca111612.tmp to gs://kafka-spark-data/spark-metadata/offsets/306\n",
      "23/06/24 15:18:46 INFO MicroBatchExecution: Committed offsets for batch 306. Metadata OffsetSeqMetadata(0,1687637925430,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:18:46 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:18:46 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:18:46 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:18:46 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:18:47 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:18:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:18:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:18:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:18:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:18:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:18:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:18:47 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:18:47 INFO DAGScheduler: Got job 102 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:18:47 INFO DAGScheduler: Final stage: ResultStage 102 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:18:47 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:18:47 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:18:47 INFO DAGScheduler: Submitting ResultStage 102 (MapPartitionsRDD[720] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:18:47 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:18:47 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:18:47 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:18:47 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:18:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 102 (MapPartitionsRDD[720] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:18:47 INFO TaskSchedulerImpl: Adding task set 102.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:18:47 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 102) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:18:47 INFO Executor: Running task 0.0 in stage 102.0 (TID 102)\n",
      "23/06/24 15:18:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:18:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:18:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:18:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:18:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:18:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:18:47 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:18:47 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:18:47 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:18:47 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:18:47 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:18:47 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:18:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:18:47 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5053 for partition ticketmaster-0\n",
      "23/06/24 15:18:47 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:18:47 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:18:47 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:18:47 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5055.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 102:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:18:48 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-d0db4662-40e1-447a-b108-18a629128414/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:18:48 INFO FileOutputCommitter: Saved output of task 'attempt_202306241518477242550692760150757_0102_m_000000_102' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-d0db4662-40e1-447a-b108-18a629128414/_temporary/0/task_202306241518477242550692760150757_0102_m_000000\n",
      "23/06/24 15:18:48 INFO SparkHadoopMapRedUtil: attempt_202306241518477242550692760150757_0102_m_000000_102: Committed. Elapsed time: 882 ms.\n",
      "23/06/24 15:18:48 INFO Executor: Finished task 0.0 in stage 102.0 (TID 102). 2536 bytes result sent to driver\n",
      "23/06/24 15:18:48 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 102) in 1443 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:18:48 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:18:48 INFO DAGScheduler: ResultStage 102 (start at NativeMethodAccessorImpl.java:0) finished in 1.482 s\n",
      "23/06/24 15:18:48 INFO DAGScheduler: Job 102 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:18:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 102: Stage finished\n",
      "23/06/24 15:18:48 INFO DAGScheduler: Job 102 finished: start at NativeMethodAccessorImpl.java:0, took 1.483428 s\n",
      "23/06/24 15:18:48 INFO FileFormatWriter: Start to commit write Job 86b59d9d-90d5-49b7-bc2d-bb27e4a5b39e.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:18:50 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-d0db4662-40e1-447a-b108-18a629128414/_temporary/0/task_202306241518477242550692760150757_0102_m_000000/' directory.\n",
      "23/06/24 15:18:50 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-d0db4662-40e1-447a-b108-18a629128414/' directory.\n",
      "23/06/24 15:18:50 INFO BlockManagerInfo: Removed broadcast_102_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:18:51 INFO FileFormatWriter: Write Job 86b59d9d-90d5-49b7-bc2d-bb27e4a5b39e committed. Elapsed time: 2103 ms.\n",
      "23/06/24 15:18:51 INFO FileFormatWriter: Finished processing stats for write job 86b59d9d-90d5-49b7-bc2d-bb27e4a5b39e.\n",
      "23/06/24 15:18:51 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-d0db4662-40e1-447a-b108-18a629128414/part-00000-dc9d3a18-37a4-43b7-b1d3-ca4290badf83-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=ba5f1610-0e5a-4f7f-911e-05969cc4669d, location=US}\n",
      "23/06/24 15:18:53 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=ba5f1610-0e5a-4f7f-911e-05969cc4669d, location=US}\n",
      "23/06/24 15:18:53 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/306 using temp file gs://kafka-spark-data/spark-metadata/commits/.306.2c41b4e9-deb0-4962-b661-556e239ee7de.tmp\n",
      "23/06/24 15:18:54 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.306.2c41b4e9-deb0-4962-b661-556e239ee7de.tmp to gs://kafka-spark-data/spark-metadata/commits/306\n",
      "23/06/24 15:18:54 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:18:45.414Z\",\n",
      "  \"batchId\" : 306,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.20920502092050208,\n",
      "  \"processedRowsPerSecond\" : 0.21429336762027215,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7046,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 16,\n",
      "    \"queryPlanning\" : 9,\n",
      "    \"triggerExecution\" : 9333,\n",
      "    \"walCommit\" : 1298\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5052\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5054\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.20920502092050208,\n",
      "    \"processedRowsPerSecond\" : 0.21429336762027215\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:18:54 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:18:54 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 5056.\n",
      "23/06/24 15:18:54 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/307 using temp file gs://kafka-spark-data/spark-metadata/offsets/.307.3046ce5a-061f-48a2-b9bd-a5ca1d3d2772.tmp\n",
      "23/06/24 15:18:55 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.307.3046ce5a-061f-48a2-b9bd-a5ca1d3d2772.tmp to gs://kafka-spark-data/spark-metadata/offsets/307\n",
      "23/06/24 15:18:55 INFO MicroBatchExecution: Committed offsets for batch 307. Metadata OffsetSeqMetadata(0,1687637934757,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:18:56 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:18:56 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:18:56 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:18:56 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:18:56 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:18:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:18:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:18:56 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:18:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:18:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:18:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:18:56 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:18:56 INFO DAGScheduler: Got job 103 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:18:56 INFO DAGScheduler: Final stage: ResultStage 103 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:18:56 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:18:56 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:18:56 INFO DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[727] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:18:56 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:18:56 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:18:56 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:18:56 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:18:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 103 (MapPartitionsRDD[727] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:18:56 INFO TaskSchedulerImpl: Adding task set 103.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:18:56 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 103) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:18:56 INFO Executor: Running task 0.0 in stage 103.0 (TID 103)\n",
      "23/06/24 15:18:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:18:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:18:56 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:18:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:18:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:18:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:18:56 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:18:56 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:18:56 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:18:56 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:18:56 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:18:56 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:18:56 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:18:56 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5054 for partition ticketmaster-0\n",
      "23/06/24 15:18:56 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:18:56 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:18:56 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:18:56 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5056.\n",
      "23/06/24 15:18:56 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5055 for partition ticketmaster-0\n",
      "23/06/24 15:18:56 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 103:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:18:57 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:18:57 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:18:57 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5056.\n",
      "23/06/24 15:18:58 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-a97a5bbf-76bc-40bb-8d4a-c347b401d1b5/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:18:58 INFO FileOutputCommitter: Saved output of task 'attempt_202306241518564010091010402261404_0103_m_000000_103' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-a97a5bbf-76bc-40bb-8d4a-c347b401d1b5/_temporary/0/task_202306241518564010091010402261404_0103_m_000000\n",
      "23/06/24 15:18:58 INFO SparkHadoopMapRedUtil: attempt_202306241518564010091010402261404_0103_m_000000_103: Committed. Elapsed time: 925 ms.\n",
      "23/06/24 15:18:58 INFO Executor: Finished task 0.0 in stage 103.0 (TID 103). 2536 bytes result sent to driver\n",
      "23/06/24 15:18:58 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 103) in 1816 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:18:58 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:18:58 INFO DAGScheduler: ResultStage 103 (start at NativeMethodAccessorImpl.java:0) finished in 1.852 s\n",
      "23/06/24 15:18:58 INFO DAGScheduler: Job 103 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:18:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 103: Stage finished\n",
      "23/06/24 15:18:58 INFO DAGScheduler: Job 103 finished: start at NativeMethodAccessorImpl.java:0, took 1.853383 s\n",
      "23/06/24 15:18:58 INFO FileFormatWriter: Start to commit write Job 1b5c110a-b18b-414f-a0fc-3b14c5e9a5fd.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:18:59 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-a97a5bbf-76bc-40bb-8d4a-c347b401d1b5/_temporary/0/task_202306241518564010091010402261404_0103_m_000000/' directory.\n",
      "23/06/24 15:19:00 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-a97a5bbf-76bc-40bb-8d4a-c347b401d1b5/' directory.\n",
      "23/06/24 15:19:00 INFO FileFormatWriter: Write Job 1b5c110a-b18b-414f-a0fc-3b14c5e9a5fd committed. Elapsed time: 2365 ms.\n",
      "23/06/24 15:19:00 INFO FileFormatWriter: Finished processing stats for write job 1b5c110a-b18b-414f-a0fc-3b14c5e9a5fd.\n",
      "23/06/24 15:19:01 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-a97a5bbf-76bc-40bb-8d4a-c347b401d1b5/part-00000-377fd59f-9c0b-49d7-a7e1-0ef5e0232ad0-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=6587292a-e64f-4794-9d38-d31649f996ea, location=US}\n",
      "23/06/24 15:19:02 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=6587292a-e64f-4794-9d38-d31649f996ea, location=US}\n",
      "23/06/24 15:19:03 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/307 using temp file gs://kafka-spark-data/spark-metadata/commits/.307.79ffb8ac-0a41-450c-a670-cd4c8fdcdf69.tmp\n",
      "23/06/24 15:19:03 INFO BlockManagerInfo: Removed broadcast_103_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:19:04 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.307.79ffb8ac-0a41-450c-a670-cd4c8fdcdf69.tmp to gs://kafka-spark-data/spark-metadata/commits/307\n",
      "23/06/24 15:19:04 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:18:54.750Z\",\n",
      "  \"batchId\" : 307,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.21422450728363324,\n",
      "  \"processedRowsPerSecond\" : 0.2080083203328133,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7269,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 7,\n",
      "    \"queryPlanning\" : 20,\n",
      "    \"triggerExecution\" : 9615,\n",
      "    \"walCommit\" : 1313\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5054\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5056\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.21422450728363324,\n",
      "    \"processedRowsPerSecond\" : 0.2080083203328133\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:19:04 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:19:04 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 5058.\n",
      "23/06/24 15:19:04 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/308 using temp file gs://kafka-spark-data/spark-metadata/offsets/.308.b7471c01-c770-45df-9553-0f621a24cf10.tmp\n",
      "23/06/24 15:19:05 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.308.b7471c01-c770-45df-9553-0f621a24cf10.tmp to gs://kafka-spark-data/spark-metadata/offsets/308\n",
      "23/06/24 15:19:05 INFO MicroBatchExecution: Committed offsets for batch 308. Metadata OffsetSeqMetadata(0,1687637944379,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:19:05 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:19:05 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:19:05 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:19:05 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:19:06 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:19:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:19:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:19:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:19:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:19:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:19:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:19:06 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:19:06 INFO DAGScheduler: Got job 104 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:19:06 INFO DAGScheduler: Final stage: ResultStage 104 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:19:06 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:19:06 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:19:06 INFO DAGScheduler: Submitting ResultStage 104 (MapPartitionsRDD[734] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:19:06 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:19:06 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:19:06 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:19:06 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:19:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 104 (MapPartitionsRDD[734] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:19:06 INFO TaskSchedulerImpl: Adding task set 104.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:19:06 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 104) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:19:06 INFO Executor: Running task 0.0 in stage 104.0 (TID 104)\n",
      "23/06/24 15:19:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:19:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:19:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:19:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:19:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:19:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:19:06 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:19:06 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:19:06 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:19:06 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:19:06 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:19:06 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:19:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:19:06 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5056 for partition ticketmaster-0\n",
      "23/06/24 15:19:06 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 104:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:19:07 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:19:07 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:19:07 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5058.\n",
      "23/06/24 15:19:08 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-0ccafbde-c49f-420c-9dc9-0d3c1fffff81/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:19:08 INFO FileOutputCommitter: Saved output of task 'attempt_202306241519067560207427288801162_0104_m_000000_104' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-0ccafbde-c49f-420c-9dc9-0d3c1fffff81/_temporary/0/task_202306241519067560207427288801162_0104_m_000000\n",
      "23/06/24 15:19:08 INFO SparkHadoopMapRedUtil: attempt_202306241519067560207427288801162_0104_m_000000_104: Committed. Elapsed time: 1019 ms.\n",
      "23/06/24 15:19:08 INFO Executor: Finished task 0.0 in stage 104.0 (TID 104). 2536 bytes result sent to driver\n",
      "23/06/24 15:19:08 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 104) in 2036 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:19:08 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:19:08 INFO DAGScheduler: ResultStage 104 (start at NativeMethodAccessorImpl.java:0) finished in 2.071 s\n",
      "23/06/24 15:19:08 INFO DAGScheduler: Job 104 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:19:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 104: Stage finished\n",
      "23/06/24 15:19:08 INFO DAGScheduler: Job 104 finished: start at NativeMethodAccessorImpl.java:0, took 2.073112 s\n",
      "23/06/24 15:19:08 INFO FileFormatWriter: Start to commit write Job 3ea51cd9-a199-4b11-8d76-abd4d7cf59b5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:19:09 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-0ccafbde-c49f-420c-9dc9-0d3c1fffff81/_temporary/0/task_202306241519067560207427288801162_0104_m_000000/' directory.\n",
      "23/06/24 15:19:10 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-0ccafbde-c49f-420c-9dc9-0d3c1fffff81/' directory.\n",
      "23/06/24 15:19:10 INFO FileFormatWriter: Write Job 3ea51cd9-a199-4b11-8d76-abd4d7cf59b5 committed. Elapsed time: 2128 ms.\n",
      "23/06/24 15:19:10 INFO FileFormatWriter: Finished processing stats for write job 3ea51cd9-a199-4b11-8d76-abd4d7cf59b5.\n",
      "23/06/24 15:19:11 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-0ccafbde-c49f-420c-9dc9-0d3c1fffff81/part-00000-08c002eb-d53e-43f3-bf73-588022fbeeed-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=7439f433-eab7-476d-acb8-25394e0f2963, location=US}\n",
      "23/06/24 15:19:13 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=7439f433-eab7-476d-acb8-25394e0f2963, location=US}\n",
      "23/06/24 15:19:14 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/308 using temp file gs://kafka-spark-data/spark-metadata/commits/.308.ca5a51e5-53e4-46db-9fb8-39d52c892f50.tmp\n",
      "23/06/24 15:19:14 INFO BlockManagerInfo: Removed broadcast_104_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:19:14 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.308.ca5a51e5-53e4-46db-9fb8-39d52c892f50.tmp to gs://kafka-spark-data/spark-metadata/commits/308\n",
      "23/06/24 15:19:14 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:19:04.367Z\",\n",
      "  \"batchId\" : 308,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.2079650618696059,\n",
      "  \"processedRowsPerSecond\" : 0.1895914304673429,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 8124,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 12,\n",
      "    \"queryPlanning\" : 6,\n",
      "    \"triggerExecution\" : 10548,\n",
      "    \"walCommit\" : 1399\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5056\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5058\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.2079650618696059,\n",
      "    \"processedRowsPerSecond\" : 0.1895914304673429\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:19:14 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 10551 milliseconds\n",
      "23/06/24 15:19:14 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:19:14 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 5060.\n",
      "23/06/24 15:19:15 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/309 using temp file gs://kafka-spark-data/spark-metadata/offsets/.309.93efc77f-71d2-41b9-b87f-de51a7fde1f8.tmp\n",
      "23/06/24 15:19:16 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.309.93efc77f-71d2-41b9-b87f-de51a7fde1f8.tmp to gs://kafka-spark-data/spark-metadata/offsets/309\n",
      "23/06/24 15:19:16 INFO MicroBatchExecution: Committed offsets for batch 309. Metadata OffsetSeqMetadata(0,1687637954929,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:19:16 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:19:16 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:19:16 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:19:16 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:19:16 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:19:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:19:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:19:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:19:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:19:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:19:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:19:16 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:19:16 INFO DAGScheduler: Got job 105 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:19:16 INFO DAGScheduler: Final stage: ResultStage 105 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:19:16 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:19:16 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:19:16 INFO DAGScheduler: Submitting ResultStage 105 (MapPartitionsRDD[741] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:19:16 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:19:16 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:19:16 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:19:16 INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:19:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 105 (MapPartitionsRDD[741] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:19:16 INFO TaskSchedulerImpl: Adding task set 105.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:19:16 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 105) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:19:16 INFO Executor: Running task 0.0 in stage 105.0 (TID 105)\n",
      "23/06/24 15:19:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:19:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:19:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:19:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:19:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:19:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:19:16 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:19:16 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:19:16 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:19:16 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:19:16 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:19:16 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:19:16 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:19:17 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5058 for partition ticketmaster-0\n",
      "23/06/24 15:19:17 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 105:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:19:17 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:19:17 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:19:17 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5060.\n",
      "23/06/24 15:19:18 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-2d2eeeee-55c5-4145-b0ab-307795491938/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:19:18 INFO FileOutputCommitter: Saved output of task 'attempt_202306241519161727501575189630195_0105_m_000000_105' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-2d2eeeee-55c5-4145-b0ab-307795491938/_temporary/0/task_202306241519161727501575189630195_0105_m_000000\n",
      "23/06/24 15:19:18 INFO SparkHadoopMapRedUtil: attempt_202306241519161727501575189630195_0105_m_000000_105: Committed. Elapsed time: 991 ms.\n",
      "23/06/24 15:19:18 INFO Executor: Finished task 0.0 in stage 105.0 (TID 105). 2536 bytes result sent to driver\n",
      "23/06/24 15:19:18 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 105) in 1914 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:19:18 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:19:18 INFO DAGScheduler: ResultStage 105 (start at NativeMethodAccessorImpl.java:0) finished in 1.933 s\n",
      "23/06/24 15:19:18 INFO DAGScheduler: Job 105 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:19:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 105: Stage finished\n",
      "23/06/24 15:19:18 INFO DAGScheduler: Job 105 finished: start at NativeMethodAccessorImpl.java:0, took 1.934221 s\n",
      "23/06/24 15:19:18 INFO FileFormatWriter: Start to commit write Job f4312eeb-72bb-4900-930e-480b60a9df25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:19:19 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-2d2eeeee-55c5-4145-b0ab-307795491938/_temporary/0/task_202306241519161727501575189630195_0105_m_000000/' directory.\n",
      "23/06/24 15:19:20 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-2d2eeeee-55c5-4145-b0ab-307795491938/' directory.\n",
      "23/06/24 15:19:20 INFO FileFormatWriter: Write Job f4312eeb-72bb-4900-930e-480b60a9df25 committed. Elapsed time: 1820 ms.\n",
      "23/06/24 15:19:20 INFO FileFormatWriter: Finished processing stats for write job f4312eeb-72bb-4900-930e-480b60a9df25.\n",
      "23/06/24 15:19:21 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-2d2eeeee-55c5-4145-b0ab-307795491938/part-00000-9f7941aa-a2e4-4f02-9d11-4020c7f55a56-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=8d7eb91d-fbfc-455f-a07c-50c2adb41cc2, location=US}\n",
      "23/06/24 15:19:23 INFO BlockManagerInfo: Removed broadcast_105_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 95.0 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:19:24 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=8d7eb91d-fbfc-455f-a07c-50c2adb41cc2, location=US}\n",
      "23/06/24 15:19:24 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/309 using temp file gs://kafka-spark-data/spark-metadata/commits/.309.b064e42a-5a9d-4a14-a871-60f41ef422b2.tmp\n",
      "23/06/24 15:19:25 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.309.b064e42a-5a9d-4a14-a871-60f41ef422b2.tmp to gs://kafka-spark-data/spark-metadata/commits/309\n",
      "23/06/24 15:19:25 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:19:14.918Z\",\n",
      "  \"batchId\" : 309,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.18955549237039143,\n",
      "  \"processedRowsPerSecond\" : 0.18426386585590568,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 8237,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 11,\n",
      "    \"queryPlanning\" : 4,\n",
      "    \"triggerExecution\" : 10853,\n",
      "    \"walCommit\" : 1467\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5058\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5060\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.18955549237039143,\n",
      "    \"processedRowsPerSecond\" : 0.18426386585590568\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:19:25 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 10855 milliseconds\n",
      "23/06/24 15:19:25 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:19:25 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 5062.\n",
      "23/06/24 15:19:25 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/310 using temp file gs://kafka-spark-data/spark-metadata/offsets/.310.0bb0d4d0-b12a-4dd9-9ba0-866b08629b45.tmp\n",
      "23/06/24 15:19:26 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.310.0bb0d4d0-b12a-4dd9-9ba0-866b08629b45.tmp to gs://kafka-spark-data/spark-metadata/offsets/310\n",
      "23/06/24 15:19:26 INFO MicroBatchExecution: Committed offsets for batch 310. Metadata OffsetSeqMetadata(0,1687637965783,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:19:27 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:19:27 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:19:27 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:19:27 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:19:27 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:19:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:19:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:19:27 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:19:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:19:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:19:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:19:27 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:19:27 INFO DAGScheduler: Got job 106 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:19:27 INFO DAGScheduler: Final stage: ResultStage 106 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:19:27 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:19:27 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:19:27 INFO DAGScheduler: Submitting ResultStage 106 (MapPartitionsRDD[748] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:19:27 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:19:27 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:19:27 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:19:27 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:19:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 106 (MapPartitionsRDD[748] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:19:27 INFO TaskSchedulerImpl: Adding task set 106.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:19:27 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 106) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:19:27 INFO Executor: Running task 0.0 in stage 106.0 (TID 106)\n",
      "23/06/24 15:19:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:19:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:19:27 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:19:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:19:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:19:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:19:27 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:19:27 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:19:27 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:19:27 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:19:27 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:19:27 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:19:27 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:19:27 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5060 for partition ticketmaster-0\n",
      "23/06/24 15:19:27 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 106:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:19:28 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:19:28 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:19:28 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5063.\n",
      "23/06/24 15:19:29 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c0d52eac-d7cc-438b-9815-099af20e5f4e/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:19:29 INFO FileOutputCommitter: Saved output of task 'attempt_202306241519278446880550907333459_0106_m_000000_106' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c0d52eac-d7cc-438b-9815-099af20e5f4e/_temporary/0/task_202306241519278446880550907333459_0106_m_000000\n",
      "23/06/24 15:19:29 INFO SparkHadoopMapRedUtil: attempt_202306241519278446880550907333459_0106_m_000000_106: Committed. Elapsed time: 961 ms.\n",
      "23/06/24 15:19:29 INFO Executor: Finished task 0.0 in stage 106.0 (TID 106). 2579 bytes result sent to driver\n",
      "23/06/24 15:19:29 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 106) in 1897 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:19:29 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:19:29 INFO DAGScheduler: ResultStage 106 (start at NativeMethodAccessorImpl.java:0) finished in 1.923 s\n",
      "23/06/24 15:19:29 INFO DAGScheduler: Job 106 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:19:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 106: Stage finished\n",
      "23/06/24 15:19:29 INFO DAGScheduler: Job 106 finished: start at NativeMethodAccessorImpl.java:0, took 1.922953 s\n",
      "23/06/24 15:19:29 INFO FileFormatWriter: Start to commit write Job 449ef8ed-0ce2-4a7f-abdd-5856696c6ebf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:19:30 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c0d52eac-d7cc-438b-9815-099af20e5f4e/_temporary/0/task_202306241519278446880550907333459_0106_m_000000/' directory.\n",
      "23/06/24 15:19:30 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c0d52eac-d7cc-438b-9815-099af20e5f4e/' directory.\n",
      "23/06/24 15:19:30 INFO BlockManagerInfo: Removed broadcast_106_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:19:31 INFO FileFormatWriter: Write Job 449ef8ed-0ce2-4a7f-abdd-5856696c6ebf committed. Elapsed time: 1691 ms.\n",
      "23/06/24 15:19:31 INFO FileFormatWriter: Finished processing stats for write job 449ef8ed-0ce2-4a7f-abdd-5856696c6ebf.\n",
      "23/06/24 15:19:31 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c0d52eac-d7cc-438b-9815-099af20e5f4e/part-00000-4dd0b8c7-9285-40ba-b4ee-41b538c43e0e-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=ae684680-08b5-480e-b5cc-1e71b4e8630b, location=US}\n",
      "23/06/24 15:19:33 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=ae684680-08b5-480e-b5cc-1e71b4e8630b, location=US}\n",
      "23/06/24 15:19:33 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/310 using temp file gs://kafka-spark-data/spark-metadata/commits/.310.e24ce51d-89c3-4b16-88c0-3a108237b0eb.tmp\n",
      "23/06/24 15:19:34 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.310.e24ce51d-89c3-4b16-88c0-3a108237b0eb.tmp to gs://kafka-spark-data/spark-metadata/commits/310\n",
      "23/06/24 15:19:34 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:19:25.773Z\",\n",
      "  \"batchId\" : 310,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.18424689083371718,\n",
      "  \"processedRowsPerSecond\" : 0.22259321090706735,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 6641,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 9,\n",
      "    \"queryPlanning\" : 5,\n",
      "    \"triggerExecution\" : 8985,\n",
      "    \"walCommit\" : 1275\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5060\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5062\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.18424689083371718,\n",
      "    \"processedRowsPerSecond\" : 0.22259321090706735\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:19:34 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:19:34 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 5064.\n",
      "23/06/24 15:19:34 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/311 using temp file gs://kafka-spark-data/spark-metadata/offsets/.311.8cc34be0-d6f5-46a2-99ed-93f51f443907.tmp\n",
      "23/06/24 15:19:35 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.311.8cc34be0-d6f5-46a2-99ed-93f51f443907.tmp to gs://kafka-spark-data/spark-metadata/offsets/311\n",
      "23/06/24 15:19:35 INFO MicroBatchExecution: Committed offsets for batch 311. Metadata OffsetSeqMetadata(0,1687637974771,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:19:36 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:19:36 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:19:36 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:19:36 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:19:36 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:19:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:19:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:19:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:19:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:19:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:19:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:19:36 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:19:36 INFO DAGScheduler: Got job 107 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:19:36 INFO DAGScheduler: Final stage: ResultStage 107 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:19:36 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:19:36 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:19:36 INFO DAGScheduler: Submitting ResultStage 107 (MapPartitionsRDD[755] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:19:36 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:19:36 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 434.0 MiB)\n",
      "23/06/24 15:19:36 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:19:36 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:19:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 107 (MapPartitionsRDD[755] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:19:36 INFO TaskSchedulerImpl: Adding task set 107.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:19:36 INFO TaskSetManager: Starting task 0.0 in stage 107.0 (TID 107) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:19:36 INFO Executor: Running task 0.0 in stage 107.0 (TID 107)\n",
      "23/06/24 15:19:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:19:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:19:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:19:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:19:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:19:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:19:36 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:19:36 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:19:36 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:19:36 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:19:36 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:19:36 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:19:36 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:19:36 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5063 for partition ticketmaster-0\n",
      "23/06/24 15:19:36 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 107:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:19:37 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:19:37 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:19:37 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5064.\n",
      "23/06/24 15:19:38 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-a56a9574-5b3d-444b-bca9-e09031242c95/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:19:38 INFO FileOutputCommitter: Saved output of task 'attempt_202306241519364081636404726572394_0107_m_000000_107' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-a56a9574-5b3d-444b-bca9-e09031242c95/_temporary/0/task_202306241519364081636404726572394_0107_m_000000\n",
      "23/06/24 15:19:38 INFO SparkHadoopMapRedUtil: attempt_202306241519364081636404726572394_0107_m_000000_107: Committed. Elapsed time: 948 ms.\n",
      "23/06/24 15:19:38 INFO Executor: Finished task 0.0 in stage 107.0 (TID 107). 2579 bytes result sent to driver\n",
      "23/06/24 15:19:38 INFO TaskSetManager: Finished task 0.0 in stage 107.0 (TID 107) in 1859 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:19:38 INFO TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:19:38 INFO DAGScheduler: ResultStage 107 (start at NativeMethodAccessorImpl.java:0) finished in 1.880 s\n",
      "23/06/24 15:19:38 INFO DAGScheduler: Job 107 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:19:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 107: Stage finished\n",
      "23/06/24 15:19:38 INFO DAGScheduler: Job 107 finished: start at NativeMethodAccessorImpl.java:0, took 1.880706 s\n",
      "23/06/24 15:19:38 INFO FileFormatWriter: Start to commit write Job 38873928-196a-423e-90fb-8e2498e046bd.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:19:39 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-a56a9574-5b3d-444b-bca9-e09031242c95/_temporary/0/task_202306241519364081636404726572394_0107_m_000000/' directory.\n",
      "23/06/24 15:19:39 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-a56a9574-5b3d-444b-bca9-e09031242c95/' directory.\n",
      "23/06/24 15:19:40 INFO FileFormatWriter: Write Job 38873928-196a-423e-90fb-8e2498e046bd committed. Elapsed time: 2008 ms.\n",
      "23/06/24 15:19:40 INFO FileFormatWriter: Finished processing stats for write job 38873928-196a-423e-90fb-8e2498e046bd.\n",
      "23/06/24 15:19:40 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-a56a9574-5b3d-444b-bca9-e09031242c95/part-00000-9ea6a1d1-f544-4d2e-806a-2d6ddf9673fa-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=639f946b-2d9a-4604-a43f-2f79f5d9ecf0, location=US}\n",
      "23/06/24 15:19:43 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=639f946b-2d9a-4604-a43f-2f79f5d9ecf0, location=US}\n",
      "23/06/24 15:19:44 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/311 using temp file gs://kafka-spark-data/spark-metadata/commits/.311.3df172ad-d87a-4237-ac33-06f48695e76e.tmp\n",
      "23/06/24 15:19:45 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.311.3df172ad-d87a-4237-ac33-06f48695e76e.tmp to gs://kafka-spark-data/spark-metadata/commits/311\n",
      "23/06/24 15:19:45 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:19:34.761Z\",\n",
      "  \"batchId\" : 311,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.22251891410769917,\n",
      "  \"processedRowsPerSecond\" : 0.19295706705258078,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7748,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 9,\n",
      "    \"queryPlanning\" : 4,\n",
      "    \"triggerExecution\" : 10364,\n",
      "    \"walCommit\" : 1498\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5062\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5064\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.22251891410769917,\n",
      "    \"processedRowsPerSecond\" : 0.19295706705258078\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:19:45 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 10367 milliseconds\n",
      "23/06/24 15:19:45 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:19:45 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 5066.\n",
      "23/06/24 15:19:45 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/312 using temp file gs://kafka-spark-data/spark-metadata/offsets/.312.dfcd382e-0b8b-4222-a90e-92b30a4a0034.tmp\n",
      "23/06/24 15:19:46 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.312.dfcd382e-0b8b-4222-a90e-92b30a4a0034.tmp to gs://kafka-spark-data/spark-metadata/offsets/312\n",
      "23/06/24 15:19:46 INFO MicroBatchExecution: Committed offsets for batch 312. Metadata OffsetSeqMetadata(0,1687637985144,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:19:46 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:19:46 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:19:46 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:19:46 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:19:46 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:19:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:19:46 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:19:46 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:19:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:19:46 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:19:46 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:19:46 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:19:46 INFO DAGScheduler: Got job 108 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:19:46 INFO DAGScheduler: Final stage: ResultStage 108 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:19:46 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:19:46 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:19:46 INFO DAGScheduler: Submitting ResultStage 108 (MapPartitionsRDD[762] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:19:46 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 295.4 KiB, free 433.7 MiB)\n",
      "23/06/24 15:19:46 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 94.9 KiB, free 433.6 MiB)\n",
      "23/06/24 15:19:46 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 94.9 KiB, free: 434.2 MiB)\n",
      "23/06/24 15:19:46 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:19:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 108 (MapPartitionsRDD[762] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:19:46 INFO TaskSchedulerImpl: Adding task set 108.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:19:46 INFO TaskSetManager: Starting task 0.0 in stage 108.0 (TID 108) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:19:46 INFO Executor: Running task 0.0 in stage 108.0 (TID 108)\n",
      "23/06/24 15:19:47 INFO BlockManagerInfo: Removed broadcast_107_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:19:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:19:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:19:47 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:19:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:19:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:19:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:19:47 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:19:47 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:19:47 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:19:47 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:19:47 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:19:47 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:19:47 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:19:47 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5064 for partition ticketmaster-0\n",
      "23/06/24 15:19:47 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:19:47 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:19:47 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:19:47 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5066.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 108:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:19:48 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c52b8e18-7ad3-411e-8a21-370717bb009b/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:19:48 INFO FileOutputCommitter: Saved output of task 'attempt_202306241519467824561801329708286_0108_m_000000_108' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c52b8e18-7ad3-411e-8a21-370717bb009b/_temporary/0/task_202306241519467824561801329708286_0108_m_000000\n",
      "23/06/24 15:19:48 INFO SparkHadoopMapRedUtil: attempt_202306241519467824561801329708286_0108_m_000000_108: Committed. Elapsed time: 861 ms.\n",
      "23/06/24 15:19:48 INFO Executor: Finished task 0.0 in stage 108.0 (TID 108). 2579 bytes result sent to driver\n",
      "23/06/24 15:19:48 INFO TaskSetManager: Finished task 0.0 in stage 108.0 (TID 108) in 1778 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:19:48 INFO TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:19:48 INFO DAGScheduler: ResultStage 108 (start at NativeMethodAccessorImpl.java:0) finished in 1.808 s\n",
      "23/06/24 15:19:48 INFO DAGScheduler: Job 108 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:19:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 108: Stage finished\n",
      "23/06/24 15:19:48 INFO DAGScheduler: Job 108 finished: start at NativeMethodAccessorImpl.java:0, took 1.809006 s\n",
      "23/06/24 15:19:48 INFO FileFormatWriter: Start to commit write Job c0859031-079f-46f1-8a87-fccc164bcf41.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:19:49 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c52b8e18-7ad3-411e-8a21-370717bb009b/_temporary/0/task_202306241519467824561801329708286_0108_m_000000/' directory.\n",
      "23/06/24 15:19:50 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c52b8e18-7ad3-411e-8a21-370717bb009b/' directory.\n",
      "23/06/24 15:19:50 INFO BlockManagerInfo: Removed broadcast_108_piece0 on nics-mbp.attlocal.net:52028 in memory (size: 94.9 KiB, free: 434.4 MiB)\n",
      "23/06/24 15:19:50 INFO FileFormatWriter: Write Job c0859031-079f-46f1-8a87-fccc164bcf41 committed. Elapsed time: 2200 ms.\n",
      "23/06/24 15:19:50 INFO FileFormatWriter: Finished processing stats for write job c0859031-079f-46f1-8a87-fccc164bcf41.\n",
      "23/06/24 15:19:51 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=twitter_kafka_pyspark_test, projectId=global-maxim-338114, tableId=kafka_pyspark}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_APPEND, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=Schema{fields=[Field{name=event_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_zipcode, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venues_timezone, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_city, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_full, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_state_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_country_short, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_address, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_longitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=venue_latitude, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_type, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_url, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_segment_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_genre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_id, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=attraction_subgenre_name, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_date, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=ticket_status, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=event_start_time, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=currency, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=min_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}, Field{name=max_price, type=STRING, mode=NULLABLE, description=null, policyTags=null, maxLength=null, scale=null, precision=null, defaultValueExpression=null, collation=null}]}, ignoreUnknownValue=null, sourceUris=[gs://kafka-spark-data/.spark-bigquery-local-1687636163344-c52b8e18-7ad3-411e-8a21-370717bb009b/part-00000-8432d59f-894c-4a15-a01c-d0f4429110fa-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=null, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null, referenceFileSchemaUri=null}. jobId: JobId{project=global-maxim-338114, job=c84293e2-446d-4f4a-80e1-389fbdfda61b, location=US}\n",
      "23/06/24 15:19:53 INFO BigQueryClient: Done loading to global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark. jobId: JobId{project=global-maxim-338114, job=c84293e2-446d-4f4a-80e1-389fbdfda61b, location=US}\n",
      "23/06/24 15:19:53 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/commits/312 using temp file gs://kafka-spark-data/spark-metadata/commits/.312.b5c659ce-a30a-4416-b504-ce25c9f70614.tmp\n",
      "23/06/24 15:19:54 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/commits/.312.b5c659ce-a30a-4416-b504-ce25c9f70614.tmp to gs://kafka-spark-data/spark-metadata/commits/312\n",
      "23/06/24 15:19:54 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"f2bc1daa-c744-4e59-9ab7-7162c43fc781\",\n",
      "  \"runId\" : \"ee32ed25-701b-49a6-888b-d137ee1cde4f\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-24T20:19:45.129Z\",\n",
      "  \"batchId\" : 312,\n",
      "  \"numInputRows\" : 2,\n",
      "  \"inputRowsPerSecond\" : 0.19290123456790123,\n",
      "  \"processedRowsPerSecond\" : 0.20787859889824342,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 7139,\n",
      "    \"getBatch\" : 0,\n",
      "    \"latestOffset\" : 15,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 9621,\n",
      "    \"walCommit\" : 1396\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5064\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 5066\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 2,\n",
      "    \"inputRowsPerSecond\" : 0.19290123456790123,\n",
      "    \"processedRowsPerSecond\" : 0.20787859889824342\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"BigQueryStreamingSink(org.apache.spark.sql.SQLContext@6be89169,Map(checkpointlocation -> gs://kafka-spark-data/spark-metadata, temporarygcsbucket -> kafka-spark-data, table -> global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark, mode -> FAILFAST),List(),Append,com.google.cloud.spark.bigquery.SparkBigQueryConfig@46bb3146,com.google.cloud.bigquery.connector.common.BigQueryClient@2110dce2)\",\n",
      "    \"numOutputRows\" : -1\n",
      "  }\n",
      "}\n",
      "23/06/24 15:19:54 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:19:54 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0-4, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-driver-0] Resetting offset for partition ticketmaster-0 to offset 5068.\n",
      "23/06/24 15:19:54 INFO CheckpointFileManager: Writing atomically to gs://kafka-spark-data/spark-metadata/offsets/313 using temp file gs://kafka-spark-data/spark-metadata/offsets/.313.789db753-b786-4cbc-9b1d-e7b58350e9dd.tmp\n",
      "23/06/24 15:19:55 INFO CheckpointFileManager: Renamed temp file gs://kafka-spark-data/spark-metadata/offsets/.313.789db753-b786-4cbc-9b1d-e7b58350e9dd.tmp to gs://kafka-spark-data/spark-metadata/offsets/313\n",
      "23/06/24 15:19:55 INFO MicroBatchExecution: Committed offsets for batch 313. Metadata OffsetSeqMetadata(0,1687637994761,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/24 15:19:56 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:19:56 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:19:56 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:19:56 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/24 15:19:56 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:19:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:19:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:19:56 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:19:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:19:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:19:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:19:56 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/24 15:19:56 INFO DAGScheduler: Got job 109 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/24 15:19:56 INFO DAGScheduler: Final stage: ResultStage 109 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/24 15:19:56 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/24 15:19:56 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/24 15:19:56 INFO DAGScheduler: Submitting ResultStage 109 (MapPartitionsRDD[769] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/24 15:19:56 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 295.4 KiB, free 434.1 MiB)\n",
      "23/06/24 15:19:56 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 95.0 KiB, free 434.0 MiB)\n",
      "23/06/24 15:19:56 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on nics-mbp.attlocal.net:52028 (size: 95.0 KiB, free: 434.3 MiB)\n",
      "23/06/24 15:19:56 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/24 15:19:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 109 (MapPartitionsRDD[769] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/24 15:19:56 INFO TaskSchedulerImpl: Adding task set 109.0 with 1 tasks resource profile 0\n",
      "23/06/24 15:19:56 INFO TaskSetManager: Starting task 0.0 in stage 109.0 (TID 109) (nics-mbp.attlocal.net, executor driver, partition 0, PROCESS_LOCAL, 5398 bytes) taskResourceAssignments Map()\n",
      "23/06/24 15:19:56 INFO Executor: Running task 0.0 in stage 109.0 (TID 109)\n",
      "23/06/24 15:19:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:19:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:19:56 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:19:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "23/06/24 15:19:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "23/06/24 15:19:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter\n",
      "23/06/24 15:19:56 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:19:56 INFO CodecConfig: Compression: SNAPPY\n",
      "23/06/24 15:19:56 INFO ParquetOutputFormat: Parquet block size to 134217728\n",
      "23/06/24 15:19:56 INFO ParquetOutputFormat: Validation is off\n",
      "23/06/24 15:19:56 INFO ParquetOutputFormat: Maximum row group padding size is 8388608 bytes\n",
      "23/06/24 15:19:56 INFO ParquetOutputFormat: Parquet properties are:\n",
      "Parquet page size to 1048576\n",
      "Parquet dictionary page size to 1048576\n",
      "Dictionary is true\n",
      "Writer version is: PARQUET_1_0\n",
      "Page size checking is: estimated\n",
      "Min row count for page size check is: 100\n",
      "Max row count for page size check is: 10000\n",
      "Truncate length for column indexes is: 64\n",
      "Truncate length for statistics min/max  is: 2147483647\n",
      "Bloom filter enabled: false\n",
      "Max Bloom filter size for a column is 1048576\n",
      "Bloom filter expected number of distinct values are: null\n",
      "Page row count limit to 20000\n",
      "Writing page checksums is: on\n",
      "23/06/24 15:19:56 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:\n",
      "{\n",
      "  \"type\" : \"struct\",\n",
      "  \"fields\" : [ {\n",
      "    \"name\" : \"event_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_zipcode\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venues_timezone\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_city\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_full\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_state_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_country_short\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_address\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_longitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"venue_latitude\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_type\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_url\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_segment_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_genre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_id\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"attraction_subgenre_name\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_date\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"ticket_status\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"event_start_time\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"currency\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"min_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  }, {\n",
      "    \"name\" : \"max_price\",\n",
      "    \"type\" : \"string\",\n",
      "    \"nullable\" : true,\n",
      "    \"metadata\" : { }\n",
      "  } ]\n",
      "}\n",
      "and corresponding Parquet message type:\n",
      "message spark_schema {\n",
      "  optional binary event_name (STRING);\n",
      "  optional binary event_type (STRING);\n",
      "  optional binary event_id (STRING);\n",
      "  optional binary event_url (STRING);\n",
      "  optional binary venue_name (STRING);\n",
      "  optional binary venue_id (STRING);\n",
      "  optional binary venue_zipcode (STRING);\n",
      "  optional binary venues_timezone (STRING);\n",
      "  optional binary venue_city (STRING);\n",
      "  optional binary venue_state_full (STRING);\n",
      "  optional binary venue_state_short (STRING);\n",
      "  optional binary venue_country_name (STRING);\n",
      "  optional binary venue_country_short (STRING);\n",
      "  optional binary venue_address (STRING);\n",
      "  optional binary venue_longitude (STRING);\n",
      "  optional binary venue_latitude (STRING);\n",
      "  optional binary attraction_name (STRING);\n",
      "  optional binary attraction_type (STRING);\n",
      "  optional binary attraction_id (STRING);\n",
      "  optional binary attraction_url (STRING);\n",
      "  optional binary attraction_segment_id (STRING);\n",
      "  optional binary attraction_segment_name (STRING);\n",
      "  optional binary attraction_genre_id (STRING);\n",
      "  optional binary attraction_genre_name (STRING);\n",
      "  optional binary attraction_subgenre_id (STRING);\n",
      "  optional binary attraction_subgenre_name (STRING);\n",
      "  optional binary event_start_date (STRING);\n",
      "  optional binary ticket_status (STRING);\n",
      "  optional binary event_start_time (STRING);\n",
      "  optional binary currency (STRING);\n",
      "  optional binary min_price (STRING);\n",
      "  optional binary max_price (STRING);\n",
      "}\n",
      "\n",
      "       \n",
      "23/06/24 15:19:56 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to offset 5066 for partition ticketmaster-0\n",
      "23/06/24 15:19:56 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/24 15:19:57 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/24 15:19:57 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/24 15:19:57 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor-3, groupId=spark-kafka-source-ee43931e-34d0-4e37-a19e-8105f3f9ff7b--2001384727-executor] Resetting offset for partition ticketmaster-0 to offset 5068.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 109:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/24 15:19:58 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://kafka-spark-data/.spark-bigquery-local-1687636163344-2feeea02-d93b-44b6-bb32-a0abd9b5baea/_temporary/0/_temporary/' directory.\n",
      "23/06/24 15:19:58 INFO FileOutputCommitter: Saved output of task 'attempt_202306241519568872264779257972892_0109_m_000000_109' to gs://kafka-spark-data/.spark-bigquery-local-1687636163344-2feeea02-d93b-44b6-bb32-a0abd9b5baea/_temporary/0/task_202306241519568872264779257972892_0109_m_000000\n",
      "23/06/24 15:19:58 INFO SparkHadoopMapRedUtil: attempt_202306241519568872264779257972892_0109_m_000000_109: Committed. Elapsed time: 948 ms.\n",
      "23/06/24 15:19:58 INFO Executor: Finished task 0.0 in stage 109.0 (TID 109). 2579 bytes result sent to driver\n",
      "23/06/24 15:19:58 INFO TaskSetManager: Finished task 0.0 in stage 109.0 (TID 109) in 1857 ms on nics-mbp.attlocal.net (executor driver) (1/1)\n",
      "23/06/24 15:19:58 INFO TaskSchedulerImpl: Removed TaskSet 109.0, whose tasks have all completed, from pool \n",
      "23/06/24 15:19:58 INFO DAGScheduler: ResultStage 109 (start at NativeMethodAccessorImpl.java:0) finished in 1.878 s\n",
      "23/06/24 15:19:58 INFO DAGScheduler: Job 109 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/24 15:19:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 109: Stage finished\n",
      "23/06/24 15:19:58 INFO DAGScheduler: Job 109 finished: start at NativeMethodAccessorImpl.java:0, took 1.878725 s\n",
      "23/06/24 15:19:58 INFO FileFormatWriter: Start to commit write Job 2b715363-5d6d-42d7-bafe-f1665591461b.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "##### STREAMING DATA PROCESSING #####\n",
    "\n",
    "# Read the data from kafka\n",
    "df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "    .option(\"subscribe\", topic_name) \\\n",
    "    .option(\"startingOffsets\", \"latest\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .load() \\\n",
    "    .selectExpr(\"CAST(value AS STRING)\")\n",
    "    \n",
    "# Apply deserialization or further processing if needed\n",
    "df1 = df.withColumn(\"parsed_data\", from_json(\"value\", schema))\n",
    "\n",
    "### DATA TYPE CONVERSIONS ####\n",
    "# Extract and convert the \"venue_zipcode\" as Integer\n",
    "# df1 = df1.withColumn(\"venue_zipcode\", col(\"parsed_data.venue_zipcode\").cast(IntegerType()))\n",
    "# # Extract and convert the coordinates as Double\n",
    "# df1 = df1.withColumn(\"venue_longitude\", col(\"parsed_data.venue_longitude\").cast(DoubleType()))\n",
    "# df1 = df1.withColumn(\"venue_latitude\", col(\"parsed_data.venue_latitude\").cast(DoubleType()))\n",
    "# # Extract and Convert the event_start_date as Date \n",
    "# df1 = df1.withColumn(\"event_start_date\", col(\"parsed_data.event_start_date\").cast(DateType()))\n",
    "\n",
    "df2 = df1.select(\"parsed_data.*\")\n",
    "\n",
    "\n",
    "df2.printSchema()\n",
    "\n",
    "path = '/Users/nicburkett/Desktop/spark_output'\n",
    "\n",
    "\n",
    "# # # Write to a local file\n",
    "# # file_query = df2.writeStream \\\n",
    "# #     .format(\"csv\") \\\n",
    "# #     .outputMode(\"append\") \\\n",
    "# #     .option(\"header\", \"true\") \\\n",
    "# #     .option(\"checkpointLocation\", path) \\\n",
    "# #     .trigger(processingTime=\"10 seconds\") \\\n",
    "# #     .start(path)\n",
    "\n",
    "# # # WRITE TO GCS BUCKET \n",
    "# gcs_write = df2.writeStream \\\n",
    "#     .format(\"csv\") \\\n",
    "#     .outputMode(\"append\") \\\n",
    "#     .option(\"path\",\"gs://kafka-spark-data/raw-spark-data\") \\\n",
    "#     .option(\"checkpointLocation\", \"gs://kafka-spark-data/spark-metadata\") \\\n",
    "#     .trigger(processingTime=\"10 seconds\") \\\n",
    "#     .start() \n",
    "\n",
    "# gcs_write.awaitTermination()\n",
    "\n",
    "# WRITE TO CONSOLE TO LOG \n",
    "# console_query = df2.writeStream \\\n",
    "#     .format(\"console\") \\\n",
    "#     .outputMode(\"append\") \\\n",
    "#     .trigger(processingTime=\"10 seconds\") \\\n",
    "#     .start() \\\n",
    "#     .awaitTermination()\n",
    "\n",
    "    # .foreachBatch(write_batch) \\\n",
    "\n",
    "gcs_bigquery_stream = df2.writeStream \\\n",
    "    .format(\"bigquery\") \\\n",
    "    .trigger(processingTime=\"10 seconds\") \\\n",
    "    .option(\"checkpointLocation\", gcs_metadata_folder) \\\n",
    "    .option(\"temporaryGcsBucket\", 'kafka-spark-data') \\\n",
    "    .option(\"table\",'global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark') \\\n",
    "    .option(\"mode\", \"FAILFAST\") \\\n",
    "    .start()\n",
    "\n",
    "    # .option(\"failOnDataLoss\",'false') \\\n",
    "\n",
    "gcs_bigquery_stream.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 20:39:55 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "23/06/22 20:39:55 INFO ResolveWriteToStream: Checkpoint root /private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c resolved to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c.\n",
      "23/06/22 20:39:55 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "23/06/22 20:39:55 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/metadata using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/.metadata.db73f13d-0540-4f6f-bd8a-73b3b535ef60.tmp\n",
      "23/06/22 20:39:55 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/.metadata.db73f13d-0540-4f6f-bd8a-73b3b535ef60.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/metadata\n",
      "23/06/22 20:39:55 INFO MicroBatchExecution: Starting [id = 5ff3f0d9-8649-4084-a0de-9c984d47f474, runId = 061d6392-20e9-47dc-a164-da2a57f51557]. Use file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c to store the query checkpoint.\n",
      "23/06/22 20:39:55 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3ffa2c25] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@313dc472]\n",
      "23/06/22 20:39:55 INFO MicroBatchExecution: Starting new streaming query.\n",
      "23/06/22 20:39:55 INFO MicroBatchExecution: Stream started from {}\n",
      "23/06/22 20:39:55 INFO ConsumerConfig: ConsumerConfig values: \n",
      "\tallow.auto.create.topics = true\n",
      "\tauto.commit.interval.ms = 5000\n",
      "\tauto.offset.reset = earliest\n",
      "\tbootstrap.servers = [localhost:9092]\n",
      "\tcheck.crcs = true\n",
      "\tclient.dns.lookup = use_all_dns_ips\n",
      "\tclient.id = consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33\n",
      "\tclient.rack = \n",
      "\tconnections.max.idle.ms = 540000\n",
      "\tdefault.api.timeout.ms = 60000\n",
      "\tenable.auto.commit = false\n",
      "\texclude.internal.topics = true\n",
      "\tfetch.max.bytes = 52428800\n",
      "\tfetch.max.wait.ms = 500\n",
      "\tfetch.min.bytes = 1\n",
      "\tgroup.id = spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0\n",
      "\tgroup.instance.id = null\n",
      "\theartbeat.interval.ms = 3000\n",
      "\tinterceptor.classes = []\n",
      "\tinternal.leave.group.on.close = true\n",
      "\tinternal.throw.on.fetch.stable.offset.unsupported = false\n",
      "\tisolation.level = read_uncommitted\n",
      "\tkey.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer\n",
      "\tmax.partition.fetch.bytes = 1048576\n",
      "\tmax.poll.interval.ms = 300000\n",
      "\tmax.poll.records = 1\n",
      "\tmetadata.max.age.ms = 300000\n",
      "\tmetric.reporters = []\n",
      "\tmetrics.num.samples = 2\n",
      "\tmetrics.recording.level = INFO\n",
      "\tmetrics.sample.window.ms = 30000\n",
      "\tpartition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]\n",
      "\treceive.buffer.bytes = 65536\n",
      "\treconnect.backoff.max.ms = 1000\n",
      "\treconnect.backoff.ms = 50\n",
      "\trequest.timeout.ms = 30000\n",
      "\tretry.backoff.ms = 100\n",
      "\tsasl.client.callback.handler.class = null\n",
      "\tsasl.jaas.config = null\n",
      "\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n",
      "\tsasl.kerberos.min.time.before.relogin = 60000\n",
      "\tsasl.kerberos.service.name = null\n",
      "\tsasl.kerberos.ticket.renew.jitter = 0.05\n",
      "\tsasl.kerberos.ticket.renew.window.factor = 0.8\n",
      "\tsasl.login.callback.handler.class = null\n",
      "\tsasl.login.class = null\n",
      "\tsasl.login.refresh.buffer.seconds = 300\n",
      "\tsasl.login.refresh.min.period.seconds = 60\n",
      "\tsasl.login.refresh.window.factor = 0.8\n",
      "\tsasl.login.refresh.window.jitter = 0.05\n",
      "\tsasl.mechanism = GSSAPI\n",
      "\tsecurity.protocol = PLAINTEXT\n",
      "\tsecurity.providers = null\n",
      "\tsend.buffer.bytes = 131072\n",
      "\tsession.timeout.ms = 10000\n",
      "\tssl.cipher.suites = null\n",
      "\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n",
      "\tssl.endpoint.identification.algorithm = https\n",
      "\tssl.engine.factory.class = null\n",
      "\tssl.key.password = null\n",
      "\tssl.keymanager.algorithm = SunX509\n",
      "\tssl.keystore.location = null\n",
      "\tssl.keystore.password = null\n",
      "\tssl.keystore.type = JKS\n",
      "\tssl.protocol = TLSv1.3\n",
      "\tssl.provider = null\n",
      "\tssl.secure.random.implementation = null\n",
      "\tssl.trustmanager.algorithm = PKIX\n",
      "\tssl.truststore.location = null\n",
      "\tssl.truststore.password = null\n",
      "\tssl.truststore.type = JKS\n",
      "\tvalue.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer\n",
      "\n",
      "23/06/22 20:39:55 INFO AppInfoParser: Kafka version: 2.6.0\n",
      "23/06/22 20:39:55 INFO AppInfoParser: Kafka commitId: 62abe01bee039651\n",
      "23/06/22 20:39:55 INFO AppInfoParser: Kafka startTimeMs: 1687484395268\n",
      "23/06/22 20:39:55 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Subscribed to topic(s): ticketmaster\n",
      "23/06/22 20:39:55 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Cluster ID: kJYfpPSDQYKOEac6knVYNg\n",
      "23/06/22 20:39:55 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Discovered group coordinator 127.0.0.1:9092 (id: 2147483646 rack: null)\n",
      "23/06/22 20:39:55 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] (Re-)joining group\n",
      "23/06/22 20:39:55 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group.\n",
      "23/06/22 20:39:55 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] (Re-)joining group\n",
      "23/06/22 20:39:58 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Finished assignment for group at generation 1: {consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33-d918989d-4970-4a0d-ba8b-2562fc284fa0=Assignment(partitions=[ticketmaster-0])}\n",
      "23/06/22 20:39:58 INFO AbstractCoordinator: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Successfully joined group with generation 1\n",
      "23/06/22 20:39:58 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Notifying assignor about the new Assignment(partitions=[ticketmaster-0])\n",
      "23/06/22 20:39:58 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Adding newly assigned partitions: ticketmaster-0\n",
      "23/06/22 20:39:58 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Found no committed offset for partition ticketmaster-0\n",
      "23/06/22 20:39:58 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 0.\n",
      "23/06/22 20:39:58 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 20:39:58 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 1393.\n",
      "23/06/22 20:39:58 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/sources/0/0 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/sources/0/.0.b96c1db1-6d54-4d9e-97a6-2e84101f2c29.tmp\n",
      "23/06/22 20:39:58 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/sources/0/.0.b96c1db1-6d54-4d9e-97a6-2e84101f2c29.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/sources/0/0\n",
      "23/06/22 20:39:58 INFO KafkaMicroBatchStream: Initial offsets: {\"ticketmaster\":{\"0\":1393}}\n",
      "23/06/22 20:39:58 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 20:39:58 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 1393.\n",
      "23/06/22 20:39:58 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/0 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.0.904f4124-92b7-4b34-8879-a7b63ce929a5.tmp\n",
      "23/06/22 20:39:58 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/.0.904f4124-92b7-4b34-8879-a7b63ce929a5.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/offsets/0\n",
      "23/06/22 20:39:58 INFO MicroBatchExecution: Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1687484398424,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))\n",
      "23/06/22 20:39:58 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 20:39:58 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 20:39:58 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 20:39:58 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 20:39:58 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 20:39:58 INFO KafkaOffsetReaderConsumer: Partitions added: Map()\n",
      "23/06/22 20:39:58 INFO WriteToDataSourceV2Exec: Start processing data source write support: org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@7349b08. The input RDD has 1 partitions.\n",
      "23/06/22 20:39:58 INFO SparkContext: Starting job: start at NativeMethodAccessorImpl.java:0\n",
      "23/06/22 20:39:58 INFO DAGScheduler: Got job 12 (start at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/06/22 20:39:58 INFO DAGScheduler: Final stage: ResultStage 13 (start at NativeMethodAccessorImpl.java:0)\n",
      "23/06/22 20:39:58 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/06/22 20:39:58 INFO DAGScheduler: Missing parents: List()\n",
      "23/06/22 20:39:58 INFO DAGScheduler: Submitting ResultStage 13 (ParallelCollectionRDD[113] at start at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/06/22 20:39:58 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 3.2 KiB, free 434.0 MiB)\n",
      "23/06/22 20:39:58 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 1987.0 B, free 434.0 MiB)\n",
      "23/06/22 20:39:58 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 192.168.4.24:51040 (size: 1987.0 B, free: 434.3 MiB)\n",
      "23/06/22 20:39:58 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1513\n",
      "23/06/22 20:39:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (ParallelCollectionRDD[113] at start at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/06/22 20:39:58 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0\n",
      "23/06/22 20:39:58 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 12) (192.168.4.24, executor driver, partition 0, PROCESS_LOCAL, 4474 bytes) taskResourceAssignments Map()\n",
      "23/06/22 20:39:58 INFO Executor: Running task 0.0 in stage 13.0 (TID 12)\n",
      "23/06/22 20:39:58 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 12, attempt 0, stage 13.0)\n",
      "23/06/22 20:39:58 INFO DataWritingSparkTask: Committed partition 0 (task 12, attempt 0, stage 13.0)\n",
      "23/06/22 20:39:58 INFO Executor: Finished task 0.0 in stage 13.0 (TID 12). 1119 bytes result sent to driver\n",
      "23/06/22 20:39:58 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 12) in 3 ms on 192.168.4.24 (executor driver) (1/1)\n",
      "23/06/22 20:39:58 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool \n",
      "23/06/22 20:39:58 INFO DAGScheduler: ResultStage 13 (start at NativeMethodAccessorImpl.java:0) finished in 0.008 s\n",
      "23/06/22 20:39:58 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/06/22 20:39:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished\n",
      "23/06/22 20:39:58 INFO DAGScheduler: Job 12 finished: start at NativeMethodAccessorImpl.java:0, took 0.008294 s\n",
      "23/06/22 20:39:58 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@7349b08 is committing.\n",
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+----------+----------+--------+---------+----------+--------+-------------+---------------+----------+----------------+-----------------+------------------+-------------------+-------------+---------------+--------------+---------------+---------------+-------------+--------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "|event_name|event_type|event_id|event_url|venue_name|venue_id|venue_zipcode|venues_timezone|venue_city|venue_state_full|venue_state_short|venue_country_name|venue_country_short|venue_address|venue_longitude|venue_latitude|attraction_name|attraction_type|attraction_id|attraction_url|attraction_segment_id|attraction_segment_name|attraction_genre_id|attraction_genre_name|attraction_subgenre_id|attraction_subgenre_name|event_start_date|ticket_status|event_start_time|currency|min_price|max_price|\n",
      "+----------+----------+--------+---------+----------+--------+-------------+---------------+----------+----------------+-----------------+------------------+-------------------+-------------+---------------+--------------+---------------+---------------+-------------+--------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "+----------+----------+--------+---------+----------+--------+-------------+---------------+----------+----------------+-----------------+------------------+-------------------+-------------+---------------+--------------+---------------+---------------+-------------+--------------+---------------------+-----------------------+-------------------+---------------------+----------------------+------------------------+----------------+-------------+----------------+--------+---------+---------+\n",
      "\n",
      "23/06/22 20:39:58 INFO WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@7349b08 committed.\n",
      "23/06/22 20:39:58 INFO CheckpointFileManager: Writing atomically to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/0 using temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.0.22f41be0-96af-4b58-8140-35d6003cf105.tmp\n",
      "23/06/22 20:39:58 INFO CheckpointFileManager: Renamed temp file file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/.0.22f41be0-96af-4b58-8140-35d6003cf105.tmp to file:/private/var/folders/gr/l9vf1gtd2_s_3tz5n15mgkn80000gn/T/temporary-7718572b-fe8e-461e-9e94-f12a490f995c/commits/0\n",
      "23/06/22 20:39:58 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T01:39:55.254Z\",\n",
      "  \"batchId\" : 0,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 27,\n",
      "    \"getBatch\" : 1,\n",
      "    \"latestOffset\" : 3170,\n",
      "    \"queryPlanning\" : 5,\n",
      "    \"triggerExecution\" : 3318,\n",
      "    \"walCommit\" : 57\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : null,\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1393\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 0\n",
      "  }\n",
      "}\n",
      "23/06/22 20:40:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 20:40:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 1393.\n",
      "23/06/22 20:40:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 20:40:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 1393.\n",
      "23/06/22 20:40:10 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T01:40:10.005Z\",\n",
      "  \"batchId\" : 1,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 3,\n",
      "    \"triggerExecution\" : 3\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1393\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1393\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 0\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicburkett/opt/anaconda3/envs/spark/lib/python3.11/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nicburkett/opt/anaconda3/envs/spark/lib/python3.11/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nicburkett/opt/anaconda3/envs/spark/lib/python3.11/socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# WRITE TO CONSOLE TO LOG \u001b[39;00m\n\u001b[1;32m      2\u001b[0m console_query \u001b[39m=\u001b[39m df2\u001b[39m.\u001b[39;49mwriteStream \\\n\u001b[1;32m      3\u001b[0m     \u001b[39m.\u001b[39;49mformat(\u001b[39m\"\u001b[39;49m\u001b[39mconsole\u001b[39;49m\u001b[39m\"\u001b[39;49m) \\\n\u001b[1;32m      4\u001b[0m     \u001b[39m.\u001b[39;49moutputMode(\u001b[39m\"\u001b[39;49m\u001b[39mappend\u001b[39;49m\u001b[39m\"\u001b[39;49m) \\\n\u001b[1;32m      5\u001b[0m     \u001b[39m.\u001b[39;49mtrigger(processingTime\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m10 seconds\u001b[39;49m\u001b[39m\"\u001b[39;49m) \\\n\u001b[1;32m      6\u001b[0m     \u001b[39m.\u001b[39;49mstart() \\\n\u001b[0;32m----> 7\u001b[0m     \u001b[39m.\u001b[39;49mawaitTermination()\n\u001b[1;32m      9\u001b[0m     \u001b[39m# .foreachBatch(write_batch) \\\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/spark/lib/python3.11/site-packages/pyspark/sql/streaming/query.py:201\u001b[0m, in \u001b[0;36mStreamingQuery.awaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jsq\u001b[39m.\u001b[39mawaitTermination(\u001b[39mint\u001b[39m(timeout \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m))\n\u001b[1;32m    200\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jsq\u001b[39m.\u001b[39;49mawaitTermination()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/spark/lib/python3.11/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_args(\u001b[39m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/spark/lib/python3.11/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1039\u001b[0m     \u001b[39mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[39mreturn\u001b[39;00m response, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/spark/lib/python3.11/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[39m=\u001b[39m smart_decode(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream\u001b[39m.\u001b[39mreadline()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mAnswer received: \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[39m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[39m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/spark/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/22 20:40:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 20:40:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 1393.\n",
      "23/06/22 20:40:20 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T01:40:20.005Z\",\n",
      "  \"batchId\" : 1,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 10,\n",
      "    \"triggerExecution\" : 12\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1393\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1393\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 0\n",
      "  }\n",
      "}\n",
      "23/06/22 20:40:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 20:40:30 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 1393.\n",
      "23/06/22 20:40:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 20:40:40 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 1393.\n",
      "23/06/22 20:40:40 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T01:40:40.003Z\",\n",
      "  \"batchId\" : 1,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 4,\n",
      "    \"triggerExecution\" : 4\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1393\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1393\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 0\n",
      "  }\n",
      "}\n",
      "23/06/22 20:40:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 20:40:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 1393.\n",
      "23/06/22 20:41:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 20:41:00 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 1393.\n",
      "23/06/22 20:41:00 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T01:41:00.004Z\",\n",
      "  \"batchId\" : 1,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 11,\n",
      "    \"triggerExecution\" : 11\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1393\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1393\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 0\n",
      "  }\n",
      "}\n",
      "23/06/22 20:41:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 20:41:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 1393.\n",
      "23/06/22 20:41:10 INFO MicroBatchExecution: Streaming query made progress: {\n",
      "  \"id\" : \"5ff3f0d9-8649-4084-a0de-9c984d47f474\",\n",
      "  \"runId\" : \"061d6392-20e9-47dc-a164-da2a57f51557\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2023-06-23T01:41:10.006Z\",\n",
      "  \"batchId\" : 1,\n",
      "  \"numInputRows\" : 0,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 0.0,\n",
      "  \"durationMs\" : {\n",
      "    \"latestOffset\" : 13,\n",
      "    \"triggerExecution\" : 13\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"KafkaV2[Subscribe[ticketmaster]]\",\n",
      "    \"startOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1393\n",
      "      }\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"ticketmaster\" : {\n",
      "        \"0\" : 1393\n",
      "      }\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 0,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 0.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@1ecfbdf1\",\n",
      "    \"numOutputRows\" : 0\n",
      "  }\n",
      "}\n",
      "23/06/22 20:41:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Seeking to LATEST offset of partition ticketmaster-0\n",
      "23/06/22 20:41:20 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0-33, groupId=spark-kafka-source-2b8cbc25-4bf7-465c-b61f-6e26ba34a2b9--2109907342-driver-0] Resetting offset for partition ticketmaster-0 to offset 1393.\n"
     ]
    }
   ],
   "source": [
    "# WRITE TO CONSOLE TO LOG \n",
    "console_query = df2.writeStream \\\n",
    "    .format(\"console\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .trigger(processingTime=\"10 seconds\") \\\n",
    "    .start() \\\n",
    "    .awaitTermination()\n",
    "\n",
    "    # .foreachBatch(write_batch) \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/06/19 19:50:27 INFO FetchSessionHandler: [Consumer clientId=consumer-spark-kafka-source-d2941ca6-4ad1-48ba-bda3-65af4267d63f--2001384727-executor-9, groupId=spark-kafka-source-d2941ca6-4ad1-48ba-bda3-65af4267d63f--2001384727-executor] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1001:\n",
      "org.apache.kafka.common.errors.TimeoutException: Failed to send request after 30000 ms.\n",
      "23/06/19 19:50:42 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-d2941ca6-4ad1-48ba-bda3-65af4267d63f--2001384727-executor-9, groupId=spark-kafka-source-d2941ca6-4ad1-48ba-bda3-65af4267d63f--2001384727-executor] Connection to node 1001 (host.docker.internal/143.244.220.150:9092) could not be established. Broker may not be available.\n",
      "23/06/19 19:50:42 INFO FetchSessionHandler: [Consumer clientId=consumer-spark-kafka-source-d2941ca6-4ad1-48ba-bda3-65af4267d63f--2001384727-executor-9, groupId=spark-kafka-source-d2941ca6-4ad1-48ba-bda3-65af4267d63f--2001384727-executor] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1001:\n",
      "org.apache.kafka.common.errors.DisconnectException\n",
      "23/06/19 19:51:12 INFO FetchSessionHandler: [Consumer clientId=consumer-spark-kafka-source-d2941ca6-4ad1-48ba-bda3-65af4267d63f--2001384727-executor-9, groupId=spark-kafka-source-d2941ca6-4ad1-48ba-bda3-65af4267d63f--2001384727-executor] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1001:\n",
      "org.apache.kafka.common.errors.TimeoutException: Failed to send request after 30000 ms.\n",
      "23/06/19 19:51:27 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-d2941ca6-4ad1-48ba-bda3-65af4267d63f--2001384727-executor-9, groupId=spark-kafka-source-d2941ca6-4ad1-48ba-bda3-65af4267d63f--2001384727-executor] Seeking to EARLIEST offset of partition ticketmaster-0\n",
      "23/06/19 19:51:42 INFO FetchSessionHandler: [Consumer clientId=consumer-spark-kafka-source-d2941ca6-4ad1-48ba-bda3-65af4267d63f--2001384727-executor-9, groupId=spark-kafka-source-d2941ca6-4ad1-48ba-bda3-65af4267d63f--2001384727-executor] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1001:\n",
      "org.apache.kafka.common.errors.TimeoutException: Failed to send request after 30000 ms.\n",
      "23/06/19 19:51:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-d2941ca6-4ad1-48ba-bda3-65af4267d63f--2001384727-executor-9, groupId=spark-kafka-source-d2941ca6-4ad1-48ba-bda3-65af4267d63f--2001384727-executor] Connection to node 1001 (host.docker.internal/143.244.220.150:9092) could not be established. Broker may not be available.\n"
     ]
    }
   ],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## BATCH DATA PROCESSING \n",
    "\n",
    "df = spark \\\n",
    "  .read \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "  .option(\"subscribe\", topic_name) \\\n",
    "  .load()\\\n",
    "  .selectExpr(\"CAST(value AS STRING)\")\n",
    "\n",
    "# Apply deserialization or further processing if needed\n",
    "df1 = df.withColumn(\"parsed_data\", from_json(\"value\", schema))\n",
    "## Select the data from the parsed_data column\n",
    "df2 = df1.select(\"parsed_data.*\")\n",
    "\n",
    "gcs_metadata_folder = \"gs://kafka-spark-data/spark-metadata\"\n",
    "gcs_data_folder = \"gs://kafka-spark-data/raw-spark-data\"\n",
    "\n",
    "print(df2.schema)\n",
    "\n",
    "## WRITE TO LOCAL STORAGE\n",
    "# gcs_write = df2.write \\\n",
    "#   .format(\"csv\") \\\n",
    "#   .option(\"checkpointLocation\", \"/Users/nicburkett/Desktop/spark_output\") \\\n",
    "#   .option(\"path\",\"/Users/nicburkett/Desktop/spark_output\") \\\n",
    "#   .mode(\"overwrite\")\\\n",
    "#   .save()\n",
    "\n",
    "##WRITE TO GCS BUCKET\n",
    "# gcs_write_newfolder = df2.write \\\n",
    "#   .format(\"parquet\") \\\n",
    "#   .option(\"checkpointLocation\", gcs_metadata_folder) \\\n",
    "#   .option(\"path\",gcs_data_folder) \\\n",
    "#   .mode(\"overwrite\")\\\n",
    "#   .save()\n",
    "\n",
    "\n",
    "dataset = 'global-maxim-338114.twitter_kafka_pyspark_test'\n",
    "table = 'twitter_kafka_pyspark_test'\n",
    "\n",
    "# Write the DataFrame to BigQuery\n",
    " ## this is the bucket where the data is stored temporarily\n",
    "df2.write \\\n",
    "    .format(\"bigquery\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"checkpointLocation\", gcs_metadata_folder) \\\n",
    "    .option(\"temporaryGcsBucket\", 'kafka-spark-data') \\\n",
    "    .option(\"table\",'global-maxim-338114.twitter_kafka_pyspark_test.kafka_pyspark') \\\n",
    "    .option(\"mode\", \"FAILFAST\") \\\n",
    "    .save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Function to save the data to GCS with a custom filename\n",
    "def save_to_gcs(batch_df, batch_id):\n",
    "    # Convert the batch dataframe to a pandas dataframe\n",
    "    pandas_df = batch_df.toPandas()\n",
    "\n",
    "    # Get the values of the desired columns from the first row\n",
    "    column1_value = pandas_df.loc[0, \"column1\"]\n",
    "    column2_value = pandas_df.loc[0, \"column2\"]\n",
    "\n",
    "    # Get the current time\n",
    "    current_time = pd.Timestamp.now()\n",
    "\n",
    "    # Generate the custom filename\n",
    "    filename = f\"file_{column1_value}_{column2_value}_{current_time}.parquet\"\n",
    "\n",
    "    # Save the dataframe to GCS with the custom filename\n",
    "    pandas_df.to_parquet(f\"gs://{bucket_name}/{path}/{filename}\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA TYPES THOUGHOUT KAFKA SERVER\n",
    "import json\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, udf\n",
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "topic_name = 'twitter'\n",
    "# Config\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"TwitterSentimentAnalysis\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "prod = {'user_id': 19, 'recipient_id': 57, 'message': 'YbfyRHyWgjuGlzOiudEcVMLJNzqUPDvV'}\n",
    "print(type(prod))\n",
    "##convert dictionary to json string (BYTES)\n",
    "serialized_prod = json.dumps(prod).encode('utf-8')\n",
    "\n",
    "print(f'The producer dtype is {type(serialized_prod)} and output is {(serialized_prod)}')\n",
    "\n",
    "## turn from string/bytes into a dictionary again\n",
    "deserializer_function = lambda x: json.loads(x.decode('utf-8'))\n",
    "deserialized_cons = deserializer_function(serialized_prod)\n",
    "\n",
    "print(f'The producer dtype is {type(deserialized_cons)} and output is {(deserialized_cons)}')\n",
    "\n",
    "### PARSING THE JSON COMING OUT \n",
    "user_id = deserialized_cons.get('user_id')\n",
    "recipient_id = deserialized_cons.get('recipient_id')\n",
    "message = deserialized_cons.get('message')\n",
    "output_parsed = print(f'UserID: {user_id}, RecipientID: {recipient_id}, Message:{message}')\n",
    "\n",
    "\n",
    "df_pandas = pd.DataFrame([deserialized_cons])\n",
    "df_pandas\n",
    "\n",
    "\n",
    "# df_spark = spark.createDataFrame(df_pandas)\n",
    "# df_spark.show()\n",
    "\n",
    "# Create a spark schema/column headers\n",
    "schema = StructType([\n",
    "    StructField(\"user_id\", IntegerType(), True),\n",
    "    StructField(\"recipient_id\", IntegerType(), True),\n",
    "    StructField(\"message\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Create DataFrame from a single row\n",
    "# data = [(user_id, recipient_id, message)]\n",
    "df_spark = spark.createDataFrame(df_pandas,schema)\n",
    "df_spark.show()\n",
    "# df.write.csv('/path/to/output.csv', header=True, mode='overwrite')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
